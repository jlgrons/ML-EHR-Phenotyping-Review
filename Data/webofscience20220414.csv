Publication Type,Authors,Book Authors,Group Authors,Book Group Authors,Researcher Ids,ORCIDs,Book Editors,Author - Arabic,Article Title,Article Title - SciELO,Article Title - SciELO,Article Title - Chinese,Article Title - Russian,Patent Number,Patent Assignee,Source Title - Arabic,Source Title,Source Title - Korean,Book Series Title,Book Series Subtitle,Volume,Issue,Special Issue,Meeting Abstract,Start Page,End Page,Article Number,DOI,Book DOI,Early Access Date,Supplement,Publication Date,Publication Year,Abstract,Abstract - Foreign,Abstract - English Transliteration ,Abstract - Foreign,Abstract - Korean,Conference Title,Conference Date,Conference Sponsor,Conference Location,"Times Cited, WoS Core","Times Cited, CSCD ","Times Cited, RSCI","Times Cited, ARCI","Times Cited, BCI","Times Cited, SCIELO","Times Cited, All Databases",180 Day Usage Count,Since 2013 Usage Count,ISSN,eISSN,ISBN,UT (Unique ID),Pubmed Id,
J,"Henderson, Jette; He, Huan; Malin, Bradley A; Denny, Joshua C; Kho, Abel N; Ghosh, Joydeep; Ho, Joyce C",,,,,,,,Phenotyping through Semi-Supervised Tensor Factorization (PSST).,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,564,573,,,,,,2018,2018,"A computational phenotype is a set of clinically relevant and interesting characteristics that describe patients with a given condition. Various machine learning methods have been proposed to derive phenotypes in an automatic, high-throughput manner. Among these methods, computational phenotyping through tensor factorization has been shown to produce clinically interesting phenotypes. However, few of these methods incorporate auxiliary patient information into the phenotype derivation process. In this work, we introduce Phenotyping through Semi-Supervised Tensor Factorization (PSST), a method that leverages disease status knowledge about subsets of patients to generate computational phenotypes from tensors constructed from the electronic health records of patients. We demonstrate the potential of PSST to uncover predictive and clinically interesting computational phenotypes through case studies focusing on type-2 diabetes and resistant hypertension. PSST yields more discriminative phenotypes compared to the unsupervised methods and more meaningful phenotypes compared to a supervised method.",,,,,,,,,6,0,0,0,4,0,6,,,,1942-597X,,MEDLINE:30815097,30815097,
J,"Tao, Carson; Filannino, Michele; Uzuner, Ozlem",,,,,,,,FABLE: A Semi-Supervised Prescription Information Extraction System.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1534,1543,,,,,,2018,2018,"Prescription information is an important component of electronic health records (EHRs). This information contains detailed medication instructions that are crucial for patients' well-being and is often detailed in the narrative portions of EHRs. As a result, narratives of EHRs need to be processed with natural language processing (NLP) methods that can extract medication and prescription information from free text. However, automatic methods for medication and prescription extraction from narratives face two major challenges: (1) dictionaries can fall short even when identifying well-defined and syntactically consistent categories of medication entities, (2) some categories of medication entities are sparse, and at the same time lexically (and syntactically) diverse. In this paper, we describe FABLE, a system for automatically extracting prescription information from discharge summaries. FABLE utilizes unannotated data to enhance annotated training data: it performs semi-supervised extraction of medication information using pseudo-labels with Conditional Random Fields (CRFs) to improve its understanding of incomplete, sparse, and diverse medication entities. When evaluated against the official benchmark set from the 2009 i2b2 Shared Task and Workshop on Medication Extraction, FABLE achieves a horizontal phrase-level F1-measure of 0.878, giving state-of-the-art performance and significantly improving on nearly all entity categories.",,,,,,,,,3,0,0,0,1,0,3,,,,1942-597X,,MEDLINE:30815199,30815199,
J,"Wang, Yanshan; Zhao, Yiqing; Therneau, Terry M.; Atkinson, Elizabeth J.; Tafti, Ahmad P.; Zhang, Nan; Amin, Shreyasee; Limper, Andrew H.; Khosla, Sundeep; Liu, Hongfang",,,,"P. Tafti, Ahmad/ABC-1866-2021","P. Tafti, Ahmad/0000-0001-9650-2862; Zhao, Yiqing/0000-0003-2874-8136",,,Unsupervised machine learning for the discovery of latent disease clusters and patient subgroups using electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103364,10.1016/j.jbi.2019.103364,,,,FEB 2020,2020,"Machine learning has become ubiquitous and a key technology on mining electronic health records (EHRs) for facilitating clinical research and practice. Unsupervised machine learning, as opposed to supervised learning, has shown promise in identifying novel patterns and relations from EHRs without using human created labels. In this paper, we investigate the application of unsupervised machine learning models in discovering latent disease clusters and patient subgroups based on EHRs. We utilized Latent Dirichlet Allocation (LDA), a generative probabilistic model, and proposed a novel model named Poisson Dirichlet Model (PDM), which extends the LDA approach using a Poisson distribution to model patients' disease diagnoses and to alleviate age and sex factors by considering both observed and expected observations. In the empirical experiments, we evaluated LDA and PDM on three patient cohorts, namely Osteoporosis, Delirium/Dementia, and Chronic Obstructive Pulmonary Disease (COPD)/Bronchiectasis Cohorts, with their EHR data retrieved from the Rochester Epidemiology Project (REP) medical records linkage system, for the discovery of latent disease clusters and patient subgroups. We compared the effectiveness of LDA and PDM in identifying disease clusters through the visualization of disease representations. We tested the performance of LDA and PDM in differentiating patient subgroups through survival analysis, as well as statistical analysis of demographics and Elixhauser Comorbidity Index (ECI) scores in those subgroups. The experimental results show that the proposed PDM could effectively identify distinguished disease clusters based on the latent patterns hidden in the EHR data by alleviating the impact of age and sex, and that LDA could stratify patients into differentiable subgroups with larger p-values than PDM. However, those subgroups identified by LDA are highly associated with patients' age and sex. The subgroups discovered by PDM might imply the underlying patterns of diseases of greater interest in epidemiology research due to the alleviation of age and sex. Both unsupervised machine learning approaches could be leveraged to discover patient subgroups using EHRs but with different foci.",,,,,,,,,18,0,0,0,5,0,18,,,1532-0464,1532-0480,,WOS:000525735200017,31891765,
J,"Feller, Daniel J; Zucker, Jason; Don't Walk, Oliver Bear 4th; Srikishan, Bharat; Martinez, Roxana; Evans, Henry; Yin, Michael T; Gordon, Peter; Elhadad, Noemie",,,,,"Yin, Michael/0000-0002-9346-9056; Feller, Daniel/0000-0002-7924-0562",,,Towards the Inference of Social and Behavioral Determinants of Sexual Health: Development of a Gold-Standard Corpus with Semi-Supervised Learning.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,422,429,,,,,,2018,2018,"Social and behavioral determinants of health (SBDH) are environmental and behavioral factors that are increasingly recognized for their impact on health outcomes. We describe ongoing research to extract SBDH related to sexual health from clinical documentation. Our work addresses several challenges. First, there is no standard set of SBDHs for sexual health; we describe our curation of 38 such SBDHs. Second, it is unknown how SBDH related to sexual health are expressed in clinical notes; we detail the characteristics of an annotated corpus. Third, SBDH documentations are rare; we describe the use of semi-supervised learning to accelerate the annotation process by identifying notes likely to document SBDH. Fourth, we describe preliminary results to infer an array of SBDH from clinical documentation using supervised learning.",,,,,,,,,9,0,0,0,3,0,9,,,,1942-597X,,MEDLINE:30815082,30815082,
J,"Cui, Liwen; Xie, Xiaolei; Shen, Zuojun",,,,,"Shen, Zuo-Jun Max/0000-0003-4538-8312",,,Prediction task guided representation learning of medical codes in EHR,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,84,,,,1,10,,10.1016/j.jbi.2018.06.013,,,,AUG 2018,2018,"There have been rapidly growing applications using machine learning models for predictive analytics in Electronic Health Records (EHR) to improve the quality of hospital services and the efficiency of healthcare resource utilization. A fundamental and crucial step in developing such models is to convert medical codes in EHR to feature vectors. These medical codes are used to represent diagnoses or procedures. Their vector representations have a tremendous impact on the performance of machine learning models. Recently, some researchers have utilized representation learning methods from Natural Language Processing (NLP) to learn vector representations of medical codes. However, most previous approaches are unsupervised, i.e. the generation of medical code vectors is independent from prediction tasks. Thus, the obtained feature vectors may be inappropriate for a specific prediction task. Moreover, unsupervised methods often require a lot of samples to obtain reliable results, but most practical problems have very limited patient samples. In this paper, we develop a new Method called Prediction Task Guided Health Record Aggregation (PTGHRA), which aggregates health records guided by prediction tasks, to construct training corpus for various representation learning models. Compared with unsupervised approaches, representation learning models integrated with PTGHRA yield a significant improvement in predictive capability of generated medical code vectors, especially for limited training samples.",,,,,,,,,7,1,0,0,2,0,8,,,1532-0464,1532-0480,,WOS:000445054800001,29928997,
J,"Ling, Albee Y.; Kurian, Allison W.; Caswell-Jin, Jennifer L.; Sledge, George W., Jr.; Shah, Nigam H.; Tamang, Suzanne R.",,,,"Kurian, Allison/A-4560-2019","Kurian, Allison/0000-0002-6175-9470; Tamang, Suzanne/0000-0003-2077-4620; Caswell-Jin, Jennifer/0000-0002-5711-8355",,,Using natural language processing to construct a metastatic breast cancer cohort from linked cancer registry and electronic medical records data,,,,,,,,JAMIA OPEN,,,,2,4,,,528,537,,10.1093/jamiaopen/ooz040,,,,DEC 2019,2019,"Objectives: Most population-based cancer databases lack information on metastatic recurrence. Electronic medical records (EMR) and cancer registries contain complementary information on cancer diagnosis, treatment and outcome, yet are rarely used synergistically. To construct a cohort of metastatic breast cancer (MBC) patients, we applied natural language processing techniques within a semisupervised machine learning framework to linked EMR-California Cancer Registry (CCR) data.Materials and Methods: We studied all female patients treated at Stanford Health Care with an incident breast cancer diagnosis from 2000 to 2014. Our database consisted of structured fields and unstructured free-text clinical notes from EMR, linked to CCR, a component of the Surveillance, Epidemiology and End Results Program (SEER). We identified de novo MBC patients from CCR and extracted information on distant recurrences from patient notes in EMR. Furthermore, we trained a regularized logistic regression model for recurrent MBC classification and evaluated its performance on a gold standard set of 146 patients.Results: There were 11 459 breast cancer patients in total and the median follow-up time was 96.3 months. We identified 1886 MBC patients, 512 (27.1%) of whom were de novo MBC patients and 1374 (72.9%) were recurrent MBC patients. Our final MBC classifier achieved an area under the receiver operating characteristic curve (AUC) of 0.917, with sensitivity 0.861, specificity 0.878, and accuracy 0.870.Discussion and Conclusion: To enable population-based research on MBC, we developed a framework for retrospective case detection combining EMR and CCR data. Our classifier achieved good AUC, sensitivity, and specificity without expert-labeled examples.",,,,,,,,,9,0,0,0,2,0,9,,,,2574-2531,,WOS:000645419800021,32025650,
J,"Huang, Li; Shea, Andrew L.; Qian, Huining; Masurkar, Aditya; Deng, Hao; Liu, Dianbo",,,,,,,,Patient clustering improves efficiency of federated machine learning to predict mortality and hospital stay time using distributed electronic medical records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103291,10.1016/j.jbi.2019.103291,,,,NOV 2019,2019,"Electronic medical records (EMRs) support the development of machine learning algorithms for predicting disease incidence, patient response to treatment, and other healthcare events. But so far most algorithms have been centralized, taking little account of the decentralized, non-identically independently distributed (non-IID), and privacy-sensitive characteristics of EMRs that can complicate data collection, sharing and learning. To address this challenge, we introduced a community-based federated machine learning (CBFL) algorithm and evaluated it on non-IID ICU EMRs. Our algorithm clustered the distributed data into clinically meaningful communities that captured similar diagnoses and geographical locations, and learnt one model for each community. Throughout the learning process, the data was kept local at hospitals, while locally-computed results were aggregated on a server. Evaluation results show that CBFL outperformed the baseline federated machine learning (FL) algorithm in terms of Area Under the Receiver Operating Characteristic Curve (ROC AUC), Area Under the Precision-Recall Curve (PR AUC), and communication cost between hospitals and the server. Furthermore, communities' performance difference could be explained by how dissimilar one community was to others.",,,,,,,,,46,0,0,0,5,0,46,,,1532-0464,1532-0480,,WOS:000525701400004,31560949,
J,"Steinberg, Ethan; Jung, Ken; Fries, Jason A.; Corbin, Conor K.; Pfohl, Stephen R.; Shah, Nigam H.",,,,,"Fries, Jason/0000-0001-9316-5768; Pfohl, Stephen/0000-0003-0551-9664",,,Language models are an effective representation learning technique for electronic health record data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103637,10.1016/j.jbi.2020.103637,,,,JAN 2021,2021,"Widespread adoption of electronic health records (EHRs) has fueled the development of using machine learning to build prediction models for various clinical outcomes. However, this process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase the accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19% when only a small number of patient records are available for training the clinical prediction model.",,,,,,,,,4,0,0,0,4,0,4,,,1532-0464,1532-0480,,WOS:000615920400006,33290879,
J,"Ferte, Thomas; Cossin, Sebastien; Schaeverbeke, Thierry; Barnetche, Thomas; Jouhet, Vianney; Hejblum, Boris P.",,,,,"jouhet, vianney/0000-0001-5272-2265",,,Automatic phenotyping of electronical health record: PheVis algorithm,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103746,10.1016/j.jbi.2021.103746,,MAR 2021,,MAY 2021,2021,"Electronic Health Records (EHRs) often lack reliable annotation of patient medical conditions. Phenorm, an automated unsupervised algorithm to identify patient medical conditions from EHR data, has been developed. PheVis extends PheNorm at the visit resolution. PheVis combines diagnosis codes together with medical concepts extracted from medical notes, incorporating past history in a machine learning approach to provide an interpretable parametric predictor of the occurrence probability for a given medical condition at each visit. PheVis is applied to two real-world use-cases using the datawarehouse of the University Hospital of Bordeaux: i) rheumatoid arthritis, a chronic condition; ii) tuberculosis, an acute condition. Cross-validated AUROC were respectively 0.943 [0.940; 0.945] and 0.987 [0.983; 0.990]. Cross-validated AUPRC were respectively 0.754 [0.744; 0.763] and 0.299 [0.198; 0.403]. PheVis performs well for chronic conditions, though absence of exclusion of past medical history by natural language processing tools limits its performance in French for acute conditions. It achieves significantly better performance than state-of-the-art unsupervised methods especially for chronic diseases.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663076900016,33746080,
J,"Estiri, Hossein; Vasey, Sebastien; Murphy, Shawn N.",,,,,"Estiri, Hossein/0000-0002-0204-8978",,,Generative transfer learning for measuring plausibility of EHR diagnosis records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,559,568,,10.1093/jamia/ocaa215,,,,MAR 2021,2021,"Objective: Due to a complex set of processes involved with the recording of health information in the Electronic Health Records (EHRs), the truthfulness of EHR diagnosis records is questionable. We present a computational approach to estimate the probability that a single diagnosis record in the EHR reflects the true disease.Materials and Methods: sing EHR data on 18 diseases from the Mass General Brigham (MGB) Biobank, we develop generative classifiers on a small set of disease-agnostic features from EHRs that aim to represent Patients, pRoviders, and their Interactions within the healthcare SysteM (PRISM features).Results: We demonstrate that PRISM features and the generative PRISM classifiers are potent for estimating disease probabilities and exhibit generalizable and transferable distributional characteristics across diseases and patient populations. The joint probabilities we learn about diseases through the PRISM features via PRISM generative models are transferable and generalizable to multiple diseases.Discussion: The Generative Transfer Learning (GTL) approach with PRISM classifiers enables the scalable validation of computable phenotypes in EHRs without the need for domain-specific knowledge about specific disease processes.Conclusion: Probabilities computed from the generative PRISM classifier can enhance and accelerate applied Machine Learning research and discoveries with EHR data.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000637314400015,33043366,
J,"Cui, Jianfei; Zhu, He; Deng, Hao; Chen, Ziwei; Liu, Dianbo",,,,,,,,FeARH: Federated machine learning with anonymous random hybridization on electronic medical records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103735,10.1016/j.jbi.2021.103735,,APR 2021,,MAY 2021,2021,"Electrical medical records are restricted and difficult to centralize for machine learning model training due to privacy and regulatory issues. One solution is to train models in a distributed manner that involves many parties in the process. However, sometimes certain parties are not trustable, and in this project, we aim to propose an alternative method to traditional federated learning with central analyzer in order to conduct training in a situation without a trustable central analyzer. The proposed algorithm is called federated machine learning with anonymous random hybridization (abbreviated as 'FeARH'), using mainly hybridization algorithm to degenerate the integration of connections between medical record data and models' parameters by adding randomization into the parameter sets shared to other parties. Based on our experiment, our new algorithm has similar AUCROC and AUCPR results compared with machine learning in a centralized manner and original federated machine learning.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000663077000011,33711540,
J,"Duy Van Le; Montgomery, James; Kirkby, Kenneth C.; Scanlan, Joel",,,,"Scanlan, Joel/AAB-1140-2022; Montgomery, James/A-1335-2008","Scanlan, Joel/0000-0003-2285-8932; Montgomery, James/0000-0002-5360-7514",,,Risk prediction using natural language processing of electronic mental health records in an inpatient forensic psychiatry setting,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,86,,,,49,58,,10.1016/j.jbi.2018.08.007,,,,OCT 2018,2018,"Objective: Instruments rating risk of harm to self and others are widely used in inpatient forensic psychiatry settings. A potential alternate or supplementary means of risk prediction is from the automated analysis of case notes in Electronic Health Records (EHRs) using Natural Language Processing (NLP). This exploratory study rated presence or absence and frequency of words in a forensic EHR dataset, comparing four reference dictionaries. Seven machine learning algorithms and different time periods of EHR analysis were used to probe. which dictionary and which time period were most predictive of risk assessment scores on validated instruments.Materials and methods: The EHR dataset comprised de-identified forensic inpatient notes from the Wilfred Lopes Centre in Tasmania. The data comprised unstructured free-text case note entries and serial ratings of three risk assessment scales: Historical Clinical Risk Management-20 (HCR-20), Short-Term Assessment of Risk and Treatability (START) and. Dynamic Appraisal of Situational Aggression (DASA). Four NLP dictionary word lists were selected: 6865 mental health symptom words from the Unified Medical Language System (UMLS), 455 DSM-IV diagnoses from UMLS repository, 6790 English positive and negative sentiment words, and 1837 high frequency words from the Corpus of Contemporary American English (COCA). Seven machine learning methods Bagging, J48, Jrip, Logistic Model Trees (LMT), Logistic Regression, Linear Regression and Support Vector Machine (SVM) were used to identify the combination of dictionaries and algorithms that best predicted risk assessment scores.Results: The most accurate prediction was attained on the DASA dataset using the sentiment dictionary and the LMT and SVM algorithms.Conclusions: NLP, used in conjunction with NLP dictionaries and machine learning, predicted risk ratings on the HCR-20, START, and DASA, based on EHR content. Further research is required to ascertain the utility of NLP approaches in predicting endpoints of actual self-harm, harm to others or victimisation.",,,,,,,,,13,0,0,0,1,0,13,,,1532-0464,1532-0480,,WOS:000460600800005,30118855,
J,"Sanyal, Josh; Rubin, Daniel; Banerjee, Imon",,,,,,,,A weakly supervised model for the automated detection of adverse events using clinical notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,126,,,,,,103969,10.1016/j.jbi.2021.103969,,,,FEB 2022,2022,"With clinical trials unable to detect all potential adverse reactions to drugs and medical devices prior to their release into the market, accurate post-market surveillance is critical to ensure their safety and efficacy. Electronic health records (EHR) contain rich observational patient data, making them a valuable source to actively monitor the safety of drugs and devices. While structured EHR data and spontaneous reporting systems often underreport the complexities of patient encounters and outcomes, free-text clinical notes offer greater detail about a patient's status. Previous studies have proposed machine learning methods to detect adverse events from clinical notes, but suffer from manually extracted features, reliance on costly hand-labeled data, and lack of validation on external datasets. To address these challenges, we develop a weakly-supervised machine learning framework for adverse event detection from unstructured clinical notes and evaluate it on insulin pump failure as a test case. Our model accurately detected cases of pump failure with 0.842 PR AUC on the holdout test set and 0.815 PR AUC when validated on an external dataset. Our approach allowed us to leverage a large dataset with far less hand-labeled data and can be easily transferred to additional adverse events for scalable post-market surveillance.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000767887400007,34864210,
J,"Kalyan, Katikapalli Subramanyam; Sangeetha, S.",,,,"S, Sangeetha/V-3705-2017","S, Sangeetha/0000-0001-6630-1664",,,SECNLP: A survey of embeddings in clinical natural language processing,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,101,,,,,,103323,10.1016/j.jbi.2019.103323,,,,JAN 2020,2020,"Distributed vector representations or embeddings map variable length text to dense fixed length vectors as well as capture prior knowledge which can transferred to downstream tasks. Even though embeddings have become de facto standard for text representation in deep learning based NLP tasks in both general and clinical domains, there is no survey paper which presents a detailed review of embeddings in Clinical Natural Language Processing. In this survey paper, we discuss various medical corpora and their characteristics, medical codes and present a brief overview as well as comparison of popular embeddings models. We classify clinical embeddings and discuss each embedding type in detail. We discuss various evaluation methods followed by possible solutions to various challenges in clinical embeddings. Finally, we conclude with some of the future directions which will advance research in clinical embeddings.",,,,,,,,,15,0,0,0,5,0,15,,,1532-0464,1532-0480,,WOS:000525735000007,31711972,
J,"Mayhew, Michael B.; Petersen, Brenden K.; Sales, Ana Paula; Greene, John D.; Liu, Vincent X.; Wasson, Todd S.",,,,,,,,"Flexible, cluster-based analysis of the electronic medical record of sepsis with composite mixture models",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,78,,,,33,42,,10.1016/j.jbi.2017.11.015,,,,FEB 2018,2018,"The widespread adoption of electronic medical records (EMRs) in healthcare has provided vast new amounts of data for statistical machine learning researchers in their efforts to model and predict patient health status, potentially enabling novel advances in treatment. In the case of sepsis, a debilitating, dysregulated host response to infection, extracting subtle, uncataloged clinical phenotypes from the EMR with statistical machine learning methods has the potential to impact patient diagnosis and treatment early in the course of their hospitalization. However, there are significant barriers that must be overcome to extract these insights from EMR data. First, EMR datasets consist of both static and dynamic observations of discrete and continuous-valued variables, many of which may be missing, precluding the application of standard multivariate analysis techniques. Second, clinical populations observed via EMRs and relevant to the study and management of conditions like sepsis are often heterogeneous; properly accounting for this heterogeneity is critical. Here, we describe an unsupervised, probabilistic framework called a composite mixture model that can simultaneously accommodate the wide variety of observations frequently observed in EMR datasets, characterize heterogeneous clinical populations, and handle missing observations. We demonstrate the efficacy of our approach on a large-scale sepsis cohort, developing novel techniques built on our model-based clusters to track patient mortality risk over time and identify physiological trends and distinct subgroups of the dataset associated with elevated risk of mortality during hospitalization.",,,,,,,,,12,0,0,0,6,0,12,,,1532-0464,1532-0480,,WOS:000430035300004,29196114,
J,"Afshar, Majid; Joyce, Cara; Oakey, Anthony; Formanek, Perry; Yang, Philip; Churpek, Matthew M; Cooper, Richard S; Zelisko, Susan; Price, Ron; Dligach, Dmitriy",,,,,"Churpek, Matthew/0000-0002-4030-5250; Yang, Philip/0000-0001-5142-1137",,,A Computable Phenotype for Acute Respiratory Distress Syndrome Using Natural Language Processing and Machine Learning.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,157,165,,,,,,2018,2018,"Acute Respiratory Distress Syndrome (ARDS) is a syndrome of respiratory failure that may be identified using text from radiology reports. The objective of this study was to determine whether natural language processing (NLP) with machine learning performs better than a traditional keyword model for ARDS identification. Linguistic pre-processing of reports was performed and text features were inputs to machine learning classifiers tuned using 10-fold cross-validation on 80% of the sample size and tested in the remaining 20%. A cohort of 533 patients was evaluated, with a data corpus of 9,255 radiology reports. The traditional model had an accuracy of 67.3% (95% CI: 58.3-76.3) with a positive predictive value (PPV) of 41.7% (95% CI: 27.7-55.6). The best NLP model had an accuracy of 83.0% (95% CI: 75.9-90.2) with a PPV of 71.4% (95% CI: 52.1-90.8). A computable phenotype for ARDS with NLP may identify more cases than the traditional model.",,,,,,,,,8,0,0,0,1,0,8,,,,1942-597X,,MEDLINE:30815053,30815053,
J,"Ning, Wenxin; Chan, Stephanie; Beam, Andrew; Yu, Ming; Geva, Alon; Liao, Katherine; Mullen, Mary; Mandl, Kenneth D.; Kohane, Isaac; Cai, Tianxi; Yu, Sheng",,,,"Geva, Alon/AAM-6793-2021","Geva, Alon/0000-0002-8574-0133",,,Feature extraction for phenotyping from semantic and knowledge resources,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,91,,,,,,103122,10.1016/j.jbi.2019.103122,,,,MAR 2019,2019,"Objective: Phenotyping algorithms can efficiently and accurately identify patients with a specific disease phenotype and construct electronic health records (EHR)-based cohorts for subsequent clinical or genomic studies. Previous studies have introduced unsupervised EHR-based feature selection methods that yielded algorithms with high accuracy. However, those selection methods still require expert intervention to tweak the parameter settings according to the EHR data distribution for each phenotype. To further accelerate the development of phenotyping algorithms, we propose a fully automated and robust unsupervised feature selection method that leverages only publicly available medical knowledge sources, instead of EHR data.Methods: SEmantics-Driven Feature Extraction (SEDFE) collects medical concepts from online knowledge sources as candidate features and gives them vector-form distributional semantic representations derived with neural word embedding and the Unified Medical Language System Metathesaurus. A number of features that are semantically closest and that sufficiently characterize the target phenotype are determined by a linear decomposition criterion and are selected for the final classification algorithm.Results: SEDFE was compared with the EHR-based SAFE algorithm and domain experts on feature selection for the classification of five phenotypes including coronary artery disease, rheumatoid arthritis, Crohn's disease, ulcerative colitis, and pediatric pulmonary arterial hypertension using both supervised and unsupervised approaches. Algorithms yielded by SEDFE achieved comparable accuracy to those yielded by SAFE and expertcurated features. SEDFE is also robust to the input semantic vectors.Conclusion: SEDFE attains satisfying performance in unsupervised feature selection for EHR phenotyping. Both fully automated and EHR-independent, this method promises efficiency and accuracy in developing algorithms for high-throughput phenotyping.",,,,,,,,,8,0,0,0,2,0,8,,,1532-0464,1532-0480,,WOS:000525688200009,30738949,
J,"Dai, Hong-Jie; Wang, Feng-Duo; Chen, Chih-Wei; Su, Chu-Hsien; Wu, Chi-Shin; Jonnagaddala, Jitendra",,,,,,,,Cohort selection for clinical trials using multiple instance learning,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,107,,,,,,103438,10.1016/j.jbi.2020.103438,,,,JUL 2020,2020,"Identifying patients eligible for clinical trials using electronic health records (EHRs) is a challenging task usually requiring a comprehensive analysis of information stored in multiple EHRs of a patient. The goal of this study is to investigate different methods and their effectiveness in identifying patients that meet specific eligibility selection criteria based on patients' longitudinal records. An unstructured dataset released by the n2c2 cohort selection for clinical trials track was used, each of which included 2-5 records manually annotated to thirteen pre-defined selection criteria. Unlike the other studies, we formulated the problem as a multiple instance learning (MIL) task and compared the performance with that of the rule-based and the single instance-based classifiers. Our official best run achieved an average micro-F score of 0.8765 which was ranked as one of the top ten results in the track. Further experiments demonstrated that the performance of the MIL-based classifiers consistently yield better performance than their single-instance counterparts in the criteria that require the overall comprehension of the information distributed among all of the patient's EHRs. Rule-based and single instance learning approaches exhibited better performance in criteria that don't require a consideration of several factors across records. This study demonstrated that cohort selection using longitudinal patient records can be formulated as a MIL problem. Our results exhibit that the MIL-based classifiers supplement the rule-based methods and provide better results in comparison to the single instance learning approaches.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000551649200007,32360937,
J,"Gibson, Teresa B.; Nguyen, Michael D.; Burrell, Timothy; Yoon, Frank; Wong, Jenna; Dharmarajan, Sai; Ouellet-Hellstrom, Rita; Hua, Wei; Ma, Yong; Baro, Elande; Bloemers, Sarah; Pack, Cory; Kennedy, Adee; Toh, Sengwee; Ball, Robert",,,,"Toh, Sengwee/D-7567-2017","Toh, Sengwee/0000-0002-5160-0810; Burrell, Timothy/0000-0001-7973-7803",,,Electronic phenotyping of health outcomes of interest using a linked claims-electronic health record database: Findings from a machine learning pilot project,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,7,,,1507,1517,,10.1093/jamia/ocab036,,MAR 2021,,JUL 2021,2021,"Objective: Claims-based algorithms are used in the Food and Drug Administration Sentinel Active Risk Identification and Analysis System to identify occurrences of health outcomes of interest (HOIs) for medical product safety assessment. This project aimed to apply machine learning classification techniques to demonstrate the feasibility of developing a claims-based algorithm to predict an HOI in structured electronic health record (EHR) data.Materials and Methods: We used the 2015-2019 IBM MarketScan Explorys Claims-EMR Data Set, linking administrative claims and EHR data at the patient level. We focused on a single HOI, rhabdomyolysis, defined by EHR laboratory test results. Using claims-based predictors, we applied machine learning techniques to predict the HOI: logistic regression, LASSO (least absolute shrinkage and selection operator), random forests, support vector machines, artificial neural nets, and an ensemble method (Super Learner).Results: The study cohort included 32 956 patients and 39 499 encounters. Model performance (positive predictive value [PPV], sensitivity, specificity, area under the receiver-operating characteristic curve) varied considerably across techniques. The area under the receiver-operating characteristic curve exceeded 0.80 in most model variations.Discussion: For the main Food and Drug Administration use case of assessing risk of rhabdomyolysis after drug use, a model with a high PPV is typically preferred. The Super Learner ensemble model without adjustment for class imbalance achieved a PPV of 75.6%, substantially better than a previously used human expert-developed model (PPV = 44.0%).Conclusions: It is feasible to use machine learning methods to predict an EHR-derived HOI with claims-based predictors. Modeling strategies can be adapted for intended uses, including surveillance, identification of cases for chart review, and outcomes research.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000685209200017,33712852,
J,"Gehrmann, Sebastian; Dernoncourt, Franck; Li, Yeran; Carlson, Eric T.; Wu, Joy T.; Welt, Jonathan; Foote, John, Jr.; Moseley, Edward T.; Grant, David W.; Tyler, Patrick D.; Celi, Leo A.",,,,,"Tyler, Patrick/0000-0001-6156-8722; Gehrmann, Sebastian/0000-0002-8257-9516",,,Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives,,,,,,,,PLOS ONE,,,,13,2,,,,,e0192360,10.1371/journal.pone.0192360,,,,FEB 15 2018,2018,"In secondary analysis of electronic health records, a crucial task consists in correctly identifying the patient cohort under investigation. In many cases, the most valuable and relevant information for an accurate classification of medical conditions exist only in clinical narratives. Therefore, it is necessary to use natural language processing (NLP) techniques to extract and evaluate these narratives. The most commonly used approach to this problem relies on extracting a number of clinician-defined medical concepts from text and using machine learning techniques to identify whether a particular patient has a certain condition. However, recent advances in deep learning and NLP enable models to learn a rich representation of (medical) language. Convolutional neural networks (CNN) for text classification can augment the existing techniques by leveraging the representation of language to learn which phrases in a text are relevant for a given medical condition. In this work, we compare concept extraction based methods with CNNs and other commonly used models in NLP in ten phenotyping tasks using 1,610 discharge summaries from the MIMIC-III database. We show that CNNs outperform concept extraction based methods in almost all of the tasks, with an improvement in F1-score of up to 26 and up to 7 percentage points in area under the ROC curve (AUC). We additionally assess the interpretability of both approaches by presenting and evaluating methods that calculate and extract the most salient phrases for a prediction. The results indicate that CNNs are a valid alternative to existing approaches in patient phenotyping and cohort identification, and should be further investigated. Moreover, the deep learning approach presented in this paper can be used to assist clinicians during chart review or support the extraction of billing codes from text by identifying and highlighting relevant phrases for various medical conditions.",,,,,,,,,65,0,0,0,27,0,65,,,1932-6203,,,WOS:000425283900028,29447188,
J,"Xu, Da; Hu, Paul Jen-Hwa; Huang, Ting-Shuo; Fang, Xiao; Hsu, Chih-Chin",,,,"Huang, Ting-Shuo/ABD-3205-2021","Huang, Ting-Shuo/0000-0002-2932-6878",,,"A deep learning-based, unsupervised method to impute missing values in electronic health records for improved patient management",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,111,,,,,,103576,10.1016/j.jbi.2020.103576,,,,NOV 2020,2020,"Electronic health records (EHRs) often suffer missing values, for which recent advances in deep learning offer a promising remedy. We develop a deep learning-based, unsupervised method to impute missing values in patient records, then examine its imputation effectiveness and predictive efficacy for peritonitis patient management. Our method builds on a deep autoencoder framework, incorporates missing patterns, accounts for essential re-lationships in patient data, considers temporal patterns common to patient records, and employs a novel loss function for error calculation and regularization. Using a data set of 27,327 patient records, we perform a comparative evaluation of the proposed method and several prevalent benchmark techniques. The results indicate the greater imputation performance of our method relative to all the benchmark techniques, recording 5.3-15.5% lower imputation errors. Furthermore, the data imputed by the proposed method better predict readmission, length of stay, and mortality than those obtained from any benchmark techniques, achieving 2.7-11.5% improvements in predictive efficacy. The illustrated evaluation indicates the proposed method's viability, imputation effectiveness, and clinical decision support utilities. Overall, our method can reduce imputation biases and be applied to various missing value scenarios clinically, thereby empowering physicians and researchers to better analyze and utilize EHRs for improved patient management.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000588330900011,33010424,
J,"Xiao, Xueli; Wei, Guanhao; Zhou, Li; Pan, Yi; Jing, Huan; Zhao, Emily; Yuan, Yilian",,,,,,,,Treatment initiation prediction by EHR mapped PPD tensor based convolutional neural networks boosting algorithm,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,120,,,,,,103840,10.1016/j.jbi.2021.103840,,JUL 2021,,AUG 2021,2021,"Electronic health records contain patient's information that can be used for health analytics tasks such as disease detection, disease progression prediction, patient profiling, etc. Traditional machine learning or deep learning methods treat EHR entities as individual features, and no relationships between them are taken into consideration. We propose to evaluate the relationships between EHR features and map them into Procedures, Prescriptions, and Diagnoses (PPD) tensor data, which can be formatted as images. The mapped images are then fed into deep convolutional networks for local pattern and feature learning. We add this relationship-learning part as a boosting module on a commonly used classical machine learning model. Experiments were performed on a Chronic Lymphocytic Leukemia dataset for treatment initiation prediction. Experimental results show that the proposed approach has better real world modeling performance than the baseline models in terms of prediction precision.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000683527500002,34139331,
J,"Steinkamp, Jackson M.; Bala, Wasif; Sharma, Abhinav; Kantrowitz, Jacob J.",,,,,"Kantrowitz, Jacob/0000-0002-7711-7552; Steinkamp, Jackson/0000-0001-7888-0691",,,"Task definition, annotated dataset, and supervised natural language processing models for symptom extraction from unstructured clinical notes",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103354,10.1016/j.jbi.2019.103354,,,,FEB 2020,2020,"Introduction: Machine learning (ML) and natural language processing have great potential to improve information extraction (IE) within electronic medical records (EMRs) for a wide variety of clinical search and summarization tools. Despite ML advancements, clinical adoption of real time IE tools for patient care remains low. Clinically motivated IE task definitions, publicly available annotated clinical datasets, and inclusion of subtasks such as coreference resolution and named entity normalization are critical for the development of useful clinical tools.Materials and methods: We provide a task definition and comprehensive annotation requirements for a clinically motivated symptom extraction task. Four annotators labeled symptom mentions within 1108 discharge summaries from two public clinical note datasets for the tasks of named entity recognition, coreference resolution, and named entity normalization; these annotations will be released to the public. Baseline human performance was assessed and two ML models were evaluated on the symptom extraction task.Results: 16,922 symptom mentions were identified within the discharge summaries, with 11,944 symptom instances after coreference resolution and 1255 unique normalized answer forms. Human annotator performance averaged 92.2% FI. Recurrent network model performance was 85.6% FI (recall 85.8%, precision 85.4%), and Transformer-based model performance was 86.3% FI (recall 86.6%, precision 86.1%). Our models extracted vague symptoms, acronyms, typographical errors, and grouping statements. The models generalized effectively to a separate clinical note corpus and can run in real time.Conclusion: To our knowledge, this dataset will be the largest and most comprehensive publicly released, annotated dataset for clinically motivated symptom extraction, as it includes annotations for named entity recognition, coreference, and normalization for more than 1000 clinical documents. Our neural network models extracted symptoms from unstructured clinical free text at near human performance in real time. In this paper, we present a clinically motivated task definition, dataset, and simple supervised natural language processing models to demonstrate the feasibility of building clinically applicable information extraction tools.",,,,,,,,,8,0,0,0,0,1,8,,,1532-0464,1532-0480,,WOS:000525735200013,31838210,
J,"De Angeli, Kevin; Gao, Shang; Danciu, Ioana; Durbin, Eric B.; Wu, Xiao-Cheng; Stroup, Antoinette; Doherty, Jennifer; Schwartz, Stephen; Wiggins, Charles; Damesyn, Mark; Coyle, Linda; Penberthy, Lynne; Tourassi, Georgia D.; Yoon, Hong-Jun",,,,,,,,Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,125,,,,,,103957,10.1016/j.jbi.2021.103957,,NOV 2021,,JAN 2022,2022,"In the last decade, the widespread adoption of electronic health record documentation has created huge opportunities for information mining. Natural language processing (NLP) techniques using machine and deep learning are becoming increasingly widespread for information extraction tasks from unstructured clinical notes. Disparities in performance when deploying machine learning models in the real world have recently received considerable attention. In the clinical NLP domain, the robustness of convolutional neural networks (CNNs) for classifying cancer pathology reports under natural distribution shifts remains understudied. In this research, we aim to quantify and improve the performance of the CNN for text classification on out-of-distribution (OOD) datasets resulting from the natural evolution of clinical text in pathology reports. We identified class imbalance due to different prevalence of cancer types as one of the sources of performance drop and analyzed the impact of previous methods for addressing class imbalance when deploying models in real-world domains. Our results show that our novel class-specialized ensemble technique outperforms other methods for the classification of rare cancer types in terms of macro F1 scores. We also found that traditional ensemble methods perform better in top classes, leading to higher micro F1 scores. Based on our findings, we formulate a series of recommendations for other ML practitioners on how to build robust models with extremely imbalanced datasets in biomedical NLP applications.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000735573800007,34823030,
J,"Liang, Jennifer J; Tsou, Ching-Huei; Dandala, Bharath; Poddar, Ananya; Joopudi, Venkata; Mahajan, Diwakar; Prager, John; Raghavan, Preethi; Payne, Michele",,,,,,,,Reducing Physicians' Cognitive Load During Chart Review: A Problem-Oriented Summary of the Patient Electronic Record.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,763,772,,,,,,2021,2021,"Overabundance of information within electronic health records (EHRs) has resulted in a need for automated systems to mitigate the cognitive burden on physicians utilizing today's EHR systems. We present ProSPER, a Problem-oriented Summary of the Patient Electronic Record that displays a patient summary centered around an auto-generated problem list and disease-specific views for chronic conditions. ProSPER was developed using 1,500 longitudinal patient records from two large multi-specialty medical groups in the United States, and leverages multiple natural language processing (NLP) components targeting various fundamental (e.g. syntactic analysis), clinical (e.g. adverse drug event extraction) and summarizing (e.g. problem list generation) tasks. We report evaluation results for each component and discuss how specific components address existing physician challenges in reviewing EHR data. This work demonstrates the need to leverage holistic information in EHRs to build a comprehensive summarization application, and the potential for NLP-based applications to support physicians and improve clinical care.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308927,35308927,
J,"Yu, Zehao; Yang, Xi; Dang, Chong; Wu, Songzi; Adekkanattu, Prakash; Pathak, Jyotishman; George, Thomas J; Hogan, William R; Guo, Yi; Bian, Jiang; Wu, Yonghui",,,,,"George, Thomas/0000-0002-6249-9180",,,A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,1225,1233,,,,,,2021,2021,"Social and behavioral determinants of health (SBDoH) have important roles in shaping people's health. In clinical research studies, especially comparative effectiveness studies, failure to adjust for SBDoH factors will potentially cause confounding issues and misclassification errors in either statistical analyses and machine learning-based models. However, there are limited studies to examine SBDoH factors in clinical outcomes due to the lack of structured SBDoH information in current electronic health record (EHR) systems, while much of the SBDoH information is documented in clinical narratives. Natural language processing (NLP) is thus the key technology to extract such information from unstructured clinical text. However, there is not a mature clinical NLP system focusing on SBDoH. In this study, we examined two state-of-the-art transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH concepts from clinical narratives, applied the best performing model to extract SBDoH concepts on a lung cancer screening patient cohort, and examined the difference of SBDoH information between NLP extracted results and structured EHRs (SBDoH information captured in standard vocabularies such as the International Classification of Diseases codes). The experimental results show that the BERT-based NLP model achieved the best strict/lenient F1-score of 0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH information and structured EHRs in the lung cancer patient cohort of 864 patients with 161,933 various types of clinical notes showed that much more detailed information about smoking, education, and employment were only captured in clinical narratives and that it is necessary to use both clinical narratives and structured EHRs to construct a more complete picture of patients' SBDoH factors.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35309014,35309014,
J,"Lucini, Filipe R.; Krewulak, Karla D.; Fiest, Kirsten M.; Bagshaw, Sean M.; Zuege, Danny J.; Lee, Joon; Stelfox, Henry T.",,,,,"Krewulak, Karla/0000-0003-0300-4122; Lucini, Filipe/0000-0002-6090-6846",,,Natural language processing to measure the frequency and mode of communication between healthcare professionals and family members of critically ill patients,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,541,548,,10.1093/jamia/ocaa263,,,,MAR 2021,2021,"Objective: To apply natural language processing (NLP) techniques to identify individual events and modes of communication between healthcare professionals and families of critically ill patients from electronic medical records (EMR).Materials and Methods: Retrospective cohort study of 280 randomly selected adult patients admitted to 1 of 15 intensive care units (ICU) in Alberta, Canada from June 19, 2012 to June 11, 2018. Individual events and modes of communication were independently abstracted using NLP and manual chart review (reference standard). Preprocessing techniques and 2 NLP approaches (rule-based and machine learning) were evaluated using sensitivity, specificity, and area under the receiver operating characteristic curves (AUROC).Results: Over 2700 combinations of NLP methods and hyperparameters were evaluated for each mode of communication using a holdout subset. The rule-based approach had the highest AUROC in 65 datasets compared to the machine learning approach in 21 datasets. Both approaches had similar performance in 17 datasets. The rule-based AUROC for the grouped categories of patient documented to have family or friends (0.972, 95% CI 0.934-1.000), visit by family/friend (0.882 95% CI 0.820-0.943) and phone call with family/friend (0.975, 95% CI: 0.952-0.998) were high.Discussion: We report an automated method to quantify communication between healthcare professionals and family members of adult patients from free-text EMRs. A rule-based NLP approach had better overall operating characteristics than a machine learning approach.Conclusion: NLP can automatically and accurately measure frequency and mode of documented family visitation and communication from unstructured free-text EMRs, to support patient- and family-centered care initiatives.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000637314400013,33201981,
J,"Huang, Yufang; Liu, Yifan; Steel, Peter A. D.; Axsom, Kelly M.; Lee, John R.; Tummalapalli, Sri Lekha; Wang, Fei; Pathak, Jyotishman; Subramanian, Lakshminarayanan; Zhang, Yiye",,,,,"Subramanian, Lakshminarayanan/0000-0001-8101-1243",,,Deep significance clustering: a novel approach for identifying risk-stratified and predictive patient subgroups,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,12,,,2641,2653,,10.1093/jamia/ocab203,,SEP 2021,,DEC 2021,2021,"Objective: Deep significance clustering (DICE) is a self-supervised learning framework. DICE identifies clinically similar and risk-stratified subgroups that neither unsupervised clustering algorithms nor supervised risk prediction algorithms alone are guaranteed to generate.Materials and Methods: Enabled by an optimization process that enforces statistical significance between the outcome and subgroup membership, DICE jointly trains 3 components, representation learning, clustering, and outcome prediction while providing interpretability to the deep representations. DICE also allows unseen patients to be predicted into trained subgroups for population-level risk stratification. We evaluated DICE using electronic health record datasets derived from 2 urban hospitals. Outcomes and patient cohorts used include discharge disposition to home among heart failure (HF) patients and acute kidney injury among COVID-19 (Cov-AKI) patients, respectively.Results: Compared to baseline approaches including principal component analysis, DICE demonstrated superior performance in the cluster purity metrics: Silhouette score (0.48 for HF, 0.51 for Cov-AKI), Calinski-Harabasz index (212 for HF, 254 for Cov-AKI), and Davies-Bouldin index (0.86 for HF, 0.66 for Cov-AKI), and prediction metric: area under the Receiver operating characteristic (ROC) curve (0.83 for HF, 0.78 for Cov-AKI). Clinical evaluation of DICE-generated subgroups revealed more meaningful distributions of member characteristics across subgroups, and higher risk ratios between subgroups. Furthermore, DICE-generated subgroup membership alone was moderately predictive of outcomes.Discussion: DICE addresses a gap in current machine learning approaches where predicted risk may not lead directly to actionable clinical steps.Conclusion: DICE demonstrated the potential to apply in heterogeneous populations, where having the same quantitative risk does not equate with having a similar clinical profile.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000728261700011,34571540,
J,"Ni, Yizhao; Bachtel, Alycia; Nause, Katie; Beal, Sarah",,,,,,,,Automated detection of substance use information from electronic health records for a pediatric population,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2116,2127,,10.1093/jamia/ocab116,,AUG 2021,,OCT 2021,2021,"Objective: Substance use screening in adolescence is unstandardized and often documented in clinical notes, rather than in structured electronic health records (EHRs). The objective of this study was to integrate logic rules with state-of-the-art natural language processing (NLP) and machine learning technologies to detect substance use information from both structured and unstructured EHR data.Materials and Methods: Pediatric patients (10-20 years of age) with any encounter between July 1, 2012, and October 31, 2017, were included (n = 3890 patients; 19 478 encounters). EHR data were extracted at each encounter, manually reviewed for substance use (alcohol, tobacco, marijuana, opiate, any use), and coded as lifetime use, current use, or family use. Logic rules mapped structured EHR indicators to screening results. A knowledge-based NLP system and a deep learning model detected substance use information from unstructured clinical narratives. System performance was evaluated using positive predictive value, sensitivity, negative predictive value, specificity, and area under the receiver-operating characteristic curve (AUC).Results: The dataset included 17 235 structured indicators and 27 141 clinical narratives. Manual review of clinical narratives captured 94.0% of positive screening results, while structured EHR data captured 22.0%. Logic rules detected screening results from structured data with 1.0 and 0.99 for sensitivity and specificity, respectively. The knowledge-based system detected substance use information from clinical narratives with 0.86, 0.79, and 0.88 for AUC, sensitivity, and specificity, respectively. The deep learning model further improved detection capacity, achieving 0.88, 0.81, and 0.85 for AUC, sensitivity, and specificity, respectively. Finally, integrating predictions from structured and unstructured data achieved high detection capacity across all cases (0.96, 0.85, and 0.87 for AUC, sensitivity, and specificity, respectively).Conclusions: It is feasible to detect substance use screening and results among pediatric patients using logic rules, NLP, and machine learning technologies.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000745625700008,34333636,
J,"Chen, Bob; Alrifai, Wael; Gao, Cheng; Jones, Barrett; Novak, Laurie; Lorenzi, Nancy; France, Daniel; Malin, Bradley; Chen, You",,,,,"Novak, Laurie/0000-0002-0415-4301; Chen, Bob/0000-0003-1508-1758",,,Mining tasks and task characteristics from electronic health record audit logs with unsupervised machine learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1168,1177,,10.1093/jamia/ocaa338,,FEB 2021,,JUN 2021,2021,"Objective: The characteristics of clinician activities while interacting with electronic health record (EHR) systems can influence the time spent in EHRs and workload. This study aims to characterize EHR activities as tasks and define novel, data-driven metrics.Materials and Methods: We leveraged unsupervised learning approaches to learn tasks from sequences of events in EHR audit logs. We developed metrics characterizing the prevalence of unique events and event repetition and applied them to categorize tasks into 4 complexity profiles. Between these profiles, Mann-Whitney U tests were applied to measure the differences in performance time, event type, and clinician prevalence, or the number of unique clinicians who were observed performing these tasks. In addition, we apply process mining frameworks paired with clinical annotations to support the validity of a sample of our identified tasks. We apply our approaches to learn tasks performed by nurses in the Vanderbilt University Medical Center neonatal intensive care unit.Results: We examined EHR audit logs generated by 33 neonatal intensive care unit nurses resulting in 57 234 sessions and 81 tasks. Our results indicated significant differences in performance time for each observed task complexity profile. There were no significant differences in clinician prevalence or in the frequency of viewing and modifying event types between tasks of different complexities. We presented a sample of expert-reviewed, annotated task workflows supporting the interpretation of their clinical meaningfulness.Conclusions: The use of the audit log provides an opportunity to assist hospitals in further investigating clinician activities to optimize EHR workflows.",,,,,,,,,6,0,0,0,0,0,6,,,1067-5027,1527-974X,,WOS:000671031900013,33576432,
J,"Afshar, Majid; Phillips, Andrew; Karnik, Niranjan; Mueller, Jeanne; To, Daniel; Gonzalez, Richard; Price, Ron; Cooper, Richard; Joyce, Cara; Dligach, Dmitriy",,,,"Karnik, Niranjan/N-4103-2019; Afshar, Majid/AAD-8365-2019","Karnik, Niranjan/0000-0001-7650-3008; Afshar, Majid/0000-0002-6368-4652",,,Natural language processing and machine learning to identify alcohol misuse from the electronic health record in trauma patients: development and internal validation,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,3,,,254,261,,10.1093/jamia/ocy166,,,,MAR 2019,2019,"Objective: Alcohol misuse is present in over a quarter of trauma patients. Information in the clinical notes of the electronic health record of trauma patients may be used for phenotyping tasks with natural language processing (NLP) and supervised machine learning. The objective of this study is to train and validate an NLP classifier for identifying patients with alcohol misuse.Materials and Methods: An observational cohort of 1422 adult patients admitted to a trauma center between April 2013 and November 2016. Linguistic processing of clinical notes was performed using the clinical Text Analysis and Knowledge Extraction System. The primary analysis was the binary classification of alcohol misuse. The Alcohol Use Disorders Identification Test served as the reference standard.Results: The data corpus comprised 91 045 electronic health record notes and 16 091 features. In the final machine learning classifier, 16 features were selected from the first 24 hours of notes for identifying alcohol misuse. The classifier's performance in the validation cohort had an area under the receiver-operating characteristic curve of 0.78 (95% confidence interval [CI], 0.72 to 0.85). Sensitivity and specificity were at 56.0% (95% CI, 44.1% to 68.0%) and 88.9% (95% CI, 84.4% to 92.8%). The Hosmer-Lemeshow goodness-of-fit test demonstrates the classifier fits the data well (P = .17). A simpler rule-based keyword approach had a decrease in sensitivity when compared with the NLP classifier from 56.0% to 18.2%.Conclusions: The NLP classifier has adequate predictive validity for identifying alcohol misuse in trauma centers. External validation is needed before its application to augment screening.",,,,,,,,,23,0,0,0,5,0,23,,,1067-5027,1527-974X,,WOS:000461520800008,30602031,
J,"Bey, Romain; Goussault, Romain; Grolleau, Francois; Benchoufi, Mehdi; Porcher, Raphael",,,,,"Porcher, Raphael/0000-0002-5277-4679; Grolleau, Francois/0000-0001-7873-7772",,,Fold-stratified cross-validation for unbiased and privacy-preserving federated learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,8,,,1244,1251,,10.1093/jamia/ocaa096,,,,AUG 2020,2020,"Objective: We introduce fold-stratified cross-validation, a validation methodology that is compatible with privacy-preserving federated learning and that prevents data leakage caused by duplicates of electronic health records (EHRs).Materials and Methods: Fold-stratified cross-validation complements cross-validation with an initial stratification of EHRs in folds containing patients with similar characteristics, thus ensuring that duplicates of a record are jointly present either in training or in validation folds. Monte Carlo simulations are performed to investigate the properties of fold-stratified cross-validation in the case of a model data analysis using both synthetic data and MIMIC-III (Medical Information Mart for Intensive Care-III) medical records.Results: In situations in which duplicated EHRs could induce overoptimistic estimations of accuracy, applying fold-stratified cross-validation prevented this bias, while not requiring full deduplication. However, a pessimistic bias might appear if the covariate used for the stratification was strongly associated with the outcome.Discussion: Although fold-stratified cross-validation presents low computational overhead, to be efficient it requires the preliminary identification of a covariate that is both shared by duplicated records and weakly associated with the outcome. When available, the hash of a personal identifier or a patient's date of birth provides such a covariate. On the contrary, pseudonymization interferes with fold-stratified cross-validation, as it may break the equality of the stratifying covariate among duplicates.Conclusion: Fold-stratified cross-validation is an easy-to-implement methodology that prevents data leakage when a model is trained on distributed EHRs that contain duplicates, while preserving privacy.",,,,,,,,,2,0,0,0,1,0,2,,,1067-5027,1527-974X,,WOS:000584507600008,32620945,
J,"Feng, Alice",,,,,,,,A Machine Learning Pipeline for Accurate COVID-19 Health Outcome Prediction using Longitudinal Electronic Health Records.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,448,456,,,,,,2021,2021,"Current COVID-19 predictive models primarily focus on predicting the risk of mortality, and rely on COVID-19 specific medical data such as chest imaging after COVID-19 diagnosis. In this project, we developed an innovative supervised machine learning pipeline using longitudinal Electronic Health Records (EHR) to accurately predict COVID-19 related health outcomes including mortality, ventilation, days in hospital or ICU. In particular, we developed unique and effective data processing algorithms, including data cleaning, initial feature screening, vector representation. Then we trained models using state-of-the-art machine learning strategies combined with different parameter settings. Based on routinely collected EHR, our machine learning pipeline not only consistently outperformed those developed by other research groups using the same set of data, but also achieved similar accuracy as those trained on medical data that were only available after COVID-19 diagnosis. In addition, top risk factors for COVID-19 were identified, and are consistent with epidemiologic findings.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35309012,35309012,
J,"Chu, Jiebin; Dong, Wei; He, Kunlun; Duan, Huilong; Huang, Zhengxing",,,,,"He, Kunlun/0000-0002-3335-5700",,,Using neural attention networks to detect adverse medical events from electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,87,,,,118,130,,10.1016/j.jbi.2018.10.002,,,,NOV 2018,2018,"The detection of Adverse Medical Events (AMEs) plays an important role in disease management in ensuring efficient treatment delivery and quality improvement of health services. Recently, with the rapid development of hospital information systems, a large volume of Electronic Health Records (EHRs) have been produced, in which AMEs are regularly documented in a free-text manner. In this study, we are concemed with the problem of AME detection by utilizing a large volume of unstructured EHR data. To address this challenge, we propose a neural attention network-based model to incorporate the contextual information of words into AME detection. Specifically, we develop a context-aware attention mechanism to locate salient words with respect to the target AMEs in patient medical records. And then we combine the proposed context attention mechanism with the deep learning tactic to boost the performance of AME detection. We validate our proposed model on a real clinical dataset that consists of 8845 medical records of patients with cardiovascular diseases. The experimental results show that our proposed model advances state-of-the-art models and achieves competitive performance in terms of AME detection.",,,,,,,,,8,0,0,0,3,0,8,,,1532-0464,1532-0480,,WOS:000460600700012,30336262,
J,"Baowaly, Mrinal Kanti; Lin, Chia-Ching; Liu, Chao-Lin; Chen, Kuan-Ta",,,,,"Baowaly, Mrinal Kanti/0000-0002-8735-0139",,,Synthesizing electronic health records using improved generative adversarial networks,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,3,,,228,241,,10.1093/jamia/ocy142,,,,MAR 2019,2019,"Objective: The aim of this study was to generate synthetic electronic health records (EHRs). The generated EHR data will be more realistic than those generated using the existing medical Generative Adversarial Network (medGAN) method.Materials and Methods: We modified medGAN to obtain two synthetic data generation models-designated as medical Wasserstein GAN with gradient penalty (medWGAN) and medical boundary-seeking GAN (medBGAN)-and compared the results obtained using the three models. We used 2 databases: MIMIC-III and National Health Insurance Research Database (NHIRD), Taiwan. First, we trained the models and generated synthetic EHRs by using these three 3 models. We then analyzed and compared the models' performance by using a few statistical methods (Kolmogorov-Smirnov test, dimension-wise probability for binary data, and dimension-wise average count for count data) and 2 machine learning tasks (association rule mining and prediction).Results: We conducted a comprehensive analysis and found our models were adequately efficient for generating synthetic EHR data. The proposed models outperformed medGAN in all cases, and among the 3 models, boundary-seeking GAN (medBGAN) performed the best.Discussion: To generate realistic synthetic EHR data, the proposed models will be effective in the medical industry and related research from the viewpoint of providing better services. Moreover, they will eliminate barriers including limited access to EHR data and thus accelerate research on medical informatics.Conclusion: The proposed models can adequately learn the data distribution of real EHRs and efficiently generate realistic synthetic EHRs. The results show the superiority of our models over the existing model.",,,,,,,,,29,0,0,0,6,0,29,,,1067-5027,1527-974X,,WOS:000461520800006,30535151,
J,"Ma, Xiaojun; Imai, Takeshi; Shinohara, Emiko; Kasai, Satoshi; Kato, Kosuke; Kagawa, Rina; Ohe, Kazuhiko",,,,,"IMAI, Takeshi/0000-0002-8708-079X",,,EHR2CCAS: A framework for mapping EHR to disease knowledge presenting causal chain of disorders ? chronic kidney disease example,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,115,,,,,,103692,10.1016/j.jbi.2021.103692,,MAR 2021,,MAR 2021,2021,"Objective: The goal of this work was to capture diseases in patients by comprehending the fine-grained medical conditions and disease progression manifested by transitions in medical conditions. We realize this by introducing our earlier work on a state-of-the-art knowledge presentation, which defines a disease as a causal chain of abnormal states (CCAS). Here, we propose a framework, EHR2CCAS, for constructing a system to map electronic health record (EHR) data to CCAS. Materials and methods: EHR2CCAS is a framework consisting of modules that access heterogeneous EHR to estimate the presence of abnormal states in a CCAS for a patient in a given time window. EHR2CCAS applies expert-driven (rule-based) and data-driven (machine learning) methods to identify abnormal states from structured and unstructured EHR data. It features data-driven approaches for unlocking clinical texts and imputations based on the EHR temporal properties and the causal CCAS structure. This study presents the CCAS of chronic kidney disease as an example. A mapping system between the EHR from the University of Tokyo Hospital and CCAS of chronic kidney disease was constructed and evaluated against expert annotation. Results: The system achieved high prediction performance in identifying abnormal states that had strong agreement among annotators. Our handling of narrative varieties in texts and our imputation of the presence of an abnormal state markedly improved the prediction performance. EHR2CCAS presents patient data describing the temporal presence of abnormal states in CCAS, which is useful in individual disease progression management. Further analysis of the differentiation of transition among abnormal states outputted by EHR2CCAS can contribute to detecting disease subtypes. Conclusion: This work represents the first step toward combining disease knowledge and EHR to extract abnormality related to a disease defined as fine-grained abnormal states and transitions among them. This can aid in disease progression management and deep phenotyping.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000640492500007,33548543,
J,"Lee, Dongha; Jiang, Xiaoqian; Yu, Hwanjo",,,,,"Lee, Dongha/0000-0003-2173-3476; Jiang, Xiaoqian/0000-0001-9933-2205",,,Harmonized representation learning on dynamic EHR graphs,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,106,,,,,,103426,10.1016/j.jbi.2020.103426,,,,JUN 2020,2020,"With the rise of deep learning, several recent studies on deep learning-based methods for electronic health records (EHR) successfully address real-world clinical challenges by utilizing effective representations of medical entities. However, existing EHR representation learning methods that focus on only diagnosis codes have limited clinical value, because such structured codes cannot concretely describe patients' medical conditions, and furthermore, some of the codes assigned to patients contain errors and inconsistency; this is one of the well-known caveats in the EHR. To overcome this limitation, in this paper, we fuse more detailed and accurate information in the form of natural language provided by unstructured clinical data sources (i.e., clinical notes). We propose HORDE, a unified graph representation learning framework to embed heterogeneous medical entities into a harmonized space for further downstream analyses as well as robustness to inconsistency in structured codes. Our extensive experiments demonstrate that HORDE significantly improves the performances of conventional clinical tasks such as subsequent code prediction and patient severity classification compared to existing methods, and also show the promising results of a novel EHR analysis about the consistency of each diagnosis code assignment.",,,,,,,,,5,0,0,0,3,0,5,,,1532-0464,1532-0480,,WOS:000540241000002,32339747,
J,"Miller, Timothy A.; Avillach, Paul; Mandl, Kenneth D.",,,,,"Miller, Timothy/0000-0003-4513-403X",,,"Experiences implementing scalable, containerized, cloud-based NLP for extracting biobank participant phenotypes at scale",,,,,,,,JAMIA OPEN,,,,3,2,,,185,189,,10.1093/jamiaopen/ooaa016,,,,JUL 2020,2020,"Objective: To develop scalable natural language processing (NLP) infrastructure for processing the free text in electronic health records (EHRs).Materials and Methods: We extend the open-source Apache cTAKES NLP software with several standard technologies for scalability. We remove processing bottlenecks by monitoring component queue size. We process EHR free text for patients in the PrecisionLink Biobank at Boston Children's Hospital. The extracted concepts are made searchable via a web-based portal.Results: We processed over 1.2 million notes for over 8000 patients, extracting 154 million concepts. Our largest tested configuration processes over 1 million notes per day.Discussion: The unique information represented by extracted NLP concepts has great potential to provide a more complete picture of patient status.Conclusion: NLP large EHR document collections can be done efficiently, in service of high throughput phenotyping.",,,,,,,,,1,0,0,0,0,0,1,,,,2574-2531,,WOS:000645439900010,32734158,
J,"Koleck, Theresa A.; Dreisbach, Caitlin; Bourne, Philip E.; Bakken, Suzanne",,,,"Dreisbach, Caitlin/AAG-1093-2019; Dreisbach, Caitlin/ABH-9611-2020; Bourne, Philip/ABG-8967-2021","Bourne, Philip/0000-0002-7618-7292",,,Natural language processing of symptoms documented in free-text narratives of electronic health records: a systematic review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,4,,,364,379,,10.1093/jamia/ocy173,,,,APR 2019,2019,"Objective Natural language processing (NLP) of symptoms from electronic health records (EHRs) could contribute to the advancement of symptom science. We aim to synthesize the literature on the use of NLP to process or analyze symptom information documented in EHR free-text narratives.Materials and Methods Our search of 1964 records from PubMed and EMBASE was narrowed to 27 eligible articles. Data related to the purpose, free-text corpus, patients, symptoms, NLP methodology, evaluation metrics, and quality indicators were extracted for each study.Results Symptom-related information was presented as a primary outcome in 14 studies. EHR narratives represented various inpatient and outpatient clinical specialties, with general, cardiology, and mental health occurring most frequently. Studies encompassed a wide variety of symptoms, including shortness of breath, pain, nausea, dizziness, disturbed sleep, constipation, and depressed mood. NLP approaches included previously developed NLP tools, classification methods, and manually curated rule-based processing. Only one-third (n=9) of studies reported patient demographic characteristics.Discussion NLP is used to extract information from EHR free-text narratives written by a variety of healthcare providers on an expansive range of symptoms across diverse clinical specialties. The current focus of this field is on the development of methods to extract symptom information and the use of symptom information for disease classification tasks rather than the examination of symptoms themselves.Conclusion Future NLP studies should concentrate on the investigation of symptoms and symptom documentation in EHR free-text narratives. Efforts should be undertaken to examine patient characteristics and make symptom-related NLP algorithms or pipelines and vocabularies openly available.",,,,,,,,,83,0,0,0,16,0,83,,,1067-5027,1527-974X,,WOS:000461148100011,30726935,
J,"Solares, Jose Roberto Ayala; Raimondi, Francesca Elisa Diletta; Zhu, Yajie; Rahimian, Fatemeh; Canoy, Dexter; Tran, Jenny; Gomes, Ana Catarina Pinho; Payberah, Amir H.; Zottoli, Mariagrazia; Nazarzadeh, Milad; Conrad, Nathalie; Rahimi, Kazem; Salimi-Khorshidi, Gholamreza",,,,"Rahimi, Kazem/AAA-4250-2022; Rahimi, Kazem/Q-1279-2015; Nazarzadeh, Milad/J-8970-2014","Ayala Solares, Jose Roberto/0000-0001-8322-6723; Rahimi, Kazem/0000-0002-4807-4610; Nazarzadeh, Milad/0000-0002-0576-8874; Zhu, Yajie/0000-0003-2490-9609",,,Deep learning for electronic health records: A comparative review of multiple deep neural architectures,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,101,,,,,,103337,10.1016/j.jbi.2019.103337,,,,JAN 2020,2020,"Despite the recent developments in deep learning models, their applications in clinical decision-support systems have been very limited. Recent igitalisation of health records, however, has provided a great platform for the assessment of the usability of such techniques in healthcare. As a result, the field is starting to see a growing number of research papers that employ deep learning on electronic health records (EHR) for personalised prediction of risks and health trajectories. While this can be a promising trend, vast paper-to-paper variability (from data sources and models they use to the clinical questions they attempt to answer) have hampered the field's ability to simply compare and contrast such models for a given application of interest. Thus, in this paper, we aim to provide a comparative review of the key deep learning architectures that have been applied to EHR data. Furthermore, we also aim to: (1) introduce and use one of the world's largest and most complex linked primary care EHR datasets (i.e., Clinical Practice Research Datalink, or CPRD) as a new asset for training such data-hungry models; (2) provide a guideline for working with EHR data for deep learning; (3) share some of the best practices for assessing the goodness of deep-learning models in clinical risk prediction; (4) and propose future research ideas for making deep learning models more suitable for the EHR data. Our results highlight the difficulties of working with highly imbalanced datasets, and show that sequential deep learning architectures such as RNN may be more suitable to deal with the temporal nature of EHR.",,,,,,,,,23,0,0,0,8,0,23,,,1532-0464,1532-0480,,WOS:000525735000004,31916973,
J,"Rasmy, Laila; Wu, Yonghui; Wan, Ningtao; Geng, Xin; Zheng, W. Jim; Wang, Fei; Wu, Hulin; Xu, Hua; Zhi, Degui",,,,,"Rasmy, Laila/0000-0002-2644-4908; Wu, Yonghui/0000-0002-6780-6135",,,A study of generalizability of recurrent neural network-based predictive models for heart failure onset risk using a large and heterogeneous EHR data set,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,84,,,,11,16,,10.1016/j.jbi.2018.06.011,,,,AUG 2018,2018,"Recently, recurrent neural networks (RNNs) have been applied in predicting disease onset risks with Electronic Health Record (EHR) data. While these models demonstrated promising results on relatively small data sets, the generalizability and transferability of those models and its applicability to different patient populations across hospitals have not been evaluated. In this study, we evaluated an RNN model, RETAIN, over Cerner Health Facts (R) EMR data, for heart failure onset risk prediction. Our data set included over 150,000 heart failure patients and over 1,000,000 controls from nearly 400 hospitals. Convincingly, RETAIN achieved an AUC of 82% in comparison to an AUC of 79% for logistic regression, demonstrating the power of more expressive deep learning models for EHR predictive modeling. The prediction performance fluctuated across different patient groups and varied from hospital to hospital. Also, we trained RETAIN models on individual hospitals and found that the model can be applied to other hospitals with only about 3.6% of reduction of AUC. Our results demonstrated the capability of RNN for predictive modeling with large and heterogeneous EHR data, and pave the road for future improvements.",,,,,,,,,21,0,1,0,6,0,22,,,1532-0464,1532-0480,,WOS:000445054800002,29908902,
J,"Chen, Yao; Zhou, Changjiang; Li, Tianxin; Wu, Hong; Zhao, Xia; Ye, Kai; Liao, Jun",,,,,,,,Named entity recognition from Chinese adverse drug event reports with lexical feature based BiLSTM-CRF and tri-training,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,96,,,,,,103252,10.1016/j.jbi.2019.103252,,,,AUG 2019,2019,"Background: The Adverse Drug Event Reports (ADERs) from the spontaneous reporting system are important data sources for studying Adverse Drug Reactions (ADRs) as well as post-marketing pharmacovigilance. Apart from the conventional ADR information contained in the structured section of ADERs, more detailed information such as pre- and post- ADR symptoms, multi-drug usages and ADR-relief treatments are described in the free-text section, which can be mined through Natural Language Processing (NLP) tools.Objective: The goal of this study was to extract ADR-related entities from free-text section of Chinese ADERs, which can act as supplements for the information contained in structured section, so as to further assist in ADR evaluation.Methods: Three models of Conditional Random Field (CRF), Bidirectional Long Short-Term Memory-CRF (BiLSTM-CRF) and Lexical Feature based BiLSTM-CRF (LF-BiLSTM-CRF) were constructed to conduct Named Entity Recognition (NER) tasks in free-text section of Chinese ADERs. A semi-supervised learning method of tritraining was applied on the basis of the three established models to give un-annotated raw data with reliable tags.Results: Among the three basic models, the LF-BiLSTM-CRF achieved the highest average F1 score of 94.35%. After the process of tri-training, almost half of the un-annotated cases were tagged with labels, and the performances of all the three models improved after iterative training.Conclusions: The LF-BiLSTM-CRF model that we constructed could achieve a comparatively high F1 score, and the fusion of CRF, while BiLSTM-CRF and LF-BiLSTM-CRF in tri-training might further strengthen the reliability of predicted tags. The results suggested the usefulness of our methods in developing the specialized NER tools for identifying ADR-related information from Chinese ADERs.",,,,,,,,,13,4,0,0,5,0,17,,,1532-0464,1532-0480,,WOS:000525698100011,31323311,
J,"Fu, Sunyang; Chen, David; He, Huan; Liu, Sijia; Moon, Sungrim; Peterson, Kevin J.; Shen, Feichen; Wang, Liwei; Wang, Yanshan; Wen, Andrew; Zhao, Yiqing; Sohn, Sunghwan; Liu, Hongfang",,,,,"Liu, Sijia/0000-0001-9763-1164; Zhao, Yiqing/0000-0003-2874-8136; Peterson, Kevin/0000-0002-9758-4609; He, Huan/0000-0003-1312-4195; Chen, David/0000-0001-5531-9180; Fu, Sunyang/0000-0003-1691-5179; Wen, Andrew/0000-0001-9090-8028",,,Clinical concept extraction: A methodology review,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,109,,,,,,103526,10.1016/j.jbi.2020.103526,,,,SEP 2020,2020,"Background: Concept extraction, a subdomain of natural language processing (NLP) with a focus on extracting concepts of interest, has been adopted to computationally extract clinical information from text for a wide range of applications ranging from clinical decision support to care quality improvement.Objectives: In this literature review, we provide a methodology review of clinical concept extraction, aiming to catalog development processes, available methods and tools, and specific considerations when developing clinical concept extraction applications.Methods: Based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a literature search was conducted for retrieving EHR-based information extraction articles written in English and published from January 2009 through June 2019 from Ovid MEDLINE In-Process & Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and the ACM Digital Library.Results: A total of 6,686 publications were retrieved. After title and abstract screening, 228 publications were selected. The methods used for developing clinical concept extraction applications were discussed in this review.",,,,,,,,,16,0,0,0,6,0,16,,,1532-0464,1532-0480,,WOS:000575072400010,32768446,
J,"Shi, Jianlin; Liu, Siru; Pruitt, Liese C C; Luppens, Carolyn L; Ferraro, Jeffrey P; Gundlapalli, Adi V; Chapman, Wendy W; Bucher, Brian T",,,,,,,,Using Natural Language Processing to improve EHR Structured Data-based Surgical Site Infection Surveillance.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,794,803,,,,,,2019,2019,"Surgical Site Infection surveillance in healthcare systems is labor intensive and plagued by underreporting as current methodology relies heavily on manual chart review. The rapid adoption of electronic health records (EHRs) has the potential to allow the secondary use of EHR data for quality surveillance programs. This study aims to investigate the effectiveness of integrating natural language processing (NLP) outputs with structured EHR data to build machine learning models for SSI identification using real-world clinical data. We examined a set of models using structured data with and without NLP document-level, mention-level, and keyword features. The top-performing model was based on a Random Forest classifier enhanced with NLP document-level features achieving a 0.58 sensitivity, 0.97 specificity, 0.54 PPV, 0.98 NPV, and 0.52 F0.5 score. We further interrogated the feature contributions, analyzed the errors, and discussed future directions.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:32308875,32308875,
J,"Dong, Xishuang; Chowdhury, Shanta; Qian, Lijun; Li, Xiangfang; Guan, Yi; Yang, Jinfeng; Yu, Qiubin",,,,"Dong, Xishuang/W-1304-2019","Dong, Xishuang/0000-0002-3742-0071",,,Deep learning for named entity recognition on Chinese electronic medical records: Combining deep transfer learning with multitask bi-directional LSTM RNN,,,,,,,,PLOS ONE,,,,14,5,,,,,e0216046,10.1371/journal.pone.0216046,,,,MAY 2 2019,2019,"Specific entity terms such as disease, test, symptom, and genes in Electronic Medical Record (EMR) can be extracted by Named Entity Recognition (NER). However, limited resources of labeled EMR pose a great challenge for mining medical entity terms. In this study, a novel multitask bi-directional RNN model combined with deep transfer learning is proposed as a potential solution of transferring knowledge and data augmentation to enhance NER performance with limited data. The proposed model has been evaluated using micro average F-score, macro average F-score and accuracy. It is observed that the proposed model outperforms the baseline model in the case of discharge datasets. For instance, for the case of discharge summary, the micro average F-score is improved by 2.55% and the overall accuracy is improved by 7.53%. For the case of progress notes, the micro average F-score and the overall accuracy are improved by 1.63% and 5.63%, respectively.",,,,,,,,,13,1,0,0,5,0,14,,,1932-6203,,,WOS:000466511200044,31048840,
J,"Hong, Na; Wen, Andrew; Stone, Daniel J.; Tsuji, Shintaro; Kingsbury, Paul R.; Rasmussen, Luke, V; Pacheco, Jennifer A.; Adekkanattu, Prakash; Wang, Fei; Luo, Yuan; Pathak, Jyotishman; Liu, Hongfang; Jiang, Guoqian",,,,"; Luo, Yuan/K-5563-2016","Wang, Fei/0000-0001-9459-9461; Pacheco, Jennifer/0000-0001-8021-5818; Rasmussen, Luke/0000-0002-4497-8049; Luo, Yuan/0000-0003-0195-7456",,,Developing a FHIR-based EHR phenotyping framework: A case study for identification of patients with obesity and multiple comorbidities from discharge summaries,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103310,10.1016/j.jbi.2019.103310,,,,NOV 2019,2019,"Background: Standards-based clinical data normalization has become a key component of effective data integration and accurate phenotyping for secondary use of electronic healthcare records (EHR) data. HL7 Fast Healthcare Interoperability Resources (FHIR) is an emerging clinical data standard for exchanging electronic healthcare data and has been used in modeling and integrating both structured and unstructured EHR data for a variety of clinical research applications. The overall objective of this study is to develop and evaluate a FHIR-based EHR phenotyping framework for identification of patients with obesity and its multiple comorbidities from semi-structured discharge summaries leveraging a FHIR-based clinical data normalization pipeline (known as NLP2FHIR).Methods: We implemented a multi-class and multi-label classification system based on the i2b2 Obesity Challenge task to evaluate the FHIR-based EHR phenotyping framework. Two core parts of the framework are: (a) the conversion of discharge summaries into corresponding FHIR resources - Composition, Condition, MedicationStatement, Procedure and FamilyMemberHistory using the NLP2FHIR pipeline, and (b) the implementation of four machine learning algorithms (logistic regression, support vector machine, decision tree, and random forest) to train classifiers to predict disease state of obesity and 15 comorbidities using features extracted from standard FHIR resources and terminology expansions. We used the macro- and micro-averaged precision (P), recall (R), and F1 score (Fl) measures to evaluate the classifier performance. We validated the framework using a second obesity dataset extracted from the MIMIC-III database.Results: Using the NLP2FHIR pipeline, 1237 clinical discharge summaries from the 2008 i2b2 obesity challenge dataset were represented as the instances of the FHIR Composition resource consisting of 5677 records with 16 unique section types. After the NLP processing and FHIR modeling, a set of 244,438 FHIR clinical resource instances were generated. As the results of the four machine learning classifiers, the random forest algorithm performed the best with Fl-micro(0.9466)/F1-macro(0.7887) and Fl-micro(0.9536)/F1-macro(0.6524) for intuitive classification (reflecting medical professionals' judgments) and textual classification (reflecting the judgments based on explicitly reported information of diseases), respectively. The MIMIC-III obesity dataset was successfully integrated for prediction with minimal configuration of the NLP2FHIR pipeline and machine learning models.Conclusions: The study demonstrated that the FHIR-based EHR phenotyping approach could effectively identify the state of obesity and multiple comorbidities using semi-structured discharge summaries. Our FHIR-based phenotyping approach is a first concrete step towards improving the data aspect of phenotyping portability across EHR systems and enhancing interpretability of the machine learning-based phenotyping algorithms.",,,,,,,,,10,0,0,0,3,0,10,,,1532-0464,1532-0480,,WOS:000525701400013,31622801,
J,"Wang, Qi; Zhou, Yangming; Ruan, Tong; Gao, Daqi; Xia, Yuhang; He, Ping",,,,,"Zhou, Yangming/0000-0002-4254-6517; Wang, Qi/0000-0002-6792-887X",,,Incorporating dictionaries into deep neural networks for the Chinese clinical named entity recognition,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,92,,,,,,103133,10.1016/j.jbi.2019.103133,,,,APR 2019,2019,"Clinical named entity recognition aims to identify and classify clinical terms such as diseases, symptoms, treatments, exams, and body parts in electronic health records, which is a fundamental and crucial task for clinical and translational research. In recent years, deep neural networks have achieved significant success in named entity recognition and many other natural language processing tasks. Most of these algorithms are trained end to end, and can automatically learn features from large scale labeled datasets. However, these data-driven methods typically lack the capability of processing rare or unseen entities. Previous statistical methods and feature engineering practice have demonstrated that human knowledge can provide valuable information for handling rare and unseen cases. In this paper, we propose a new model which combines data-driven deep learning approaches and knowledge-driven dictionary approaches. Specifically, we incorporate dictionaries into deep neural networks. In addition, two different architectures that extend the bi-directional long short-term memory neural network and five different feature representation schemes are also proposed to handle the task. Computational results on the CCKS-2017 Task 2 benchmark dataset show that the proposed method achieves the highly competitive performance compared with the state-of-the-art deep learning methods.",,,,,,,,,40,9,0,0,12,0,49,,,1532-0464,1532-0480,,WOS:000525688900006,30818005,
J,"Xiao, Cao; Choi, Edward; Sun, Jimeng",,,,"Choi, Edward/AAC-8825-2020",,,,Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,10,,,1419,1428,,10.1093/jamia/ocy068,,,,OCT 2018,2018,"Objective: To conduct a systematic review of deep learning models for electronic health record (EHR) data, and illustrate various deep learning architectures for analyzing different data sources and their target applications. We also highlight ongoing research and identify open challenges in building deep learning models of EHRs.Design/method: We searched PubMed and Google Scholar for papers on deep learning studies using EHR data published between January 1, 2010, and January 31, 2018. We summarize them according to these axes: types of analytics tasks, types of deep learning model architectures, special challenges arising from health data and tasks and their potential solutions, as well as evaluation strategies.Results: We surveyed and analyzed multiple aspects of the 98 articles we found and identified the following analytics tasks: disease detection/classification, sequential prediction of clinical events, concept embedding, data augmentation, and EHR data privacy. We then studied how deep architectures were applied to these tasks. We also discussed some special challenges arising from modeling EHR data and reviewed a few popular approaches. Finally, we summarized how performance evaluations were conducted for each task.Discussion: Despite the early success in using deep learning for health analytics applications, there still exist a number of issues to be addressed. We discuss them in detail including data and label availability, the interpretability and transparency of the model, and ease of deployment.",,,,,,,,,169,2,0,0,47,0,171,,,1067-5027,1527-974X,,WOS:000448166200019,29893864,
J,"Yang, Songchun; Zheng, Xiangwen; Xiao, Yu; Yin, Xiangfei; Pang, Jianfei; Mao, Huajian; Wei, Wei; Zhang, Wenqin; Yang, Yu; Xu, Haifeng; Li, Mei; Zhao, Dongsheng",,,,,,,,"Improving Chinese electronic medical record retrieval by field weight assignment, negation detection, and re-ranking",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,119,,,,,,103836,10.1016/j.jbi.2021.103836,,JUN 2021,,JUL 2021,2021,"The technique of information retrieval has been widely used in electronic medical record (EMR) systems. It's a pity that most existing methods have not considered the structures and language features of Chinese EMRs, which affects the performance of retrieval. To improve accuracy and comprehensiveness, we propose an improved algorithm of Chinese EMR retrieval. First, the weights of fields in Chinese EMRs are assigned based on the corresponding importance in clinical applications. Second, negative relations in EMRs are detected, and the retrieval scores of negative terms are adjusted accordingly. Third, the retrieval results are re-ranked by expansion terms and time information to enhance the recall without decreasing precision. Experiment results show that the improved algorithm increases the precision and recall significantly, which shows that the algorithm takes a full account of the characteristics of Chinese EMRs and fits the needs for clinical applications.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000674512900002,34116253,
J,"Liu, Feifan; Pradhan, Richeek; Druhl, Emily; Freund, Elaine; Liu, Weisong; Sauer, Brian C.; Cunningham, Fran; Gordon, Adam J.; Peters, Celena B.; Yu, Hong",,,,"Liu, Feifan/D-2478-2012; Gordon, Adam Joseph/AAX-9001-2020","Liu, Feifan/0000-0003-0881-6365; Gordon, Adam Joseph/0000-0002-2453-8871",,,Learning to detect and understand drug discontinuation events from clinical narratives,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,10,,,943,951,,10.1093/jamia/ocz048,,,,OCT 2019,2019,"Objective: Identifying drug discontinuation (DDC) events and understanding their reasons are important for medication management and drug safety surveillance. Structured data resources are often incomplete and lack reason information. In this article, we assessed the ability of natural language processing (NLP) systems to unlock DDC information from clinical narratives automatically.Materials and Methods: We collected 1867 de-identified providers' notes from the University of Massachusetts Medical School hospital electronic health record system. Then 2 human experts chart reviewed those clinical notes to annotate DDC events and their reasons. Using the annotated data, we developed and evaluated NLP systems to automatically identify drug discontinuations and reasons at the sentence level using a novel semantic enrichment-based vector representation (SEVR) method for enhanced feature representation.Results: Our SEVR-based NLP system achieved the best performance of 0.785 (AUC-ROC) for detecting discontinuation events and 0.745 (AUC-ROC) for identifying reasons when testing this highly imbalanced data, outperforming 2 state-of-the-art non-SEVR-basedmodels. Compared with a rule-based baseline system for discontinuation detection, our system improved the sensitivity significantly (57.75% vs 18.31%, absolute value) while retaining a high specificity of 99.25%, leading to a significant improvement in AUC-ROC by 32.83%(absolute value).Conclusion: Experiments have shown that a high-performance NLP system can be developed to automatically identify DDCs and their reasons from providers' notes. The SEVR model effectively improved the system performance showing better generalization and robustness on unseen test data. Our work is an important step toward identifying reasons for drug discontinuation that will inform drug safety surveillance and pharmacovigilance.",,,,,,,,,4,0,0,0,4,0,4,,,1067-5027,1527-974X,,WOS:000515123700008,31034028,
J,"Zhao, Shan; Cai, Zhiping; Chen, Haiwen; Wang, Ye; Liu, Fang; Liu, Anfeng",,,,,,,,Adversarial training based lattice LSTM for Chinese clinical named entity recognition,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103290,10.1016/j.jbi.2019.103290,,,,NOV 2019,2019,"Clinical named entity recognition (CNER), which intends to automatically detect clinical entities in electronic health record (EHR), is a committed step for further clinical text mining. Recently, more and more deep learning models are used to Chinese CNER. However, these models do not make full use of the information in EHR, for these models are either word-based or character-based. In addition, neural models tend to be locally unstable and even tiny perturbation may mislead them. In this paper, we firstly propose a novel adversarial training based lattice LSTM with a conditional random field layer (AT-lattice LSTM-CRF) for Chinese CNER. Lattice LSTM is used to capture richer information in EHR. As a powerful regularization method, AT can be used to improve the robustness of neural models by adding perturbations to the training data. Then, we conduct experiments on the proposed neural model with dataset of CCKS-2017 Task 2. The results show that the proposed model achieves a highly competitive performance (with an Fl score of 89.64%) compared to other prevalent neural models, which can be a reinforced baseline for further research in this field.",,,,,,,,,15,2,0,0,5,0,17,,,1532-0464,1532-0480,,WOS:000525701400003,31557528,
J,"Lin, Yu-Wei; Zhou, Yuqian; Faghri, Faraz; Shawl, Michael J.; Campbell, Roy H.",,,,"Campbell, Roy/O-1141-2019","Campbell, Roy/0000-0002-3754-7777",,,Analysis and prediction of unplanned intensive care unit readmission using recurrent neural networks with long shortterm memory,,,,,,,,PLOS ONE,,,,14,7,,,,,e0218942,10.1371/journal.pone.0218942,,,,JUL 8 2019,2019,"BackgroundUnplanned readmission of a hospitalized patient is an indicator of patients' exposure to risk and an avoidable waste of medical resources. In addition to hospital readmission, intensive care unit (ICU) readmission brings further financial risk, along with morbidity and mortality risks. Identification of high-risk patients who are likely to be readmitted can provide significant benefits for both patients and medical providers. The emergence of machine learning solutions to detect hidden patterns in complex, multi-dimensional datasets provides unparalleled opportunities for developing an efficient discharge decision-making support system for physicians and ICU specialists.Methods and findingsWe used supervised machine learning approaches for ICU readmission prediction. We used machine learning methods on comprehensive, longitudinal clinical data from the MIMIC-III to predict the ICU readmission of patients within 30 days of their discharge. We incorporate multiple types of features including chart events, demographic, and ICD-9 embeddings. We have utilized recent machine learning techniques such as Recurrent Neural Networks (RNN) with Long Short-Term Memory (LSTM), by this we have been able to incorporate the multivariate features of EHRs and capture sudden fluctuations in chart event features (e.g. glucose and heart rate). We show that our LSTM-based solution can better capture high volatility and unstable status in ICU patients, an important factor in ICU readmission. Our machine learning models identify ICU readmissions at a higher sensitivity rate of 0.742 (95% CI, 0.718-0.766) and an improved Area Under the Curve of 0.791 (95% CI, 0.782-0.800) compared with traditional methods. We perform in-depth deep learning performance analysis, as well as the analysis of each feature contribution to the predictive model.ConclusionOur manuscript highlights the ability of machine learning models to improve our ICU decision-making accuracy and is a real-world example of precision medicine in hospitals. These data-driven solutions hold the potential for substantial clinical impact by augmenting clinical decision-making for physicians and ICU specialists. We anticipate that machine learning models will improve patient counseling, hospital administration, allocation of healthcare resources and ultimately individualized clinical care.",,,,,,,,,27,1,0,0,8,0,28,,,1932-6203,,,WOS:000484939800014,31283759,
J,"Wu, Stephen; Roberts, Kirk; Datta, Surabhi; Du, Jingcheng; Ji, Zongcheng; Si, Yuqi; Soni, Sarvesh; Wang, Qiong; Wei, Qiang; Xiang, Yang; Zhao, Bo; Xu, Hua",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213; Tao, Cui/0000-0002-4267-1924; Du, Jingcheng/0000-0002-0322-4566; Si, Yuqi/0000-0002-8123-8947; Wang, Qiong/0000-0002-7225-5235; Krause, Kate/0000-0001-9473-0335",,,Deep learning in clinical natural language processing: a methodical review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,3,,,457,470,,10.1093/jamia/ocz200,,,,MAR 2020,2020,"Objective: This article methodically reviews the literature on deep learning (DL) for natural language processing (NLP) in the clinical domain, providing quantitative analysis to answer 3 research questions concerning methods, scope, and context of current research.Materials and Methods: We searched MEDLINE, EMBASE, Scopus, the Association for Computing Machinery Digital Library, and the Association for Computational Linguistics Anthology for articles using DL-based approaches to NLP problems in electronic health records. After screening 1,737 articles, we collected data on 25 variables across 212 papers.Results: DL in clinical NLP publications more than doubled each year, through 2018. Recurrent neural networks (60.8%) and word2vec embeddings (74.1%) were the most popular methods; the information extraction tasks of text classification, named entity recognition, and relation extraction were dominant (89.2%). However, there was a long tail of other methods and specific tasks. Most contributions were methodological variants or applications, but 20.8% were new methods of some kind. The earliest adopters were in the NLP community, but the medical informatics community was the most prolific.Discussion: Our analysis shows growing acceptance of deep learning as a baseline for NLP research, and of DL-based NLP in the medical community. A number of common associations were substantiated (eg, the preference of recurrent neural networks for sequence-labeling named entity recognition), while others were surprisingly nuanced (eg, the scarcity of French language clinical NLP with deep learning).Conclusion: Deep learning has not yet fully penetrated clinical NLP and is growing rapidly. This review highlighted both the popular and unique trends in this active field.",,,,,,,,,60,0,0,0,16,0,60,,,1067-5027,1527-974X,,WOS:000548302800014,31794016,
J,"Carson, Nicholas J.; Mullin, Brian; Sanchez, Maria Jose; Lu, Frederick; Yang, Kelly; Menezes, Michelle; Le Cook, Benjamin",,,,"Cook, Benjamin/AAA-3543-2022","Sanchez R., Maria Jose/0000-0001-8551-1368; Lu, Frederick/0000-0002-9884-8231",,,Identification of suicidal behavior among psychiatrically hospitalized adolescents using natural language processing and machine learning of electronic health records,,,,,,,,PLOS ONE,,,,14,2,,,,,e0211116,10.1371/journal.pone.0211116,,,,FEB 19 2019,2019,"ObjectiveThe rapid proliferation of machine learning research using electronic health records to classify healthcare outcomes offers an opportunity to address the pressing public health problem of adolescent suicidal behavior. We describe the development and evaluation of a machine learning algorithm using natural language processing of electronic health records to identify suicidal behavior among psychiatrically hospitalized adolescents.MethodsAdolescents hospitalized on a psychiatric inpatient unit in a community health system in the northeastern United States were surveyed for history of suicide attempt in the past 12 months. A total of 73 respondents had electronic health records available prior to the index psychiatric admission. Unstructured clinical notes were downloaded from the year preceding the index inpatient admission. Natural language processing identified phrases from the notes associated with the suicide attempt outcome. We enriched this group of phrases with a clinically focused list of terms representing known risk and protective factors for suicide attempt in adolescents. We then applied the random forest machine learning algorithm to develop a classification model. The model performance was evaluated using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy.ResultsThe final model had a sensitivity of 0.83, specificity of 0.22, AUC of 0.68, a PPV of 0.42, NPV of 0.67, and an accuracy of 0.47. The terms mostly highly associated with suicide attempt clustered around terms related to suicide, family members, psychiatric disorders, and psychotropic medications.ConclusionThis analysis demonstrates modest success of a natural language processing and machine learning approach to identifying suicide attempt among a small sample of hospitalized adolescents in a psychiatric setting.",,,,,,,,,20,0,0,0,6,0,20,,,1932-6203,,,WOS:000459062900011,30779800,
J,"Oliwa, Tomasz; Furner, Brian; Schmitt, Jessica; Schneider, John; Ridgway, Jessica P.",,,,,"Oliwa, Tomasz/0000-0002-1960-0562; Furner, Brian/0000-0001-7074-7247",,,Development of a predictive model for retention in HIV care using natural language processing of clinical notes,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,1,,,104,112,,10.1093/jamia/ocaa220,,,,JAN 2021,2021,"Objective: Adherence to a treatment plan from HIV-positive patients is necessary to decrease their mortality and improve their quality of life, however some patients display poor appointment adherence and become lost to follow-up (LTFU). We applied natural language processing (NLP) to analyze indications towards or against LTFU in HIV-positive patients' notes.Materials and Methods: Unstructured lemmatized notes were labeled with an LTFU or Retained status using a 183-day threshold. An NLP and supervised machine learning system with a linear model and elastic net regularization was trained to predict this status. Prevalence of characteristics domains in the learned model weights were evaluated.Results: We analyzed 838 LTFU vs 2964 Retained notes and obtained a weighted F1 mean of 0.912 via nested cross-validation; another experiment with notes from the same patients in both classes showed substantially lower metrics. Comorbidities were associated with LTFU through, for instance, HCV (hepatitis C virus) and likewise Good adherence with Retained, represented with Well on ART (antiretroviral therapy).Discussion: Mentions of mental health disorders and substance use were associated with disparate retention outcomes, however history vs active use was not investigated. There remains further need to model transitions between LTFU and being retained in care over time.Conclusion: We provided an important step for the future development of a model that could eventually help to identify patients who are at risk for falling out of care and to analyze which characteristics could be factors for this. Further research is needed to enhance this method with structured electronic medical record fields.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000648972200013,33150369,
J,"Lee, Dongha; Yu, Hwanjo; Jiang, Xiaoqian; Rogith, Deevakar; Gudala, Meghana; Tejani, Mubeen; Zhang, Qiuchen; Xiong, Li",,,,,"Xiong, Li/0000-0001-7354-0428; Lee, Dongha/0000-0003-2173-3476",,,Generating sequential electronic health records using dual adversarial autoencoder,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1411,1419,,10.1093/jamia/ocaa119,,,,SEP 2020,2020,"Objective: Recent studies on electronic health records (EHRs) started to learn deep generative models and synthesize a huge amount of realistic records, in order to address significant privacy issues surrounding the EHR. However, most of them only focus on structured records about patients' independent visits, rather than on chronological clinical records. In this article, we aim to learn and synthesize realistic sequences of EHRs based on the generative autoencoder.Materials and Methods: We propose a dual adversarial autoencoder (DAAE), which learns set-valued sequences of medical entities, by combining a recurrent autoencoder with 2 generative adversarial networks (GANs). DAAE improves the mode coverage and quality of generated sequences by adversarially learning both the continuous latent distribution and the discrete data distribution. Using the MIMIC-III (Medical Information Mart for Intensive Care-III) and UT Physicians clinical databases, we evaluated the performances of DAAE in terms of predictive modeling, plausibility, and privacy preservation.Results: Our generated sequences of EHRs showed the comparable performances to real data for a predictive modeling task, and achieved the best score in plausibility evaluation conducted by medical experts among all baseline models. In addition, differentially private optimization of our model enables to generate synthetic sequences without increasing the privacy leakage of patients' data.Conclusions: DAAE can effectively synthesize sequential EHRs by addressing its main challenges: the synthetic records should be realistic enough not to be distinguished from the real records, and they should cover all the training patients to reproduce the performance of specific downstream tasks.",,,,,,,,,4,0,0,0,1,0,4,,,1067-5027,1527-974X,,WOS:000593113300010,32989459,
J,"Noble, Peter-John Mantyla; Appleton, Charlotte; Radford, Alan David; Nenadic, Goran",,,,,,,,Using topic modelling for unsupervised annotation of electronic health records to identify an outbreak of disease in UK dogs,,,,,,,,PLOS ONE,,,,16,12,,,,,e0260402,10.1371/journal.pone.0260402,,,,DEC 9 2021,2021,"A key goal of disease surveillance is to identify outbreaks of known or novel diseases in a timely manner. Such an outbreak occurred in the UK associated with acute vomiting in dogs between December 2019 and March 2020. We tracked this outbreak using the clinical free text component of anonymised electronic health records (EHRs) collected from a sentinel network of participating veterinary practices. We sourced the free text (narrative) component of each EHR supplemented with one of 10 practitioner-derived main presenting complaints (MPCs), with the 'gastroenteric' MPC identifying cases involved in the disease outbreak. Such clinician-derived annotation systems can suffer from poor compliance requiring retrospective, often manual, coding, thereby limiting real-time usability, especially where an outbreak of a novel disease might not present clinically as a currently recognised syndrome or MPC. Here, we investigate the use of an unsupervised method of EHR annotation using latent Dirichlet allocation topic-modelling to identify topics inherent within the clinical narrative component of EHRs. The model comprised 30 topics which were used to annotate EHRs spanning the natural disease outbreak and investigate whether any given topic might mirror the outbreak time-course. Narratives were annotated using the Gensim Library LdaModel module for the topic best representing the text within them. Counts for narratives labelled with one of the topics significantly matched the disease outbreak based on the practitioner-derived 'gastroenteric' MPC (Spearman correlation 0.978); no other topics showed a similar time course. Using artificially injected outbreaks, it was possible to see other topics that would match other MPCs including respiratory disease. The underlying topics were readily evaluated using simple word-cloud representations and using a freely available package (LDAVis) providing rapid insight into the clinical basis of each topic. This work clearly shows that unsupervised record annotation using topic modelling linked to simple text visualisations can provide an easily interrogable method to identify and characterise outbreaks and other anomalies of known and previously un-characterised diseases based on changes in clinical narratives.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000755037200028,34882714,
J,"Diaz-Garelli, Franck; Lenoir, Kristin M; Wells, Brian J",,,,,,,,Catch Me if You Can: Acute Events Hidden in Structured Chronic Disease Diagnosis Descriptions Show Detectable Recording Patterns in EHR.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,373,382,,,,,,2020,2020,"Our previous research shows that structured cancer DX description data accuracy varied across electronic health record (EHR) segments (e.g. encounter DX, problem list, etc.). We provide initial evidence corroborating these findings in EHRs from patients with diabetes. We hypothesized that the odds of recording an uncontrolled diabetes DX increased after a hemoglobin A1c result above 9% and that this rate would vary across EHR segments. Our statistical models revealed that each DX indicating uncontrolled diabetes was 2.6% more likely to occur post-A1c>9% overall (adj-p=.0005) and 3.9% after controlling for EHR segment (adj-p<.0001). However, odds ratios varied across segments (1.021<OR<1.224, .0001<adj-p<.087). The number of providers (adj-p<.0001) and departments (adjp<.0001) also impacted the number of DX reporting uncontrolled diabetes. Segment heterogeneity must be accounted for when analyzing clinical data. Understanding this phenomenon will support accuracy-driven EHR data extraction to foster reliable secondary analyses of EHR data.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936410,33936410,
J,"Datta, Surabhi; Bernstam, Elmer, V; Roberts, Kirk",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213",,,A frame semantic overview of NLP-based information extraction for cancer-related EHR notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103301,10.1016/j.jbi.2019.103301,,,,DEC 2019,2019,"Objective: There is a lot of information about cancer in Electronic Health Record (EHR) notes that can be useful for biomedical research provided natural language processing (NLP) methods are available to extract and structure this information. In this paper, we present a scoping review of existing clinical NLP literature for cancer.Methods: We identified studies describing an NLP method to extract specific cancer-related information from EHR sources from PubMed, Google Scholar, ACL Anthology, and existing reviews. Two exclusion criteria were used in this study. We excluded articles where the extraction techniques used were too broad to be represented as frames (e.g., document classification) and also where very low-level extraction methods were used (e.g. simply identifying clinical concepts). 78 articles were included in the final review. We organized this information according to frame semantic principles to help identify common areas of overlap and potential gaps.Results: Frames were created from the reviewed articles pertaining to cancer information such as cancer diagnosis, tumor description, cancer procedure, breast cancer diagnosis, prostate cancer diagnosis and pain in prostate cancer patients. These frames included both a definition as well as specific frame elements (i.e. extractable attributes). We found that cancer diagnosis was the most common frame among the reviewed papers (36 out of 78), with recent work focusing on extracting information related to treatment and breast cancer diagnosis.Conclusion: The list of common frames described in this paper identifies important cancer-related information extracted by existing NLP techniques and serves as a useful resource for future researchers requiring cancer information extracted from EHR notes. We also argue, due to the heavy duplication of cancer NLP systems, that a general purpose resource of annotated cancer frames and corresponding NLP tools would be valuable.",,,,,,,,,11,0,0,0,2,0,11,,,1532-0464,1532-0480,,WOS:000525702900001,31589927,
J,"Ashfaq, Awais; Sant'Anna, Anita; Lingman, Markus; Nowaczyk, Slawomir",,,,"Ashfaq, Awais/AAR-9634-2020; Nowaczyk, Sławomir/AAG-5417-2020","Ashfaq, Awais/0000-0001-5688-0156; Nowaczyk, Sławomir/0000-0002-7796-5201",,,Readmission prediction using deep learning on electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,97,,,,,,103256,10.1016/j.jbi.2019.103256,,,,SEP 2019,2019,"Unscheduled 30-day readmissions are a hallmark of Congestive Heart Failure (CHF) patients that pose significant health risks and escalate care cost. In order to reduce readmissions and curb the cost of care, it is important to initiate targeted intervention programs for patients at risk of readmission. This requires identifying high-risk patients at the time of discharge from hospital. Here, using real data from over 7500 CHF patients hospitalized between 2012 and 2016 in Sweden, we built and tested a deep learning framework to predict 30-day unscheduled readmission. We present a cost-sensitive formulation of Long Short-Term Memory (LSTM) neural network using expert features and contextual embedding of clinical concepts. This study targets key elements of an Electronic Health Record (EHR) driven prediction model in a single framework: using both expert and machine derived features, incorporating sequential patterns and addressing the class imbalance problem. We evaluate the contribution of each element towards prediction performance (ROC-AUC, Fl-measure) and costsavings. We show that the model with all key elements achieves higher discrimination ability (AUC: 0.77; Fl: 0.51; Cost: 22% of maximum possible savings) outperforming the reduced models in at least two evaluation metrics. Additionally, we present a simple financial analysis to estimate annual savings if targeted interventions are offered to high risk patients.",,,,,,,,,27,1,0,0,9,0,28,,,1532-0464,1532-0480,,WOS:000525699100005,31351136,
J,"Guo, Aixia; Smith, Sakima; Khan, Yosef M.; Langabeer, James R., II; Foraker, Randi E.",,,,,,,,Application of a time-series deep learning model to predict cardiac dysrhythmias in electronic health records,,,,,,,,PLOS ONE,,,,16,9,,,,,e0239007,10.1371/journal.pone.0239007,,,,SEP 13 2021,2021,"Background Cardiac dysrhythmias (CD) affect millions of Americans in the United States (US), and are associated with considerable morbidity and mortality. New strategies to combat this growing problem are urgently needed.Objectives Predicting CD using electronic health record (EHR) data would allow for earlier diagnosis and treatment of the condition, thus improving overall cardiovascular outcomes. The Guideline Advantage (TGA) is an American Heart Association ambulatory quality clinical data registry of EHR data representing 70 clinics distributed throughout the US, and has been used to monitor outpatient prevention and disease management outcome measures across populations and for longitudinal research on the impact of preventative care.Methods For this study, we represented all time-series cardiovascular health (CVH) measures and the corresponding data collection time points for each patient by numerical embedding vectors. We then employed a deep learning technique-long-short term memory (LSTM) model-to predict CD from the vector of time-series CVH measures by 5-fold cross validation and compared the performance of this model to the results of deep neural networks, logistic regression, random forest, and Naive Bayes models.Results We demonstrated that the LSTM model outperformed other traditional machine learning models and achieved the best prediction performance as measured by the average area under the receiver operator curve (AUROC): 0.76 for LSTM, 0.71 for deep neural networks, 0.66 for logistic regression, 0.67 for random forest, and 0.59 for Naive Bayes. The most influential feature from the LSTM model were blood pressure.Conclusions These findings may be used to prevent CD in the outpatient setting by encouraging appropriate surveillance and management of CVH.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000707114200001,34516567,
J,"Wang, Yanshan; Liu, Sijia; Afzal, Naveed; Rastegar-Mojarad, Majid; Wang, Liwei; Shen, Feichen; Kingsbury, Paul; Liu, Hongfang",,,,"Wang, Yanshan/H-4686-2018","Wang, Yanshan/0000-0003-4433-7839; Liu, Sijia/0000-0001-9763-1164",,,A comparison of word embeddings for the biomedical natural language processing,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,87,,,,12,20,,10.1016/j.jbi.2018.09.008,,,,NOV 2018,2018,"Background: Word embeddings have been prevalently used in biomedical Natural Language Processing (NLP) applications due to the ability of the vector representations being able to capture useful semantic properties and linguistic relationships between words. Different textual resources (e.g., Wikipedia and biomedical literature corpus) have been utilized in biomedical NLP to train word embeddings and these word embeddings have been commonly leveraged as feature input to downstream machine learning models. However, there has been little work on evaluating the word embeddings trained from different textual resources.Methods: In this study, we empirically evaluated word embeddings trained from four different corpora, namely clinical notes, biomedical publications, Wikipedia, and news. For the former two resources, we trained word embeddings using unstructured electronic health record (EHR) data available at Mayo Clinic and articles (MedLit) from PubMed Central, respectively. For the latter two resources, we used publicly available pre-trained word embeddings, GloVe and Google News. The evaluation was done qualitatively and quantitatively. For the qualitative evaluation, we randomly selected medical terms from three categories (i.e., disorder, symptom, and drug), and manually inspected the five most similar words computed by embeddings for each term. We also analyzed the word embeddings through a 2-dimensional visualization plot of 377 medical terms. For the quantitative evaluation, we conducted both intrinsic and extrinsic evaluation. For the intrinsic evaluation, we evaluated the word embeddings' ability to capture medical semantics by measruing the semantic similarity between medical terms using four published datasets: Pedersen's dataset, Hliaoutakis's dataset, MayoSRS, and UMNSRS. For the extrinsic evaluation, we applied word embeddings to multiple downstream biomedical NLP applications, including clinical information extraction (IE), biomedical information retrieval (IR), and relation extraction (RE)-, with data from-shared tasks.Results: The qualitative evaluation shows that the word embeddings trained from EHR and MedLit can find more similar medical terms than those trained from GloVe and Google News. The intrinsic quantitative evaluation verifies that the semantic similarity captured by the word embeddings trained from EHR is closer to human experts' judgments on all four tested datasets. The extrinsic quantitative evaluation shows that the word embeddings trained on EHR achieved the best F1 score of 0.900 for the clinical IE task; no word embeddings improved the performance for the biomedical IR task; and the word embeddings trained on Google News had the best overall F1 score of 0.790 for the RE task.Conclusion: Based on the evaluation results, we can draw the following conclusions. First, the word embeddings trained from EHR and MedLit can capture the semantics of medical terms better, and find semantically relevant medical terms closer to human experts' judgments than those trained from GloVe and Google News. Second, there does not exist a consistent global ranking of word embeddings for all downstream biomedical NLP applications. However, adding word embeddings as extra features will improve results on most downstream tasks. Finally, the word embeddings trained from the biomedical domain corpora do not necessarily have better performance than those trained from the general domain corpora for any downstream biomedical NLP task.",,,,,,,,,117,1,0,0,37,0,118,,,1532-0464,1532-0480,,WOS:000460600700002,30217670,
J,"Hu, Szu-Yeu; Santus, Enrico; Forsyth, Alexander W.; Malhotra, Devvrat; Haimson, Josh; Chatterjee, Neal A.; Kramer, Daniel B.; Barzilay, Regina; Tulsky, James A.; Lindvall, Charlotta",,,,,"Lindvall, Charlotta/0000-0003-2090-2039",,,Can machine learning improve patient selection for cardiac resynchronization therapy?,,,,,,,,PLOS ONE,,,,14,10,,,,,e0222397,10.1371/journal.pone.0222397,,,,OCT 3 2019,2019,"RationaleMultiple clinical trials support the effectiveness of cardiac resynchronization therapy (CRT); however, optimal patient selection remains challenging due to substantial treatment heterogeneity among patients who meet the clinical practice guidelines.ObjectiveTo apply machine learning to create an algorithm that predicts CRT outcome using electronic health record (EHR) data avaible before the procedure.Methods and resultsWe applied machine learning and natural language processing to the EHR of 990 patients who received CRT at two academic hospitals between 2004-2015. The primary outcome was reduced CRT benefit, defined as <0% improvement in left ventricular ejection fraction (LVEF) 6-18 months post-procedure or death by 18 months. Data regarding demographics, laboratory values, medications, clinical characteristics, and past health services utilization were extracted from the EHR available before the CRT procedure. Bigrams (i.e., two-word sequences) were also extracted from the clinical notes using natural language processing. Patients accrued on average 75 clinical notes (SD, 29) before the procedure including data not captured anywhere else in the EHR. A machine learning model was built using 80% of the patient sample (training and validation dataset), and tested on a held-out 20% patient sample (test dataset). Among 990 patients receiving CRT the mean age was 71.6 (SD, 11.8), 78.1% were male, 87.2% non-Hispanic white, and the mean baseline LVEF was 24.8% (SD, 7.69). Out of 990 patients, 403 (40.7%) were identified as having a reduced benefit from the CRT device (<0% LVEF improvement in 25.2%, death by 18 months in 15.6%). The final model identified 26% of these patients at a positive predictive value of 79% (model performance: F-beta (beta = 0.1): 77%; recall 0.26; precision 0.79; accuracy 0.65).ConclusionsA machine learning model that leveraged readily available EHR data and clinical notes identified a subset of CRT patients who may not benefit from CRT before the procedure.",,,,,,,,,12,0,0,0,3,0,12,,,1932-6203,,,WOS:000532398600011,31581234,
J,"Kashyap, Mehr; Seneviratne, Martin; Banda, Juan M.; Falconer, Thomas; Ryu, Borim; Yoo, Sooyoung; Hripcsak, George; Shah, Nigam H.",,,,,"Kashyap, Mehr/0000-0002-7336-1056; Banda, Juan/0000-0001-8499-824X; Ryu, Borim/0000-0002-2000-4565",,,Development and validation of phenotype classifiers across multiple sites in the observational health data sciences and informatics network,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,6,,,877,883,,10.1093/jamia/ocaa032,,,,JUN 2020,2020,"Objective: Accurate electronic phenotyping is essential to support collaborative observational research. Supervised machine learning methods can be used to train phenotype classifiers in a high-throughput manner using imperfectly labeled data. We developed 10 phenotype classifiers using this approach and evaluated performance across multiple sites within the Observational Health Data Sciences and Informatics (OHDSI) network.Materials and Methods: We constructed classifiers using the Automated PHenotype Routine for Observational Definition, Identification, Training and Evaluation (APHRODITE) R-package, an open-source framework for learning phenotype classifiers using datasets in the Observational Medical Outcomes Partnership Common Data Model. We labeled training data based on the presence of multiple mentions of disease-specific codes. Performance was evaluated on cohorts derived using rule-based definitions and real-world disease prevalence. Classifiers were developed and evaluated across 3 medical centers, including 1 international site.Results: Compared to the multiple mentions labeling heuristic, classifiers showed a mean recall boost of 0.43 with a mean precision loss of 0.17. Performance decreased slightly when classifiers were shared across medical centers, with mean recall and precision decreasing by 0.08 and 0.01, respectively, at a site within the USA, and by 0.18 and 0.10, respectively, at an international site.Discussion and Conclusion: We demonstrate a high-throughput pipeline for constructing and sharing phenotype classifiers across sites within the OHDSI network using APHRODITE. Classifiers exhibit good portability between sites within the USA, however limited portability internationally, indicating that classifier generalizability may have geographic limitations, and, consequently, sharing the classifier-building recipe, rather than the pretrained classifiers, may be more useful for facilitating collaborative observational research.",,,,,,,,,4,0,0,0,3,0,4,,,1067-5027,1527-974X,,WOS:000542064800006,32374408,
J,"Patel, Jay; Mowery, Danielle; Krishnan, Anand; Thyvalikakath, Thankam",,,,"Thyvalikakath, Thankam/M-6272-2018","Thyvalikakath, Thankam/0000-0002-7294-2318; Patel, Jay/0000-0003-0559-5958",,,Assessing Information Congruence of Documented Cardiovascular Disease between Electronic Dental and Medical Records.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1442,1450,,,,,,2018,2018,"Dentists are more often treating patients with Cardiovascular Diseases (CVD) in their clinics; therefore, dentists may need to alter treatment plans in the presence of CVD. However, it's unclear to what extent patient-reported CVD information is accurately captured in Electronic Dental Records (EDRs). In this pilot study, we aimed to measure the reliability of patient-reported CVD conditions in EDRs. We assessed information congruence by comparing patients' self-reported dental histories to their original diagnosis assigned by their medical providers in the Electronic Medical Record (EMR). To enable this comparison, we encoded patients CVD information from the free-text data of EDRs into a structured format using natural language processing (NLP). Overall, our NLP approach achieved promising performance extracting patients' CVD-related information. We observed disagreement between self-reported EDR data and physician-diagnosed EMR data.",,,,,,,,,5,0,0,0,2,0,5,,,,1942-597X,,MEDLINE:30815189,30815189,
J,"Lin, Wei-Chun; Goldstein, Isaac H; Hribar, Michelle R; Sanders, David S; Chiang, Michael F",,,,,,,,Predicting Wait Times in Pediatric Ophthalmology Outpatient Clinic Using Machine Learning.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,1121,1128,,,,,,2019,2019,"Patient perceptions of wait time during outpatient office visits can affect patient satisfaction. Providing accurate information about wait times could improve patients' satisfaction by reducing uncertainty. However, these are rarely known about efficient ways to predict wait time in the clinic. Supervised machine learning algorithms is a powerful tool for predictive modeling with large and complicated data sets. In this study, we tested machine learning models to predict wait times based on secondary EHR data in pediatric ophthalmology outpatient clinic. We compared several machine-learning algorithms, including random forest, elastic net, gradient boosting machine, support vector machine, and multiple linear regressions to find the most accurate model for prediction. The importance of the predictors was also identified via machine learning models. In the future, these models have the potential to combine with real-time EHR data to provide real time accurate estimates of patient wait time outpatient clinics.",,,,,,,,,4,0,0,0,0,0,4,,,,1942-597X,,MEDLINE:32308909,32308909,
J,"Li, Ziyi; Roberts, Kirk; Jiang, Xiaoqian; Long, Qi",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213; Long, Qi/0000-0003-0660-5230",,,Distributed learning from multiple EHR databases: Contextual embedding models for medical events,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,92,,,,,,103138,10.1016/j.jbi.2019.103138,,,,APR 2019,2019,"Electronic health record (EHR) data provide promising opportunities to explore personalized treatment regimes and to make clinical predictions. Compared with regular clinical data, EHR data are known for their irregularity and complexity. In addition, analyzing EHR data involves privacy issues and sharing such data is often infeasible among multiple research sites due to regulatory and other hurdles. A recently published work uses contextual embedding models and successfully builds one predictive model for more than seventy common diagnoses. Despite of the high predictive power, the model cannot be generalized to other institutions without sharing data. In this work, a novel method is proposed to learn from multiple databases and build predictive models based on Distributed Noise Contrastive Estimation (Distributed NCE). We use differential privacy to safeguard the intermediary information sharing. The numerical study with a real dataset demonstrates that the proposed method not only can build predictive models in a distributed manner with privacy protection, but also preserve model structure well and achieve comparable prediction accuracy. The proposed methods have been implemented as a stand-alone Python library and the implementation is available on Github (http://github.com/ziyili20/DistributedLearningPredictor) with installation instructions and use-cases.",,,,,,,,,10,0,0,0,3,0,10,,,1532-0464,1532-0480,,WOS:000525688900004,30825539,
J,"Estiri, Hossein; Strasser, Zachary H.; Murphy, Shawn N.",,,,,"Strasser, Zachary/0000-0002-4846-6059; Estiri, Hossein/0000-0002-0204-8978",,,High-throughput phenotyping with temporal sequences,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,772,781,,10.1093/jamia/ocaa288,,,,APR 2021,2021,"Objective: High-throughput electronic phenotyping algorithms can accelerate translational research using data from electronic health record (EHR) systems. The temporal information buried in EHRs is often underutilized in developing computational phenotypic definitions. This study aims to develop a high-throughput phenotyping method, leveraging temporal sequential patterns from EHRs.Materials and Methods: We develop a representation mining algorithm to extract 5 classes of representations from EHR diagnosis and medication records: the aggregated vector of the records (aggregated vector representation), the standard sequential patterns (sequential pattern mining), the transitive sequential patterns (transitive sequential pattern mining), and 2 hybrid classes. Using EHR data on 10 phenotypes from the Mass General Brigham Biobank, we train and validate phenotyping algorithms.Results: Phenotyping with temporal sequences resulted in a superior classification performance across all 10 phenotypes compared with the standard representations in electronic phenotyping. The high-throughput algorithm's classification performance was superior or similar to the performance of previously published electronic phenotyping algorithms. We characterize and evaluate the top transitive sequences of diagnosis records paired with the records of risk factors, symptoms, complications, medications, or vaccinations.Discussion: The proposed high-throughput phenotyping approach enables seamless discovery of sequential record combinations that may be difficult to assume from raw EHR data. Transitive sequences offer more accurate characterization of the phenotype, compared with its individual components, and reflect the actual lived experiences of the patients with that particular disease.Conclusion: Sequential data representations provide a precise mechanism for incorporating raw EHR records into downstream machine learning. Our approach starts with user interpretability and works backward to the technology.",,,,,,,,,1,0,0,0,1,0,1,,,1067-5027,1527-974X,,WOS:000648977500013,33313899,
J,"Zhou, Fang; Gillespie, Avrum; Gligorijevic, Djordje; Gligorijevic, Jelena; Obradovic, Zoran",,,,,"Obradovic, Zoran/0000-0002-2051-0142",,,Use of disease embedding technique to predict the risk of progression to end-stage renal disease,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,105,,,,,,103409,10.1016/j.jbi.2020.103409,,,,MAY 2020,2020,"The accurate prediction of progression of Chronic Kidney Disease (CKD) to End Stage Renal Disease (ESRD) is of great importance to clinicians and a challenge to researchers as there are many causes and even more comorbidities that are ignored by the traditional prediction models. We examine whether utilizing a novel low-dimensional embedding model disease2disease (D2D) learned from a large-scale electronic health records (EHRs) could well clusters the causes of kidney diseases and comorbidities and further improve prediction of progression of CKD to ESRD compared to traditional risk factors. The study cohort consists of 2,507 hospitalized Stage 3 CKD patients of which 1,375 (54.8%) progressed to ESRD within 3 years. We evaluated the proposed unsupervised learning framework by applying a regularized logistic regression model and a cox proportional hazard model respectively, and compared the accuracies with the ones obtained by four alternative models. The results demonstrate that the learned low-dimensional disease representations from EHRs can capture the relationship between vast arrays of diseases, and can outperform traditional risk factors in a CKD progression prediction model. These results can be used both by clinicians in patient care and researchers to develop new prediction methods.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000535653800009,32304869,
J,"Sinnott, Jennifer A.; Cai, Fiona; Yu, Sheng; Hejblum, Boris P.; Hong, Chuan; Kohane, Isaac S.; Liao, Katherine P.",,,,"Hejblum, Boris P/T-5309-2019","Hejblum, Boris P/0000-0003-0646-452X",,,PheProb: probabilistic phenotyping using diagnosis codes to improve power for genetic association studies,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,10,,,1359,1365,,10.1093/jamia/ocy056,,,,OCT 2018,2018,"Objective: Standard approaches for large scale phenotypic screens using electronic health record (EHR) data apply thresholds, such as >= 2 diagnosis codes, to define subjects as having a phenotype. However, the variation in the accuracy of diagnosis codes can impair the power of such screens. Our objective was to develop and evaluate an approach which converts diagnosis codes into a probability of a phenotype (PheProb). We hypothesized that this alternate approach for defining phenotypes would improve power for genetic association studies.Methods: The PheProb approach employs unsupervised clustering to separate patients into 2 groups based on diagnosis codes. Subjects are assigned a probability of having the phenotype based on the number of diagnosis codes. This approach was developed using simulated EHR data and tested in a real world EHR cohort. In the latter, we tested the association between low density lipoprotein cholesterol (LDL-C) genetic risk alleles known for association with hyperlipidemia and hyperlipidemia codes (ICD-9 272.x). PheProb and thresholding approaches were compared.Results: Among n = 1462 subjects in the real world EHR cohort, the threshold-based p-values for association between the genetic risk score (GRS) and hyperlipidemia were 0.126 (>= 1 code), 0.123 (>= 2 codes), and 0.142 (>= 3 codes). The PheProb approach produced the expected significant association between the GRS and hyperlipidemia: p = .001.Conclusions: PheProb improves statistical power for association studies relative to standard thresholding approaches by leveraging information about the phenotype in the billing code counts. The PheProb approach has direct applications where efficient approaches are required, such as in Phenome-Wide Association Studies.",,,,,,,,,6,0,0,0,3,0,6,,,1067-5027,1527-974X,,WOS:000448166200011,29788308,
J,"Santiso, Sara; Perez, Alicia; Casillas, Arantza; Oronoz, Maite",,,,"Pérez, Alicia/AAF-7338-2019; CASILLAS RUBIO, ARANTZA/B-8954-2018","Pérez, Alicia/0000-0003-2638-9598; ORONOZ ANCHORDOQUI, MAITE/0000-0001-9097-6047; CASILLAS RUBIO, ARANTZA/0000-0003-4248-8182",,,Neural negated entity recognition in Spanish electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,105,,,,,,103419,10.1016/j.jbi.2020.103419,,,,MAY 2020,2020,"This work deals with negation detection in the context of clinical texts. Negation detection is a key for decision support systems since negated events (detection of absence of some events) help ascertain current medical conditions. For artificial intelligence, negation detection is a valuable point as it can revert the meaning of a part of a text and, accordingly, influence other tasks such as medical dosage adjustment, the detection of adverse drug reactions or hospital acquired diseases.We focus on negated medical events such as disorders, findings and allergies. From Natural Language Processing (NLP) background, we refer to them as negated medical entities. A novelty of this work is that we approached this task as Named Entity Recognition (NER) with the restriction that just negated medical entities must be recognized (in an attempt to help distinguish them from non-negated ones).Our study is driven with Electronic Health Records (EHRs) written in Spanish. A challenge to cope with is the lexical variability (alternative medical forms, abbreviations, etc.). To this end, we employed an approach based on deep learning. Specifically, the system combines character embeddings to cope with out-of-vocabulary (OOV) words, Long Short-Term Memory (LSTM) networks to model contextual representations and it makes use of Conditional Random Fields (CRF) to classify each medical entity as either negated or not given the contextual dense representation. Moreover, we explored both embeddings created from words and embeddings created from lemmas.The best results were obtained with the lemmatized embeddings. Apparently, this approach reinforced the capability of the LSTMs to cope with the high lexical variability. The f-measure for exact-match was 65.1 and 82.4 for the partial-match.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000535653800008,32298847,
J,"Claerhout, Brecht; Kalra, Dipak; Mueller, Christina; Singh, Gurparkash; Ammour, Nadir; Meloni, Laura; Blomster, Juuso; Hopley, Mark; Kafatos, George; Garvey, Almenia; Kuhn, Peter; Lewi, Martine; Vannieuwenhuyse, Bart; Marchal, Benoit; Patel, Ketan; Schindler, Christoph; Sundgren, Mats",,,,"Patel, Ketan/AAB-9932-2019; Kalra, D.K./H-6661-2019","Kalra, D.K./0000-0001-5254-4067",,,Federated electronic health records research technology to support clinical trial protocol optimization: Evidence from EHR4CR and the InSite platform,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,90,,,,,,103090,10.1016/j.jbi.2018.12.004,,,,FEB 2019,2019,"Objective: To determine if inclusion/exclusion (I/E) criteria of clinical trial protocols can be represented as structured queries and executed using a secure federated research platform (InSite) on hospital electronic health records (EHR) systems, to estimate the number of potentially eligible patients.Methods: Twenty-three clinical trial protocols completed during 2011-2017 across diverse disease areas were analyzed to construct queries that were executed with InSite using EHR records from 24 European hospitals containing records of > 14 million patients. The number of patients matching I/E criteria of each protocol was estimated.Results: All protocols could be formalized to some extent into a medical coding system (e.g. ICD-10CM, ATC, LOINC, SNOMED) and mapped to local hospital coding systems. The median number of I/E criteria of protocols tested was 29 (range: 14-47). A median of 55% (range 38-89%) of I/E criteria in each protocol could be transformed into a computable format. The median number of eligible patients identified was 26 per hospital site (range: 1-134).Conclusion: Clinical trial I/E eligibility criteria can be structured computationally and executed as queries on EHR systems to estimate the patient recruitment pool at each site.The results further suggest that an increase in structured coded information in EHRs would increase the number of I/E criteria that could be evaluated. Additional work is needed on broader deployment of federated platforms such as InSite.",,,,,,,,,11,0,0,0,5,0,11,,,1532-0464,1532-0480,,WOS:000462243700003,30611012,
J,"Dong, Xinyu; Deng, Jianyuan; Hou, Wei; Rashidian, Sina; Rosenthal, Richard N.; Saltz, Mary; Saltz, Joel H.; Wang, Fusheng",,,,"Rosenthal, Richard Nelson/AAD-3629-2022; Deng, Jianyuan/ABE-5454-2021; Deng, Jianyuan/ABE-5456-2021","Rosenthal, Richard Nelson/0000-0002-6011-809X; Deng, Jianyuan/0000-0003-0647-1287",,,Predicting opioid overdose risk of patients with opioid prescriptions using electronic health records based on temporal deep learning,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,116,,,,,,103725,10.1016/j.jbi.2021.103725,,APR 2021,,APR 2021,2021,"The US is experiencing an opioid epidemic, and opioid overdose is causing more than 100 deaths per day. Early identification of patients at high risk of Opioid Overdose (OD) can help to make targeted preventative interventions. We aim to build a deep learning model that can predict the patients at high risk for opioid overdose and identify most relevant features. The study included the information of 5,231,614 patients from the Health Facts database with at least one opioid prescription between January 1, 2008 and December 31, 2017. Potential predictors (n = 1185) were extracted to build a feature matrix for prediction. Long Short-Term Memory (LSTM) based models were built to predict overdose risk in the next hospital visit. Prediction performance was compared with other machine learning methods assessed using machine learning metrics. Our sequential deep learning models built upon LSTM outperformed the other methods on opioid overdose prediction. LSTM with attention mechanism achieved the highest F-1 score (F-1 score: 0.7815, AUCROC: 0.8449). The model is also able to reveal top ranked predictive features by permutation important method, including medications and vital signs. This study demonstrates that a temporal deep learning based predictive model can achieve promising results on identifying risk of opioid overdose of patients using the history of electronic health records. It provides an alternative informatics-based approach to improving clinical decision support for possible early detection and intervention to reduce opioid overdose.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000640446800005,33711546,
J,"Dong, Xinyu; Rashidian, Sina; Wang, Yu; Hajagos, Janos; Zhao, Xia; Rosenthal, Richard N; Kong, Jun; Saltz, Mary; Saltz, Joel; Wang, Fusheng",,,,"; Rosenthal, Richard N/A-7632-2009","Wang, Fusheng/0000-0002-9369-9361; Wang, Yu/0000-0003-3991-9009; Hajagos, Janos/0000-0001-6251-9586; Rosenthal, Richard N/0000-0002-6011-809X; Rashidian, Sina/0000-0003-1210-2939",,,Machine Learning Based Opioid Overdose Prediction Using Electronic Health Records.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,389,398,,,,,,2019,2019,"Opioid addiction in the United States has come to national attention as opioid overdose (OD) related deaths have risen at alarming rates. Combating opioid epidemic becomes a high priority for not only governments but also healthcare providers. This depends on critical knowledge to understand the risk of opioid overdose of patients. In this paper, we present our work on building machine learning based prediction models to predict opioid overdose of patients based on the history of patients' electronic health records (EHR). We performed two studies using New York State claims data (SPARCS) with 440,000 patients and Cerner's Health Facts database with 110,000 patients. Our experiments demonstrated that EHR based prediction can achieve best recall with random forest method (precision: 95.3%, recall: 85.7%, F1 score: 90.3%), best precision with deep learning (precision: 99.2%, recall: 77.8%, F1 score: 87.2%). We also discovered that clinical events are among critical features for the predictions.",,,,,,,,,6,0,0,0,3,0,6,,,,1942-597X,,MEDLINE:32308832,32308832,
J,"Suarez-Paniagua, Victor; Rivera Zavala, Renzo M.; Segura-Bedmar, Isabel; Martinez, Paloma",,,,"; SEGURA BEDMAR, ISABEL/L-6077-2017","MARTINEZ, PALOMA/0000-0003-3013-3771; SEGURA BEDMAR, ISABEL/0000-0002-7810-2360",,,A two-stage deep learning approach for extracting entities and relationships from medical texts,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103285,10.1016/j.jbi.2019.103285,,,,NOV 2019,2019,"This work presents a two-stage deep learning system for Named Entity Recognition (NER) and Relation Extraction (RE) from medical texts. These tasks are a crucial step to many natural language understanding applications in the biomedical domain. Automatic medical coding of electronic medical records, automated summarizing of patient records, automatic cohort identification for clinical studies, text simplification of health documents for patients, early detection of adverse drug reactions or automatic identification of risk factors are only a few examples of the many possible opportunities that the text analysis can offer in the clinical domain. In this work, our efforts are primarily directed towards the improvement of the pharmacovigilance process by the automatic detection of drug-drug interactions (DDI) from texts. Moreover, we deal with the semantic analysis of texts containing health information for patients. Our two-stage approach is based on Deep Learning architectures. Concretely, NER is performed combining a bidirectional Long Short-Term Memory (Bi-LSTM) and a Conditional Random Field (CRF), while RE applies a Convolutional Neural Network (CNN). Since our approach uses very few language resources, only the pre-trained word embeddings, and does not exploit any domain resources (such as dictionaries or ontologies), this can be easily expandable to support other languages and clinical applications that require the exploitation of semantic information (concepts and relationships) from texts.During the last years, the task of DDI extraction has received great attention by the BioNLP community. However, the problem has been traditionally evaluated as two separate subtasks: drug name recognition and extraction of DDIs. To the best of our knowledge, this is the first work that provides an evaluation of the whole pipeline. Moreover, our system obtains state-of-the-art results on the eHealth-KD challenge, which was part of the Workshop on Semantic Analysis at SEPLN (TASS-2018).",,,,,,,,,16,0,0,0,6,0,16,,,1532-0464,1532-0480,,WOS:000525701400002,31546016,
J,"Steele, Andrew J.; Denaxas, Spiros C.; Shah, Anoop D.; Hemingway, Harry; Luscombe, Nicholas M.",,,,"Luscombe, Nicholas/G-6011-2015; Shah, Anoop Dinesh/D-4396-2014; Hemingway, Harry/C-1219-2009","Luscombe, Nicholas/0000-0001-5293-4778; Denaxas, Spiros/0000-0001-9612-7791; Shah, Anoop Dinesh/0000-0002-8907-5724; Steele, Andrew/0000-0002-6836-5925; Hemingway, Harry/0000-0003-2279-0624",,,Machine learning models in electronic health records can outperform conventional survival models for predicting patient mortality in coronary artery disease,,,,,,,,PLOS ONE,,,,13,8,,,,,e0202344,10.1371/journal.pone.0202344,,,,AUG 31 2018,2018,"Prognostic modelling is important in clinical practice and epidemiology for patient management and research. Electronic health records (EHR) provide large quantities of data for such models, but conventional epidemiological approaches require significant researcher time to implement. Expert selection of variables, fine-tuning of variable transformations and interactions, and imputing missing values are time-consuming and could bias subsequent analysis, particularly given that missingness in EHR is both high, and may carry meaning. Using a cohort of 80,000 patients from the CALIBER programme, we compared traditional modelling and machine-learning approaches in EHR. First, we used Cox models and random survival forests with and without imputation on 27 expert-selected, preprocessed variables to predict all-cause mortality. We then used Cox models, random forests and elastic net regression on an extended dataset with 586 variables to build prognostic models and identify novel prognostic factors without prior expert input. We observed that data-driven models used on an extended dataset can outperform conventional models for prognosis, without data preprocessing or imputing missing values. An elastic net Cox regression based with 586 unimputed variables with continuous values discretised achieved a C-index of 0.801 (bootstrapped 95% CI 0.799 to 0.802), compared to 0.793 (0.791 to 0.794) for a traditional Cox model comprising 27 expert-selected variables with imputation for missing values. We also found that data-driven models allow identification of novel prognostic variables; that the absence of values for particular variables carries meaning, and can have significant implications for prognosis; and that variables often have a nonlinear association with mortality, which discretised Cox models and random forests can elucidate. This demonstrates that machine-learning approaches applied to raw EHR data can be used to build models for use in research and clinical practice, and identify novel predictive variables and their effects to inform future research.",,,,,,,,,71,0,4,0,24,0,74,,,1932-6203,,,WOS:000443374400010,30169498,
J,"King, Andrew J.; Cooper, Gregory F.; Clermont, Gilles; Hochheiser, Harry; Hauskrecht, Milos; Sittig, Dean F.; Visweswaran, Shyam",,,,"King, Andrew/AAW-5399-2021; Sittig, Dean F./D-2471-2009","King, Andrew/0000-0002-9809-0563; Sittig, Dean F./0000-0001-5811-8915",,,Using machine learning to selectively highlight patient information,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103327,10.1016/j.jbi.2019.103327,,,,DEC 2019,2019,"Background center dot Electronic medical record (EMR) systems need functionality that decreases cognitive overload by drawing the clinician's attention to the right data, at the right time. We developed a Learning EMR (LEMR) system that learns statistical models of clinician information-seeking behavior and applies those models to direct the display of data in future patients. We evaluated the performance of the system in identifying relevant patient data in intensive care unit (ICU) patient cases.Methods: To capture information-seeking behavior, we enlisted critical care medicine physicians who reviewed a set of patient cases and selected data items relevant to the task of presenting at morning rounds. Using patient EMR data as predictors, we built machine learning models to predict their relevancy. We prospectively evaluated the predictions of a set of high performing models.Results: On an independent evaluation data set, 25 models achieved precision of 0.52, 95% CI [0.49, 0.54] and recall of 0.77, 95% CI [0.75, 0.80] in identifying relevant patient data items. For data items missed by the system, the reviewers rated the effect of not seeing those data from no impact to minor impact on patient care in about 82% of the cases.Conclusion: Data-driven approaches for adaptively displaying data in EMR systems, like the LEMR system, show promise in using information-seeking behavior of clinicians to identify and highlight relevant patient data.",,,,,,,,,8,0,0,0,1,0,8,,,1532-0464,1532-0480,,WOS:000525702900022,31676461,
J,"Marzec, Lucas; Raghavan, Sridharan; Banaei-Kashani, Farnoush; Creasy, Seth; Melanson, Edward L.; Lange, Leslie; Ghosh, Debashis; Rosenberg, Michael A.",,,,"Melanson, Edward L/AAY-9224-2021","Rosenberg, Michael/0000-0002-6708-1648; Ghosh, Debashis/0000-0001-6618-1316",,,Device-measured physical activity data for classification of patients with ventricular arrhythmia events: A pilot investigation,,,,,,,,PLOS ONE,,,,13,10,,,,,e0206153,10.1371/journal.pone.0206153,,,,OCT 29 2018,2018,"Low levels of physical activity are associated with increased mortality risk, especially in cardiac patients, but most studies are based on self-report. Cardiac implantable electronic devices (CIEDs) offer an opportunity to collect data for longer periods of time. However, there is limited agreement on the best approaches for quantification of activity measures due to the time series nature of the data. We examined physical activity time series data from 235 subjects with CIEDs and at least 365 days of uninterrupted measures. Summary statistics for raw daily physical activity (minutes/day), including statistical moments (e.g., mean, standard deviation, skewness, kurtosis), time series regression coefficients, frequency domain components, and forecasted predicted values, were calculated for each individual, and used to predict occurrence of ventricular tachycardia (VT) events as recorded by the device. In unsupervised analyses using principal component analysis, we found that while certain features tended to cluster near each other, most provided a reasonable spread across activity space without a large degree of redundancy. In supervised analyses, we found several features that were associated with the outcome (P < 0.05) in univariable and multivariable approaches, but few were consistent across models. Using a machine-learning approach in which the data was split into training and testing sets, and models ranging in complexity from simple univariable logistic regression to ensemble decision trees were fit, there was no improvement in classification of risk over naive methods for any approach. Although standard approaches identified summary features of physical activity data that were correlated with risk of VT, machine-learning approaches found that none of these features provided an improvement in classification. Future studies are needed to explore and validate methods for feature extraction and machine learning in classification of that no competing interests exist. VT risk based on device-measured activity.",,,,,,,,,3,0,0,0,2,0,3,,,1932-6203,,,WOS:000448641200024,30372463,
J,"Kim, Youngjun; Heider, Paul; Meystre, Stephane",,,,,,,,Ensemble-based Methods to Improve De-identification of Electronic Health Record Narratives.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,663,672,,,,,,2018,2018,"Text de-identification is an application of clinical natural language processing that offers significant efficiency and scalability advantages. Hence, various learning algorithms have been applied to this task to yield better performance. Instead of choosing the best individual learning algorithm, we aim to improve de-identification by constructing ensembles that lead to more accurate classification. We present three different ensemble methods that combine multiple de-identification models trained from deep learning, shallow learning, and rule-based approaches. Each model is capable of automated de-identification without manual medical expertise. Our experimental results show that the stacked learning ensemble is more effective than other ensemble methods, producing the highest recall, the most important metric for de-identification. The stacked ensemble achieved state-of-the-art performance on the 2014 i2b2 dataset with 97.04% precision, 94.45% recall, and 95.73% F1 score.",,,,,,,,,6,0,0,0,0,0,6,,,,1942-597X,,MEDLINE:30815108,30815108,
J,"Chen, Peipei; Dong, Wei; Lu, Xudong; Kaymak, Uzay; He, Kunlun; Huang, Zhengxing",,,,"Kaymak, Uzay/A-3364-2008","Kaymak, Uzay/0000-0002-4500-9098; He, Kunlun/0000-0002-3335-5700",,,Deep representation learning for individualized treatment effect estimation using electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103303,10.1016/j.jbi.2019.103303,,,,DEC 2019,2019,"Utilizing clinical observational data to estimate individualized treatment effects (ITE) is a challenging task, as confounding inevitably exists in clinical data. Most of the existing models for ITE estimation tackle this problem by creating unbiased estimators of the treatment effects. Although valuable, learning a balanced representation is sometimes directly opposed to the objective of learning an effective and discriminative model for ITE estimation. We propose a novel hybrid model bridging multi-task deep learning and K-nearest neighbors (KNN) for ITE estimation. In detail, the proposed model firstly adopts multi-task deep learning to extract both outcome-predictive and treatment-specific latent representations from Electronic Health Records (EHR), by jointly performing the outcome prediction and treatment category classification. Thereafter, we estimate counterfactual outcomes by KNN based on the learned hidden representations. We validate the proposed model on a widely used semi-simulated dataset, i.e. IHDP, and a real-world clinical dataset consisting of 736 heart failure (HF) patients. The performance of our model remains robust and reaches 1.7 and 0.23 in terms of Precision in the estimation of heterogeneous effect (PEHE) and average treatment effect (ATE), respectively, on IHDP dataset, and 0.703 and 0.796 in terms of accuracy and F1 score respectively, on HF dataset. The results demonstrate that the proposed model achieves competitive performance over state-of-the-art models. In addition, the results reveal several findings which are consistent with existing medical domain knowledge, and discover certain suggestive hypotheses that could be validated through further investigations in the clinical domain.",,,,,,,,,6,0,0,0,3,0,6,,,1532-0464,1532-0480,,WOS:000525702900009,31610264,
J,"Nagarajan, Gayathri; Babu, L. D. Dhinesh",,,,"D, Dhinesh Babu L/K-6683-2017","D, Dhinesh Babu L/0000-0002-3354-8713",,,A hybrid of whale optimization and late acceptance hill climbing based imputation to enhance classification performance in electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,94,,,,,,103190,10.1016/j.jbi.2019.103190,,,,JUN 2019,2019,"Electronic health records (EHR) are a major source of information in biomedical informatics. Yet, missing values are prominent characteristics of EHR. Prediction on dataset with missing values results in inaccurate inferences. Nearest neighbour imputation based on lazy learning approach is a proven technique for missing data imputation and is recognized as one among the top ten data mining algorithms due to its simplicity and understandability. But its performance is deteriorated due to the curse of dimensionality as unimportant features are likely to dominate. We address this problem by proposing a novel approach for feature weighting based on a hybrid of metaheuristic whale optimization algorithm (WOA) and local search late acceptance hill climbing algorithm (LAHCA) on nearest neighbour imputation method. Our proposed approach Metaheuristic and Local Search based Feature Weighted Nearest Neighbour Imputation (kNN +LAHCAWOA) also learns different k values for different test points. Our approach is tested on benchmark EHR datasets with three proven classifiers Support Vector Machines(SVM), Random forest(RF) and Deep neural networks(DNN). The results prove that kNN + LAHCAWOA is an effective imputation strategy and aids in improving the classification performance when compared with its competitor methods.",,,,,,,,,5,0,0,0,0,0,5,,,1532-0464,1532-0480,,WOS:000525692600005,31054960,
J,"Weegar, Rebecka; Sundstrom, Karin",,,,,"Sundstrom, Karin/0000-0002-6865-0224",,,Using machine learning for predicting cervical cancer from Swedish electronic health records by mining hierarchical representations,,,,,,,,PLOS ONE,,,,15,8,,,,,e0237911,10.1371/journal.pone.0237911,,,,AUG 21 2020,2020,"Electronic health records (EHRs) contain rich documentation regarding disease symptoms and progression, but EHR data is challenging to use for diagnosis prediction due to its high dimensionality, relative scarcity, and substantial level of noise. We investigated how to best represent EHR data for predicting cervical cancer, a serious disease where early detection is beneficial for the outcome of treatment. A case group of 1321 patients with cervical cancer were matched to ten times as many controls, and for both groups several types of events were extracted from their EHRs. These events included clinical codes, lab results, and contents of free text notes retrieved using a LSTM neural network. Clinical events are described with great variation in EHR texts, leading to a very large feature space. Therefore, an event hierarchy inferred from the textual events was created to represent the clinical texts. Overall, the events extracted from free text notes contributed the most to the final prediction, and the hierarchy of textual events further improved performance. Four classifiers were evaluated for predicting a future cancer diagnosis where Random Forest achieved the best results with an AUC of 0.70 from a year before diagnosis up to 0.97 one day before diagnosis. We conclude that our approach is sound and had excellent discrimination at diagnosis, but only modest discrimination capacity before this point. Since our study objective was earlier disease prediction than such, we propose further work should consider extending patient histories through e.g. the integration of primary health records preceding referral to hospital.",,,,,,,,,4,0,0,0,1,0,4,,,1932-6203,,,WOS:000564080300039,32822401,
J,"Badger, Jonathan; LaRose, Eric; Mayer, John; Bashiri, Fereshteh; Page, David; Peissig, Peggy",,,,"Bashiri, Fereshteh/T-3941-2019","Badger, Jonathan/0000-0001-9924-2648",,,Machine learning for phenotyping opioid overdose events,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,94,,,,,,103185,10.1016/j.jbi.2019.103185,,,,JUN 2019,2019,"Objective: To develop machine learning models for classifying the severity of opioid overdose events from clinical data.Materials and methods: Opioid overdoses were identified by diagnoses codes from the Marshfield Clinic population and assigned a severity score via chart review to form a gold standard set of labels. Three primary feature sets were constructed from disparate data sources surrounding each event and used to train machine learning models for phenotyping.Results: Random forest and penalized logistic regression models gave the best performance with cross-validated mean areas under the ROC curves (AUCs) for all severity classes of 0.893 and 0.882 respectively. Features derived from a common data model outperformed features collected from disparate data sources for the same cohort of patients (AUCs 0.893 versus 0.837, p value = 0.002). The addition of features extracted from free text to machine learning models also increased AUCs from 0.827 to 0.893 (p value < 0.0001). Key word features extracted using natural language processing (NLP) such as 'Narcan' and 'Endotracheal Tube' are important for classifying overdose event severity.Conclusion: Random forest models using features derived from a common data model and free text can be effective for classifying opioid overdose events.",,,,,,,,,8,0,0,0,3,0,8,,,1532-0464,1532-0480,,WOS:000525692600025,31028874,
J,"Chen, Tao; Dredze, Mark; Weiner, Jonathan R.; Kharrazi, Hadi",,,,"Kharrazi, Hadi/Q-1725-2015","Kharrazi, Hadi/0000-0003-1481-4323; Chen, Tao/0000-0002-5334-219X",,,Identifying vulnerable older adult populations by contextualizing geriatric syndrome information in clinical notes of electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,8-9,,,787,795,,10.1093/jamia/ocz093,,,,AUG-SEP 2019,2019,"Objective: Geriatric syndromes such as functional disability and lack of social support are often not encoded in electronic health records (EHRs), thus obscuring the identification of vulnerable older adults in need of additional medical and social services. In this study, we automatically identify vulnerable older adult patients with geriatric syndrome based on clinical notes extracted from an EHR system, and demonstrate how contextual information can improve the process.Materials and Methods: We propose a novel end-to-end neural architecture to identify sentences that contain geriatric syndromes. Our model learns a representation of the sentence and augments it with contextual information: surrounding sentences, the entire clinical document, and the diagnosis codes associated with the document. We trained our system on annotated notes from 85 patients, tuned the model on another 50 patients, and evaluated its performance on the rest, 50 patients.Results: Contextual information improved classification, with the most effective context coming from the surrounding sentences. At sentence level, our best performing model achieved a micro-F-1 of 0.605, significantly outperforming context-free baselines. At patient level, our best model achieved a micro-F-1 of 0.843.Discussion: Our solution can be used to expand the identification of vulnerable older adults with geriatric syndromes. Since functional and social factors are often not captured by diagnosis codes in EHRs, the automatic identification of the geriatric syndrome can reduce disparities by ensuring consistent care across the older adult population.Conclusion: EHR free-text can be used to identify vulnerable older adults with a range of geriatric syndromes.",,,,,,,,,7,0,0,0,1,0,7,,,1067-5027,1527-974X,,WOS:000493114800012,31265063,
J,"Wu, Honghan; Toti, Giulia; Morley, Katherine I.; Ibrahim, Zina M.; Folarin, Amos; Jackson, Richard; Kartoglu, Ismail; Agrawal, Asha; Stringer, Clive; Gale, Darren; Gorrell, Genevieve; Roberts, Angus; Broadbent, Matthew; Stewart, Robert; Dobson, Richard J. B.",,,,"Wu, Honghan/AAT-6084-2020; Folarin, Amos/AAD-5525-2020; Stewart, Robert/B-1667-2010; Morley, Katherine/A-2986-2011; dobson, richard/C-9269-2011","Folarin, Amos/0000-0002-0333-1927; Stewart, Robert/0000-0002-4435-6397; Roberts, Angus/0000-0002-4570-9801; Wu, Honghan/0000-0002-0213-5668; Ibrahim, Zina/0000-0001-6203-2727; Morley, Katherine/0000-0002-2725-5535; dobson, richard/0000-0003-4224-9245",,,"SemEHR: A general-purpose semantic search system to surface semantic data from clinical notes for tailored care, trial recruitment, and clinical research",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,5,,,530,537,,10.1093/jamia/ocx160,,,,MAY 2018,2018,"Objective: Unlocking the data contained within both structured and unstructured components of electronic health records (EHRs) has the potential to provide a step change in data available for secondary research use, generation of actionable medical insights, hospital management, and trial recruitment. To achieve this, we implemented SemEHR, an open source semantic search and analytics tool for EHRs.Methods: SemEHR implements a generic information extraction (IE) and retrieval infrastructure by identifying contextualized mentions of a wide range of biomedical concepts within EHRs. Natural language processing annotations are further assembled at the patient level and extended with EHR-specific knowledge to generate a timeline for each patient. The semantic data are serviced via ontology-based search and analytics interfaces.Results: SemEHR has been deployed at a number of UK hospitals, including the Clinical Record Interactive Search, an anonymized replica of the EHR of the UK South London and Maudsley National Health Service Foundation Trust, one of Europe's largest providers of mental health services. In 2 Clinical Record Interactive Search-based studies, SemEHR achieved 93% (hepatitis C) and 99% (HIV) F-measure results in identifying true positive patients. At King's College Hospital in London, as part of the CogStack program (github. com/cogstack), SemEHR is being used to recruit patients into the UK Department of Health 100 000 Genomes Project (genomicsengland. co. uk). The validation study suggests that the tool can validate previously recruited cases and is very fast at searching phenotypes; time for recruitment criteria checking was reduced from days to minutes. Validated on open intensive care EHR data, Medical Information Mart for Intensive Care III, the vital signs extracted by SemEHR can achieve around 97% accuracy.Conclusion: Results from the multiple case studies demonstrate SemEHR's efficiency: weeks or months of work can be done within hours or minutes in some cases. SemEHR provides a more comprehensive view of patients, bringing in more and unexpected insight compared to study-oriented bespoke IE systems. SemEHR is open source, available at https://github. com/CogStack/SemEHR.",,,,,,,,,30,1,0,0,7,0,31,,,1067-5027,1527-974X,,WOS:000434113200010,29361077,
J,"Zhao, Shiyi; Li, Lishuang; Lu, Hongbin; Zhou, Anqiao; Qian, Shuang",,,,,,,,Associative attention networks for temporal relation extraction from electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103309,10.1016/j.jbi.2019.103309,,,,NOV 2019,2019,"Temporal relations are crucial in constructing a timeline over the course of clinical care, which can help medical practitioners and researchers track the progression of diseases, treatments and adverse reactions over time. Due to the rapid adoption of Electronic Health Records (EHRs) and high cost of manual curation, using Natural Language Processing (NLP) to extract temporal relations automatically has become a promising approach. Typically temporal relation extraction is formulated as a classification problem for the instances of entity pairs, which relies on the information hidden in context. However, EHRs contain an overwhelming amount of entities and a large number of entity pairs gathering in the same context, making it difficult to distinguish instances and identify relevant contextual information for a specific entity pair. All these pose significant challenges towards temporal relation extraction while existing methods rarely pay attention to. In this work, we propose the associative attention networks to address these issues. Each instance is first carved into three segments according to the entity pair to obtain the differentiated representation initially. Then we devise the associative attention mechanism for a further distinction by emphasizing the relevant information, and meanwhile, for the reconstruction of association among segments as the final representation of the whole instance. In addition, position weights are utilized to enhance the performance. We validate the merit of our method on the widely used THYME corpus and achieve an average F1-score of 64.3% over three runs, which outperforms the state-of-the-art by 1.5%.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000525701400012,31627021,
J,"Wen, Guihua; Chen, Hehong; Li, Huihui; Hu, Yang; Li, Yanghui; Wang, Changjun",,,,"Wang, Changjun/AAY-1571-2021","LI, HUIHUI/0000-0003-0463-8178",,,Cross domains adversarial learning for Chinese named entity recognition for online medical consultation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,112,,,,,,103608,10.1016/j.jbi.2020.103608,,,,DEC 2020,2020,"Deep learning methods have been applied to Chinese named entity recognition for the online medical consultation. They require a large number of marked samples. However, no such database is available at present. This paper begins with constructing a larger labelled Chinese texts database for the online medical consultation. Second, a basic framework unit is proposed, which is pre-trained by the transfer learning from both Bidirectional language model and Mask language model trained on the larger unlabelled data. Finally, cross domains adversarial learning (CDAL) for Chinese named entity recognition is proposed to further improve the performance, which not only uses the pre-trained basic framework unit, but also uses the adversarial multi-task learning on both electronic medical record texts and online medical consultation texts. Experimental results validate the effectiveness of CDAL.",,,,,,,,,4,0,0,0,1,0,4,,,1532-0464,1532-0480,,WOS:000615718800007,33132138,
J,"Moskovitch, Robert; Shahar, Yuval; Wang, Fei; Hripcsak, George",,,,"Moskovitch, Robert/AAU-1611-2020; Shahar, Yuval/P-5185-2019","Shahar, Yuval/0000-0003-0328-2333",,,Temporal biomedical data analytics,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,90,,,,,,103092,10.1016/j.jbi.2018.12.006,,,,FEB 2019,2019,,,,,,,,,,6,0,0,0,2,0,6,,,1532-0464,1532-0480,,WOS:000462243700005,30654029,
J,"Cohen, Aaron M.; Chamberlin, Steven; Deloughery, Thomas; Nguyen, Michelle; Bedrick, Steven; Meninger, Stephen; Ko, John J.; Amin, Jigar J.; Wei, Alex J.; Hersh, William; Ramagopalan, Sreeram V.; Ramagopalan, Sreeram V.; Ramagopalan, Sreeram V.; Ramagopalan, Sreeram V.",,,,,"Cohen, Aaron/0000-0002-4610-9912",,,Detecting rare diseases in electronic health records using machine learning and knowledge engineering: Case study of acute hepatic porphyria,,,,,,,,PLOS ONE,,,,15,7,,,,,e0235574,10.1371/journal.pone.0235574,,,,JUL 2 2020,2020,"Background With the growing adoption of the electronic health record (EHR) worldwide over the last decade, new opportunities exist for leveraging EHR data for detection of rare diseases. Rare diseases are often not diagnosed or delayed in diagnosis by clinicians who encounter them infrequently. One such rare disease that may be amenable to EHR-based detection is acute hepatic porphyria (AHP). AHP consists of a family of rare, metabolic diseases characterized by potentially life-threatening acute attacks and chronic debilitating symptoms. The goal of this study was to apply machine learning and knowledge engineering to a large extract of EHR data to determine whether they could be effective in identifying patients not previously tested for AHP who should receive a proper diagnostic workup for AHP. Methods and findings We used an extract of the complete EHR data of 200,000 patients from an academic medical center and enriched it with records from an additional 5,571 patients containing any mention of porphyria in the record. After manually reviewing the records of all 47 unique patients with the ICD-10-CM code E80.21 (Acute intermittent [hepatic] porphyria), we identified 30 patients who were positive cases for our machine learning models, with the rest of the patients used as negative cases. We parsed the record into features, which were scored by frequency of appearance and filtered using univariate feature analysis. We manually choose features not directly tied to provider attributes or suspicion of the patient having AHP. We trained on the full dataset, with the best cross-validation performance coming from support vector machine (SVM) algorithm using a radial basis function (RBF) kernel. The trained model was applied back to the full data set and patients were ranked by margin distance. The top 100 ranked negative cases were manually reviewed for symptom complexes similar to AHP, finding four patients where AHP diagnostic testing was likely indicated and 18 patients where AHP diagnostic testing was possibly indicated. From the top 100 ranked cases of patients with mention of porphyria in their record, we identified four patients for whom AHP diagnostic testing was possibly indicated and had not been previously performed. Based solely on the reported prevalence of AHP, we would have expected only 0.002 cases out of the 200 patients manually reviewed. Conclusions The application of machine learning and knowledge engineering to EHR data may facilitate the diagnosis of rare diseases such as AHP. Further work will recommend clinical investigation to identified patients' clinicians, evaluate more patients, assess additional feature selection and machine learning algorithms, and apply this methodology to other rare diseases. This work provides strong evidence that population-level informatics can be applied to rare diseases, greatly improving our ability to identify undiagnosed patients, and in the future improve the care of these patients and our ability study these diseases. The next step is to learn how best to apply these EHR-based machine learning approaches to benefit individual patients with a clinical study that provides diagnostic testing and clinical follow up for those identified as possibly having undiagnosed AHP.",,,,,,,,,7,0,0,0,3,0,7,,,1932-6203,,,WOS:000549913100061,32614911,
J,"Goenaga, Iakes; Lahuerta, Xabier; Atutxa, Aitziber; Gojenola, Koldo",,,,,"Goenaga, Iakes/0000-0002-0946-5782; Gojenola, Koldo/0000-0002-2116-6611",,,A section identification tool: Towards HL7 CDA/CCR standardization in summaries,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,121,,,,,,103875,10.1016/j.jbi.2021.103875,,JUL 2021,,SEP 2021,2021,"Background. Nowadays, with the digitalization of healthcare systems, huge amounts of clinical narratives are available. However, despite the wealth of information contained in them, interoperability and extraction of relevant information from documents remains a challenge. Objective. This work presents an approach towards automatically standardizing Spanish Electronic Discharge Summaries (EDS) following the HL7 Clinical Document Architecture. We address the task of section annotation in EDSs written in Spanish, experimenting with three different approaches, with the aim of boosting interoperability across healthcare systems and hospitals. Methods. The paper presents three different methods, ranging from a knowledge-based solution by means of manually constructed rules to supervised Machine Learning approaches, using state of the art algorithms like the Perceptron and transfer learning-based Neural Networks. Results. The paper presents a detailed evaluation of the three approaches on two different hospitals. Overall, the best system obtains a 93.03% F-score for section identification. It is worth mentioning that this result is not completely homogeneous over all section types and hospitals, showing that cross-hospital variability in certain sections is bigger than in others. Conclusions. As a main result, this work proves the feasibility of accurate automatic detection and standardization of section blocks in clinical narratives, opening the way to interoperability and secondary use of clinical data.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000694715700011,34325020,
J,"Mahbub, Maria; Srinivasan, Sudarshan; Danciu, Ioana; Peluso, Alina; Begoli, Edmon; Tamang, Suzanne; Peterson, Gregory D",,,,,"Mahbub, Maria/0000-0002-3422-9650; Tamang, Suzanne/0000-0003-2077-4620",,,"Unstructured clinical notes within the 24 hours since admission predict short, mid & long-term mortality in adult ICU patients.",,,,,,,,PloS one,,,,17,1,,,e0262182,e0262182,,10.1371/journal.pone.0262182,,,,2022,2022,"Mortality prediction for intensive care unit (ICU) patients is crucial for improving outcomes and efficient utilization of resources. Accessibility of electronic health records (EHR) has enabled data-driven predictive modeling using machine learning. However, very few studies rely solely on unstructured clinical notes from the EHR for mortality prediction. In this work, we propose a framework to predict short, mid, and long-term mortality in adult ICU patients using unstructured clinical notes from the MIMIC III database, natural language processing (NLP), and machine learning (ML) models. Depending on the statistical description of the patients' length of stay, we define the short-term as 48-hour and 4-day period, the mid-term as 7-day and 10-day period, and the long-term as 15-day and 30-day period after admission. We found that by only using clinical notes within the 24 hours of admission, our framework can achieve a high area under the receiver operating characteristics (AU-ROC) score for short, mid and long-term mortality prediction tasks. The test AU-ROC scores are 0.87, 0.83, 0.83, 0.82, 0.82, and 0.82 for 48-hour, 4-day, 7-day, 10-day, 15-day, and 30-day period mortality prediction, respectively. We also provide a comparative study among three types of feature extraction techniques from NLP: frequency-based technique, fixed embedding-based technique, and dynamic embedding-based technique. Lastly, we provide an interpretation of the NLP-based predictive models using feature-importance scores.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:34990485,34990485,
J,"Kronzer, Vanessa L.; Wang, Liwei; Liu, Hongfang; Davis, John M., III; Sparks, Jeffrey A.; Crowson, Cynthia S.",,,,"Sparks, Jeffrey/Z-1574-2018","Sparks, Jeffrey/0000-0002-5556-4618; Davis, John/0000-0002-9710-8143; Kronzer, Vanessa/0000-0002-7489-3134",,,Investigating the impact of disease and health record duration on the eMERGE algorithm for rheumatoid arthritis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,4,,,601,605,,10.1093/jamia/ocaa014,,,,APR 2020,2020,"Objective: The study sought to determine the dependence of the Electronic Medical Records and Genomics (eMERGE) rheumatoid arthritis (RA) algorithm on both RA and electronic health record (EHR) duration.Materials and Methods: Using a population-based cohort from the Mayo Clinic Biobank, we identified 497 patients with at least 1 RA diagnosis code. RA case status was manually determined using validated criteria for RA. RA duration was defined as time from first RA code to the index date of biobank enrollment. To simulate EHR duration, various years of EHR lookback were applied, starting at the index date and going backward. Model performance was determined by sensitivity, specificity, positive predictive value, negative predictive value, and area under the curve (AUC).Results: The eMERGE algorithm performed well in this cohort, with overall sensitivity 53%, specificity 99%, positive predictive value 97%, negative predictive value 74%, and AUC 76%. Among patients with RA duration <2 years, sensitivity and AUC were only 9% and 54%, respectively, but increased to 71% and 85% among patients with RA duration >10 years. Longer EHR lookback also improved model performance up to a threshold of 10 years, in which sensitivity reached 52% and AUC 75%. However, optimal EHR lookback varied by RA duration; an EHR lookback of 3 years was best able to identify recently diagnosed RA cases.Conclusions: eMERGE algorithm performance improves with longer RA duration as well as EHR duration up to 10 years, though shorter EHR lookback can improve identification of recently diagnosed RA cases.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000548306200013,32134444,
J,"Chen, Li; Li, Yuanju; Chen, Weipeng; Liu, Xinglong; Yu, Zhonghua; Zhang, Siyuan",,,,,,,,Utilizing soft constraints to enhance medical relation extraction from the history of present illness in electronic medical records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,87,,,,108,117,,10.1016/j.jbi.2018.09.013,,,,NOV 2018,2018,"Relation extraction between medical concepts from electronic medical records has pervasive applications as well as significance. However, previous researches utilizing machine learning algorithms judge the semantic types of medical concept pair mentions independently. In fact, different concept pair mentions in the same context are of dependencies which can provide beneficial evidences for identifying their relation types. To the best of our knowledge, only one study has considered such dependencies in discharge summaries. However, its hard constraints are not applied effectively to the History of Present Illness (HPI) in electronic Medical Records. According to the writing characteristics of HPI records, we generalize two regularities of dependencies among concept pairs mentioned in an HPI record to enhance the performance of relation extraction. We incorporate the two soft constraints corresponding to the regularities and the posterior probabilities returned by a local classifier into a joint inference process which applies Integer Quadratic Programming method to carry out collective classification for all concept pair mentions in an HPI record. We implement four local classification models including support vector machine, logistics regression, random forest and piecewise convolutional neural networks to examine the performance of our approach. A series of experimental results demonstrate that our collective classification method has made a principal improvement and outperforms the other state-of-the-art methods.",,,,,,,,,1,1,0,0,1,0,2,,,1532-0464,1532-0480,,WOS:000460600700011,30292854,
J,"Vo, Kha; Jonnagaddala, Jitendra; Liaw, Siaw-Teng",,,,"Liaw, Siaw-Teng/C-3673-2012","Liaw, Siaw-Teng/0000-0001-5989-3614",,,Statistical supervised meta-ensemble algorithm for medical record linkage,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,95,,,,,,103220,10.1016/j.jbi.2019.103220,,,,JUL 2019,2019,"Identifying unique patients across multiple care facilities or services is a major challenge in providing continuous care and undertaking health research. Identifying and linking patients without compromising privacy and security is an emerging issue in the big data era. The large quantity and complexity of the patient data emphasize the need for effective linkage methods that are both scalable and accurate. In this study, we aim to develop and evaluate an ensemble classification method using the three most typically used supervised learning methods, namely support vector machines, logistic regression and standard feed-forward neural networks, to link records that belong to the same patient across multiple service locations. Our ensemble method is the combination of bagging and stacking. Each base learner's critical hyperparameters were selected through grid search technique. Two synthetic datasets were used in this study namely FEBRL and ePBRN. ePBRN linkage dataset was based on linkage errors noticed in the Australian primary care setting. The overall linkage performance was determined by assessing the blocking performance and classification performance. Our ensemble method outperformed the base learners in all evaluation metrics on one dataset. More specifically, the precision, which is average of individual precision scores in case of base learners increased from 90.70% to 94.85% in FEBRL, and from 62.17% to 99.28% in ePBRN. Similarly, the F-score increased from 94.92% to 98.18% in FEBRL, and from 72.99% to 91.72% in ePBRN. Our experiments suggest that we can significantly improve the linkage performance of individual algorithms by employing ensemble strategies.",,,,,,,,,2,0,0,0,1,0,2,,,1532-0464,1532-0480,,WOS:000525695600015,31158554,
J,"Sun, Hong; Depraetere, Kristof; Meesseman, Laurent; De Roo, Jos; Vanbiervliet, Martijn; De Baerdemaeker, Jos; Muys, Herman; Dossow, Vera von; Hulde, Nikolai; Szymanowsky, Ralph",,,,,"Depraetere, Kristof/0000-0002-3859-3791; Sun, Hong/0000-0002-7112-5420; Meesseman, Laurent/0000-0002-3761-9822; Vanbiervliet, Martijn/0000-0001-6951-4585",,,A scalable approach for developing clinical risk prediction applications in different hospitals,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,118,,,,,,103783,10.1016/j.jbi.2021.103783,,APR 2021,,JUN 2021,2021,"Objective: Machine learning (ML) algorithms are now widely used in predicting acute events for clinical applications. While most of such prediction applications are developed to predict the risk of a particular acute event at one hospital, few efforts have been made in extending the developed solutions to other events or to different hospitals. We provide a scalable solution to extend the process of clinical risk prediction model development of multiple diseases and their deployment in different Electronic Health Records (EHR) systems.& nbsp; Materials and methods: We defined a generic process for clinical risk prediction model development. A calibration tool has been created to automate the model generation process. We applied the model calibration process at four hospitals, and generated risk prediction models for delirium, sepsis and acute kidney injury (AKI) respectively at each of these hospitals.& nbsp; Results: The delirium risk prediction models have on average an area under the receiver-operating characteristic curve (AUROC) of 0.82 at admission and 0.95 at discharge on the test datasets of the four hospitals. The sepsis models have on average an AUROC of 0.88 and 0.95, and the AKI models have on average an AUROC of 0.85 and 0.92, at the day of admission and discharge respectively.& nbsp; Discussion: The scalability discussed in this paper is based on building common data representations (syntactic interoperability) between EHRs stored in different hospitals. Semantic interoperability, a more challenging requirement that different EHRs share the same meaning of data, e.g. a same lab coding system, is not mandated with our approach.& nbsp; & nbsp;Conclusions: Our study describes a method to develop and deploy clinical risk prediction models in a scalable way. We demonstrate its feasibility by developing risk prediction models for three diseases across four hospitals.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000663600500005,33887456,
J,"Zhao, Juan; Feng, QiPing; Wu, Patrick; Warner, Jeremy L.; Denny, Joshua C.; Wei, Wei-Qi",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Warner, Jeremy/0000-0002-2851-7242; Wu, Patrick/0000-0002-1437-6688",,,Using topic modeling via non-negative matrix factorization to identify relationships between genetic variants and disease phenotypes: A case study of Lipoprotein(a) (LPA),,,,,,,,PLOS ONE,,,,14,2,,,,,e0212112,10.1371/journal.pone.0212112,,,,FEB 13 2019,2019,"Genome-wide and phenome-wide association studies are commonly used to identify important relationships between genetic variants and phenotypes. Most studies have treated diseases as independent variables and suffered from the burden of multiple adjustment due to the large number of genetic variants and disease phenotypes. In this study, we used topic modeling via non-negative matrix factorization (NMF) for identifying associations between disease phenotypes and genetic variants. Topic modeling is an unsupervised machine learning approach that can be used to learn patterns from electronic health record data. We chose the single nucleotide polymorphism (SNP) rs10455872 in LPA as the predictor since it has been shown to be associated with increased risk of hyperlipidemia and cardiovascular diseases (CVD). Using data of 12,759 individuals with electronic health records (EHR) and linked DNA samples at Vanderbilt University Medical Center, we trained a topic model using NMF from 1,853 distinct phenotypes and identified six topics. We tested their associations with rs10455872 in LPA. Topics enriched for CVD and hyperlipidemia had positive correlations with rs10455872 (P < 0.001), replicating a previous finding. We also identified a negative correlation between LPA and a topic enriched for lung cancer (P < 0.001) which was not previously identified via phenome-wide scanning. We were able to replicate the top finding in a separate dataset. Our results demonstrate the applicability of topic modeling in exploring the relationship between genetic variants and clinical diseases.",,,,,,,,,4,0,0,0,1,0,4,,,1932-6203,,,WOS:000458761300074,30759150,
J,"Ji, Bin; Li, Shasha; Yu, Jie; Ma, Jun; Tang, Jintao; Wu, Qingbo; Tan, Yusong; Liu, Huijun; Ji, Yun",,,,,"Ji, Bin/0000-0002-5508-5051",,,Research on Chinese medical named entity recognition based on collaborative cooperation of multiple neural network models,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,104,,,,,,103395,10.1016/j.jbi.2020.103395,,,,APR 2020,2020,"Medical named entity recognition (NER) in Chinese electronic medical records (CEMRs) has drawn much research attention, and plays a vital prerequisite role for extracting high-value medical information. In 2018, China Health Information Processing Conference (CHIP2018) organized a medical NER academic competition aiming to extract three types of malignant tumor entity from CEMRs. Since the three types of entity are highly domain-specific and interdependency, extraction of them cannot be achieved with a single neural network model. Based on comprehensive study of the three types of entity and the entity interdependencies, we propose a collaborative cooperation of multiple neural network models based approach, which consists of two BiLSTM-CRF models and a CNN model. In order to tackle the problem that target scene dataset is small and entity distributions are sparse, we introduce non-target scene datasets and propose sentence-level neural network model transfer learning. Based on 30,000 real-world CEMRs, we pre-train medical domain-specific Chinese character embeddings with word2vec, GloVe and ELMo, and apply them to our approach respectively to validate effects of pre-trained language models in Chinese medical NER. Also, as control experiments, we apply Gated Recurrent Unit to our approach. Finally, our approach achieves an overall F1-score of 87.60%, which is the state-of-the-art performance to the best of our knowledge. In addition, our approach has won the champion of the medical NER academic competition organized by 2019 China Conference on Knowledge Graph and Semantic Computing, which proves the outstanding generalization ability of our approach.",,,,,,,,,9,3,0,0,1,0,12,,,1532-0464,1532-0480,,WOS:000525736200008,32109551,
J,"Li, Fei; Yu, Hong",,,,,,,,An investigation of single-domain and multidomain medication and adverse drug event relation extraction from electronic health record notes using advanced deep learning models,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,7,,,646,654,,10.1093/jamia/ocz018,,,,JUL 2019,2019,"Objective: We aim to evaluate the effectiveness of advanced deep learning models (eg, capsule network [CapNet], adversarial training [ADV]) for single-domain and multidomain relation extraction from electronic health record (EHR) notes.Materials and Methods: We built multiple deep learning models with increased complexity, namely a multilayer perceptron (MLP) model and a CapNet model for single-domain relation extraction and fully shared (FS), shared-private (SP), and adversarial training (ADV) modes for multidomain relation extraction. Our models were evaluated in 2 ways: first, we compared our models using our expert-annotated cancer (the MADE1.0 corpus) and cardio corpora; second, we compared our models with the systems in the MADE1.0 and i2b2 challenges.Results: Multidomain models outperform single-domain models by 0.7%-1.4% in F1 (t test P<.05), but the results of FS, SP, and ADV modes are mixed. Our results show that the MLP model generally outperforms the CapNet model by 0.1%-1.0% in F1. In the comparisons with other systems, the CapNet model achieves the state-of-the-art result (87.2% in F1) in the cancer corpus and the MLP model generally outperforms MedEx in the cancer, cardiovascular diseases, and i2b2 corpora.Conclusions: Our MLP or CapNet model generally outperforms other state-of-the-art systems in medication and adverse drug event relation extraction. Multidomain models perform better than single-domain models. However, neither the SP nor the ADV mode can always outperform the FS mode significantly. Moreover, the CapNet model is not superior to the MLP model for our corpora.",,,,,,,,,8,1,0,0,1,0,9,,,1067-5027,1527-974X,,WOS:000474273800010,30938761,
J,"Wang, Liqin; Foer, Dinah; MacPhaul, Erin; Lo, Ying-Chih; Bates, David W.; Zhou, Li",,,,,"Foer, Dinah/0000-0002-0717-5714; Wang, Liqin/0000-0002-8280-8892; Lo, Ying-Chih/0000-0001-6538-842X",,,PASCLex: A comprehensive post-acute sequelae of COVID-19 (PASC) symptom lexicon derived from electronic health record clinical notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,125,,,,,,103951,10.1016/j.jbi.2021.103951,,NOV 2021,,JAN 2022,2022,"Objective: To develop a comprehensive post-acute sequelae of COVID-19 (PASC) symptom lexicon (PASCLex) from clinical notes to support PASC symptom identification and research. Methods: We identified 26,117 COVID-19 positive patients from the Mass General Brigham's electronic health records (EHR) and extracted 328,879 clinical notes from their post-acute infection period (day 51-110 from first positive COVID-19 test). PASCLex incorporated Unified Medical Language System (R) (UMLS) Metathesaurus concepts and synonyms based on selected semantic types. The MTERMS natural language processing (NLP) tool was used to automatically extract symptoms from a development dataset. The lexicon was iteratively revised with manual chart review, keyword search, concept consolidation, and evaluation of NLP output. We assessed the comprehensiveness of PASCLex and the NLP performance using a validation dataset and reported the symptom prevalence across the entire corpus. Results: PASCLex included 355 symptoms consolidated from 1520 UMLS concepts of 16,466 synonyms. NLP achieved an averaged precision of 0.94 and an estimated recall of 0.84. Symptoms with the highest frequency included pain (43.1%), anxiety (25.8%), depression (24.0%), fatigue (23.4%), joint pain (21.0%), shortness of breath (20.8%), headache (20.0%), nausea and/or vomiting (19.9%), myalgia (19.0%), and gastroesophageal reflux (18.6%). Discussion and conclusion: PASC symptoms are diverse. A comprehensive lexicon of PASC symptoms can be derived using an ontology-driven, EHR-guided and NLP-assisted approach. By using unstructured data, this approach may improve identification and analysis of patient symptoms in the EHR, and inform prospective study design, preventative care strategies, and therapeutic interventions for patient care.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000735573800003,34785382,
J,"Wang, Jingqi; Abu-el-Rub, Noor; Gray, Josh; Pham, Huy Anh; Zhou, Yujia; Manion, Frank J.; Liu, Mei; Song, Xing; Xu, Hua; Rouhizadeh, Masoud; Zhang, Yaoyun",,,,"Gray, Josh/AAC-3394-2019","Gray, Josh/0000-0002-3388-5867; Liu, Mei/0000-0002-8036-2110; Zhou, Yujia/0000-0003-0889-2261",,,COVID-19 SignSym: a fast adaptation of a general clinical NLP tool to identify and normalize COVID-19 signs and symptoms to OMOP common data model,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1275,1283,,10.1093/jamia/ocab015,,MAR 2021,,JUN 2021,2021,"The COVID-19 pandemic swept across the world rapidly, infecting millions of people. An efficient tool that can accurately recognize important clinical concepts of COVID-19 from free text in electronic health records (EHRs) will be valuable to accelerate COVID-19 clinical research. To this end, this study aims at adapting the existing CLAMP natural language processing tool to quickly build COVID-19 SignSym, which can extract COVID-19 signs/symptoms and their 8 attributes (body location, severity, temporal expression, subject, condition, uncertainty, negation, and course) from clinical text. The extracted information is also mapped to standard concepts in the Observational Medical Outcomes Partnership common data model. A hybrid approach of combining deep learning-based models, curated lexicons, and pattern-based rules was applied to quickly build the COVID-19 SignSym from CLAMP, with optimized performance. Our extensive evaluation using 3 external sites with clinical notes of COVID-19 patients, as well as the online medical dialogues of COVID-19, shows COVID-19 SignSym can achieve high performance across data sources. The workflow used for this study can be generalized to other use cases, where existing clinical natural language processing tools need to be customized for specific information needs within a short time. COVID-19 SignSym is freely accessible to the research community as a downloadable package (https://clamp.uth.edu/covid/nlp.php) and has been used by 16 healthcare organizations to support clinical research of COVID-19.",,,,,,,,,7,0,0,0,4,0,7,,,1067-5027,1527-974X,,WOS:000671031900026,33674830,
J,"Sohn, Sunghwan; Wang, Yanshan; Wi, Chung-Il; Krusemark, Elizabeth A.; Ryu, Euijung; Ali, Mir H.; Juhn, Young J.; Liu, Hongfang",,,,"Wang, Yanshan/H-4686-2018","Wang, Yanshan/0000-0003-4433-7839",,,Clinical documentation variations and NLP system portability: a case study in asthma birth cohorts across institutions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,3,,,353,359,,10.1093/jamia/ocx138,,,,MAR 2018,2018,"Objective: To assess clinical documentation variations across health care institutions using different electronic medical record systems and investigate how they affect natural language processing (NLP) system portability.Materials and Methods: Birth cohorts from Mayo Clinic and Sanford Children's Hospital (SCH) were used in this study (n = 298 for each). Documentation variations regarding asthma between the 2 cohorts were examined in various aspects: (1) overall corpus at the word level (ie, lexical variation), (2) topics and asthma-related concepts (ie, semantic variation), and (3) clinical note types (ie, process variation). We compared those statistics and explored NLP system portability for asthma ascertainment in 2 stages: prototype and refinement.Results: There exist notable lexical variations (word-level similarity = 0.669) and process variations (differences in major note types containing asthma-related concepts). However, semantic-level corpora were relatively homogeneous (topic similarity = 0.944, asthma-related concept similarity = 0.971). The NLP system for asthma ascertainment had an F-score of 0.937 at Mayo, and produced 0.813 (prototype) and 0.908 (refinement) when applied at SCH.Discussion: The criteria for asthma ascertainment are largely dependent on asthma-related concepts. Therefore, we believe that semantic similarity is important to estimate NLP system portability. As the Mayo Clinic and SCH corpora were relatively homogeneous at a semantic level, the NLP system, developed at Mayo Clinic, was imported to SCH successfully with proper adjustments to deal with the intrinsic corpus heterogeneity.",,,,,,,,,20,0,0,0,1,0,20,,,1067-5027,1527-974X,,WOS:000426850500018,29202185,
J,"McNeer, Elizabeth; Beck, Cole; Weeks, Hannah L.; Williams, Michael L.; James, Nathan T.; Bejan, Cosmin A.; Choi, Leena",,,,,"James, Nathan/0000-0001-7079-9151; Choi, Leena/0000-0002-2544-7090; Beck, Cole/0000-0002-6849-6255; Williams, Michael/0000-0003-4991-2329; Weeks, Hannah/0000-0002-0262-6790",,,Building longitudinal medication dose data using medication information extracted from clinical notes in electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,782,790,,10.1093/jamia/ocaa291,,,,APR 2021,2021,"Objective: To develop an algorithm for building longitudinal medication dose datasets using information extracted from clinical notes in electronic health records (EHRs).Materials and Methods: We developed an algorithm that converts medication information extracted using natural language processing (NLP) into a usable format and builds longitudinal medication dose datasets. We evaluated the algorithm on 2 medications extracted from clinical notes of Vanderbilt's EHR and externally validated the algorithm using clinical notes from the MIMIC-III clinical care database.Results: For the evaluation using Vanderbilt's EHR data, the performance of our algorithm was excellent; F1-measures were >= 0.98 for both dose intake and daily dose. For the external validation using MIMIC-III, the algorithm achieved F1-measures >= 0.85 for dose intake and >= 0.82 for daily dose.Discussion: Our algorithm addresses the challenge of building longitudinal medication dose data using information extracted from clinical notes. Overall performance was excellent, but the algorithm can perform poorly when incorrect information is extracted by NLP systems. Although it performed reasonably well when applied to the external data source, its performance was worse due to differences in the way the drug information was written. The algorithm is implemented in the R package, EHR, and the extracted data from Vanderbilt's EHRs along with the gold standards are provided so that users can reproduce the results and help improve the algorithm.Conclusion: Our algorithm for building longitudinal dose data provides a straightforward way to use EHR data for medication-based studies. The external validation results suggest its potential for applicability to other systems.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000648977500014,33338223,
J,"Mullin, Sarah; Zola, Jaroslaw; Lee, Robert; Hu, Jinwei; MacKenzie, Brianne; Brickman, Arlen; Anaya, Gabriel; Sinha, Shyamashree; Li, Angie; Elkin, Peter L.",,,,"Lee, Robert/AAV-6870-2020","Lee, Robert/0000-0002-4099-1625",,,Longitudinal K-means approaches to clustering and analyzing EHR opioid use trajectories for clinical subtypes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,122,,,,,,103889,10.1016/j.jbi.2021.103889,,SEP 2021,,OCT 2021,2021,"Identification of patient subtypes from retrospective Electronic Health Record (EHR) data is fraught with inherent modeling issues, such as missing data and variable length time intervals, and the results obtained are highly dependent on data pre-processing strategies. As we move towards personalized medicine, assessing ac-curate patient subtypes will be a key factor in creating patient specific treatment plans. Partitioning longitudinal trajectories from irregularly spaced and variable length time intervals is a well-established, but open problem. In this work, we present and compare k-means approaches for subtyping opioid use trajectories from EHR data. We then interpret the resulting subtypes using decision trees, examining how each subtype is influenced by opioid medication features and patient diagnoses, procedures, and demographics. Finally, we discuss how the subtypes can be incorporated in static machine learning models as features in predicting opioid overdose and adverse events. The proposed methods are general, and can be extended to other EHR prescription dosage trajectories.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000703562100004,34411708,
J,"Ho, Long, V; Aczon, Melissa; Ledbetter, David; Wetzel, Randall",,,,,"Ledbetter, David/0000-0003-0382-5086",,,Interpreting a recurrent neural network's predictions of ICU mortality risk,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,114,,,,,,103672,10.1016/j.jbi.2021.103672,,JAN 2021,,FEB 2021,2021,"Deep learning has demonstrated success in many applications; however, their use in healthcare has been limited due to the lack of transparency into how they generate predictions. Algorithms such as Recurrent Neural Networks (RNNs) when applied to Electronic Medical Records (EMR) introduce additional barriers to transparency because of the sequential processing of the RNN and the multi-modal nature of EMR data. This work seeks to improve transparency by: 1) introducing Learned Binary Masks (LBM) as a method for identifying which EMR variables contributed to an RNN model's risk of mortality (ROM) predictions for critically ill children; and 2) applying KernelSHAP for the same purpose. Given an individual patient, LBM and KernelSHAP both generate an attribution matrix that shows the contribution of each input feature to the RNN's sequence of predictions for that patient. Attribution matrices can be aggregated in many ways to facilitate different levels of analysis of the RNN model and its predictions. Presented are three methods of aggregations and analyses: 1) over volatile time periods within individual patient predictions, 2) over populations of ICU patients sharing specific diagnoses, and 3) across the general population of critically ill children.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000695470600001,33422663,
J,"Niu, Ke; Lu, You; Peng, Xueping; Zeng, Jingni",,,,,"Peng, Xueping/0000-0002-8901-1472",,,Fusion of sequential visits and medical ontology for mortality prediction,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,104012,10.1016/j.jbi.2022.104012,,,,MAR 2022,2022,"The goal of mortality prediction task is to predict the future death risk of patients according to their previous Electronic Healthcare Records (EHR). The main challenge of mortality prediction is how to design an accurate and robust predictive model with sequential, multivariate, sparse and irregular EHR data. In addition, the performance of model may be affected by lack of sufficient information of some patients with rare diseases in EHRs. To address these challenges, we propose a model to fuse Sequential visits and Medical Ontology to predict patients' death risk. SeMO not only learns reasonable embeddings for medical concepts from sequential and irregular visits, but also exploits medical ontology to improve the prediction performance. With integration of multivariate features, SeMO learns robust representations of medical codes, mitigating data insufficiency and insightful sequential dependencies among patient's visits. Experimental results on real world datasets prove that the proposed SeMO improves the prediction performance compared with the baseline approaches. Our model achieves an precision of up to 0.975. Compared with RNN, the precision has been improved up to 2.204%.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000013,35144001,
J,"Cade, Brian E.; Hassan, Syed Moin; Dashti, Hassan S.; Kiernan, Melissa; Pavlova, Milena K.; Redline, Susan; Karlson, Elizabeth W.",,,,,,,,Sleep apnea phenotyping and relationship to disease in a large clinical biobank,,,,,,,,JAMIA OPEN,,,,5,1,,,,,ooab117,10.1093/jamiaopen/ooab117,,,,APR 2022,2022,"Objective: Sleep apnea is associated with a broad range of pathophysiology. While electronic health record (EHR) information has the potential for revealing relationships between sleep apnea and associated risk factors and outcomes, practical challenges hinder its use. Our objectives were to develop a sleep apnea phenotyping algorithm that improves the precision of EHR case/control information using natural language processing (NLP); identify novel associations between sleep apnea and comorbidities in a large clinical biobank; and investigate the relationship between polysomnography statistics and comorbid disease using NLP phenotyping.Materials and Methods: We performed clinical chart reviews on 300 participants putatively diagnosed with sleep apnea and applied International Classification of Sleep Disorders criteria to classify true cases and noncases. We evaluated 2 NLP and diagnosis code-only methods for their abilities to maximize phenotyping precision. The lead algorithm was used to identify incident and cross-sectional associations between sleep apnea and common comorbidities using 4876 NLP-defined sleep apnea cases and 3x matched controls.Results: The optimal NLP phenotyping strategy had improved model precision (>= 0.943) compared to the use of one diagnosis code (<= 0.733). Of the tested diseases, 170 disorders had significant incidence odds ratios (ORs) between cases and controls, 8 of which were confirmed using polysomnography (n= 4544), and 281 disorders had significant prevalence OR between sleep apnea cases versus controls, 41 of which were confirmed using polysomnography data.Discussion and Conclusion: An NLP-informed algorithm can improve the accuracy of case-control sleep apnea ascertainment and thus improve the performance of phenome-wide, genetic, and other EHR analyses of a highly prevalent disorder.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000744381100007,,
J,"Murray, Sara G.; Avati, Anand; Schmajuk, Gabriela; Yazdany, Jinoos",,,,,,,,Automated and flexible identification of complex disease: building a model for systemic lupus erythematosus using noisy labeling,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,1,,,61,65,,10.1093/jamia/ocy154,,,,JAN 2019,2019,"Accurate and efficient identification of complex chronic conditions in the electronic health record (EHR) is an important but challenging task that has historically relied on tedious clinician review and oversimplification of the disease. Here we adapt methods that allow for automated noisy labeling of positive and negative controls to create a silver standard for machine learning to automate identification of systemic lupus erythematosus (SLE). Our final model, which includes both structured data as well as text processing of clinical notes, outperformed all existing algorithms for SLE (AUC 0.97). In addition, we demonstrate how the probabilistic outputs of this model can be adapted to various clinical needs, selecting high thresholds when specificity is the priority and lower thresholds when a more inclusive patient population is desired. Deploying a similar methodology to other complex diseases has the potential to dramatically simplify the landscape of population identification in the EHR.",,,,,,,,,14,0,0,0,3,0,14,,,1067-5027,1527-974X,,WOS:000461520100010,30476175,
J,"Wang, Yanshan; Wang, Liwei; Rastegar-Mojarad, Majid; Moon, Sungrim; Shen, Feichen; Afzal, Naveed; Liu, Sijia; Zeng, Yuqun; Mehrabi, Saeed; Sohn, Sunghwan; Liu, Hongfang",,,,"Wang, Yanshan/H-4686-2018","Wang, Yanshan/0000-0003-4433-7839; Liu, Sijia/0000-0001-9763-1164",,,Clinical information extraction applications: A literature review,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,77,,,,34,49,,10.1016/j.jbi.2017.11.011,,,,JAN 2018,2018,"Background: With the rapid adoption of electronic health records (EHRs), it is desirable to harvest information and knowledge from EHRs to support automated systems at the point of care and to enable secondary use of EHRs for clinical and translational research. One critical component used to facilitate the secondary use of EHR data is the information extraction (IE) task, which automatically extracts and encodes clinical information from text.Objectives: In this literature review, we present a review of recent published research on clinical information extraction (IE) applications.Methods: A literature search was conducted for articles published from January 2009 to September 2016 based on Ovid MEDLINE In-Process Sr Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and ACM Digital Library.Results: A total of 1917 publications were identified for title and abstract screening. Of these publications, 263 articles were selected and discussed in this review in terms of publication venues and data sources, clinical IE tools, methods, and applications in the areas of disease- and drug-related studies, and clinical workflow optimizations.Conclusions: Clinical IE has been used for a wide range of applications, however, there is a considerable gap between clinical studies using EHR data and studies using clinical IE. This study enabled us to gain a more concrete understanding of the gap and to provide potential solutions to bridge this gap.",,,,,,,,,227,6,1,0,52,1,233,,,1532-0464,1532-0480,,WOS:000426221800004,29162496,
J,"Wei, Qiang; Ji, Zongcheng; Li, Zhiheng; Du, Jingcheng; Wang, Jingqi; Xu, Jun; Xiang, Yang; Tiryaki, Firat; Wu, Stephen; Zhang, Yaoyun; Tao, Cui; Xu, Hua",,,,,"Tao, Cui/0000-0002-4267-1924; Du, Jingcheng/0000-0002-0322-4566",,,A study of deep learning approaches for medication and adverse drug event extraction from clinical text,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,13,21,,10.1093/jamia/ocz063,,,,JAN 2020,2020,"Objective: This article presents our approaches to extraction of medications and associated adverse drug events (ADEs) from clinical documents, which is the second track of the 2018 National NLP Clinical Challenges (n2c2) shared task.Materials and Methods: The clinical corpus used in this study was from the MIMIC-III database and the organizers annotated 303 documents for training and 202 for testing. Our system consists of 2 components: a named entity recognition (NER) and a relation classification (RC) component. For each component, we implemented deep learning-based approaches (eg, BI-LSTM-CRF) and compared them with traditional machine learning approaches, namely, conditional random fields for NER and support vector machines for RC, respectively. In addition, we developed a deep learning-based joint model that recognizes ADEs and their relations to medications in 1 step using a sequence labeling approach. To further improve the performance, we also investigated different ensemble approaches to generating optimal performance by combining outputs from multiple approaches.Results: Our best-performing systems achieved F1 scores of 93.45% for NER, 96.30% for RC, and 89.05% for end-to-end evaluation, which ranked #2, #1, and #1 among all participants, respectively. Additional evaluations show that the deep learning-based approaches did outperform traditional machine learning algorithms in both NER and RC. The joint model that simultaneously recognizes ADEs and their relations to medications also achieved the best performance on RC, indicating its promise for relation extraction.Conclusion: In this study, we developed deep learning approaches for extracting medications and their attributes such as ADEs, and demonstrated its superior performance compared with traditional machine learning algorithms, indicating its uses in broader NER and RC tasks in the medical domain.",,,,,,,,,21,0,0,0,8,0,21,,,1067-5027,1527-974X,,WOS:000548300200003,31135882,
J,"Xie, Feng; Yuan, Han; Ning, Yilin; Ong, Marcus Eng Hock; Feng, Mengling; Hsu, Wynne; Chakraborty, Bibhas; Liu, Nan",,,,,"Ning, Yilin/0000-0002-6758-4472; Liu, Nan/0000-0003-3610-4883",,,Deep learning for temporal data representation in electronic health records: A systematic review of challenges and methodologies,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,126,,,,,,103980,10.1016/j.jbi.2021.103980,,,,FEB 2022,2022,"Objective: Temporal electronic health records (EHRs) contain a wealth of information for secondary uses, such as clinical events prediction and chronic disease management. However, challenges exist for temporal data representation. We therefore sought to identify these challenges and evaluate novel methodologies for addressing them through a systematic examination of deep learning solutions. Methods: We searched five databases (PubMed, Embase, the Institute of Electrical and Electronics Engineers [IEEE] Xplore Digital Library, the Association for Computing Machinery [ACM] Digital Library, and Web of Science) complemented with hand-searching in several prestigious computer science conference proceedings. We sought articles that reported deep learning methodologies on temporal data representation in structured EHR data from January 1, 2010, to August 30, 2020. We summarized and analyzed the selected articles from three perspectives: nature of time series, methodology, and model implementation. Results: We included 98 articles related to temporal data representation using deep learning. Four major challenges were identified, including data irregularity, heterogeneity, sparsity, and model opacity. We then studied how deep learning techniques were applied to address these challenges. Finally, we discuss some open challenges arising from deep learning. Conclusion: Temporal EHR data present several major challenges for clinical prediction modeling and data utilization. To some extent, current deep learning solutions can address these challenges. Future studies may consider designing comprehensive and integrated solutions. Moreover, researchers should incorporate clinical domain knowledge into study designs and enhance model interpretability to facilitate clinical implementation.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000767887400004,34974189,
J,"Si, Yuqi; Du, Jingcheng; Li, Zhao; Jiang, Xiaoqian; Miller, Timothy; Wang, Fei; Zheng, W. Jim; Roberts, Kirk",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213; Si, Yuqi/0000-0002-8123-8947",,,Deep representation learning of patient data from Electronic Health Records (EHR): A systematic review,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,115,,,,,,103671,10.1016/j.jbi.2020.103671,,MAR 2021,,MAR 2021,2021,"Objectives: Patient representation learning refers to learning a dense mathematical representation of a patient that encodes meaningful information from Electronic Health Records (EHRs). This is generally performed using advanced deep learning methods. This study presents a systematic review of this field and provides both qualitative and quantitative analyses from a methodological perspective.Methods: We identified studies developing patient representations from EHRs with deep learning methods from MEDLINE, EMBASE, Scopus, the Association for Computing Machinery (ACM) Digital Library, and the Institute of Electrical and Electronics Engineers (IEEE) Xplore Digital Library. After screening 363 articles, 49 papers were included for a comprehensive data collection.Results: Publications developing patient representations almost doubled each year from 2015 until 2019. We noticed a typical workflow starting with feeding raw data, applying deep learning models, and ending with clinical outcome predictions as evaluations of the learned representations. Specifically, learning representations from structured EHR data was dominant (37 out of 49 studies). Recurrent Neural Networks were widely applied as the deep learning architecture (Long short-term memory: 13 studies, Gated recurrent unit: 11 studies). Learning was mainly performed in a supervised manner (30 studies) optimized with cross-entropy loss. Disease prediction was the most common application and evaluation (31 studies). Benchmark datasets were mostly unavailable (28 studies) due to privacy concerns of EHR data, and code availability was assured in 20 studies.Discussion & Conclusion: The existing predictive models mainly focus on the prediction of single diseases, rather than considering the complex mechanisms of patients from a holistic review. We show the importance and feasibility of learning comprehensive representations of patient EHR data through a systematic review. Advances in patient representation learning techniques will be essential for powering patient-level EHR analyses. Future work will still be devoted to leveraging the richness and potential of available EHR data. Reproducibility and transparency of reported results will hopefully improve. Knowledge distillation and advanced learning techniques will be exploited to assist the capability of learning patient representation further.",,,,,,,,,2,0,0,0,2,0,2,,,1532-0464,1532-0480,,WOS:000640492500008,33387683,
J,"Patra, Braja G.; Sharma, Mohit M.; Vekaria, Veer; Adekkanattu, Prakash; Patterson, Olga, V; Glicksberg, Benjamin; Lepow, Lauren A.; Ryu, Euijung; Biernacka, Joanna M.; Furmanchuk, Al'ona; George, Thomas J.; Hogan, William; Wu, Yonghui; Yang, Xi; Bian, Jiang; Weissman, Myrna; Wickramaratne, Priya; Mann, J. John; Olfson, Mark; Campion, Thomas R., Jr.; Weiner, Mark; Pathak, Jyotishman",,,,"Patra, Braja Gopal/P-7126-2018","Patra, Braja Gopal/0000-0003-2997-5314; Glicksberg, Benjamin/0000-0003-4515-8090; George, Thomas/0000-0002-6249-9180; Patterson, Olga V/0000-0002-8717-5975; Furmanchuk, Alona/0000-0001-7419-9620; Vekaria, Veer/0000-0001-9801-2250",,,Extracting social determinants of health from electronic health records using natural language processing: a systematic review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,12,,,2716,2727,,10.1093/jamia/ocab170,,OCT 2021,,DEC 2021,2021,"Objective: Social determinants of health (SDoH) are nonclinical dispositions that impact patient health risks and clinical outcomes. Leveraging SDoH in clinical decision-making can potentially improve diagnosis, treatment planning, and patient outcomes. Despite increased interest in capturing SDoH in electronic health records (EHRs), such information is typically locked in unstructured clinical notes. Natural language processing (NLP) is the key technology to extract SDoH information from clinical text and expand its utility in patient care and research. This article presents a systematic review of the state-of-the-art NLP approaches and tools that focus on identifying and extracting SDoH data from unstructured clinical text in EHRs.Materials and Methods: A broad literature search was conducted in February 2021 using 3 scholarly databases (ACL Anthology, PubMed, and Scopus) following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A total of 6402 publications were initially identified, and after applying the study inclusion criteria, 82 publications were selected for the final review.Results: Smoking status (n=27), substance use (n=21), homelessness (n=20), and alcohol use (n=15) are the most frequently studied SDoH categories. Homelessness (n=7) and other less-studied SDoH (eg, education, financial problems, social isolation and support, family problems) are mostly identified using rule-based approaches. In contrast, machine learning approaches are popular for identifying smoking status (n=13), substance use (n=9), and alcohol use (n=9).Conclusion: NLP offers significant potential to extract SDoH data from narrative clinical notes, which in turn can aid in the development of screening tools, risk prediction models, and clinical decision support systems.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000728261700020,34613399,
J,"Karagounis, Sotiris; Sarkar, Indra Neil; Chen, Elizabeth S",,,,,,,,Coding Free-Text Chief Complaints from a Health Information Exchange: A Preliminary Study.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,638,647,,,,,,2020,2020,"Chief complaints are important textual data that can serve to enrich diagnosis and symptom data in electronic health record (EHR) systems. In this study, a method is presented to preprocess chief complaints and assign corresponding ICD-10-CM codes using the MetaMap natural language processing (NLP) system and Unified Medical Language System (UMLS) Metathesaurus. An exploratory analysis was conducted using a set of 7,942 unique chief complaints from the statewide health information exchange containing EHR data from hospitals across Rhode Island. An evaluation of the proposed method was then performed using a set of 123,086 chief complaints with corresponding ICD-10-CM encounter diagnoses. With 87.82% of MetaMap-extracted concepts correctly assigned, the preliminary findings support the potential use of the method explored in this study for improving upon existing NLP techniques for enabling use of data captured within chief complaints to support clinical care, research, and public health surveillance.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936438,33936438,
J,"Park, Jihyun; Kotzias, Dimitrios; Kuo, Patty; Logan, Robert L.; Merced, Kritzia; Singh, Sameer; Tanana, Michael; Taniskidou, Efi Karra; Lafata, Jennifer Elston; Atkins, David C.; Tai-Seale, Ming; Imel, Zac E.; Smyth, Padhraic",,,,,"Smyth, Padhraic/0000-0001-9971-8378",,,Detecting conversation topics in primary care office visits from transcripts of patient-provider interactions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1493,1504,,10.1093/jamia/ocz140,,,,DEC 2019,2019,"Objective: Amid electronic health records, laboratory tests, and other technology, office-based patient and provider communication is still the heart of primary medical care. Patients typically present multiple complaints, requiring physicians to decide how to balance competing demands. How this time is allocated has implications for patient satisfaction, payments, and quality of care. We investigate the effectiveness of machine learning methods for automated annotation of medical topics in patient-provider dialog transcripts.Materials and Methods: We used dialog transcripts from 279 primary care visits to predict talk-turn topic labels. Different machine learning models were trained to operate on single or multiple local talk-turns (logistic classifiers, support vector machines, gated recurrent units) as well as sequential models that integrate information across talk-turn sequences (conditional random fields, hidden Markov models, and hierarchical gated recurrent units).Results: Evaluation was performed using cross-validation to measure 1) classification accuracy for talk-turns and 2) precision, recall, and F1 scores at the visit level. Experimental results showed that sequential models had higher classification accuracy at the talk-turn level and higher precision at the visit level. Independent models had higher recall scores at the visit level compared with sequential models.Conclusions: Incorporating sequential information across talk-turns improves the accuracy of topic prediction in patient-provider dialog by smoothing out noisy information from talk-turns. Although the results are promising, more advanced prediction techniques and larger labeled datasets will likely be required to achieve prediction performance appropriate for real-world clinical applications.",,,,,,,,,9,0,0,0,0,1,9,,,1067-5027,1527-974X,,WOS:000515125300009,31532490,
J,"Han, Sifei; Zhang, Robert F.; Shi, Lingyun; Richie, Russell; Liu, Haixia; Tseng, Andrew; Quan, Wei; Ryan, Neal; Brent, David; Tsui, Fuchiang R.",,,,,"Han, Sifei/0000-0002-3281-5955",,,Classifying social determinants of health from unstructured electronic health records using deep learning-based natural language processing,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,103984,10.1016/j.jbi.2021.103984,,,,MAR 2022,2022,"Objective: Social determinants of health (SDOH) are non-medical factors that can profoundly impact patient health outcomes. However, SDOH are rarely available in structured electronic health record (EHR) data such as diagnosis codes, and more commonly found in unstructured narrative clinical notes. Hence, identifying social context from unstructured EHR data has become increasingly important. Yet, previous work on using natural language processing to automate extraction of SDOH from text (a) usually focuses on an ad hoc selection of SDOH, and (b) does not use the latest advances in deep learning. Our objective was to advance automatic extraction of SDOH from clinical text by (a) systematically creating a set of SDOH based on standard biomedical and psychiatric ontologies, and (b) training state-of-the-art deep neural networks to extract mentions of these SDOH from clinical notes.Design: A retrospective cohort study.Setting and participants: Data were extracted from the Medical Information Mart for Intensive Care (MIMIC-III) database. The corpus comprised 3,504 social related sentences from 2,670 clinical notes.Methods: We developed a framework for automated classification of multiple SDOH categories. Our dataset comprised narrative clinical notes under the Social Work category in the MIMIC-III Clinical Database. Using standard terminologies, SNOMED-CT and DSM-IV, we systematically curated a set of 13 SDOH categories and created annotation guidelines for these. After manually annotating the 3,504 sentences, we developed and tested three deep neural network (DNN) architectures - convolutional neural network (CNN), long short-term memory (LSTM) network, and the Bidirectional Encoder Representations from Transformers (BERT) - for automated detection of eight SDOH categories. We also compared these DNNs to three baselines models: (1) cTAKES, as well as (2) L2-regularized logistic regression and (3) random forests on bags-of-words. Model evaluation metrics included micro- and macro- F1, and area under the receiver operating characteristic curve (AUC).Results: All three DNN models accurately classified all SDOH categories (minimum micro-F1 = 0.632, minimum macro-AUC = 0.854). Compared to the CNN and LSTM, BERT performed best in most key metrics (micro-F1 = 0.690, macro-AUC = 0.907). The BERT model most effectively identified the occupational category (F1 = 0.774, AUC = 0.965) and least effectively identified the non-SDOH category (F = 0.491, AUC = 0.788). BERT outperformed cTAKES in distinguishing social vs non-social sentences (BERT F1 = 0.87 vs. cTAKES F1 = 0.06), and outperformed logistic regression (micro-F1 = 0.649, macro-AUC = 0.696) and random forest (micro-F1 = 0.502, macro-AUC = 0.523) trained on bag-of-words.Conclusions: Our study framework with DNN models demonstrated improved performance for efficiently identifying a systematic range of SDOH categories from clinical notes in the EHR. Improved identification of patient SDOH may further improve healthcare outcomes.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000001,35007754,
J,"Gao, Cheng; Osmundson, Sarah; Edwards, Digna R. Velez; Jackson, Gretchen Purcell; Malin, Bradley A.; Chen, You",,,,,"Chen, You/0000-0001-8232-8840",,,Deep learning predicts extreme preterm birth from electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103334,10.1016/j.jbi.2019.103334,,,,DEC 2019,2019,"Objective: Models for predicting preterm birth generally have focused on very preterm (28-32 weeks) and moderate to late preterm (32-37 weeks) settings. However, extreme preterm birth (EPB), before the 28th week of gestational age, accounts for the majority of newborn deaths. We investigated the extent to which deep learning models that consider temporal relations documented in electronic health records (EHRs) can predict EPB.Study design: EHR data were subject to word embedding and a temporal deep learning model, in the form of recurrent neural networks (RNNs) to predict EPB. Due to the low prevalence of EPB, the models were trained on datasets where controls were undersampled to balance the case-control ratio. We then applied an ensemble approach to group the trained models to predict EPB in an evaluation setting with a nature EPB ratio. We evaluated the RNN ensemble models with 10 years of EHR data from 25,689 deliveries at Vanderbilt University Medical Center. We compared their performance with traditional machine learning models (logistical regression, support vector machine, gradient boosting) trained on the datasets with balanced and natural EPB ratio. Risk factors associated with EPB were identified using an adjusted odds ratio.Results: The RNN ensemble models trained on artificially balanced data achieved a higher AUC (0.827 vs. 0.744) and sensitivity (0.965 vs. 0.682) than those RNN models trained on the datasets with naturally imbalanced EPB ratio. In addition, the AUC (0.827) and sensitivity (0.965) of the RNN ensemble models were better than the AUC (0.777) and sensitivity (0.819) of the best baseline models trained on balanced data. Also, risk factors, including twin pregnancy, short cervical length, hypertensive disorder, systemic lupus erythematosus, and hydroxychloroquine sulfate, were found to be associated with EPB at a significant level.Conclusion: Temporal deep learning can predict EPB up to 8 weeks earlier than its occurrence. Accurate prediction of EPB may allow healthcare organizations to allocate resources effectively and ensure patients receive appropriate care.",,,,,,,,,13,0,1,0,4,0,14,,,1532-0464,1532-0480,,WOS:000525702900008,31678588,
J,"Cade, Brian E.; Hassan, Syed Moin; Dashti, Hassan S.; Kiernan, Melissa; Pavlova, Milena K.; Redline, Susan; Karlson, Elizabeth W.",,,,,,,,Sleep apnea phenotyping and relationship to disease in a large clinical biobank,,,,,,,,JAMIA OPEN,,,,5,1,,,,,ooab117,10.1093/jamiaopen/ooab117,,,,JAN 7 2022,2022,"Lay Summary Sleep apnea is a common disease in which breathing partially or completely pauses during sleep, leading to less oxygen in the blood, repeated awakenings, and increased risk of developing multiple diseases. Current studies of sleep apnea often have relatively few participants due to the challenge of performing overnight sleep recordings. Electronic health record (EHR) billing code diagnoses of sleep apnea could be repurposed to increase the size of research studies, but the accuracy of the diagnoses is reduced. We developed a reusable algorithm that improves the accuracy of EHR sleep apnea diagnoses using natural language processing to extract information from clinical notes. As a proof of concept, we used the algorithm to identify hundreds of diseases that are increased among participants with sleep apnea compared to similar patients without sleep apnea. Many of these disease relationships with sleep apnea have not been previously recognized. This improved algorithm will help to accelerate future large-scale investigations of the causes and consequences of sleep apnea.Objective Sleep apnea is associated with a broad range of pathophysiology. While electronic health record (EHR) information has the potential for revealing relationships between sleep apnea and associated risk factors and outcomes, practical challenges hinder its use. Our objectives were to develop a sleep apnea phenotyping algorithm that improves the precision of EHR case/control information using natural language processing (NLP); identify novel associations between sleep apnea and comorbidities in a large clinical biobank; and investigate the relationship between polysomnography statistics and comorbid disease using NLP phenotyping. Materials and Methods We performed clinical chart reviews on 300 participants putatively diagnosed with sleep apnea and applied International Classification of Sleep Disorders criteria to classify true cases and noncases. We evaluated 2 NLP and diagnosis code-only methods for their abilities to maximize phenotyping precision. The lead algorithm was used to identify incident and cross-sectional associations between sleep apnea and common comorbidities using 4876 NLP-defined sleep apnea cases and 3x matched controls. Results The optimal NLP phenotyping strategy had improved model precision (>= 0.943) compared to the use of one diagnosis code (<= 0.733). Of the tested diseases, 170 disorders had significant incidence odds ratios (ORs) between cases and controls, 8 of which were confirmed using polysomnography (n = 4544), and 281 disorders had significant prevalence OR between sleep apnea cases versus controls, 41 of which were confirmed using polysomnography data. Discussion and Conclusion An NLP-informed algorithm can improve the accuracy of case-control sleep apnea ascertainment and thus improve the performance of phenome-wide, genetic, and other EHR analyses of a highly prevalent disorder.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000764262900010,,
J,"Zheng, Neil S.; Feng, QiPing; Kerchberger, V. Eric; Zhao, Juan; Edwards, Todd L.; Cox, Nancy J.; Stein, C. Michael; Roden, Dan M.; Denny, Joshua C.; Wei, Wei-Qi",,,,"Denny, Josh/AAL-3359-2021; Roden, Dan/ABD-5412-2021","Denny, Josh/0000-0002-3049-7332; Kerchberger, Vern/0000-0002-0342-1965; Zheng, Neil/0000-0001-8737-0773",,,PheMap: a multi-resource knowledge base for high-throughput phenotyping within electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,11,,,1675,1687,,10.1093/jamia/ocaa104,,,,NOV 2020,2020,"Objective: Developing algorithms to extract phenotypes from electronic health records (EHRs) can be challenging and time-consuming. We developed PheMap, a high-throughput phenotyping approach that leverages multiple independent, online resources to streamline the phenotyping process within EHRs.Materials and Methods: PheMap is a knowledge base of medical concepts with quantified relationships to phenotypes that have been extracted by natural language processing from publicly available resources. PheMap searches EHRs for each phenotype's quantified concepts and uses them to calculate an individual's probability of having this phenotype. We compared PheMap to clinician-validated phenotyping algorithms from the Electronic Medical Records and Genomics (eMERGE) network for type 2 diabetes mellitus (T2DM), dementia, and hypothyroidism using 84 821 individuals from Vanderbilt Univeresity Medical Center's BioVU DNA Biobank. We implemented PheMap-based phenotypes for genome-wide association studies (GWAS) for T2DM, dementia, and hypothyroidism, and phenome-wide association studies (PheWAS) for variants in FTO, HLA-DRB1, and TCF7L2.Results: In this initial iteration, the PheMap knowledge base contains quantified concepts for 841 disease phenotypes. For T2DM, dementia, and hypothyroidism, the accuracy of the PheMap phenotypes were >97% using a 50% threshold and eMERGE case-control status as a reference standard. In the GWAS analyses, Phe-Mapderived phenotype probabilities replicated 43 of 51 previously reported disease-associated variants for the 3 phenotypes. For 9 of the 11 top associations, PheMap provided an equivalent or more significant P value than eMERGE-based phenotypes. The PheMap-based PheWAS showed comparable or better performance to a traditional phecode-based PheWAS. PheMap is publicly available online.Conclusions: PheMap significantly streamlines the process of extracting research-quality phenotype information from EHRs, with comparable or better performance to current phenotyping approaches.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000594986600006,32974638,
J,"Miller, James K.; Chen, Jieshi; Sundermann, Alexander; Marsh, Jane W.; Saul, Melissa, I; Shutt, Kathleen A.; Pacey, Marissa; Mustapha, Mustapha M.; Harrison, Lee H.; Dubrawski, Artur",,,,,"Chen, Jieshi/0000-0003-2660-4913",,,Statistical outbreak detection by joining medical records and pathogen similarity,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,91,,,,,,103126,10.1016/j.jbi.2019.103126,,,,MAR 2019,2019,"We present a statistical inference model for the detection and characterization of outbreaks of hospital associated infection. The approach combines patient exposures, determined from electronic medical records, and pathogen similarity, determined by whole-genome sequencing, to simultaneously identify probable outbreaks and their root-causes. We show how our model can be used to target isolates for whole-genome sequencing, improving outbreak detection and characterization even without comprehensive sequencing. Additionally, we demonstrate how to learn model parameters from reference data of known outbreaks. We demonstrate model performance using semi-synthetic experiments.",,,,,,,,,6,0,0,0,5,0,6,,,1532-0464,1532-0480,,WOS:000525688200012,30771483,
J,"Poirier, Canelle; Hswen, Yulin; Bouzille, Guillaume; Cuggia, Marc; Lavenu, Audrey; Brownstein, John S.; Brewer, Thomas; Santillana, Mauricio",,,,"CUGGIA, Marc/AAF-4729-2021","CUGGIA, Marc/0000-0001-6943-3937; Lavenu, Audrey/0000-0002-0049-2397; poirier, canelle/0000-0002-6972-2621",,,"Influenza forecasting for French regions combining EHR, web and climatic data sources with a machine learning ensemble approach",,,,,,,,PLOS ONE,,,,16,5,,,,,e0250890,10.1371/journal.pone.0250890,,,,MAY 19 2021,2021,"Effective and timely disease surveillance systems have the potential to help public health officials design interventions to mitigate the effects of disease outbreaks. Currently, healthcare-based disease monitoring systems in France offer influenza activity information that lags real-time by one to three weeks. This temporal data gap introduces uncertainty that prevents public health officials from having a timely perspective on the population-level disease activity. Here, we present a machine-learning modeling approach that produces real-time estimates and short-term forecasts of influenza activity for the twelve continental regions of France by leveraging multiple disparate data sources that include, Google search activity, real-time and local weather information, flu-related Twitter micro-blogs, electronic health records data, and historical disease activity synchronicities across regions. Our results show that all data sources contribute to improving influenza surveillance and that machine-learning ensembles that combine all data sources lead to accurate and timely predictions.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000664630900024,34010293,
J,"Przybyla, Piotr; Brockmeier, Austin J.; Ananiadou, Sophia",,,,"Brockmeier, Austin Jay/Y-3262-2018","Brockmeier, Austin Jay/0000-0002-7293-8140; Przybyla, Piotr/0000-0001-9043-6817",,,Quantifying risk factors in medical reports with a context-aware linear model,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,6,,,537,546,,10.1093/jamia/ocz004,,,,JUN 2019,2019,"Objective: We seek to quantify the mortality risk associated with mentions of medical concepts in textual electronic health records (EHRs). Recognizing mentions of named entities of relevant types (eg, conditions, symptoms, laboratory tests or behaviors) in text is a well-researched task. However, determining the level of risk associated with them is partly dependent on the textual context in which they appear, which may describe severity, temporal aspects, quantity, etc.Methods: To take into account that a given word appearing in the context of different risk factors (medical concepts) can make different contributions toward risk level, we propose a multitask approach, called context-aware linear modeling, which can be applied using appropriately regularized linear regression. To improve the performance for risk factors unseen in training data (eg, rare diseases), we take into account their distributional similarity to other concepts.Results: The evaluation is based on a corpus of 531 reports from EHRs with 99 376 risk factors rated manually by experts. While context-aware linear modeling significantly outperforms single-task models, taking into account concept similarity further improves performance, reaching the level of human annotators' agreements.Conclusion: Our results show that automatic quantification of risk factors in EHRs can achieve performance comparable to human assessment, and taking into account the multitask structure of the problem and the ability to handle rare concepts is crucial for its accuracy.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000482416300007,30840055,
J,"Searle, Thomas; Ibrahim, Zina; Teo, James; Dobson, Richard",,,,"Teo, James T/D-9696-2011; dobson, richard/C-9269-2011","Teo, James T/0000-0002-6899-8319; Ibrahim, Zina/0000-0001-6203-2727; Searle, Thomas/0000-0001-8424-3218; dobson, richard/0000-0003-4224-9245",,,Estimating redundancy in clinical text,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,124,,,,,,103938,10.1016/j.jbi.2021.103938,,OCT 2021,,DEC 2021,2021,"The current mode of use of Electronic Health Records (EHR) elicits text redundancy. Clinicians often populate new documents by duplicating existing notes, then updating accordingly. Data duplication can lead to propagation of errors, inconsistencies and misreporting of care. Therefore, measures to quantify information redundancy play an essential role in evaluating innovations that operate on clinical narratives.This work is a quantitative examination of information redundancy in EHR notes. We present and evaluate two methods to measure redundancy: an information-theoretic approach and a lexicosyntactic and semantic model. Our first measure trains large Transformer-based language models using clinical text from a large openly available US-based ICU dataset and a large multi-site UK based Hospital. By comparing the information-theoretic efficient encoding of clinical text against open-domain corpora, we find that clinical text is similar to 1.5x to similar to 3x less efficient than open-domain corpora at conveying information. Our second measure, evaluates automated summarisation metrics Rouge and BERTScore to evaluate successive note pairs demonstrating lexicosyntactic and semantic redundancy, with averages from similar to 43 to similar to 65%.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000718926700001,34695581,
J,"Zhang, Jiaying; Zhang, Zhixing; Zhang, Huanhuan; Ma, Zhiyuan; Ye, Qi; He, Ping; Zhou, Yangming",,,,,"Ma, Zhiyuan/0000-0003-2153-5824; Zhou, Yangming/0000-0002-4254-6517",,,From electronic health records to terminology base: A novel knowledge base enrichment approach,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103628,10.1016/j.jbi.2020.103628,,JAN 2021,,JAN 2021,2021,"Enriching terminology base (TB) is an important and continuous process, since formal term can be renamed and new term alias emerges all the time. As a potential supplementary for TB enrichment, electronic health record (EHR) is a fundamental source for clinical research and practise. The task to align the set of external terms in EHRs to TB can be regarded as entity alignment without structure information. Conventional approaches mainly use internal structural information of multiple knowledge bases (KBs) to map entities and their counterparts among KBs. However, the external terms in EHRs are independent clinical terms, which lack of interrelations. To achieve entity alignment in this case, we proposed a novel automatic TB enrichment approach, named semantic & structure embeddings-based relevancy prediction (S2ERP). To obtain the semantic embedding of external terms, we fed them with formal entity into a pre-trained language model. Meanwhile, a graph convolutional network was used to obtain the structure embeddings of the synonyms and hyponyms in TB. Afterwards, S2ERP combines both embeddings to measure the relevancy. Experimental results on clinical indicator TB, collected from 38 top-class hospitals of Shanghai Hospital Development Center, showed that the proposed approach outperforms baseline methods by 14.16% in Hits@1.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000615920400001,33232839,
J,"Ayre, Karyn; Bittar, Andre; Kam, Joyce; Verma, Somain; Howard, Louise M.; Dutta, Rina",,,,,"Bittar, Andre/0000-0001-6587-0080; Ayre, Karyn/0000-0001-9602-4485; Howard, Louise/0000-0001-9942-744X",,,Developing a Natural Language Processing tool to identify perinatal self-harm in electronic healthcare records,,,,,,,,PLOS ONE,,,,16,8,,,,,e0253809,10.1371/journal.pone.0253809,,,,AUG 4 2021,2021,"Background Self-harm occurring within pregnancy and the postnatal year (perinatal self-harm) is a clinically important yet under-researched topic. Current research likely under-estimates prevalence due to methodological limitations. Electronic healthcare records (EHRs) provide a source of clinically rich data on perinatal self-harm. Aims (1) To create a Natural Language Processing (NLP) tool that can, with acceptable precision and recall, identify mentions of acts of perinatal self-harm within EHRs. (2) To use this tool to identify service-users who have self-harmed perinatally, based on their EHRs. Methods We used the Clinical Record Interactive Search system to extract de-identified EHRs of secondary mental healthcare service-users at South London and Maudsley NHS Foundation Trust. We developed a tool that applied several layers of linguistic processing based on the spaCy NLP library for Python. We evaluated mention-level performance in the following domains: span, status, temporality and polarity. Evaluation was done against a manually coded reference standard. Mention-level performance was reported as precision, recall, F-score and Cohen's kappa for each domain. Performance was also assessed at 'service-user' level and explored whether a heuristic rule improved this. We report per-class statistics for service-user performance, as well as likelihood ratios and post-test probabilities. Results Mention-level performance: micro-averaged F-score, precision and recall for span, polarity and temporality >0.8. Kappa for status 0.68, temporality 0.62, polarity 0.91. Service-user level performance with heuristic: F-score, precision, recall of minority class 0.69, macro-averaged F-score 0.81, positive LR 9.4 (4.8-19), post-test probability 69.0% (53-82%). Considering the task difficulty, the tool performs well, although temporality was the attribute with the lowest level of annotator agreement. Conclusions It is feasible to develop an NLP tool that identifies, with acceptable validity, mentions of perinatal self-harm within EHRs, although with limitations regarding temporality. Using a heuristic rule, it can also function at a service-user-level.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000685264900043,34347787,
J,"Wilkinson, Katie; Sheets, Lincoln; Fitch, Dale; Popejoy, Lori",,,,,"Popejoy, Lori/0000-0002-3701-7231; Fitch, Dale/0000-0002-7793-2020",,,Systematic review of approaches to use of neighborhood-level risk factors with clinical data to predict clinical risk and recommend interventions,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,116,,,,,,103713,10.1016/j.jbi.2021.103713,,MAR 2021,,APR 2021,2021,"Background: Despite a large body of literature investigating how the environment influences health outcomes, most published work to date includes only a limited subset of the rich clinical and environmental data that is available and does not address how these data might best be used to predict clinical risk or expected impact of clinical interventions. Objective: Identify existing approaches to inclusion of a broad set of neighborhood-level risk factors with clinical data to predict clinical risk and recommend interventions. Methods: A systematic review of scientific literature published and indexed in PubMed, Web of Science, Association of Computing Machinery (ACM) and SCOPUS from 2010 through October 2020 was performed. To be included, articles had to include search terms related to Electronic Health Record (EHR) data NeighborhoodLevel Risk Factors (NLRFs), and Machine Learning (ML) Methods. Citations of relevant articles were also reviewed for additional articles for inclusion. Articles were reviewed and coded by two independent reviewers to capture key information including data sources, linkage of EHR to NRLFs, methods, and results. Articles were assessed for quality using a modified Quality Assessment Tool for Systematic Reviews of Observational Studies (QATSO). Results: A total of 334 articles were identified for abstract review. 36 articles were identified for full review with 19 articles included in the final analysis. All but two of the articles included socio-demographic data derived from the U.S. Census and we found great variability in sources of NLRFs beyond the Census. The majority or the articles (14 of 19) included broader clinical (e.g. medications, labs and co-morbidities) and demographic information about the individual from the EHR in addition to the clinical outcome variable. Half of the articles (10) had a stated goal to predict the outcome(s) of interest. While results of the studies reinforced the correlative association of NLRFs to clinical outcomes, only one article found that adding NLRFs into a model with other data added predictive power with the remainder concluding either that NLRFs were of mixed value depending on the model and outcome or that NLRFs added no predictive power over other data in the model. Only one article scored high on the quality assessment with 13 scoring moderate and 4 scoring low. Conclusions: In spite of growing interest in combining NLRFs with EHR data for clinical prediction, we found limited evidence that NLRFs improve predictive power in clinical risk models. We found these data and methods are being used in four ways. First, early approaches to include broad NLRFs to predict clinical risk primarily focused on dimension reduction for feature selection or as a data preparation step to input into regression analysis. Second, more recent work incorporates NLRFs into more advanced predictive models, such as Neural Networks, Random Forest, and Penalized Lasso to predict clinical outcomes or predict value of interventions. Third, studies that test how inclusion of NLRFs predict clinical risk have shown mixed results regarding the value of these data over EHR or claims data alone and this review surfaced evidence of potential quality challenges and biases inherent to this approach. Finally, NLRFs were used with unsupervised learning to identify underlying",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000640446800016,33610880,
J,"Cade, Brian E; Hassan, Syed Moin; Dashti, Hassan S; Kiernan, Melissa; Pavlova, Milena K; Redline, Susan; Karlson, Elizabeth W",,,,,,,,Sleep apnea phenotyping and relationship to disease in a large clinical biobank.,,,,,,,,JAMIA open,,,,5,1,,,ooab117,ooab117,,10.1093/jamiaopen/ooab117,,,,2022-Apr,2022,"Objective: Sleep apnea is associated with a broad range of pathophysiology. While electronic health record (EHR) information has the potential for revealing relationships between sleep apnea and associated risk factors and outcomes, practical challenges hinder its use. Our objectives were to develop a sleep apnea phenotyping algorithm that improves the precision of EHR case/control information using natural language processing (NLP); identify novel associations between sleep apnea and comorbidities in a large clinical biobank; and investigate the relationship between polysomnography statistics and comorbid disease using NLP phenotyping.Materials and Methods: We performed clinical chart reviews on 300 participants putatively diagnosed with sleep apnea and applied International Classification of Sleep Disorders criteria to classify true cases and noncases. We evaluated 2 NLP and diagnosis code-only methods for their abilities to maximize phenotyping precision. The lead algorithm was used to identify incident and cross-sectional associations between sleep apnea and common comorbidities using 4876 NLP-defined sleep apnea cases and 3* matched controls.Results: The optimal NLP phenotyping strategy had improved model precision (≥0.943) compared to the use of one diagnosis code (≤0.733). Of the tested diseases, 170 disorders had significant incidence odds ratios (ORs) between cases and controls, 8 of which were confirmed using polysomnography (n=4544), and 281 disorders had significant prevalence OR between sleep apnea cases versus controls, 41 of which were confirmed using polysomnography data.Discussion and Conclusion: An NLP-informed algorithm can improve the accuracy of case-control sleep apnea ascertainment and thus improve the performance of phenome-wide, genetic, and other EHR analyses of a highly prevalent disorder.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,MEDLINE:35156000,35156000,
J,"Hatef, Elham; Rouhizadeh, Masoud; Nau, Claudia; Xie, Fagen; Rouillard, Christopher; Abu-Nasser, Mahmoud; Padilla, Ariadna; Lyons, Lindsay Joe; Kharrazi, Hadi; Weiner, Jonathan P.; Roblin, Douglas",,,,"Kharrazi, Hadi/Q-1725-2015","Kharrazi, Hadi/0000-0003-1481-4323",,,Development and assessment of a natural language processing model to identify residential instability in electronic health records' unstructured data: a comparison of 3 integrated healthcare delivery systems,,,,,,,,JAMIA OPEN,,,,5,1,,,,,ooac006,10.1093/jamiaopen/ooac006,,,,JAN 7 2022,2022,"Objective To evaluate whether a natural language processing (NLP) algorithm could be adapted to extract, with acceptable validity, markers of residential instability (ie, homelessness and housing insecurity) from electronic health records (EHRs) of 3 healthcare systems. Materials and methods We included patients 18 years and older who received care at 1 of 3 healthcare systems from 2016 through 2020 and had at least 1 free-text note in the EHR during this period. We conducted the study independently; the NLP algorithm logic and method of validity assessment were identical across sites. The approach to the development of the gold standard for assessment of validity differed across sites. Using the EntityRuler module of spaCy 2.3 Python toolkit, we created a rule-based NLP system made up of expert-developed patterns indicating residential instability at the lead site and enriched the NLP system using insight gained from its application at the other 2 sites. We adapted the algorithm at each site then validated the algorithm using a split-sample approach. We assessed the performance of the algorithm by measures of positive predictive value (precision), sensitivity (recall), and specificity. Results The NLP algorithm performed with moderate precision (0.45, 0.73, and 1.0) at 3 sites. The sensitivity and specificity of the NLP algorithm varied across 3 sites (sensitivity: 0.68, 0.85, and 0.96; specificity: 0.69, 0.89, and 1.0). Discussion The performance of this NLP algorithm to identify residential instability in 3 different healthcare systems suggests the algorithm is generally valid and applicable in other healthcare systems with similar EHRs. Conclusion The NLP approach developed in this project is adaptable and can be modified to extract types of social needs other than residential instability from EHRs across different healthcare systems.Lay Summary We evaluated the performance of a natural language processing (NLP) algorithm to extract markers of residential instability (ie, homelessness and housing insecurity) from electronic health records (EHRs) of 3 healthcare systems. We included patients 18 years and older who received care at 1 of 3 healthcare systems from 2016 through 2020 and had at least 1 free-text note in the EHR during this period. We conducted the study independently; the NLP algorithm logic and method of validity assessment were identical across sites. The approach to the development of the gold standard for assessment of validity differed across sites. We created a rule-based NLP system made up of expert-developed patterns indicating residential instability at the lead site and enriched the NLP system using insight gained from its application at the other 2 sites. We assessed the performance of the algorithm by measures of positive predictive value (PPV), sensitivity, and specificity. The NLP algorithm performed with moderate PPV (0.45, 0.73, and 1.0), sensitivity (0.68, 0.85, and 0.96), and specificity (0.69, 0.89, and 1.0) across the 3 sites. Our findings suggest that this approach to extracting information on social needs from the free-text EHR notes is generally applicable in other healthcare systems with similar EHRs.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000764262900005,35224458,
J,"Liu, Cong; Ta, Casey N.; Rogers, James R.; Li, Ziran; Lee, Junghwan; Butler, Alex M.; Shang, Ning; Kury, Fabricio Sampaio Peres; Wang, Liwei; Shen, Feichen; Liu, Hongfang; Ena, Lyudmila; Friedman, Carol; Weng, Chunhua",,,,,"Shang, Ning/0000-0001-7040-5204",,,Ensembles of natural language processing systems for portable phenotyping solutions,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103318,10.1016/j.jbi.2019.103318,,,,DEC 2019,2019,"Background: Manually curating standardized phenotypic concepts such as Human Phenotype Ontology (HPO) terms from narrative text in electronic health records (EHRs) is time consuming and error prone. Natural language processing (NLP) techniques can facilitate automated phenotype extraction and thus improve the efficiency of curating clinical phenotypes from clinical texts. While individual NLP systems can perform well for a single cohort, an ensemble-based method might shed light on increasing the portability of NLP pipelines across different cohorts.Methods: We compared four NLP systems, MetaMapLite, MedLEE, ClinPhen and cTAKES, and four ensemble techniques, including intersection, union, majority-voting and machine learning, for extracting generic phenotypic concepts. We addressed two important research questions regarding automated phenotype recognition. First, we evaluated the performance of different approaches in identifying generic phenotypic concepts. Second, we compared the performance of different methods to identify patient-specific phenotypic concepts. To better quantify the effects caused by concept granularity differences on performance, we developed a novel evaluation metric that considered concept hierarchies and frequencies. Each of the approaches was evaluated on a gold standard set of clinical documents annotated by clinical experts. One dataset containing 1,609 concepts derived from 50 clinical notes from two different institutions was used in both evaluations, and an additional dataset of 608 concepts derived from 50 case report abstracts obtained from PubMed was used for evaluation of identifying generic phenotypic concepts only.Results: For generic phenotypic concept recognition, the top three performers in the NYP/CUIMC dataset are union ensemble (F-1, 0.634), training-based ensemble (F-1, 0.632), and majority vote-based ensemble (F-1, 0.622). In the Mayo dataset, the top three are majority vote-based ensemble (F-1, 0.642), cTAKES (F-1, 0.615), and MedLEE (F-1, 0.559). In the PubMed dataset, the top three are majority vote-based ensemble (F-1, 0.719), trainingbased (F-1, 0.696) and MetaMapLite (F-1, 0.694). For identifying patient specific phenotypes, the top three performers in the NYP/CUIMC dataset are majority vote-based ensemble (F-1, 0.610), MedLEE (F-1, 0.609), and training-based ensemble (F-1, 0.585). In the Mayo dataset, the top three are majority vote-based ensemble (F-1, 0.604), cTAKES (F-1, 0.531) and MedLEE (F-1, 0.527).Conclusions: Our study demonstrates that ensembles of natural language processing can improve both generic phenotypic concept recognition and patient specific phenotypic concept identification over individual systems. Among the individual NLP systems, each individual system performed best when they were applied in the dataset that they were primary designed for. However, combining multiple NLP systems to create an ensemble can generally improve the performance. Specifically, the ensemble can increase the results reproducibility across different cohorts and tasks, and thus provide a more portable phenotyping solution compared to individual NLP systems.",,,,,,,,,6,0,0,0,4,0,6,,,1532-0464,1532-0480,,WOS:000525702900011,31655273,
J,"Shamshirband, Shahab; Fathi, Mahdis; Dehzangi, Abdollah; Chronopoulos, Anthony Theodore; Alinejad-Rokny, Hamid",,,,"S. Band, Shahab/ABB-2469-2020; S.Band, Shahab/AAD-3311-2021; S.Band, Shahab/ABI-7388-2020","S. Band, Shahab/0000-0001-6109-1311; S.Band, Shahab/0000-0002-8963-731X",,,"A review on deep learning approaches in healthcare systems: Taxonomies, challenges, and open issues",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103627,10.1016/j.jbi.2020.103627,,JAN 2021,,JAN 2021,2021,"In the last few years, the application of Machine Learning approaches like Deep Neural Network (DNN) models have become more attractive in the healthcare system given the rising complexity of the healthcare data. Machine Learning (ML) algorithms provide efficient and effective data analysis models to uncover hidden patterns and other meaningful information from the considerable amount of health data that conventional analytics are not able to discover in a reasonable time. In particular, Deep Learning (DL) techniques have been shown as promising methods in pattern recognition in the healthcare systems. Motivated by this consideration, the contribution of this paper is to investigate the deep learning approaches applied to healthcare systems by reviewing the cutting-edge network architectures, applications, and industrial trends. The goal is first to provide extensive insight into the application of deep learning models in healthcare solutions to bridge deep learning techniques and human healthcare interpretability. And then, to present the existing open challenges and future directions.",,,,,,,,,27,0,0,0,6,0,27,,,1532-0464,1532-0480,,WOS:000615920400008,33259944,
J,"Liao, Katherine R.; Sun, Jiehuan; Cai, Tianrun A.; Link, Nicholas; Hong, Chuan; Huang, Jie; Huffman, Jennifer E.; Gronsbell, Jessica; Zhang, Yichi; Ho, Yuk-Lam; Castro, Victor; Gainer, Vivian; Murphy, Shawn N.; ODonnell, Christopher J.; Gaziano, J. Michael; Cho, Kelly; Szolovits, Peter; Kohane, Isaac S.; Yu, Sheng; Cai, Tianxi",,Million Vet Program,,,,,,High-throughput multimodal automated phenotyping (MAP) with application to PheWAS,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1255,1262,,10.1093/jamia/ocz066,,,,NOV 2019,2019,"Objective: Electronic health records linked with biorepositories are a powerful platform for translational studies. A major bottleneck exists in the ability to phenotype patients accurately and efficiently. The objective of this study was to develop an automated high-throughput phenotyping method integrating International Classification of Diseases (ICD) codes and narrative data extracted using natural language processing (NLP).Materials and Methods: We developed a mapping method for automatically identifying relevant ICD and NLP concepts for a specific phenotype leveraging the Unified Medical Language System. Along with health care utilization, aggregated ICD and NLP counts were jointly analyzed by fitting an ensemble of latent mixture models. The multimodal automated phenotyping (MAP) algorithm yields a predicted probability of phenotype for each patient and a threshold for classifying participants with phenotype yes/no. The algorithm was validated using labeled data for 16 phenotypes from a biorepository and further tested in an independent cohort phenome-wide association studies (PheWAS) for 2 single nucleotide polymorphisms with known associations.Results: The MAP algorithm achieved higher or similar AUC and F-scores compared to the ICD code across all 16 phenotypes. The features assembled via the automated approach had comparable accuracy to those assembled via manual curation (AUC(MAP) 0.943, AUC(manual) 0.941). The PheWAS results suggest that the MAP approach detected previously validated associations with higher power when compared to the standard PheWAS method based on ICD codes.Conclusion: The MAP approach increased the accuracy of phenotype definition while maintaining scalability, thereby facilitating use in studies requiring large-scale phenotyping, such as PheWAS.",,,,,,,,,20,0,0,0,7,0,20,,,1067-5027,1527-974X,,WOS:000498169400013,31613361,
J,"Klann, Jeffrey G.; Estiri, Hossein; Weber, Griffin M.; Moal, Bertrand; Avillach, Paul; Hong, Chuan; Tan, Amelia L. M.; Beaulieu-Jones, Brett K.; Castro, Victor; Maulhardt, Thomas; Geva, Alon; Malovini, Alberto; South, Andrew M.; Visweswaran, Shyam; Morris, Michele; Samayamuthu, Malarkodi J.; Omenn, Gilbert S.; Ngiam, Kee Yuan; Mandl, Kenneth D.; Boeker, Martin; Olson, Karen L.; Mowery, Danielle L.; Follett, Robert W.; Hanauer, David A.; Bellazzi, Riccardo; Moore, Jason H.; Loh, Ne-Hooi Will; Bell, Douglas S.; Wagholikar, Kavishwar B.; Chiovato, Luca; Tibollo, Valentina; Rieg, Siegbert; Li, Anthony L. L. J.; Jouhet, Vianney; Schriver, Emily; Xia, Zongqi; Hutch, Meghan; Luo, Yuan; Kohane, Isaac S.; Brat, Gabriel A.; Murphy, Shawn N.",,Consortium Clinical Characterizati,,"Malovini, Alberto/I-8727-2018; Geva, Alon/AAM-6793-2021; Samayamuthu, Malarkodi Jebathilagam/AAU-6232-2021; Boeker, Martin/N-3854-2016; Chiovato, Luca/K-6617-2016; Tibollo, Valentina/AAC-1652-2020; Luo, Yuan/K-5563-2016","Malovini, Alberto/0000-0003-2857-5773; Geva, Alon/0000-0002-8574-0133; Samayamuthu, Malarkodi Jebathilagam/0000-0003-0061-8196; Boeker, Martin/0000-0003-2972-2042; Chiovato, Luca/0000-0001-7457-7353; Estiri, Hossein/0000-0002-0204-8978; Weber, Griffin/0000-0002-2597-881X; Moal, Bertrand/0000-0001-9197-721X; Tibollo, Valentina/0000-0003-2687-3822; jouhet, vianney/0000-0001-5272-2265; Maulhardt, Thomas/0000-0003-3184-1366; Luo, Yuan/0000-0003-0195-7456",,,Validation of an internationally derived patient severity phenotype to support COVID-19 analytics from electronic health record data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,7,,,1411,1420,,10.1093/jamia/ocab018,,APR 2021,,JUL 2021,2021,"Objective: The Consortium for Clinical Characterization of COVID-19 by EHR (4CE) is an international collaboration addressing coronavirus disease 2019 (COVID-19) with federated analyses of electronic health record (EHR) data. We sought to develop and validate a computable phenotype for COVID-19 severity.Materials and Methods: Twelve 4CE sites participated. First, we developed an EHR-based severity phenotype consisting of 6 code classes, and we validated it on patient hospitalization data from the 12 4CE clinical sites against the outcomes of intensive care unit (ICU) admission and/or death. We also piloted an alternative machine learning approach and compared selected predictors of severity with the 4CE phenotype at 1 site.Results: The full 4CE severity phenotype had pooled sensitivity of 0.73 and specificity 0.83 for the combined outcome of ICU admission and/or death. The sensitivity of individual code categories for acuity had high variability-up to 0.65 across sites. At one pilot site, the expert-derived phenotype had mean area under the curve of 0.903 (95% confidence interval, 0.886-0.921), compared with an area under the curve of 0.956 (95% confidence interval, 0.952-0.959) for the machine learning approach. Billing codes were poor proxies of ICU admission, with as low as 49% precision and recall compared with chart review.Discussion: We developed a severity phenotype using 6 code classes that proved resilient to coding variability across international institutions. In contrast, machine learning approaches may overfit hospital-specific orders. Manual chart review revealed discrepancies even in the gold-standard outcomes, possibly owing to heterogeneous pandemic conditions.Conclusions: We developed an EHR-based severity phenotype for COVID-19 in hospitalized patients and validated it at 12 international sites.",,,,,,,,,7,0,0,0,1,0,7,,,1067-5027,1527-974X,,WOS:000685209200007,33566082,
J,"Hripcsak, George; Albers, David J.",,,,,,,,High-fidelity phenotyping: richness and freedom from bias,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,3,,,289,294,,10.1093/jamia/ocx110,,,,MAR 2018,2018,"Electronic health record phenotyping is the use of raw electronic health record data to assert characterizations about patients. Researchers have been doing it since the beginning of biomedical informatics, under different names. Phenotyping will benefit from an increasing focus on fidelity, both in the sense of increasing richness, such as measured levels, degree or severity, timing, probability, or conceptual relationships, and in the sense of reducing bias. Research agendas should shift from merely improving binary assignment to studying and improving richer representations. The field is actively researching new temporal directions and abstract representations, including deep learning. The field would benefit from research in nonlinear dynamics, in combining mechanistic models with empirical data, including data assimilation, and in topology. The health care process produces substantial bias, and studying that bias explicitly rather than treating it as merely another source of noise would facilitate addressing it.",,,,,,,,,20,0,0,0,11,0,20,,,1067-5027,1527-974X,,WOS:000426850500009,29040596,
J,"Gonzalez-Juanatey, Carlos; Anguita-Sa Nchez, Manuel; Barrios, Vivencio; Nunez-Gil, Ivan; Gomez-Doblas, Juan Josa; Garcia-Moll, Xavier; Lafuente-Gormaz, Carlos; Rollan-Gomez, Maria Jesus; Peral-Disdie, Vicente; Martinez-Dolz, Luis; Rodriguez-Santamarta, Miguel; Vinolas-Prat, Xavier; Soriano-Colome, Toni; Munoz-Aguilera, Roberto; Plaza, Ignacio; Curcio-Ruigomez, Alejandro; Orts-Soler, Ernesto; Segovia, Javier; Mate, Claudia; Cequier, Angel",,SAVANA Research Group,,"Martinez-Dolz, Luis/X-4627-2018","Martinez-Dolz, Luis/0000-0001-5145-8191; Del Rio-Bermudez, Carlos/0000-0002-1036-1673",,,Assessment of medical management in Coronary Type 2 Diabetic patients with previous percutaneous coronary intervention in Spain: A retrospective analysis of electronic health records using Natural Language Processing.,,,,,,,,PloS one,,,,17,2,,,e0263277,e0263277,,10.1371/journal.pone.0263277,,,,2022,2022,"INTRODUCTION AND OBJECTIVES: Patients with type 2 diabetes (T2D) and stable coronary artery disease (CAD) previously revascularized with percutaneous coronary intervention (PCI) are at high risk of recurrent ischemic events. We aimed to provide real-world insights into the clinical characteristics and management of this clinical population, excluding patients with a history of myocardial infarction (MI) or stroke, using Natural Language Processing (NLP) technology.METHODS: This is a multicenter, retrospective study based on the secondary use of 2014-2018 real-world data captured in the Electronic Health Records (EHRs) of 1,579 patients (0.72% of the T2D population analyzed; n = 217,632 patients) from 12 representative hospitals in Spain. To access the unstructured clinical information in EHRs, we used the EHRead technology, based on NLP and machine learning. Major adverse cardiovascular events (MACE) were considered: MI, ischemic stroke, urgent coronary revascularization, and hospitalization due to unstable angina. The association between MACE rates and the variables included in this study was evaluated following univariate and multivariate approaches.RESULTS: Most patients were male (72.13%), with a mean age of 70.5±10 years. Regarding T2D, most patients were non-insulin-dependent T2D (61.75%) with high prevalence of comorbidities. The median (Q1-Q3) duration of follow-up was 1.2 (0.3-4.5) years. Overall, 35.66% of patients suffered from at least one MACE during follow up. Using a Cox Proportional Hazards regression model analysis, several independent factors were associated with MACE during follow up: CAD duration (p < 0.001), COPD/Asthma (p = 0.021), heart valve disease (p = 0.031), multivessel disease (p = 0.005), insulin treatment (p < 0.001), statins treatment (p < 0.001), and clopidogrel treatment (p = 0.039).CONCLUSIONS: Our results showed high rates of MACE in a large real-world series of PCI-revascularized patients with T2D and CAD with no history of MI or stroke. These data represent a potential opportunity to improve the clinical management of these patients.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35143527,35143527,
J,"Chapman, Alec B.; Jones, Audrey; Kelley, A. Taylor; Jones, Barbara; Gawron, Lori; Montgomery, Ann Elizabeth; Byrne, Thomas; Suo, Ying; Cook, James; Pettey, Warren; Peterson, Kelly; Jones, Makoto; Nelson, Richard",,,,,,,,ReHouSED: A novel measurement of Veteran housing stability using natural language processing,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,122,,,,,,103903,10.1016/j.jbi.2021.103903,,SEP 2021,,OCT 2021,2021,"Housing stability is an important determinant of health. The US Department of Veterans Affairs (VA) administers several programs to assist Veterans experiencing unstable housing. Measuring long-term housing stability of Veterans who receive assistance from VA is difficult due to a lack of standardized structured documentation in the Electronic Health Record (EHR). However, the text of clinical notes often contains detailed information about Veterans' housing situations that may be extracted using natural language processing (NLP). We present a novel NLP-based measurement of Veteran housing stability: Relative Housing Stability in Electronic Documentation (ReHouSED). We first develop and evaluate a system for classifying documents containing information about Veterans' housing situations. Next, we aggregate information from multiple documents to derive a patient-level measurement of housing stability. Finally, we demonstrate this method's ability to differentiate between Vet-erans who are stably and unstably housed. Thus, ReHouSED provides an important methodological framework for the study of long-term housing stability among Veterans receiving housing assistance.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000696619600001,34474188,
J,"Sholle, Evan T.; Pinheiro, Laura C.; Adekkanattu, Prakash; Davila, Marcos A., III; Johnson, Stephen B.; Pathak, Jyotishman; Sinha, Sanjai; Li, Cassidie; Lubansky, Stasi A.; Safford, Monika M.; Campion, Thomas R., Jr.",,,,,"Johnson, Stephen/0000-0002-7663-4355; Johnson, Stephen/0000-0002-6079-8419; Sholle, Evan/0000-0001-9518-4399",,,Underserved populations with missing race ethnicity data differ significantly from those with structured race/ethnicity documentation,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,8-9,,,722,729,,10.1093/jamia/ocz040,,,,AUG-SEP 2019,2019,"Objective: We aimed to address deficiencies in structured electronic health record (EHR) data for race and ethnicity by identifying black and Hispanic patients from unstructured clinical notes and assessing differences between patients with or without structured race/ethnicity data.Materials and Methods: Using EHR notes for 16 665 patients with encounters at a primary care practice, we developed rule-based natural language processing (NLP) algorithms to classify patients as black/Hispanic. We evaluated performance of the method against an annotated gold standard, compared race and ethnicity between NLP-derived and structured EHR data, and compared characteristics of patients identified as black or Hispanic using only NLP vs patients identified as such only in structured EHR data.Results: For the sample of 16 665 patients, NLP identified 948 additional patients as black, a 26% increase, and 665 additional patients as Hispanic, a 20% increase. Compared with the patients identified as black or Hispanic in structured EHR data, patients identified as black or Hispanic via NLP only were older, more likely to be male, less likely to have commercial insurance, and more likely to have higher comorbidity.Discussion: Structured EHR data for race and ethnicity are subject to data quality issues. Supplementing structured EHR race data with NLP-derived race and ethnicity may allow researchers to better assess the demographic makeup of populations and draw more accurate conclusions about intergroup differences in health outcomes.Conclusions: Black or Hispanic patients who are not documented as such in structured EHR race/ethnicity fields differ significantly from those who are. Relatively simple NLP can help address this limitation.",,,,,,,,,14,0,0,0,4,0,14,,,1067-5027,1527-974X,,WOS:000493114800005,31329882,
J,"An, Yang; Mao, Yakun; Zhang, Liang; Jin, Bo; Xiao, Keli; Wei, Xiaopeng; Yan, Jun",,,,,"Jin, Bo/0000-0002-4094-7499",,,RAHM: Relation augmented hierarchical multi-task learning framework for reasonable medication stocking,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103502,10.1016/j.jbi.2020.103502,,,,AUG 2020,2020,"As an important task in digital preventive healthcare management, especially in the secondary prevention stage, active medication stocking refers to the process of preparing necessary medications in advance according to the predicted disease progression of patients. However, predicting preventive or even life-saving medicine for each patient is a non-trivial task. Existing models usually overlook the implicit hierarchical relation between patient's predicted diseases and medications, and mainly focus on single tasks (medication recommendation or disease prediction). To tackle this limitation, we propose a relation augmented hierarchical multi-task learning framework, named RAHM. which is capable of learning multi-level relation-aware patient representation for reasonable medication stocking. Specifically, the framework first leverages the underlying structural relations of Electronic Health Record (EHR) data to learn the low-level patient visit representation. Then, it uses a regular LSTM to encode the historical temporal disease information for disease-level patient representation learning. Further, a relation-aware LSTM (R-LSTM) is proposed to handle the relations between diseases and medication in longitudinal patient records, which can better integrate the historical information into the medication-level patient representation. In the learning process, two pseudo residual structures are introduced to mitigate the error propagation and preserve the valuable relation information of EHRs. To validate our method, extensive experiments have been conducted based on the real-world clinical dataset. The results demonstrate a consistent superiority of our framework over several baselines in suggesting reasonable stock medication.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000564594600008,32673789,
J,"Gabriel, Rodney A.; Kuo, Tsung-Ting; McAuley, Julian; Hsu, Chun-Nan",,,,"Kuo, Tsung-Ting/AAF-6730-2019","Kuo, Tsung-Ting/0000-0002-8728-4477; Hsu, Chun-Nan/0000-0002-5240-4707",,,Identifying and characterizing highly similar notes in big clinical note datasets,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,82,,,,63,69,,10.1016/j.jbi.2018.04.009,,,,JUN 2018,2018,"Background: Big clinical note datasets found in electronic health records (EHR) present substantial opportunities to train accurate statistical models that identify patterns in patient diagnosis and outcomes. However, near-to-exact duplication in note texts is a common issue in many clinical note datasets. We aimed to use a scalable algorithm to de-duplicate notes and further characterize the sources of duplication.Methods: We use an approximation algorithm to minimize pairwise comparisons consisting of three phases: (1) Minhashing with Locality Sensitive Hashing; (2) a clustering method using tree-structured disjoint sets; and (3) classification of near-duplicates (exact copies, common machine output notes, or similar notes) via pairwise comparison of notes in each cluster. We use the Jaccard Similarity (JS) to measure similarity between two documents. We analyzed two big clinical note datasets: our institutional dataset and MIMIC-III.Results: There were 1,528,940 notes analyzed from our institution. The de-duplication algorithm completed in 36.3 h. When the JS threshold was set at 0.7, the total number of clusters was 82,371 (total notes = 304,418). Among all JS thresholds, no clusters contained pairs of notes that were incorrectly clustered. When the JS threshold was set at 0.9 or 1.0, the de-duplication algorithm captured 100% of all random pairs with their JS at least as high as the set thresholds from the validation set. Similar performance was noted when analyzing the MIMIC-III dataset.Conclusions: We showed that among the EHR from our institution and from the publicly-available MIMIC-III dataset, there were a significant number of near-to-exact duplicated notes.",,,,,,,,,4,0,0,0,1,0,4,,,1532-0464,1532-0480,,WOS:000445054600006,29679685,
J,"Koola, Jejo D.; Davis, Sharon E.; Al-Nimri, Omar; Parr, Sharidan K.; Fabbri, Daniel; Malin, Bradley A.; Ho, Samuel B.; Matheny, Michael E.",,,,"Matheny, Michael E/B-3541-2008","Matheny, Michael E/0000-0003-3217-4147; Parr, Sharidan/0000-0002-4596-3818; Koola, Jejo/0000-0001-5171-8475",,,Development of an automated phenotyping algorithm for hepatorenal syndrome,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,80,,,,87,95,,10.1016/j.jbi.2018.03.001,,,,APR 2018,2018,"Objective: Hepatorenal Syndrome (HRS) is a devastating form of acute kidney injury (MU) in advanced liver disease patients with high morbidity and mortality, but phenotyping algorithms have not yet been developed using large electronic health record (EHR) databases. We evaluated and compared multiple phenotyping methods to achieve an accurate algorithm for HRS identification.Materials and methods: A national retrospective cohort of patients with cirrhosis and AKI admitted to 124 Veterans Affairs hospitals was assembled from electronic health record data collected from 2005 to 2013. AKI was defined by the Kidney Disease: Improving Global Outcomes criteria. Five hundred and four hospitalizations were selected for manual chart review and served as the gold standard. Electronic Health Record based predictors were identified using structured and free text clinical data, subjected through NLP from the clinical Text Analysis Knowledge Extraction System. We explored several dimension reduction techniques for the NLP data, including newer high-throughput phenotyping and word embedding methods, and ascertained their effectiveness in identifying the phenotype without structured predictor variables. With the combined structured and NLP variables, we analyzed five phenotyping algorithms: penalized logistic regression, naive Bayes, support vector machines, random forest, and gradient boosting. Calibration and discrimination metrics were calculated using 100 bootstrap iterations. In the final model, we report odds ratios and 95% confidence intervals.Results: The area under the receiver operating characteristic curve (AUC) for the different models ranged from 0.73 to 0.93; with penalized logistic regression having the best discriminatory performance. Calibration for logistic regression was modest, but gradient boosting and support vector machines were superior. NLP identified 6985 variables; a priori variable selection performed similarly to dimensionality reduction using high-throughput phenotyping and semantic similarity informed clustering (AUC of 0.81-0.82).Conclusion: This study demonstrated improved phenotyping of a challenging MU etiology, HRS, over ICD-9 coding. We also compared performance among multiple approaches to EHR-derived phenotyping, and found similar results between methods. Lastly, we showed that automated NLP dimension reduction is viable for acute illness.",,,,,,,,,13,1,0,0,4,0,13,,,1532-0464,1532-0480,,WOS:000430035000009,29530803,
J,"Coquet, Jean; Bozkurt, Selen; Kan, Kathleen M.; Ferrari, Michelle K.; Blayney, Douglas W.; Brooks, James D.; Hernandez-Boussard, Tina",,,,"Coquet, Jean/AAI-5591-2020","Coquet, Jean/0000-0002-7008-6925; Hernandez-Boussard, Tina/0000-0001-6553-3455; Blayney, Douglas/0000-0002-7931-4533",,,Comparison of orthogonal NLP methods for clinical phenotyping and assessment of bone scan utilization among prostate cancer patients,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,94,,,,,,103184,10.1016/j.jbi.2019.103184,,,,JUN 2019,2019,"Objective: Clinical care guidelines recommend that newly diagnosed prostate cancer patients at high risk for metastatic spread receive a bone scan prior to treatment and that low risk patients not receive it. The objective was to develop an automated pipeline to interrogate heterogeneous data to evaluate the use of bone scans using a two different Natural Language Processing (NLP) approaches.Materials and Methods: Our cohort was divided into risk groups based on Electronic Health Records (EHR). Information on bone scan utilization was identified in both structured data and free text from clinical notes. Our pipeline annotated sentences with a combination of a rule-based method using the ConText algorithm (a generalization of NegEx) and a Convolutional Neural Network (CNN) method using word2vec to produce word embeddings.Results: A total of 5500 patients and 369,764 notes were included in the study. A total of 39% of patients were high-risk and 73% of these received a bone scan; of the 18% low risk patients, 10% received one. The accuracy of CNN model outperformed the rule-based model one (F-measure = 0.918 and 0.897 respectively). We demonstrate a combination of both models could maximize precision or recall, based on the study question.Conclusion: Using structured data, we accurately classified patients' cancer risk group, identified bone scan documentation with two NLP methods, and evaluated guideline adherence. Our pipeline can be used to provide concrete feedback to clinicians and guide treatment decisions.",,,,,,,,,4,0,0,0,1,0,4,,,1532-0464,1532-0480,,WOS:000525692600015,31014980,
J,"Landsman, David; Abdelbasit, Ahmed; Wang, Christine; Guerzhoy, Michael; Joshi, Ujash; Mathew, Shaun; Pou-Prom, Chloe; Dai, David; Pequegnat, Victoria; Murray, Joshua; Chokar, Kamalprit; Banning, Michaelia; Mamdani, Muhammad; Mishra, Sharmistha; Batt, Jane",,,,,"Guerzhoy, Michael/0000-0003-1856-6742; Landsman, David/0000-0001-8214-5585",,,"Cohort profile: St. Michael's Hospital Tuberculosis Database (SMH-TB), a retrospective cohort of electronic health record data and variables extracted using natural language processing",,,,,,,,PLOS ONE,,,,16,3,,,,,e0247872,10.1371/journal.pone.0247872,,,,MAR 3 2021,2021,"BackgroundTuberculosis (TB) is a major cause of death worldwide. TB research draws heavily on clinical cohorts which can be generated using electronic health records (EHR), but granular information extracted from unstructured EHR data is limited. The St. Michael's Hospital TB database (SMH-TB) was established to address gaps in EHR-derived TB clinical cohorts and provide researchers and clinicians with detailed, granular data related to TB management and treatment.MethodsWe collected and validated multiple layers of EHR data from the TB outpatient clinic at St. Michael's Hospital, Toronto, Ontario, Canada to generate the SMH-TB database. SMH-TB contains structured data directly from the EHR, and variables generated using natural language processing (NLP) by extracting relevant information from free-text within clinic, radiology, and other notes. NLP performance was assessed using recall, precision and F-1 score averaged across variable labels. We present characteristics of the cohort population using binomial proportions and 95% confidence intervals (CI), with and without adjusting for NLP misclassification errors.ResultsSMH-TB currently contains retrospective patient data spanning 2011 to 2018, for a total of 3298 patients (N = 3237 with at least 1 associated dictation). Performance of TB diagnosis and medication NLP rulesets surpasses 93% in recall, precision and F-1 metrics, indicating good generalizability. We estimated 20% (95% CI: 18.4-21.2%) were diagnosed with active TB and 46% (95% CI: 43.8-47.2%) were diagnosed with latent TB. After adjusting for potential misclassification, the proportion of patients diagnosed with active and latent TB was 18% (95% CI: 16.8-19.7%) and 40% (95% CI: 37.8-41.6%) respectivelyConclusionSMH-TB is a unique database that includes a breadth of structured data derived from structured and unstructured EHR data by using NLP rulesets. The data are available for a variety of research applications, such as clinical epidemiology, quality improvement and mathematical modeling studies.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000625981500036,33657184,
J,"Wu, Stephen; Liu, Sijia; Sohn, Sunghwan; Moon, Sungrim; Wi, Chung-il; Juhn, Young; Liu, Hongfang",,,,,"Liu, Sijia/0000-0001-9763-1164",,,Modeling asynchronous event sequences with RNNs,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,83,,,,167,177,,10.1016/j.jbi.2018.05.016,,,,JUL 2018,2018,"Sequences of events have often been modeled with computational techniques, but typical preprocessing steps and problem settings do not explicitly address the ramifications of timestamped events. Clinical data, such as is found in electronic health records (EHRs), typically comes with timestamp information. In this work, we define event sequences and their properties: synchronicity, evenness, and co-cardinality; we then show how asynchronous, uneven, and multi-cardinal problem settings can support explicit accountings of relative dine. Our evaluation uses the temporally sensitive clinical use case of pediatric asthma, which is a chronic disease with symptoms (and lack thereof) evolving over time. We show several approaches to explicitly incorporating relative time into a recurrent neural network (RNN) model that improve the overall classification of patients into those with no asthma, those with persistent asthma, those in long-term remission, and those who have experienced relapse. We also compare and contrast these results with those in an inpatient intensive care setting.",,,,,,,,,17,0,0,0,8,0,17,,,1532-0464,1532-0480,,WOS:000445054700016,29883623,
J,"Balestra, Martina; Chen, Ji; Iturrate, Eduardo; Aphinyanaphongs, Yindalon; Nov, Oded",,,,,"Balestra, Martina/0000-0003-4246-3719",,,Predicting inpatient pharmacy order interventions using provider action data,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab083,10.1093/jamiaopen/ooab083,,,,JUL 2021,2021,"Objective: The widespread deployment of electronic health records (EHRs) has introduced new sources of error and inefficiencies to the process of ordering medications in the hospital setting. Existing work identifies orders that require pharmacy intervention by comparing them to a patient's medical records. In this work, we develop a machine learning model for identifying medication orders requiring intervention using only provider behavior and other contextual features that may reflect these new sources of inefficiencies.Materials and Methods: Data on providers' actions in the EHR system and pharmacy orders were collected over a 2-week period in a major metropolitan hospital system. A classification model was then built to identify orders requiring pharmacist intervention. We tune the model to the context in which it would be deployed and evaluate global and local feature importance.Results: The resultant model had an area under the receiver-operator characteristic curve of 0.91 and an area under the precision-recall curve of 0.44.Conclusions: Providers' actions can serve as useful predictors in identifying medication orders that require pharmacy intervention. Careful model tuning for the clinical context in which the model is deployed can help to create an effective tool for improving health outcomes without using sensitive patient data.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500051,34617009,
J,"Zhao, Juan; Zhang, Yun; Schlueter, David J.; Wu, Patrick; Kerchberger, Vern Eric; Rosenbloom, S. Trent; Wells, Quinn S.; Feng, QiPing; Denny, Joshua C.; Wei, Wei-Qi",,,,"Kerchberger, Vern/AAH-2302-2020; Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Wu, Patrick/0000-0002-1437-6688; Kerchberger, Vern/0000-0002-0342-1965",,,Detecting time-evolving phenotypic topics via tensor factorization on electronic health records: Cardiovascular disease case study,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103270,10.1016/j.jbi.2019.103270,,,,OCT 2019,2019,"Objective: Discovering subphenotypes of complex diseases can help characterize disease cohorts for investigative studies aimed at developing better diagnoses and treatments. Recent advances in unsupervised machine learning on electronic health record (EHR) data have enabled researchers to discover phenotypes without input from domain experts. However, most existing studies have ignored time and modeled diseases as discrete events. Uncovering the evolution of phenotypes - how they emerge, evolve and contribute to health outcomes - is essential to define more precise phenotypes and refine the understanding of disease progression. Our objective was to assess the benefits of an unsupervised approach that incorporates time to model diseases as dynamic processes in phenotype discovery.Methods: In this study, we applied a constrained non-negative tensor-factorization approach to characterize the complexity of cardiovascular disease (CVD) patient cohort based on longitudinal EHR data. Through tensorfactorization, we identified a set of phenotypic topics (i.e., subphenotypes) that these patients established over the 10 years prior to the diagnosis of CVD, and showed the progress pattern. For each identified subphenotype, we examined its association with the risk for adverse cardiovascular outcomes estimated by the American College of Cardiology/American Heart Association Pooled Cohort Risk Equations, a conventional CVD-risk assessment tool frequently used in clinical practice. Furthermore, we compared the subsequent myocardial infarction (MI) rates among the six most prevalent subphenotypes using survival analysis.Results: From a cohort of 12,380 adult CVD individuals with 1068 unique PheCodes, we successfully identified 14 subphenotypes. Through the association analysis with estimated CVD risk for each subtype, we found some phenotypic topics such as Vitamin D deficiency and depression, Urinary infections cannot be explained by the conventional risk factors. Through a survival analysis, we found markedly different risks of subsequent MI following the diagnosis of CVD among the six most prevalent topics (p < 0.0001), indicating these topics may capture clinically meaningful subphenotypes of CVD.Conclusion: This study demonstrates the potential benefits of using tensor-decomposition to model diseases as dynamic processes from longitudinal EHR data. Our results suggest that this data-driven approach may potentially help researchers identify complex and chronic disease subphenotypes in precision medicine research.",,,,,,,,,11,1,0,0,6,0,11,,,1532-0464,1532-0480,,WOS:000525699600005,31445983,
J,"Topaz, Maxim; Murga, Ludmila; Gaddis, Katherine M.; McDonald, Margaret V.; Bar-Bachar, Ofrit; Goldberg, Yoav; Bowles, Kathryn H.",,,,"Topaz, Maxim/AAQ-7121-2021","Topaz, Maxim/0000-0002-2358-9837; McDonald, Margaret/0000-0003-1045-0956",,,Mining fall-related information in clinical notes: Comparison of rule-based and novel word embedding-based machine learning approaches,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,90,,,,,,103103,10.1016/j.jbi.2019.103103,,,,FEB 2019,2019,"Background: Natural language processing (NLP) of health-related data is still an expertise demanding, and resource expensive process. We created a novel, open source rapid clinical text mining system called NimbleMiner. NimbleMiner combines several machine learning techniques (word embedding models and positive only labels learning) to facilitate the process in which a human rapidly performs text mining of clinical narratives, while being aided by the machine learning components.Objective: This manuscript describes the general system architecture and user Interface and presents results of a case study aimed at classifying fall-related information (including fall history, fall prevention interventions, and fall risk) in homecare visit notes.Methods: We extracted a corpus of homecare visit notes (n = 1,149,586) for 89,459 patients from a large US based homecare agency. We used a gold standard testing dataset of 750 notes annotated by two human reviewers to compare the NimbleMiner's ability to classify documents regarding whether they contain fall-related information with a previously developed rule-based NLP system.Results: NimbleMiner outperformed the rule-based system in almost all domains. The overall F- score was 85.8% compared to 81% by the rule based-system with the best performance for identifying general fall history (F = 89% vs. F = 85.1% rule-based), followed by fall risk (F = 87% vs. F = 78.7% rule-based), fall prevention interventions (F = 88.1% vs. F = 78.2% rule-based) and fall within 2 days of the note date (F = 83.1% vs. F = 80.6% rule-based). The rule-based system achieved slightly better performance for fall within 2 weeks of the note date (F = 81.9% vs. F = 84% rule-based).Discussion & conclusions: NimbleMiner outperformed other systems aimed at fall information classification, including our previously developed rule-based approach. These promising results indicate that clinical text mining can be implemented without the need for large labeled datasets necessary for other types of machine learning. This is critical for domains with little NLP developments, like nursing or allied health professions.",,,,,,,,,23,0,0,0,2,0,23,,,1532-0464,1532-0480,,WOS:000462243700009,30639392,
J,"DeLozier, Sarah; Speltz, Peter; Brito, Jason; Tang, Leigh Anne; Wang, Janey; Smith, Joshua C.; Giuse, Dario; Phillips, Elizabeth; Williams, Kristina; Strickland, Teresa; Davogustto, Giovanni; Roden, Dan; Denny, Joshua C.",,,,"Roden, Dan/ABD-5412-2021",,,,Real-time clinical note monitoring to detect conditions for rapid follow-up: A case study of clinical trial enrollment in drug-induced torsades de pointes and Stevens-Johnson syndrome,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,1,,,126,131,,10.1093/jamia/ocaa213,,,,JAN 2021,2021,"Identifying acute events as they occur is challenging in large hospital systems. Here, we describe an automated method to detect 2 rare adverse drug events (ADEs), drug-induced torsades de pointes and Stevens-Johnson syndrome and toxic epidermal necrolysis, in near real time for participant recruitment into prospective clinical studies. A text processing system searched clinical notes from the electronic health record (EHR) for relevant keywords and alerted study personnel via email of potential patients for chart review or in-person evaluation. Between 2016 and 2018, the automated recruitment system resulted in capture of 138 true cases of drug-induced rare events, improving recall from 43% to 93%. Our focused electronic alert system maintained 2-year enrollment, including across an EHR migration from a bespoke system to Epic. Real-time monitoring of EHR notes may accelerate research for certain conditions less amenable to conventional study recruitment paradigms.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000648972200016,33120413,
J,"Trivedi, Gaurav; Phuong Pham; Chapman, Wendy W.; Hwa, Rebecca; Wiebe, Janyce; Hochheiser, Harry",,,,"Trivedi, Gaurav/J-9069-2019","Trivedi, Gaurav/0000-0001-8472-2139",,,NLPReViz: an interactive tool for natural language processing on clinical text,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,1,,,81,87,,10.1093/jamia/ocx070,,,,JAN 2018,2018,"The gap between domain experts and natural language processing expertise is a barrier to extracting understanding from clinical text. We describe a prototype tool for interactive review and revision of natural language processing models of binary concepts extracted from clinical notes. We evaluated our prototype in a user study involving 9 physicians, who used our tool to build and revise models for 2 colonoscopy quality variables. We report changes in performance relative to the quantity of feedback. Using initial training sets as small as 10 documents, expert review led to final F(1)scores for the appendiceal-orifice variable between 0.78 and 0.91 (with improvements ranging from 13.26% to 29.90%). F(1)for biopsy ranged between 0.88 and 0.94 (-1.52% to 11.74% improvements). The average System Usability Scale score was 70.56. Subjective feedback also suggests possible design improvements.",,,,,,,,,13,1,0,0,2,0,14,,,1067-5027,1527-974X,,WOS:000419605800013,29016825,
J,"Kovalchuk, Sergey, V; Funkner, Anastasia A.; Metsker, Oleg G.; Yakovlev, Aleksey N.",,,,"Yakovlev, Alexey/L-7022-2016; Funkner, Anastasia/AAJ-4662-2021; Metsker, Oleg/M-5687-2016; Kovalchuk, Sergey V/A-3025-2010","Yakovlev, Alexey/0000-0001-5656-3978; Funkner, Anastasia/0000-0002-4596-6293; Metsker, Oleg/0000-0003-3427-7932; Kovalchuk, Sergey V/0000-0001-8828-4615",,,Simulation of patient flow in multiple healthcare units using process and data mining techniques for model identification,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,82,,,,128,142,,10.1016/j.jbi.2018.05.004,,,,JUN 2018,2018,"Introduction: An approach to building a hybrid simulation of patient flow is introduced with a combination of data-driven methods for automation of model identification. The approach is described with a conceptual framework and basic methods for combination of different techniques. The implementation of the proposed approach for simulation of the acute coronary syndrome (ACS) was developed and used in an experimental study.Methods: A combination of data, text, process mining techniques, and machine learning approaches for the analysis of electronic health records (EHRs) with discrete-event simulation (DES) and queueing theory for the simulation of patient flow was proposed. The performed analysis of EHRs for ACS patients enabled identification of several classes of clinical pathways (CPs) which were used to implement a more realistic simulation of the patient flow. The developed solution was implemented using Python libraries (SimPy, SciPy, and others).Results: The proposed approach enables more a realistic and detailed simulation of the patient flow within a group of related departments. An experimental study shows an improved simulation of patient length of stay for ACS patient flow obtained from EHRs in Almazov National Medical Research Centre in Saint Petersburg, Russia.Conclusion: The proposed approach, methods, and solutions provide a conceptual, methodological, and programming framework for the implementation of a simulation of complex and diverse scenarios within a flow of patients for different purposes: decision making, training, management optimization, and others.",,,,,,,,,27,0,1,0,6,0,27,,,1532-0464,1532-0480,,WOS:000445054600010,29753874,
J,"Bucher, Brian T; Shi, Jianlin; Pettit, Robert John; Ferraro, Jeffrey; Chapman, Wendy W; Gundlapalli, Adi",,,,,,,,Determination of Marital Status of Patients from Structured and Unstructured Electronic Healthcare Data.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,267,274,,,,,,2019,2019,"Social Determinants of Health, including marital status, are becoming increasingly identified as key drivers of health care utilization. This paper describes a robust method to determine the marital status of patients using structured and unstructured electronic healthcare data from a single academic institution in the United States. We developed and validated a natural language processing pipeline (NLP) for the ascertainment of marital status from clinical notes and compared the performance against two baseline methods: a machine learning n-gram model, and structured data obtained from the electronic health record. Overall our NLP engine had excellent performance on both document-level (F1 0.97) and patient-level (F1 0.95) classification. The NLP Engine had superior performance compared with a baseline machine learning n-gram model. We also observed a good correlation between the marital status obtained from our NLP engine and the baseline structured electronic healthcare data (kappa 0.6).",,,,,,,,,3,0,0,0,0,0,3,,,,1942-597X,,MEDLINE:32308819,32308819,
J,"Goodday, S. M.; Kormilitzin, A.; Vaci, N.; Liu, Q.; Cipriani, A.; Smith, T.; Nevado-Holgado, A.",,,,"; Cipriani, Andrea/P-6944-2015","Goodday, Sarah/0000-0003-2159-1754; Nevado-Holgado, Alejo/0000-0001-9276-2720; Vaci, Nemanja/0000-0002-8094-0902; Cipriani, Andrea/0000-0001-5179-8321",,,Maximizing the use of social and behavioural information from secondary care mental health electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,107,,,,,,103429,10.1016/j.jbi.2020.103429,,,,JUL 2020,2020,"Purpose: The contribution of social and behavioural factors in the development of mental health conditions and treatment effectiveness is widely supported, yet there are weak population level data sources on social and behavioural determinants of mental health. Enriching these data gaps will be crucial to accelerating precision medicine. Some have suggested the broader use of electronic health records (EHR) as a source of non-clinical determinants, although social and behavioural information are not systematically collected metrics in EHRs, internationally.Objective: In this commentary, we highlight the nature and quality of key available structured and unstructured social and behavioural data using a case example of value counts from secondary mental health data available in the UK from the UK Clinical Record Interactive Search (CRIS) database; highlight the methodological challenges in the use of such data; and possible solutions and opportunities involving the use of natural language processing (NLP) of unstructured EHR text.Conclusions: Most structured non-clinical data fields within secondary care mental health EHR data have too much missing data for adequate use. The utility of other non-clinical fields reported semi-consistently (e.g., ethnicity and marital status) is entirely dependent on treating them appropriately in analyses, quantifying the many reasons behind missingness in consideration of selection biases. Advancements in NLP offer new opportunities in the exploitation of unstructured text from secondary care EHR data particularly given that clinical notes and attachments are available in large volumes of patients and are more routinely completed by clinicians. Tackling ways to re-use, harmonize, and improve our existing and future secondary care mental health data, leveraging advanced analytics such as NLP is worth the effort in an attempt to fill the data gap on social and behavioural contributors to mental health conditions and will be necessary to fulfill all of the domains needed to inform personalized interventions.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000551649200005,32387393,
J,"Song, Jiyoun; Hobensack, Mollie; Bowles, Kathryn H.; V. McDonald, Margaret; Cato, Kenrick; Rossetti, Sarah Collins; Chae, Sena; Kennedy, Erin; Barron, Yolanda; Sridharan, Sridevi; Topax, Maxim",,,,,"Kennedy, Erin/0000-0002-1981-0260; McDonald, Margaret/0000-0003-1045-0956; Chae, Sena/0000-0002-9136-6176; Song, Jiyoun/0000-0003-0362-0670",,,Clinical notes: An untapped opportunity for improving risk prediction for hospitalization and emergency department visit during home health care,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,128,,,,,,104039,10.1016/j.jbi.2022.104039,,,,APR 2022,2022,"Background/Objective: Between 10 and 25% patients are hospitalized or visit emergency department (ED) during home healthcare (HHC). Given that up to 40% of these negative clinical outcomes are preventable, early and accurate prediction of hospitalization risk can be one strategy to prevent them. In recent years, machine learningbased predictive modeling has become widely used for building risk models. This study aimed to compare the predictive performance of four risk models built with various data sources for hospitalization and ED visits in HHC. Methods: Four risk models were built using different variables from two data sources: structured data (i.e., Outcome and Assessment Information Set (OASIS) and other assessment items from the electronic health record (EHR)) and unstructured narrative-free text clinical notes for patients who received HHC services from the largest non-profit HHC organization in New York between 2015 and 2017. Then, five machine learning algorithms (logistic regression, Random Forest, Bayesian network, support vector machine (SVM), and Naive Bayes) were used on each risk model. Risk model performance was evaluated using the F-score and Precision-Recall Curve (PRC) area metrics. Results: During the study period, 8373/86,823 (9.6%) HHC episodes resulted in hospitalization or ED visits. Among five machine learning algorithms on each model, the SVM showed the highest F-score (0.82), while the Random Forest showed the highest PRC area (0.864). Adding information extracted from clinical notes significantly improved the risk prediction ability by up to 16.6% in F-score and 17.8% in PRC. Conclusion: All models showed relatively good hospitalization or ED visit risk predictive performance in HHC. Information from clinical notes integrated with the structured data improved the ability to identify patients at risk for these emergent care events.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000767877600012,35231649,
J,"Banerjee, Imon; Li, Kevin; Seneviratne, Martin; Ferrari, Michelle; Seto, Tina; Brooks, James D.; Rubin, Daniel L.; Hernandez-Boussard, Tina",,,,,"Seneviratne, Martin/0000-0003-0435-3738; Seto, Tina/0000-0002-7937-9564; Banerjee, Imon/0000-0002-3327-8004",,,Weakly supervised natural language processing for assessing patient-centered outcome following prostate cancer treatment,,,,,,,,JAMIA OPEN,,,,2,1,,,150,159,,10.1093/jamiaopen/ooy057,,,,APR 2019,2019,"Background: The population-based assessment of patient-centered outcomes (PCOs) has been limited by the efficient and accurate collection of these data. Natural language processing (NLP) pipelines can determine whether a clinical note within an electronic medical record contains evidence on these data. We present and demonstrate the accuracy of an NLP pipeline that targets to assess the presence, absence, or risk discussion of two important PCOs following prostate cancer treatment: urinary incontinence (UI) and bowel dysfunction (BD).Methods: We propose a weakly supervised NLP approach which annotates electronic medical record clinical notes without requiring manual chart review. A weighted function of neural word embedding was used to create a sentence-level vector representation of relevant expressions extracted from the clinical notes. Sentence vectors were used as input for a multinomial logistic model, with output being either presence, absence or risk discussion of UI/BD. The classifier was trained based on automated sentence annotation depending only on domain-specific dictionaries (weak supervision).Results: The model achieved an average F1 score of 0.86 for the sentence-level, three-tier classification task (presence/absence/risk) in both UI and BD. The model also outperformed a pre-existing rule-based model for note-level annotation of UI with significant margin.Conclusions: We demonstrate a machine learning method to categorize clinical notes based on important PCOs that trains a classifier on sentence vector representations labeled with a domain-specific dictionary, which eliminates the need for manual engineering of linguistic rules or manual chart review for extracting the PCOs. The weakly supervised NLP pipeline showed promising sensitivity and specificity for identifying important PCOs in unstructured clinical text notes compared to rule-based algorithms.",,,,,,,,,13,0,0,0,3,0,13,,,,2574-2531,,WOS:000645417700020,31032481,
J,"Alfattni, Ghada; Peek, Niels; Nenadic, Goran",,,,,"Alfattni, Ghada/0000-0002-2060-195X",,,Extraction of temporal relations from clinical free text: A systematic review of current approaches,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103488,10.1016/j.jbi.2020.103488,,,,AUG 2020,2020,"Background: Temporal relations between clinical events play an important role in clinical assessment and decision making. Extracting such relations from free text data is a challenging task because it lies on between medical natural language processing, temporal representation and temporal reasoning.Objectives: To survey existing methods for extracting temporal relations (TLINKs) between events from clinical free text in English; to establish the state-of-the-art in this field; and to identify outstanding methodological challenges.Methods: A systematic search in PubMed and the DBLP computer science bibliography was conducted for studies published between January 2006 and December 2018. The relevant studies were identified by examining the titles and abstracts. Then, the full text of selected studies was analyzed in depth and information were collected on TLINK tasks, TLINK types, data sources, features selection, methods used, and reported performance.Results: A total of 2834 publications were identified for title and abstract screening. Of these publications, 51 studies were selected. Thirty-two studies used machine learning approaches, 15 studies used a hybrid approaches, and only four studies used a rule-based approach. The majority of studies use publicly available corpora: THYME (28 studies) and the i2b2 corpus (17 studies).Conclusion: The performance of TLINK extraction methods ranges widely depending on relation types and events (e.g. from 32% to 87% F-score for identifying relations between clinical events and document creation time). A small set of TLINKs (before, after, overlap and contains) has been widely studied with relatively good performance, whereas other types of TLINK (e.g., started by, finished by, precedes) are rarely studied and remain challenging. Machine learning classifiers (such as Support Vector Machine and Conditional Random Fields) and Deep Neural Networks were among the best performing methods for extracting TLINKs, but nearly all the work has been carried out and tested on two publicly available corpora only. The field would benefit from the availability of more publicly available, high-quality, annotated clinical text corpora.",,,,,,,,,10,1,0,0,4,0,11,,,1532-0464,1532-0480,,WOS:000564595700011,32673788,
J,"Maurits, Marc P.; Korsunsky, Ilya; Raychaudhuri, Soumya; Murphy, Shawn N.; Smoller, Jordan W.; Weiss, Scott T.; Huizinga, Thomas W. J.; Reinders, Marcel J. T.; Karlson, Elizabeth W.; van den Akker, Erik B.; Knevel, Rachel",,,,"Maurits, Marc/Y-2432-2018","Maurits, Marc/0000-0002-3266-6232",,,A framework for employing longitudinally collected multicenter electronic health records to stratify heterogeneous patient populations on disease history,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac008,,FEB 2022,,,2022,"Objective To facilitate patient disease subset and risk factor identification by constructing a pipeline which is generalizable, provides easily interpretable results, and allows replication by overcoming electronic health records (EHRs) batch effects. Material and Methods We used 1872 billing codes in EHRs of 102 880 patients from 12 healthcare systems. Using tools borrowed from single-cell omics, we mitigated center-specific batch effects and performed clustering to identify patients with highly similar medical history patterns across the various centers. Our visualization method (PheSpec) depicts the phenotypic profile of clusters, applies a novel filtering of noninformative codes (Ranked Scope Pervasion), and indicates the most distinguishing features. Results We observed 114 clinically meaningful profiles, for example, linking prostate hyperplasia with cancer and diabetes with cardiovascular problems and grouping pediatric developmental disorders. Our framework identified disease subsets, exemplified by 6 other headache clusters, where phenotypic profiles suggested different underlying mechanisms: migraine, convulsion, injury, eye problems, joint pain, and pituitary gland disorders. Phenotypic patterns replicated well, with high correlations of >= 0.75 to an average of 6 (2-8) of the 12 different cohorts, demonstrating the consistency with which our method discovers disease history profiles. Discussion Costly clinical research ventures should be based on solid hypotheses. We repurpose methods from single-cell omics to build these hypotheses from observational EHR data, distilling useful information from complex data. Conclusion We establish a generalizable pipeline for the identification and replication of clinically meaningful (sub)phenotypes from widely available high-dimensional billing codes. This approach overcomes datatype problems and produces comprehensive visualizations of validation-ready phenotypes.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000767677800001,35139533,
J,"Jones, Audrey L; Pettey, Warren B P; Carter, Marjorie E; Brignone, Emily; Redd, Andrew; Suo, Ying; Divita, Guy; Blais, Rebecca K; Fargo, Jamison D; Gundlapalli, Adi V",,,,,"Pettey, Warren/0000-0002-4436-3319; Jones, Audrey/0000-0003-1533-7469",,,Regional Variations in Documentation of Sexual Trauma Concepts in Electronic Medical Records in the United States Veterans Health Administration.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,514,522,,,,,,2019,2019,"Background: Experiences of sexual trauma are associated with adverse patient and health system outcomes, but are not systematically documented in electronic health records (EHR). Objective: To describe variations in how sexual trauma is documented in the Veterans Health Adminstration's EHR. Methods: Sexual trauma concepts were extracted from from 362,559 clinical notes using a natural language processing pipeline. Results: We observed variations in the presence of sexual trauma in notes across five United States regions: Pacific, Continental, Midwest, North Atlantic, Southeast. We also observed variations in the types of notes used to document sexual trauma (e.g., mental health, primary care) and sources of sexual trauma (e.g., adult, childhood, military) mentioned in the EHR. Our findings illustrate potential differences in cultural norms related to patient disclosure of sensitive information, and provider documentation. Standardized protocol for eliciting and documenting sexual trauma histories are needed to ensure Veteran access to high quality, trauma-informed care.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:32308845,32308845,
J,"Caraballo, Pedro J.; Sutton, Joseph A.; Giri, Jyothsna; Wright, Jessica A.; Nicholson, Wayne T.; Kullo, Iftikhar; Parkulo, Mark A.; Bielinski, Suzette J.; Moyer, Ann M.",,,,"Bielinski, Suzette/A-2238-2009","Bielinski, Suzette/0000-0002-2905-5430; Wright, Jessica/0000-0001-9659-4875",,,Integrating pharmacogenomics into the electronic health record by implementing genomic indicators,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,154,158,,10.1093/jamia/ocz177,,,,JAN 2020,2020,"Pharmacogenomics (PGx) clinical decision support integrated into the electronic health record (EHR) has the potential to provide relevant knowledge to clinicians to enable individualized care. However, past experience implementing PGx clinical decision support into multiple EHR platforms has identified important clinical, procedural, and technical challenges. Commercial EHRs have been widely criticized for the lack of readiness to implement precision medicine. Herein, we share our experiences and lessons learned implementing new EHR functionality charting PGx phenotypes in a unique repository, genomic indicators, instead of using the problem or allergy list. The Gen-Ind has additional features including a brief description of the clinical impact, a hyperlink to the original laboratory report, and links to additional educational resources. The automatic generation of genomic indicators from interfaced PGx test results facilitates implementation and long-term maintenance of PGx data in the EHR and can be used as criteria for synchronous and asynchronous CDS.",,,,,,,,,7,0,0,0,4,0,7,,,1067-5027,1527-974X,,WOS:000548300200019,31591640,
J,"Yehia, Engy; Boshnak, Hussein; AbdelGaber, Sayed; Abdo, Amany; Elzanfaly, Doaa S.",,,,,,,,Ontology-based clinical information extraction from physician's free-text notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103276,10.1016/j.jbi.2019.103276,,,,OCT 2019,2019,"Documenting clinical notes in electronic health records might affect physician's workflow. In this paper, an Ontology-based clinical information extraction system, OB-CIE, has been developed. OB-CIE system provides a method for extracting clinical concepts from physician's free-text notes and converts the unstructured clinical notes to structured information to be accessed in electronic health records. OB-CIE system can help physicians to document visit notes without changing their workflow. For recognizing named entities of clinical concepts, ontology concepts have been used to construct a dictionary of semantic categories, then, exact dictionary matching method has been used to match noun phrases to their semantic categories. A rule-based approach has been used to classify clinical sentences to their predefined categories. The system evaluation results have achieved an F-measure of 94.90% and 97.80% for concepts classification and sentences classification, respectively. The results have showed that OB-CIE system performed well on extracting clinical concepts compared with data mining techniques. The system can be used in another field by adapting its ontology and extraction rule set.",,,,,,,,,6,0,0,0,0,0,6,,,1532-0464,1532-0480,,WOS:000525699600010,31473365,
J,"Buckland, Ryan S; Hogan, Joseph W; Chen, Elizabeth S",,,,,,,,Selection of Clinical Text Features for Classifying Suicide Attempts.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,273,282,,,,,,2020,2020,"Research has demonstrated cohort misclassification when studies of suicidal thoughts and behaviors (STBs) rely on ICD-9/10-CM diagnosis codes. Electronic health record (EHR) data are being explored to better identify patients, a process called EHR phenotyping. Most STB phenotyping studies have used structured EHR data, but some are beginning to incorporate unstructured clinical text. In this study, we used a publicly-accessible natural language processing (NLP) program for biomedical text (MetaMap) and iterative elastic net regression to extract and select predictive text features from the discharge summaries of 810 inpatient admissions of interest. Initial sets of 5,866 and 2,709 text features were reduced to 18 and 11, respectively. The two models fit with these features obtained an area under the receiver operating characteristic curve of 0.866-0.895 and an area under the precision-recall curve of 0.800-0.838, demonstrating the approach's potential to identify textual features to incorporate in phenotyping models.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936399,33936399,
J,"Yan, Melissa Y.; Gustad, Lise Tuset; Nytro, Oystein",,,,,"Nytro, Oystein/0000-0002-8163-2362; Yan, Melissa/0000-0002-8079-7923; Gustad, Lise Tuset/0000-0003-2709-3991",,,"Sepsis prediction, early detection, and identification using clinical text for machine learning: a systematic review",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,559,575,,10.1093/jamia/ocab236,,,,JAN 29 2022,2022,"Objective To determine the effects of using unstructured clinical text in machine learning (ML) for prediction, early detection, and identification of sepsis. Materials and methods PubMed, Scopus, ACM DL, dblp, and IEEE Xplore databases were searched. Articles utilizing clinical text for ML or natural language processing (NLP) to detect, identify, recognize, diagnose, or predict the onset, development, progress, or prognosis of systemic inflammatory response syndrome, sepsis, severe sepsis, or septic shock were included. Sepsis definition, dataset, types of data, ML models, NLP techniques, and evaluation metrics were extracted. Results The clinical text used in models include narrative notes written by nurses, physicians, and specialists in varying situations. This is often combined with common structured data such as demographics, vital signs, laboratory data, and medications. Area under the receiver operating characteristic curve (AUC) comparison of ML methods showed that utilizing both text and structured data predicts sepsis earlier and more accurately than structured data alone. No meta-analysis was performed because of incomparable measurements among the 9 included studies. Discussion Studies focused on sepsis identification or early detection before onset; no studies used patient histories beyond the current episode of care to predict sepsis. Sepsis definition affects reporting methods, outcomes, and results. Many methods rely on continuous vital sign measurements in intensive care, making them not easily transferable to general ward units. Conclusions Approaches were heterogeneous, but studies showed that utilizing both unstructured text and structured data in ML can improve identification and early detection of sepsis.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000761451900017,34897469,
J,"Aliabadi, Ali; Sheikhtaheri, Abbas; Ansari, Hossein",,,,"Sheikhtaheri, Abbas/M-6433-2018","Sheikhtaheri, Abbas/0000-0002-6879-5415",,,Electronic health record-based disease surveillance systems: A systematic literature review on challenges and solutions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1977,1986,,10.1093/jamia/ocaa186,,,,DEC 2020,2020,"Objective: Disease surveillance systems are expanding using electronic health records (EHRs). However, there are many challenges in this regard. In the present study, the solutions and challenges of implementing EHR-based disease surveillance systems (EHR-DS) have been reviewed.Materials and Methods: We searched the related keywords in ProQuest, PubMed, Web of Science, Cochrane Library, Embase, and Scopus. Then, we assessed and selected articles using the inclusion and exclusion criteria and, finally, classified the identified solutions and challenges.Results: Finally, 50 studies were included, and 52 unique solutions and 47 challenges were organized into 6 main themes (policy and regulatory, technical, management, standardization, financial, and data quality). The results indicate that due to the multifaceted nature of the challenges, the implementation of EHR-DS is not low cost and easy to implement and requires a variety of interventions. On the one hand, the most common challenges include the need to invest significant time and resources; the poor data quality in EHRs; difficulty in analyzing, cleaning, and accessing unstructured data; data privacy and security; and the lack of interoperability standards. On the other hand, the most common solutions are the use of natural language processing and machine learning algorithms for unstructured data; the use of appropriate technical solutions for data retrieval, extraction, identification, and visualization; the collaboration of health and clinical departments to access data; standardizing EHR content for public health; and using a unique health identifier for individuals.Conclusions: EHR systems have an important role in modernizing disease surveillance systems. However, there are many problems and challenges facing the development and implementation of EHR-DS that need to be appropriately addressed.",,,,,,,,,5,0,0,0,1,0,5,,,1067-5027,1527-974X,,WOS:000606832500019,32929458,
J,"Hassanzadeh, Hamed; Karimi, Sarvnaz; Nguyen, Anthony",,,,"Nguyen, Anthony/AFQ-7018-2022; Hassanzadeh, Hamed/O-2719-2019; Nguyen, Anthony/B-5913-2009","Nguyen, Anthony/0000-0002-6215-6954; Hassanzadeh, Hamed/0000-0003-2315-1963; Nguyen, Anthony/0000-0002-6215-6954; Karimi, Sarvnaz/0000-0002-4927-3937",,,Matching patients to clinical trials using semantically enriched document representation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,105,,,,,,103406,10.1016/j.jbi.2020.103406,,,,MAY 2020,2020,"Recruiting eligible patients for clinical trials is crucial for reliably answering specific questions about medical interventions and evaluation. However, clinical trial recruitment is a bottleneck in clinical research and drug development. Our goal is to provide an approach towards automating this manual and time-consuming patient recruitment task using natural language processing and machine learning techniques. Specifically, our approach extracts key information from series of narrative clinical documents in patient's records and collates helpful evidence to make decisions on eligibility of patients according to certain inclusion and exclusion criteria. Challenges in applying narrative clinical documents such as differences in reporting styles and sub-languages are addressed by enriching them with knowledge from domain ontologies in the form of semantic vector representations. We show that a machine learning model based on Multi-Layer Perceptron (MLP) is more effective for the task than five other neural networks and four conventional machine learning models. Our approach achieves overall micro-F1-Score of 84% for 13 different eligibility criteria. Our experiments also indicate that semantically enriched documents are more effective than using original documents for cohort selection. Our system provides an end-to-end machine learning-based solution that achieves comparable results with the state-of-the-art which relies on hand-crafted rules or data-centric engineered features.",,,,,,,,,7,0,0,0,2,0,7,,,1532-0464,1532-0480,,WOS:000535653800007,32169670,
J,"Bush, Ruth A.; Perez, Alexa; Baum, Tanja; Etland, Caroline; Connelly, Cynthia D.",,,,,", Ruth/0000-0002-1610-132X",,,"A systematic review of the use of the electronic health record for patient identification, communication, and clinical support in palliative care",,,,,,,,JAMIA OPEN,,,,1,2,,,294,303,,10.1093/jamiaopen/ooy028,,,,OCT 2018,2018,"Objectives: Globally, healthcare systems are using the electronic health record (EHR) and elements of clinical decision support (CDS) to facilitate palliative care (PC). Examination of published results is needed to determine if the EHR is successfully supporting the multidisciplinary nature and complexity of PC by identifying applications, methodology, outcomes, and barriers of active incorporation of the EHR in PC clinical workflow.Methods: A systematic review using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The data sources PubMed, CINAL, EBSCOhost, and Academic Search Premier were used to identify literature published 1999-2017 of human subject peer-reviewed articles in English containing original research about the EHR and PC.Results: The search returned 433 articles, 30 of which met inclusion criteria. Most studies were feasibility studies or retrospective cohort analyses; one study incorporated prospective longitudinal mixed methods. Twenty-three of 30 (77%) were published after 2014. The review identified five major areas in which the EHR is used to support PC. Studies focused on CDS to: identify individuals who could benefit from PC; electronic advanced care planning (ACP) documentation; patient-reported outcomemeasures (PROMs) such as rapid, real-time pain feedback; to augment EHR PC data capture capabilities; and to enhance interdisciplinary communication and care.Discussion: Beginning in 2015, there was a proliferation of articles about PC and EHRs, suggesting increasing incorporation of and research about the EHR with PC. This review indicates the EHR is underutilized for PC CDS, facilitating PROMs, and capturing ACPs.",,,,,,,,,14,0,0,0,0,0,14,,,,2574-2531,,WOS:000645417100023,30842998,
J,"Nori, Vijay S.; Hane, Christopher A.; Sun, Yezhou; Crown, William H.; Bleicher, Paul A.",,,,,,,,Deep neural network models for identifying incident dementia using claims and EHR datasets,,,,,,,,PLOS ONE,,,,15,9,,,,,e0236400,10.1371/journal.pone.0236400,,,,SEP 24 2020,2020,"This study investigates the use of deep learning methods to improve the accuracy of a predictive model for dementia, and compares the performance to a traditional machine learning model. With sufficient accuracy the model can be deployed as a first round screening tool for clinical follow-up including neurological examination, neuropsychological testing, imaging and recruitment to clinical trials. Seven cohorts with two years of data, three to eight years prior to index date, and an incident cohort were created. Four trained models for each cohort, boosted trees, feed forward network, recurrent neural network and recurrent neural network with pre-trained weights, were constructed and their performance compared using validation and test data. The incident model had an AUC of 94.4% and F1 score of 54.1%. Eight years removed from index date the AUC and F1 scores were 80.7% and 25.6%, respectively. The results for the remaining cohorts were between these ranges. Deep learning models can result in significant improvement in performance but come at a cost in terms of run times and hardware requirements. The results of the model at index date indicate that this modeling can be effective at stratifying patients at risk of dementia. At this time, the inability to sustain this quality at longer lead times is more an issue of data availability and quality rather than one of algorithm choices.",,,,,,,,,5,0,0,0,2,0,5,,,1932-6203,,,WOS:000576265600104,32970677,
J,"Nagata, Kenichiro; Tsuji, Toshikazu; Suetsugu, Kimitaka; Muraoka, Kayoko; Watanabe, Hiroyuki; Kanaya, Akiko; Egashira, Nobuaki; Ieiri, Ichiro",,,,,,,,Detection of overdose and underdose prescriptions-An unsupervised machine learning approach,,,,,,,,PLOS ONE,,,,16,11,,,,,e0260315,10.1371/journal.pone.0260315,,,,NOV 19 2021,2021,"Overdose prescription errors sometimes cause serious life-threatening adverse drug events, while underdose errors lead to diminished therapeutic effects. Therefore, it is important to detect and prevent these errors. In the present study, we used the one-class support vector machine (OCSVM), one of the most common unsupervised machine learning algorithms for anomaly detection, to identify overdose and underdose prescriptions. We extracted prescription data from electronic health records in Kyushu University Hospital between January 1, 2014 and December 31, 2019. We constructed an OCSVM model for each of the 21 candidate drugs using three features: age, weight, and dose. Clinical overdose and underdose prescriptions, which were identified and rectified by pharmacists before administration, were collected. Synthetic overdose and underdose prescriptions were created using the maximum and minimum doses, defined by drug labels or the UpToDate database. We applied these prescription data to the OCSVM model and evaluated its detection performance. We also performed comparative analysis with other unsupervised outlier detection algorithms (local outlier factor, isolation forest, and robust covariance). Twenty-seven out of 31 clinical overdose and underdose prescriptions (87.1%) were detected as abnormal by the model. The constructed OCSVM models showed high performance for detecting synthetic overdose prescriptions (precision 0.986, recall 0.964, and F-measure 0.973) and synthetic underdose prescriptions (precision 0.980, recall 0.794, and F-measure 0.839). In comparative analysis, OCSVM showed the best performance. Our models detected the majority of clinical overdose and underdose prescriptions and demonstrated high performance in synthetic data analysis. OCSVM models, constructed using features such as age, weight, and dose, are useful for detecting overdose and underdose prescriptions.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000755334700062,34797894,
J,"Roy, Subhrajit; Mincu, Diana; Loreaux, Eric; Mottram, Anne; Protsyuk, Ivan; Harris, Natalie; Xue, Yuan; Schrouff, Jessica; Montgomery, Hugh; Connell, Alistair; Tomasev, Nenad; Karthikesalingam, Alan; Seneviratne, Martin",,,,"Montgomery, Hugh/C-2592-2008","Montgomery, Hugh/0000-0001-8797-5019",,,Multitask prediction of organ dysfunction in the intensive care unit using sequential subnetwork routing,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,9,,,1936,1946,,10.1093/jamia/ocab101,,JUN 2021,,SEP 2021,2021,"Objective: Multitask learning (MTL) using electronic health records allows concurrent prediction of multiple endpoints. MTL has shown promise in improving model performance and training efficiency; however, it often suffers from negative transfer - impaired learning if tasks are not appropriately selected. We introduce a sequential subnetwork routing (SeqSNR) architecture that uses soft parameter sharing to find related tasks and encourage cross-learning between them.Materials and Methods: Using the MIMIC-III (Medical Information Mart for Intensive Care-III) dataset, we train deep neural network models to predict the onset of 6 endpoints including specific organ dysfunctions and general clinical outcomes: acute kidney injury, continuous renal replacement therapy, mechanical ventilation, vasoactive medications, mortality, and length of stay. We compare single-task (ST) models with naive multitask and SeqSNR in terms of discriminative performance and label efficiency.Results: SeqSNR showed a modest yet statistically significant performance boost across 4 of 6 tasks compared with ST and naive multitasking. When the size of the training dataset was reduced for a given task (label efficiency), SeqSNR outperformed ST for all cases showing an average area under the precision-recall curve boost of 2.1%, 2.9%, and 2.1% for tasks using 1%, 5%, and 10% of labels, respectively.Conclusions: The SeqSNR architecture shows superior label efficiency compared with ST and naive multitasking, suggesting utility in scenarios in which endpoint labels are difficult to ascertain.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000692577000016,34151965,
J,"Brelsford, Kathleen M.; Spratt, Susan E.; Beskow, Laura M.",,,,,"Beskow, Laura/0000-0002-9314-1915; Brelsford, Kathleen/0000-0002-9423-681X",,,Research use of electronic health records: patients' perspectives on contact by researchers,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,9,,,1122,1129,,10.1093/jamia/ocy087,,,,SEP 2018,2018,"Objective: The use of electronic health records (EHRs) for research has the potential to improve the diagnosis and treatment of disease, yet contact with patients based on results of EHR phenotyping has received little attention. Researchers will almost certainly discover discrepancies in EHRs that call for resolution and, in some cases, raise the ethical dilemma of whether to contact patients about a potentially undiagnosed or untreated health concern. The objective of this study was to explore patients' attitudes and opinions about potential contact by researchers who have had access to their EHRs.Materials and methods: We conducted 15 focus groups in four diverse counties in the southeastern United States. We designed vignettes to describe different situations in which researchers conducting a hypothetical study might have reason to consider contact with patients.Results: Many patients believed it was important for researchers to take action if they discovered information suggesting a current serious health concern. Relaying the information through patients' physicians was considered the most appropriate course of action. Across vignettes, there were significant differences between urban and rural sites.Discussion and conclusions: Researchers may increasingly encounter situations involving contact with patients following EHR phenotyping. They should carefully consider the possibility of such contact when planning their studies, including the time and expertise needed to adjudicate potentially serious discrepancies. Our focus group results are one source of input for the development of ethical approaches to the research use of EHRs.",,,,,,,,,8,0,0,0,0,0,8,,,1067-5027,1527-974X,,WOS:000443542400003,29986107,
J,"Bose, Saurav; Kenyon, Chen C.; Masino, Aaron J.",,,,"Bose, Saurav/AAD-3622-2022","Bose, Saurav/0000-0003-2355-1449",,,Personalized prediction of early childhood asthma persistence: A machine learning approach,,,,,,,,PLOS ONE,,,,16,3,,,,,e0247784,10.1371/journal.pone.0247784,,,,MAR 1 2021,2021,"Early childhood asthma diagnosis is common; however, many children diagnosed before age 5 experience symptom resolution and it remains difficult to identify individuals whose symptoms will persist. Our objective was to develop machine learning models to identify which individuals diagnosed with asthma before age 5 continue to experience asthma-related visits. We curated a retrospective dataset for 9,934 children derived from electronic health record (EHR) data. We trained five machine learning models to differentiate individuals without subsequent asthma-related visits (transient diagnosis) from those with asthma-related visits between ages 5 and 10 (persistent diagnosis) given clinical information up to age 5 years. Based on average NPV-Specificity area (ANSA), all models performed significantly better than random chance, with XGBoost obtaining the best performance (0.43 mean ANSA). Feature importance analysis indicated age of last asthma diagnosis under 5 years, total number of asthma related visits, self-identified black race, allergic rhinitis, and eczema as important features. Although our models appear to perform well, a lack of prior models utilizing a large number of features to predict individual persistence makes direct comparison infeasible. However, feature importance analysis indicates our models are consistent with prior research indicating diagnosis age and prior health service utilization as important predictors of persistent asthma. We therefore find that machine learning models can predict which individuals will experience persistent asthma with good performance and may be useful to guide clinician and parental decisions regarding asthma counselling in early childhood.",,,,,,,,,5,0,0,0,0,0,5,,,1932-6203,,,WOS:000625328100020,33647071,
J,"Li, Yuan; Du, Guodong; Xiang, Yan; Li, Shaozi; Ma, Lei; Shao, Dangguo; Wang, Xiongbin; Chen, Haoyu",,,,"Du, Guodong/AAD-3202-2019","Du, Guodong/0000-0002-8277-387X; Li, Yuan/0000-0003-3428-8340",,,Towards Chinese clinical named entity recognition by dynamic embedding using domain-specific knowledge,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,106,,,,,,103435,10.1016/j.jbi.2020.103435,,,,JUN 2020,2020,"The task of electronic medical record named entity recognition (NER) refers to automatically identify all kinds of named entities in the medical record text. Chinese clinical NER remains a major challenge. One of the main reasons is that Chinese word segmentation will lead to the wrong downstream works. Besides, existing methods only use the information of the general field, not consider the knowledge from field of medicine. To address these issues, we propose a dynamic embedding method based on dynamic attention which combines features of both character and word in embedding layer. Domain knowledge is provided by word vector trained by domain dataset. In addition, spatial attention is added to enable the model to obtain more and more effective context encoding information. Finally, we conduct extensive experiments to demonstrate the effectiveness of our proposed algorithm. Experiments on CCKS2017 and Common dataset shows that the proposed method outperforms the baseline.",,,,,,,,,10,0,0,0,1,0,10,,,1532-0464,1532-0480,,WOS:000540241000009,32360988,
J,"Gilmore-Bykovskyi, Andrea L.; Block, Laura M.; Walljasper, Lily; Hill, Nikki; Gleason, Carey; Shah, Manish N.",,,,"Hill, Nikki/AAA-4229-2020","Hill, Nikki/0000-0002-9014-7051; Gilmore-Bykovskyi, Andrea/0000-0003-4930-3558; Shah, Manish/0000-0001-6331-1074",,,Unstructured clinical documentation reflecting cognitive and behavioral dysfunction: toward an EHR-based phenotype for cognitive impairment,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,9,,,1206,1212,,10.1093/jamia/ocy070,,,,SEP 2018,2018,"Despite increased risk for negative outcomes, cognitive impairment (CI) is greatly under-detected during hospitalization. While automated EHR-based phenotypes have potential to improve recognition of CI, they are hindered by widespread under-diagnosis of underlying etiologies such as dementia-limiting the utility of more precise structured data elements. This study examined unstructured data on symptoms of CI in the acute-care EHRs of hip and stroke fracture patients with dementia from two hospitals. Clinician reviewers identified and classified unstructured EHR data using standardized criteria. Relevant narrative text was descriptively characterized and evaluated for key terminology. Most patient EHRs (90%) had narrative text reflecting cognitive and/or behavioral dysfunction common in CI that were reliably classified (kappa 0.82). The majority of statements reflected vague descriptions of cognitive/behavioral dysfunction as opposed to diagnostic terminology. Findings from this preliminary derivation study suggest that clinicians use specific terminology in unstructured EHR fields to describe common symptoms of Cl. This terminology can inform the design of EHR-based phenotypes for CI and merits further investigation in more diverse, robustly characterized samples.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000443542400014,29947805,
J,"Newman-Griffis, Denis; Divita, Guy; Desmet, Bart; Zirikly, Ayah; Rose, Carolyn P.; Fosler-Lussier, Eric",,,,,"Zirikly, Ayah/0000-0002-8441-1741; Newman-Griffis, Denis/0000-0002-0473-4226",,,Ambiguity in medical concept normalization: An analysis of types and coverage in electronic health record datasets,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,516,532,,10.1093/jamia/ocaa269,,,,MAR 2021,2021,"Objectives: Normalizing mentions of medical concepts to standardized vocabularies is a fundamental component of clinical text analysis. Ambiguity-words or phrases that may refer to different concepts-has been extensively researched as part of information extraction from biomedical literature, but less is known about the types and frequency of ambiguity in clinical text. This study characterizes the distribution and distinct types of ambiguity exhibited by benchmark clinical concept normalization datasets, in order to identify directions for advancing medical concept normalization research.Materials and Methods: We identified ambiguous strings in datasets derived from the 2 available clinical corpora for concept normalization and categorized the distinct types of ambiguity they exhibited. We then compared observed string ambiguity in the datasets with potential ambiguity in the Unified Medical Language System (UMLS) to assess how representative available datasets are of ambiguity in clinical language.Results: We found that <15% of strings were ambiguous within the datasets, while over 50% were ambiguous in the UMLS, indicating only partial coverage of clinical ambiguity. The percentage of strings in common between any pair of datasets ranged from 2% to only 36%; of these, 40% were annotated with different sets of concepts, severely limiting generalization. Finally, we observed 12 distinct types of ambiguity, distributed unequally across the available datasets, reflecting diverse linguistic and medical phenomena.Discussion: Existing datasets are not sufficient to cover the diversity of clinical concept ambiguity, limiting both training and evaluation of normalization methods for clinical text. Additionally, the UMLS offers important semantic information for building and evaluating normalization methods.Conclusions: Our findings identify 3 opportunities for concept normalization research, including a need for ambiguity-specific clinical datasets and leveraging the rich semantics of the UMLS in new methods and evaluation measures for normalization.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000637314400011,33319905,
J,"Choudhury, Olivia; Park, Yoonyoung; Salonidis, Theodoros; Gkoulalas-Divanis, Aris; Sylla, Issa; Das, Amar K",,,,,,,,Predicting Adverse Drug Reactions on Distributed Health Data using Federated Learning.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,313,322,,,,,,2019,2019,"Using electronic health data to predict adverse drug reaction (ADR) incurs practical challenges, such as lack of adequate data from any single site for rare ADR detection, resource constraints on integrating data from multiple sources, and privacy concerns with creating a centralized database from person-specific, sensitive data. We introduce a federated learning framework that can learn a global ADR prediction model from distributed health data held locally at different sites. We propose two novel methods of local model aggregation to improve the predictive capability of the global model. Through comprehensive experimental evaluation using real-world health data from 1 million patients, we demonstrate the effectiveness of our proposed approach in achieving comparable performance to centralized learning and outperforming localized learning models for two types of ADRs. We also demonstrate that, for varying data distributions, our aggregation methods outperform state-of-the-art techniques, in terms of precision, recall, and accuracy.",,,,,,,,,8,0,0,0,0,0,8,,,,1942-597X,,MEDLINE:32308824,32308824,
J,"Segura-Bedmar, Isabel; Colon-Ruiz, Cristobal; Angel Tejedor-Alonso, Miguel; Moro-Moro, Mar",,,,"alonso, miguel angel tejedor/I-6682-2019; Alonso, Miguel Angel Tejedor/AAM-8217-2021; alonso, miguel angel tejedor/J-1703-2019; SEGURA BEDMAR, ISABEL/L-6077-2017","alonso, miguel angel tejedor/0000-0003-3618-8220; alonso, miguel angel tejedor/0000-0003-3618-8220; Colon-Ruiz, Cristobal/0000-0002-9167-809X; SEGURA BEDMAR, ISABEL/0000-0002-7810-2360",,,Predicting of anaphylaxis in big data EMR by exploring machine learning approaches,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,87,,,,50,59,,10.1016/j.jbi.2018.09.012,,,,NOV 2018,2018,"Anaphylaxis is a life-threatening allergic reaction that occurs suddenly after contact with an allergen. Epidemiological studies about anaphylaxis are very important in planning and evaluating new strategies that prevent this reaction, but also in providing a guide to the treatment of patients who have just suffered an anaphylactic reaction. Electronic Medical Records (EMR) are one of the most effective and richest sources for the epidemiology of anaphylaxis, because they provide a low-cost way of accessing rich longitudinal data on large populations. However, a negative aspect is that researchers have to manually review a huge amount of information, which is a very costly and highly time consuming task. Therefore, our goal is to explore different machine learning techniques to process Big Data EMR, lessening the needed efforts for performing epidemiological studies about anaphylaxis. In particular, we aim to study the incidence of anaphylaxis by the automatic classification of EMR. To do this, we employ the most widely used and efficient classifiers in text classification and compare different document representations, which range from well-known methods such as Bag Of Words (BoW) to more recent ones based on word embedding models, such as a simple average of word embeddings or a bag of centroids of word embeddings. Because the identification of anaphylaxis cases in EMR is a class-imbalanced problem (less than 1% describe anaphylaxis cases), we employ a novel undersampling technique based on clustering to balance our dataset. In addition to classical machine learning algorithms, we also use a Convolutional Neural Network (CNN) to classify our dataset. In general, experiments show that the most classifiers and representations are effective (F1 above 90%). Logistic Regression, Linear SVM, Multilayer Perceptron and Random-Forest achieve an F1 around 95%, however linear methods have-considerably lower training times, CNN provides slightly better performance (F1 = 95.6%).",,,,,,,,,15,0,1,0,8,0,17,,,1532-0464,1532-0480,,WOS:000460600700005,30266231,
J,"Hammond, Robert; Athanasiadou, Rodoniki; Curado, Silvia; Aphinyanaphongs, Yindalon; Abrams, Courtney; Messito, Mary Jo; Gross, Rachel; Katzow, Michelle; Jay, Melanie; Razavian, Narges; Elbel, Brian",,,,"Katzow, Michelle/W-2136-2019","Katzow, Michelle/0000-0002-1915-6094; Messito, Mary Jo/0000-0001-5328-0593; Aphinyanaphongs, Yin/0000-0001-8605-5392; Elbel, Brian/0000-0003-1615-9430; Jay, Melanie/0000-0001-7343-3120; Gross, Rachel/0000-0003-4613-6985; Hammond, Rob/0000-0003-4476-6406; Razavian, Narges/0000-0002-9922-6370",,,Predicting childhood obesity using electronic health records and publicly available data,,,,,,,,PLOS ONE,,,,14,4,,,,,e0215571,10.1371/journal.pone.0215571,,,,APR 22 2019,2019,"BackgroundBecause of the strong link between childhood obesity and adulthood obesity comorbidities, and the difficulty in decreasing body mass index (BMI) later in life, effective strategies are needed to address this condition in early childhood. The ability to predict obesity before age five could be a useful tool, allowing prevention strategies to focus on high risk children. The few existing prediction models for obesity in childhood have primarily employed data from longitudinal cohort studies, relying on difficult to collect data that are not readily available to all practitioners. Instead, we utilized real-world unaugmented electronic health record (EHR) data from the first two years of life to predict obesity status at age five, an approach not yet taken in pediatric obesity research.Methods and findingsWe trained a variety of machine learning algorithms to perform both binary classification and regression. Following previous studies demonstrating different obesity determinants for boys and girls, we similarly developed separate models for both groups. In each of the separate models for boys and girls we found that weight for length z-score, BMI between 19 and 24 months, and the last BMI measure recorded before age two were the most important features for prediction. The best performing models were able to predict obesity with an Area Under the Receiver Operator Characteristic Curve (AUC) of 81.7% for girls and 76.1% for boys.ConclusionsWe were able to predict obesity at age five using EHR data with an AUC comparable to cohort-based studies, reducing the need for investment in additional data collection. Our results suggest that machine learning approaches for predicting future childhood obesity using EHR data could improve the ability of clinicians and researchers to drive future policy, intervention design, and the decision-making process in a clinical setting.",,,,,,,,,14,1,0,0,9,0,15,,,1932-6203,,,WOS:000465087500030,31009509,
J,"Ohno-Machado, Lucila",,,,,,,,"Clinical informatics applications of medication reconciliation, decision support systems, and online portal patient-provider communications",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,11,,,1431,1431,,10.1093/jamia/ocy150,,,,NOV 2018,2018,,,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000450392500001,30380084,
J,"Alimova, Ilseyar; Tutubalina, Elena",,,,"Tutubalina, Elena/E-3752-2017","Tutubalina, Elena/0000-0001-7936-0284",,,Multiple features for clinical relation extraction: A machine learning approach,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,103,,,,,,103382,10.1016/j.jbi.2020.103382,,,,MAR 2020,2020,"Relation extraction aims to discover relational facts about entity mentions from plain texts. In this work, we focus on clinical relation extraction; namely, given a medical record with mentions of drugs and their attributes, we identify relations between these entities. We propose a machine learning model with a novel set of knowledge-based and BioSentVec embedding features. We systematically investigate the impact of these features with standard distance- and word-based features, conducting experiments on two benchmark datasets of clinical texts from MADE 2018 and n2c2 2018 shared tasks. For comparison with the feature-based model, we utilize state-of-the-art models and three BERT-based models, including BioBERT and Clinical BERT. Our results demonstrate that distance and word features provide significant benefits to the classifier. Knowledge-based features improve classification results only for particular types of relations. The sentence embedding feature provides the largest improvement in results, among other explored features on the MADE corpus. The classifier obtains state-of-the-art performance in clinical relation extraction with F-measure of 92.6%, improving F-measure by 3.5% on the MADE corpus.",,,,,,,,,9,0,0,0,2,0,9,,,1532-0464,1532-0480,,WOS:000525735700008,32028051,
J,"Goodwin, Travis R.; Harabagiu, Sanda M.",,,,"Goodwin, Travis/ABA-1799-2020","Goodwin, Travis/0000-0002-0047-1078",,,Learning relevance models for patient cohort retrieval,,,,,,,,JAMIA OPEN,,,,1,2,,,265,274,,10.1093/jamiaopen/ooy010,,,,OCT 2018,2018,"Objective: We explored how judgements provided by physicians can be used to learn relevance models that enhance the quality of patient cohorts retrieved from Electronic Health Records (EHRs) collections.Methods: A very large number of features were extracted from patient cohort descriptions as well as EHR collections. The features were used to investigate retrieving (1) neurology-specific patient cohorts from the deidentified Temple University Hospital electroencephalography (EEG) Corpus as well as (2) the more general cohorts evaluated in the TREC Medical Records Track (TRECMed) from the de-identified hospital records provided by the University of Pittsburgh Medical Center. The features informed a learning relevance model (LRM) that took advantage of relevance judgements provided by physicians. The LRM implements a pairwise learning-to-rank framework, which enables our learning patient cohort retrieval (L-PCR) system to learn fromphysicians' feedback.Results and Discussion: We evaluated the L-PCR system against state-of-the-art traditional patient cohort retrieval systems, and observed a 27% improvement when operating on EEGs and a 53% improvement when operating on TRECMed EHRs, showing the promise of the L-PCR system. We also performed extensive feature analyses to reveal the most effective strategies for representing cohort descriptions as queries, encoding EHRs, and measuring cohort relevance.Conclusion: The L-PCR system has significant promise for reliably retrieving patient cohorts from EHRs in multiple settings when trained with relevance judgments. When provided with additional cohort descriptions, the L-PCR system will continue to learn, thus offering a potential solution to the performance barriers of current cohort retrieval systems.",,,,,,,,,4,0,0,0,1,0,4,,,,2574-2531,,WOS:000645417100020,30474078,
J,"King, Andrew J; Cooper, Gregory F; Hochheiser, Harry; Clermont, Gilles; Hauskrecht, Milos; Visweswaran, Shyam",,,,,"King, Andrew/0000-0002-9809-0563",,,Using Machine Learning to Predict the Information Seeking Behavior of Clinicians Using an Electronic Medical Record System.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,673,682,,,,,,2018,2018,"Poor electronic medical record (EMR) usability is detrimental to both clinicians and patients. A better EMR would provide concise, context sensitive patient data, but doing so entails the difficult task of knowing which data are relevant. To determine the relevance of patient data in different contexts, we collect and model the information seeking behavior of clinicians using a learning EMR (LEMR) system. Sufficient data were collected to train predictive models for 80 different targets (e.g., glucose level, heparin administration) and 27 of them had AUROC values of greater than 0.7. These results are encouraging considering the high variation in information seeking behavior (intraclass correlation 0.40). We plan to apply these models to a new set of patient cases and adapt the LEMR interface to highlight relevant patient data, and thus provide concise, context sensitive data.",,,,,,,,,8,0,0,0,1,0,8,,,,1942-597X,,MEDLINE:30815109,30815109,
J,"Seneviratne, Martin G; Banda, Juan M; Brooks, James D; Shah, Nigam H; Hernandez-Boussard, Tina M",,,,,"Banda, Juan/0000-0001-8499-824X",,,Identifying Cases of Metastatic Prostate Cancer Using Machine Learning on Electronic Health Records.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1498,1504,,,,,,2018,2018,"Cancer stage is rarely captured in structured form in the electronic health record (EHR). We evaluate the performance of a classifier, trained on structured EHR data, in identifying prostate cancer patients with metastatic disease. Using EHR data for a cohort of 5,861 prostate cancer patients mapped to the Observational Health Data Sciences and Informatics (OHDSI) data model, we constructed feature vectors containing frequency counts of conditions, procedures, medications, observations and laboratory values. Staging information from the California Cancer Registry was used as the ground-truth. For identifying patients with metastatic disease, a random forest model achieved precision and recall of 0.90, 0.40 using data within 12 months of diagnosis. This compared to precision 0.33, recall 0.54 for an ICD code-based query. High-precision classifiers using hundreds of structured data elements significantly outperform ICD queries, and may assist in identifying cohorts for observational research or clinical trial matching.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:30815195,30815195,
J,"Brown, I. I. I. William; Balyan, Renu; Karter, Andrew J.; Crossley, Scott; Semere, Wagahta; Duran, Nicholas D.; Lyles, Courtney; Liu, Jennifer; Moffet, Howard H.; Daniels, Ryane; McNamara, Danielle S.; Schillinger, Dean",,,,"Duran, Nicholas/P-1079-2017","Duran, Nicholas/0000-0002-8872-5617",,,Challenges and solutions to employing natural language processing and machine learning to measure patients' health literacy and physician writing complexity: The ECLIPPSE study,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103658,10.1016/j.jbi.2020.103658,,,,JAN 2021,2021,"Objective: In the National Library of Medicine funded ECLIPPSE Project (Employing Computational Linguistics to Improve Patient-Provider Secure Emails exchange), we attempted to create novel, valid, and scalable measures of both patients' health literacy (HL) and physicians' linguistic complexity by employing natural language processing (NLP) techniques and machine learning (ML). We applied these techniques to > 400,000 patients' and physicians' secure messages (SMs) exchanged via an electronic patient portal, developing and validating an automated patient literacy profile (LP) and physician complexity profile (CP). Herein, we describe the challenges faced and the solutions implemented during this innovative endeavor.Materials and methods: To describe challenges and solutions, we used two data sources: study documents and interviews with study investigators. Over the five years of the project, the team tracked their research process using a combination of Google Docs tools and an online team organization, tracking, and management tool (Asana). In year 5, the team convened a number of times to discuss, categorize, and code primary challenges and solutions.Results: We identified 23 challenges and associated approaches that emerged from three overarching process domains: (1) Data Mining related to the SM corpus; (2) Analyses using NLP indices on the SM corpus; and (3) Interdisciplinary Collaboration. With respect to Data Mining, problems included cleaning SMs to enable analyses, removing hidden caregiver proxies (e.g., other family members) and Spanish language SMs, and culling SMs to ensure that only patients' primary care physicians were included. With respect to Analyses, critical decisions needed to be made as to which computational linguistic indices and ML approaches should be selected; how to enable the NLP-based linguistic indices tools to run smoothly and to extract meaningful data from a large corpus of medical text; and how to best assess content and predictive validities of both the LP and the CP. With respect to the Interdisciplinary Collaboration, because the research required engagement between clinicians, health services researchers, biomedical informaticians, linguists, and cognitive scientists, continual effort was needed to identify and reconcile differences in scientific terminologies and resolve confusion; arrive at common understanding of tasks that needed to be completed and priorities therein; reach compromises regarding what represents meaningful findings in health services vs. cognitive science research; and address constraints regarding potential transportability of the final LP and CP to different health care settings.Discussion: Our study represents a process evaluation of an innovative research initiative to harness big linguistic data to estimate patient HL and physician linguistic complexity. Any of the challenges we identified, if left unaddressed, would have either rendered impossible the effort to generate LPs and CPs, or invalidated analytic results related to the LPs and CPs. Investigators undertaking similar research in HL or using computational linguistic methods to assess patient-clinician exchange will face similar challenges and may find our solutions helpful when designing and executing their health communications research.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000615920800008,33316421,
J,"Olex, Amy L.; McInnes, Bridget T.",,,,,,,,Review of Temporal Reasoning in the Clinical Domain for Timeline Extraction: Where we are and where we need to be,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,118,,,,,,103784,10.1016/j.jbi.2021.103784,,MAY 2021,,JUN 2021,2021,"Understanding a patient's medical history, such as how long symptoms last or when a procedure was performed, is vital to diagnosing problems and providing good care. Frequently, important information regarding a patient's medical timeline is buried in their Electronic Health Record (EHR) in the form of unstructured clinical notes. This results in care providers spending time reading notes in a patient's record in order to become familiar with their condition prior to developing a diagnosis or treatment plan. Valuable time could be saved if this information was readily accessible for searching and visualization for fast comprehension by the medical team. Clinical Natural Language Processing (NLP) is an area of research that aims to build computational methods to automatically extract medically relevant information from unstructured clinical texts. A key component of Clinical NLP is Temporal Reasoning, as understanding a patient's medical history relies heavily on the ability to identify, assimilate, and reason over temporal information. In this work, we review the current state of Temporal Reasoning in the clinical domain with respect to Clinical Timeline Extraction. While much progress has been made, the current state-of-the-art still has a ways to go before practical application in the clinical setting will be possible. Areas such as handling relative and implicit temporal expressions, both in normalization and in identifying temporal relationships, improving co-reference resolution, and building inter-operable timeline extraction tools that can integrate multiple types of data are in need of new and innovative solutions to improve performance on clinical data.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663600500001,33862232,
J,"Ben-Assuli, Ofir; Vest, Joshua R.",,,,,,,,Data mining techniques utilizing latent class models to evaluate emergency department revisits,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,101,,,,,,103341,10.1016/j.jbi.2019.103341,,,,JAN 2020,2020,"Background: The use of machine learning techniques is especially pertinent to the composite and challenging conditions of emergency departments (EDs). Repeat ED visits (i.e. revisits) are an example of potentially inappropriate utilization of resources that can be forecasted by these techniques.Objective: To track the ED revisit risk over time using the hidden Markov model (HMM) as a major latent class model. Given the HMM states, we carried out forecasting of future ED revisits with various data mining models.Methods: Information integrated from four distributed sources (e.g. electronic health records and health information exchange) was integrated into four HMMs which capture the relationships between an observed and a hidden progression that shift over time through a series of hidden states in an adult patient population.Results: Assimilating a pre-analysis of the various patients by applying latent class models and directing them to well-known classifiers functioned well. The performance was significantly better than without utilizing preanalysis of HMM for all prediction models (classifiers(.Conclusions: These findings suggest that one prospective approach to advanced risk prediction is to leverage the longitudinal nature of health care data by exploiting patients' between state variation.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000525735000003,31747623,
J,"Chen, Long; Gu, Yu; Ji, Xin; Sun, Zhiyong; Li, Haodan; Gao, Yuan; Huang, Yang",,,,"Chen, Long/AAB-3426-2020",,,,Extracting medications and associated adverse drug events using a natural language processing system combining knowledge base and deep learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,56,64,,10.1093/jamia/ocz141,,,,JAN 2020,2020,"Objective: Detecting adverse drug events (ADEs) and medications related information in clinical notes is important for both hospital medical care and medical research. We describe our clinical natural language processing (NLP) system to automatically extract medical concepts and relations related to ADEs and medications from clinical narratives. This work was part of the 2018 National NLP Clinical Challenges Shared Task and Workshop on Adverse Drug Events and Medication Extraction.Materials and Methods: The authors developed a hybrid clinical NLP system that employs a knowledge-based general clinical NLP system for medical concepts extraction, and a task-specific deep learning system for relations identification using attention-based bidirectional long short-term memory networks.Results: The systems were evaluated as part of the 2018 National NLP Clinical Challenges challenge, and our attention-based bidirectional long short-term memory networks based system obtained an F-measure of 0.9442 for relations identification task, ranking fifth at the challenge, and had <2% difference from the best system. Error analysis was also conducted targeting at figuring out the root causes and possible approaches for improvement.Conclusions: We demonstrate the generic approaches and the practice of connecting general purposed clinical NLP system to task-specific requirements with deep learning methods. Our results indicate that a well-designed hybrid NLP system is capable of ADE and medication-related information extraction, which can be used in real-world applications to support ADE-related researches and medical decisions.",,,,,,,,,15,0,0,0,5,0,15,,,1067-5027,1527-974X,,WOS:000548300200008,31591641,
J,"Tsui, Fuchiang R.; Shi, Lingyun; Ruiz, Victor; Ryan, Neal D.; Biernesser, Candice; Iyengar, Satish; Walsh, Colin G.; Brent, David A.",,,,,,,,Natural language processing and machine learning of electronic health records for prediction of first-time suicide attempts,,,,,,,,JAMIA OPEN,,,,4,1,,,,,,10.1093/jamiaopen/ooab011,,MAR 2021,,JAN 2021,2021,"Objective: Limited research exists in predicting first-time suicide attempts that account for two-thirds of suicide decedents. We aimed to predict first-time suicide attempts using a large data-driven approach that applies natural language processing (NLP) and machine learning (ML) to unstructured (narrative) clinical notes and structured electronic health record (EHR) data.Methods: This case-control study included patients aged 10-75 years who were seen between 2007 and 2016 from emergency departments and inpatient units. Cases were first-time suicide attempts from coded diagnosis; controls were randomly selected without suicide attempts regardless of demographics, following a ratio of nine controls per case. Four data-driven ML models were evaluated using 2-year historical EHR data prior to suicide attempt or control index visits, with prediction windows from 7 to 730 days. Patients without any historical notes were excluded. Model evaluation on accuracy and robustness was performed on a blind dataset (30% cohort).Results: The study cohort included 45 238 patients (5099 cases, 40 139 controls) comprising 54 651 variables from 5.7 million structured records and 798 665 notes. Using both unstructured and structured data resulted in significantly greater accuracy compared to structured data alone (area-under-the-curve [AUC]: 0.932 vs. 0.901 P<.001). The best-predicting model utilized 1726 variables with AUC = 0.932 (95% CI, 0.922-0.941). The model was robust across multiple prediction windows and subgroups by demographics, points of historical most recent clinical contact, and depression diagnosis history.Conclusions: Our large data-driven approach using both structured and unstructured EHR data demonstrated accurate and robust first-time suicide attempt prediction, and has the potential to be deployed across various populations and clinical settings.",,,,,,,,,2,0,0,0,0,0,2,,,,2574-2531,,WOS:000731860400009,33758800,
J,"Paul, Devon W.; Neely, Nigel B.; Clement, Meredith; Riley, Isaretta; Al-Hegelan, Mashael; Phelan, Matthew; Kraft, Monica; Murdoch, David M.; Lucas, Joseph; Bartlett, John; McKellar, Mehri; Que, Loretta G.",,,,,,,,Development and validation of an electronic medical record (EMR)-based computed phenotype of HIV-1 infection,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,2,,,150,157,,10.1093/jamia/ocx061,,,,FEB 2018,2018,"Background: Electronic medical record (EMR) computed algorithms allow investigators to screen thousands of patient records to identify specific disease cases. No computed algorithms have been developed to detect all cases of human immunodeficiency virus (HIV) infection using administrative, laboratory, and clinical documentation data outside of the Veterans Health Administration. We developed novel EMR-based algorithms for HIV detection and validated them in a cohort of subjects in the Duke University Health System (DUHS).Methods: We created 2 novel algorithms to identify HIV-infected subjects. Algorithm 1 used laboratory studies and medications to identify HIV-infected subjects, whereas Algorithm 2 used International Classification of Diseases, Ninth Revision (ICD-9) codes, medications, and laboratory testing. We applied the algorithms to a well-characterized cohort of patients and validated both against the gold standard of physician chart review. We determined sensitivity, specificity, and prevalence of HIV between 2007 and 2011 in patients seen at DUHS.Results: A total of 172 271 patients were detected with complete data; 1063 patients met algorithm criteria for HIV infection. In all, 970 individuals were identified by both algorithms, 78 by Algorithm 1 alone, and 15 by Algorithm 2 alone. The sensitivity and specificity of each algorithm were 78% and 99%, respectively, for Algorithm 1 and 77% and 100% for Algorithm 2. The estimated prevalence of HIV infection at DUHS between 2007 and 2011 was 0.6%.Conclusions: EMR-based phenotypes of HIV infection are capable of detecting cases of HIV-infected adults with good sensitivity and specificity. These algorithms have the potential to be adapted to other EMR systems, allowing for the creation of cohorts of patients across EMR systems.",,,,,,,,,15,0,0,0,3,0,15,,,1067-5027,1527-974X,,WOS:000424930900007,28645207,
J,"Denaxas, Spiros; Gonzalez-Izquierdo, Arturo; Direk, Kenan; Fitzpatrick, Natalie K.; Fatemifar, Ghazaleh; Banerjee, Amitava; Dobson, Richard J. B.; Howe, Laurence J.; Kuan, Valerie; Lumbers, R. Tom; Pasea, Laura; Patel, Riyaz S.; Shah, Anoop D.; Hingorani, Aroon D.; Sudlow, Cathie; Hemingway, Harry",,,,"Shah, Anoop Dinesh/D-4396-2014; Banerjee, Amitava/D-4381-2014; dobson, richard/C-9269-2011; Hemingway, Harry/C-1219-2009","Shah, Anoop Dinesh/0000-0002-8907-5724; Banerjee, Amitava/0000-0001-8741-3411; Gonzalez-Izquierdo, Arturo/0000-0002-0984-5830; dobson, richard/0000-0003-4224-9245; Hingorani, Aroon/0000-0001-8365-0081; Direk, Kenan/0000-0001-9440-1638; Hemingway, Harry/0000-0003-2279-0624; Denaxas, Spiros/0000-0001-9612-7791",,,UK phenomics platform for developing and validating electronic health record phenotypes: CALIBER,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1545,1559,,10.1093/jamia/ocz105,,,,DEC 2019,2019,"Objective: Electronic health records (EHRs) are a rich source of information on human diseases, but the information is variably structured, fragmented, curated using different coding systems, and collected for purposes other than medical research. We describe an approach for developing, validating, and sharing reproducible phenotypes from national structured EHR in the United Kingdom with applications for translational research.Materials and Methods: We implemented a rule-based phenotyping framework, with up to 6 approaches of validation. We applied our framework to a sample of 15 million individuals in a national EHR data source (population-based primary care, all ages) linked to hospitalization and death records in England. Data comprised continuous measurements (for example, blood pressure; medication information; coded diagnoses, symptoms, procedures, and referrals), recorded using 5 controlled clinical terminologies: (1) read (primary care, subset of SNOMED-CT [Systematized Nomenclature of Medicine Clinical Terms]), (2) International Classification of Diseases-Ninth Revision and Tenth Revision (secondary care diagnoses and cause of mortality), (3) Office of Population Censuses and Surveys Classification of Surgical Operations and Procedures, Fourth Revision (hospital surgical procedures), and (4) DM+D prescription codes.Results: Using the CALIBER phenotyping framework, we created algorithms for 51 diseases, syndromes, bio-markers, and lifestyle risk factors and provide up to 6 validation approaches. The EHR phenotypes are curated in the open-access CALIBER Portal (https://www.caliberresearch.org/portal) and have been used by 40 national and international research groups in 60 peer-reviewed publications.Conclusions: We describe a UK EHR phenomics approach within the CALIBER EHR data platform with initial evidence of validity and use, as an important step toward international use of UK EHR data for health research.",,,,,,,,,52,0,0,0,20,0,51,,,1067-5027,1527-974X,,WOS:000515125300014,31329239,
J,"Laksana, Eugene; Aczon, Melissa; Ho, Long; Carlin, Cameron; Ledbetter, David; Wetzel, Randall",,,,,"Carlin, Cameron/0000-0002-9973-7322; Ledbetter, David/0000-0003-0382-5086",,,The impact of extraneous features on the performance of recurrent neural network models in clinical tasks,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103351,10.1016/j.jbi.2019.103351,,,,FEB 2020,2020,"Electronic Medical Records (EMR) are a rich source of patient information, including measurements reflecting physiologic signs and administered therapies. Identifying which variables or features are useful in predicting clinical outcomes can be challenging. Advanced algorithms, such as deep neural networks, were designed to process high-dimensional inputs containing variables in their measured form, thus bypass separate feature selection or engineering steps. We investigated the effect of extraneous input features on the predictive performance of Recurrent Neural Networks (RNN) by including in the input vector extraneous features that were randomly drawn from theoretical and empirical distributions. RNN models using different input vectors (EMR features only; EMR and extraneous features; extraneous features only) were trained to predict three clinical outcomes: in-ICU mortality, 72-h ICU re-admission, and 30-day ICU-free days. The measured degradations of the RNN's predictive performance with the inclusion of extraneous features to EMR variables were negligible.",,,,,,,,,6,0,0,0,3,0,6,,,1532-0464,1532-0480,,WOS:000525735200015,31870949,
J,"Mitra, Avijit; Rawat, Bhanu Pratap Singh; McManus, David; Kapoor, Alok; Yu, Hong",,,,,,,,Bleeding Entity Recognition in Electronic Health Records: A Comprehensive Analysis of End-to-End Systems.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,860,869,,,,,,2020,2020,"A bleeding event is a common adverse drug reaction amongst patients on anticoagulation and factors critically into a clinician's decision to prescribe or continue anticoagulation for atrial fibrillation. However, bleeding events are not uniformly captured in the administrative data of electronic health records (EHR). As manual review is prohibitively expensive, we investigate the effectiveness of various natural language processing (NLP) methods for automatic extraction of bleeding events. Using our expert-annotated 1,079 de-identified EHR notes, we evaluated state-of-the-art NLP models such as biLSTM-CRF with language modeling, and different BERT variants for six entity types. On our dataset, the biLSTM-CRF surpassed other models resulting in a macro F1-score of 0.75 whereas the performance difference is negligible for sentence and document-level predictions with the best macro F1-scores of 0.84 and 0.96, respectively. Our error analyses suggest that the models' incorrect predictions can be attributed to variability in entity spans, memorization, and missing negation signals.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:33936461,33936461,
J,"Balyan, Renu; Crossley, Scott A.; Brown, William, III; Karter, Andrew J.; McNamara, Danielle S.; Liu, Jennifer Y.; Lyles, Courtney R.; Schillinger, Dean",,,,,", Renu/0000-0003-1393-2416",,,Using natural language processing and machine learning to classify health literacy from secure messages: The ECLIPPSE study,,,,,,,,PLOS ONE,,,,14,2,,,,,e0212488,10.1371/journal.pone.0212488,,,,FEB 22 2019,2019,"Limited health literacy is a barrier to optimal healthcare delivery and outcomes. Current measures requiring patients to self-report limitations are time-consuming and may be considered intrusive by some. This makes widespread classification of patient health literacy challenging. The objective of this study was to develop and validate literacy profiles as automated indicators of patients' health literacy to facilitate a non-intrusive, economic and more comprehensive characterization of health literacy among a health care delivery system's membership. To this end, three literacy profiles were generated based on natural language processing (combining computational linguistics and machine learning) using a sample of 283,216 secure messages sent from 6,941 patients to their primary care physicians. All patients were participants in Kaiser Permanente Northern California's DISTANCE Study. Performance of the three literacy profiles were compared against a gold standard of patient self-reported health literacy. Associations were analyzed between each literacy profile and patient demographics, health outcomes and healthcare utilization. T-tests were used for numeric data such as A1C, Charlson comorbidity index and healthcare utilization rates, and chi-square tests for categorical data such as sex, race, poor adherence and severe hypoglycemia. Literacy profiles varied in their test characteristics, with C-statistics ranging from 0.61-0.74. Relations between literacy profiles and health outcomes revealed patterns consistent with previous health literacy research: patients identified via literacy profiles indicative of limited health literacy: (a) were older and more likely of minority status; (b) had poorer medication adherence and glycemic control; and (c) exhibited higher rates of hypoglycemia, comorbidities and healthcare utilization. This represents the first successful attempt to employ natural language processing to estimate health literacy. Literacy profiles can offer an automated and economical way to identify patients with limited health literacy and greater vulnerability to poor health outcomes.",,,,,,,,,11,0,0,0,1,0,11,,,1932-6203,,,WOS:000459709100078,30794616,
J,"Jiang, Kun; Yang, Tao; Wu, Chunyan; Chen, Luming; Mao, Longfei; Wu, Yongyou; Deng, Lizong; Jiang, Taijiao",,,,,"Mao, Longfei/0000-0003-0759-0501",,,LATTE: A knowledge-based method to normalize various expressions of laboratory test results in free text of Chinese electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103372,10.1016/j.jbi.2019.103372,,,,FEB 2020,2020,"Background: A wealth of clinical information is buried in free text of electronic health records (EHR), and converting clinical information to machine-understandable form is crucial for the secondary use of EHRs. Laboratory test results, as one of the most important types of clinical information, are written in various styles in free text of EHRs. This has brought great difficulties for data integration and utilization of EHRs. Therefore, developing technology to normalize different expressions of laboratory test results in free text is indispensable for the secondary use of EHRs.Methods: In this study, we developed a knowledge-based method named LATTE (transforming lab test results), which could transform various expressions of laboratory test results into a normalized and machine-understandable format. We first identified the analyte of a laboratory test result with a dictionary-based method and then designed a series of rules to detect information associated with the analyte, including its specimen, measured value, unit of measure, conclusive phrase and sampling factor. We determined whether a test result is normal or abnormal by understanding the meaning of conclusive phrases or by comparing its measured value with an appropriate normal range. Finally, we converted various expressions of laboratory test results, either in numeric or textual form, into a normalized form as specimen-analyte-abnormality. With this method, a laboratory test with the same type of abnormality would have the same representation, regardless of the way that it is mentioned in free text.Results: LATTE was developed and optimized on a training set including 8894 laboratory test results from 756 EHRs, and evaluated on a test set including 3740 laboratory test results from 210 EHRs. Compared to experts' annotations, LATTE achieved a precision of 0.936, a recall of 0.897 and an F1 score of 0.916 on the training set, and a precision of 0.892, a recall of 0.843 and an F1 score of 0.867 on the test set. For 223 laboratory tests with at least two different expression forms in the test set, LATTE transformed 85.7% (2870/3350) of laboratory test results into a normalized form. Besides, LATTE achieved F1 scores above 0.8 for EHRs from 18 of 21 different hospital departments, indicating its generalization capabilities in normalizing laboratory test results.Conclusion: In conclusion, LATTE is an effective method for normalizing various expressions of laboratory test results in free text of EHRs. LATTE will facilitate EHR-based applications such as cohort querying, patient clustering and machine learning.Availability: LATTE is freely available for download on GitHub (https://github.com/denglizong/LATTE).",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000525735200009,31901507,
J,"Wang, Amy Y; Osborne, John D; Danila, Maria I; Naidech, Andrew M; Liebovitz, David M",,,,"Osborne, John/F-3445-2016; Liebovitz, David/AAI-9398-2020","Osborne, John/0000-0002-0851-1150; Liebovitz, David/0000-0002-2518-5940",,,AllergyMap: An Open Source Corpus of Allergy Mention Normalizations.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1249,1257,,,,,,2020,2020,"Allergy mention normalization is challenging because of the wide range of possible allergens including medications, foods, plants, animals, and consumer products. This paper describes the process of mapping free-text allergy information from an electronic health record (EHR) system in a university hospital to standard terminologies and migration of those data into an enterprise EHR system. The review, mapping, and migration revealed interesting issues and challenges with the free-text allergy information and the mapping in preparation for implementation in the new EHR system. These findings provide insights that can form the basis of guidelines for future mapping and migration efforts involving free-text allergy data. As part of this process, we generate and make freely available AllergyMap, a mapping between free-text entered allergy medication to standard non-proprietary ontologies. To our knowledge, this is the first such mapping available and could serve as a public resource for allergy mention normalization and system evaluation.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936501,33936501,
J,"Jabbour, Sarah; Fouhey, David; Kazerooni, Ella; Wiens, Jenna; Sjoding, Michael W.",,,,,,,,Combining chest X-rays and electronic health record (EHR) data using machine learning to diagnose acute respiratory failure,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac030,,MAR 2022,,,2022,"Objective When patients develop acute respiratory failure (ARF), accurately identifying the underlying etiology is essential for determining the best treatment. However, differentiating between common medical diagnoses can be challenging in clinical practice. Machine learning models could improve medical diagnosis by aiding in the diagnostic evaluation of these patients. Materials and Methods Machine learning models were trained to predict the common causes of ARF (pneumonia, heart failure, and/or chronic obstructive pulmonary disease [COPD]). Models were trained using chest radiographs and clinical data from the electronic health record (EHR) and applied to an internal and external cohort. Results The internal cohort of 1618 patients included 508 (31%) with pneumonia, 363 (22%) with heart failure, and 137 (8%) with COPD based on physician chart review. A model combining chest radiographs and EHR data outperformed models based on each modality alone. Models had similar or better performance compared to a randomly selected physician reviewer. For pneumonia, the combined model area under the receiver operating characteristic curve (AUROC) was 0.79 (0.77-0.79), image model AUROC was 0.74 (0.72-0.75), and EHR model AUROC was 0.74 (0.70-0.76). For heart failure, combined: 0.83 (0.77-0.84), image: 0.80 (0.71-0.81), and EHR: 0.79 (0.75-0.82). For COPD, combined: AUROC = 0.88 (0.83-0.91), image: 0.83 (0.77-0.89), and EHR: 0.80 (0.76-0.84). In the external cohort, performance was consistent for heart failure and increased for COPD, but declined slightly for pneumonia. Conclusions Machine learning models combining chest radiographs and EHR data can accurately differentiate between common causes of ARF. Further work is needed to determine how these models could act as a diagnostic aid to clinicians in clinical settings.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000767423500001,35271711,
J,"Dligach, Dmitriy; Afshar, Majid; Miller, Timothy",,,,,"Afshar, Majid/0000-0002-6368-4652",,,Toward a clinical text encoder: pretraining for clinical natural language processing with applications to substance misuse,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1272,1278,,10.1093/jamia/ocz072,,,,NOV 2019,2019,"Objective: Our objective is to develop algorithms for encoding clinical text into representations that can be used for a variety of phenotyping tasks.Materials and Methods: Obtaining large datasets to take advantage of highly expressive deep learning methods is difficult in clinical natural language processing (NLP). We address this difficulty by pretraining a clinical text encoder on billing code data, which is typically available in abundance. We explore several neural encoder architectures and deploy the text representations obtained from these encoders in the context of clinical text classification tasks. While our ultimate goal is learning a universal clinical text encoder, we also experiment with training a phenotype-specific encoder. A universal encoder would be more practical, but a phenotype-specific encoder could perform better for a specific task.Results: We successfully train several clinical text encoders, establish a new state-of-the-art on comorbidity data, and observe good performance gains on substance misuse data.Discussion: We find that pretraining using billing codes is a promising research direction. The representations generated by this type of pretraining have universal properties, as they are highly beneficial for many phenotyping tasks. Phenotype-specific pretraining is a viable route for trading the generality of the pretrained encoder for better performance on a specific phenotyping task.Conclusions: We successfully applied our approach to many phenotyping tasks. We conclude by discussing potential limitations of our approach.",,,,,,,,,8,0,0,0,4,0,8,,,1067-5027,1527-974X,,WOS:000498169400015,31233140,
J,"Guo, Aixia; Mazumder, Nikhilesh R.; Ladner, Daniela P.; Foraker, Randi E.",,,,"; Mazumder, Nikhilesh/AAR-1748-2021","Foraker, Randi/0000-0001-9255-9394; Mazumder, Nikhilesh/0000-0001-9749-5334",,,Predicting mortality among patients with liver cirrhosis in electronic health records with machine learning,,,,,,,,PLOS ONE,,,,16,8,,,,,e0256428,10.1371/journal.pone.0256428,,,,AUG 31 2021,2021,"Objective Liver cirrhosis is a leading cause of death and effects millions of people in the United States. Early mortality prediction among patients with cirrhosis might give healthcare providers more opportunity to effectively treat the condition. We hypothesized that laboratory test results and other related diagnoses would be associated with mortality in this population. Our another assumption was that a deep learning model could outperform the current Model for End Stage Liver disease (MELD) score in predicting mortality.Materials and methods We utilized electronic health record data from 34,575 patients with a diagnosis of cirrhosis from a large medical center to study associations with mortality. Three time-windows of mortality (365 days, 180 days and 90 days) and two cases with different number of variables (all 41 available variables and 4 variables in MELD-NA) were studied. Missing values were imputed using multiple imputation for continuous variables and mode for categorical variables. Deep learning and machine learning algorithms, i.e., deep neural networks (DNN), random forest (RF) and logistic regression (LR) were employed to study the associations between baseline features such as laboratory measurements and diagnoses for each time window by 5-fold cross validation method. Metrics such as area under the receiver operating curve (AUC), overall accuracy, sensitivity, and specificity were used to evaluate models.Results Performance of models comprising all variables outperformed those with 4 MELD-NA variables for all prediction cases and the DNN model outperformed the LR and RF models. For example, the DNN model achieved an AUC of 0.88, 0.86, and 0.85 for 90, 180, and 365-day mortality respectively as compared to the MELD score, which resulted in corresponding AUCs of 0.81, 0.79, and 0.76 for the same instances. The DNN and LR models had a significantly better f1 score compared to MELD at all time points examined.Conclusion Other variables such as alkaline phosphatase, alanine aminotransferase, and hemoglobin were also top informative features besides the 4 MELD-Na variables. Machine learning and deep learning models outperformed the current standard of risk prediction among patients with cirrhosis. Advanced informatics techniques showed promise for risk prediction in patients with cirrhosis.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000761695800013,34464403,
J,"Zeiberg, Daniel; Prahlad, Tejas; Nallamothu, Brahmajee K.; Iwashyna, Theodore J.; Wiens, Jenna; Sjoding, Michael W.",,,,,,,,Machine learning for patient risk stratification for acute respiratory distress syndrome,,,,,,,,PLOS ONE,,,,14,3,,,,,e0214465,10.1371/journal.pone.0214465,,,,MAR 28 2019,2019,"BackgroundExisting prediction models for acute respiratory distress syndrome (ARDS) require manual chart abstraction and have only fair performance-limiting their suitability for driving clinical interventions. We sought to develop a machine learning approach for the prediction of ARDS that (a) leverages electronic health record (EHR) data, (b) is fully automated, and (c) can be applied at clinically relevant time points throughout a patient's stay.Methods and FindingsWe trained a risk stratification model for ARDS using a cohort of 1,621 patients with moderate hypoxia from a single center in 2016, of which 51 patients developed ARDS. We tested the model in a temporally distinct cohort of 1,122 patients from 2017, of which 27 patients developed ARDS. Gold standard diagnosis of ARDS was made by intensive care trained physicians during retrospective chart review. We considered both linear and non-linear approaches to learning the model. The best model used L2-logistic regression with 984 features extracted from the EHR. For patients observed in the hospital at least six hours who then developed moderate hypoxia, the model achieved an area under the receiver operating characteristics curve (AUROC) of 0.81 (95% CI: 0.73-0.88). Selecting a threshold based on the 85th percentile of risk, the model had a sensitivity of 56% (95% CI: 35%, 74%), specificity of 86% (95% CI: 85%, 87%) and positive predictive value of 9% (95% CI: 5%, 14%), identifying a population at four times higher risk for ARDS than other patients with moderate hypoxia and 17 times the risk of hospitalized adults.ConclusionsWe developed an ARDS prediction model based on EHR data with good discriminative performance. Our results demonstrate the feasibility of a machine learning approach to risk stratifying patients for ARDS solely from data extracted automatically from the EHR.",,,,,,,,,22,0,0,0,3,0,22,,,1932-6203,,,WOS:000462594000073,30921400,
J,"Adekkanattu, Prakash; Sholle, Evan T; DeFerio, Joseph; Pathak, Jyotishman; Johnson, Stephen B; Campion, Thomas R Jr",,,,,"Johnson, Stephen/0000-0002-6079-8419; Johnson, Stephen/0000-0002-7663-4355",,,Ascertaining Depression Severity by Extracting Patient Health Questionnaire-9 (PHQ-9) Scores from Clinical Notes.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,147,156,,,,,,2018,2018,"The Patient Health Questionnaire-9 (PHQ-9) is a validated instrument for assessing depression severity. While some electronic health record (EHR) systems capture PHQ-9 scores in a structured format, unstructured clinical notes remain the only source in many settings, which presents data retrieval challenges for research and clinical decision support. To address this gap, we extended the open-source Leo natural language processing (NLP) platform to extract PHQ-9 scores from clinical notes and evaluated performance using EHR data for n=123,703 patients who were prescribed antidepressants. Compared to a reference standard, the NLP method exhibited high accuracy (97%), sensitivity (98%), precision (97%), and F-score (97%). Furthermore, of patients with PHQ-9 scores identified by the NLP method, 31% (n=498) had at least one PHQ-9 score clinically indicative of major depressive disorder (MDD), but lacked a structured ICD-9/10 diagnosis code for MDD. This NLP technique may facilitate accurate identification and stratification of patients with depression.",,,,,,,,,7,0,0,0,1,0,7,,,,1942-597X,,MEDLINE:30815052,30815052,
J,"Soni, Sarvesh; Roberts, Kirk",,,,,,,,Patient Cohort Retrieval using Transformer Language Models.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1150,1159,,,,,,2020,2020,"We apply deep learning-based language models to the task of patient cohort retrieval (CR) with the aim to assess their efficacy. The task ofCR requires the extraction of relevant documents from the electronic health records (EHRs) on the basis of a given query. Given the recent advancements in the field of document retrieval, we map the task of CR to a document retrieval task and apply various deep neural models implemented for the general domain tasks. In this paper, we propose a framework for retrieving patient cohorts using neural language models without the need of explicit feature engineering and domain expertise. We find that a majority of our models outperform the BM25 baseline method on various evaluation metrics.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936491,33936491,
J,"Hong, Na; Wen, Andrew; Shen, Feichen; Sohn, Sunghwan; Wang, Chen; Liu, Hongfang; Jiang, Guoqian",,,,,,,,Developing a scalable FHIR-based clinical data normalization pipeline for standardizing and integrating unstructured and structured electronic health record data,,,,,,,,JAMIA OPEN,,,,2,4,,,570,579,,10.1093/jamiaopen/ooz056,,,,DEC 2019,2019,"Objective: To design, develop, and evaluate a scalable clinical data normalization pipeline for standardizing unstructured electronic health record (EHR) data leveraging the HL7 Fast Healthcare Interoperability Resources (FHIR) specification.Methods: We established an FHIR-based clinical data normalization pipeline known as NLP2FHIR that mainly comprises: (1) a module for a core natural language processing (NLP) engine with an FHIR-based type system; (2) a module for integrating structured data; and (3) a module for content normalization. We evaluated the FHIR modeling capability focusing on core clinical resources such as Condition, Procedure, MedicationStatement (including Medication), and FamilyMemberHistory using Mayo Clinic's unstructured EHR data. We constructed a gold standard reusing annotation corpora from previous NLP projects.Results: A total of 30 mapping rules, 62 normalization rules, and 11 NLP-specific FHIR extensions were created and implemented in the NLP2FHIR pipeline. The elements that need to integrate structured data from each clinical resource were identified. The performance of unstructured data modeling achieved F scores ranging from 0.69 to 0.99 for various FHIR element representations (0.69-0.99 for Condition; 0.75-0.84 for Procedure; 0.71-0.99 for MedicationStatement; and 0.75-0.95 for FamilyMemberHistory).Conclusion: We demonstrated that the NLP2FHIR pipeline is feasible for modeling unstructured EHR data and integrating structured elements into the model. The outcomes of this work provide standards-based tools of clinical data normalization that is indispensable for enabling portable EHR-driven phenotyping and large-scale data analytics, as well as useful insights for future developments of the FHIR specifications with regard to handling unstructured clinical data.",,,,,,,,,11,1,0,0,1,0,12,,,,2574-2531,,WOS:000645419800026,32025655,
J,"Moller, Jens Kjolseth; Sorensen, Martin; Hardahl, Christian",,,,,"Sorensen, Martin/0000-0001-6928-4521; Moller, Jens Kjolseth/0000-0002-5547-5498",,,Prediction of risk of acquiring urinary tract infection during hospital stay based on machine-learning: A retrospective cohort study,,,,,,,,PLOS ONE,,,,16,3,,,,,e0248636,10.1371/journal.pone.0248636,,,,MAR 31 2021,2021,"BackgroundHealthcare associated infections (HAI) are a major burden for the healthcare system and associated with prolonged hospital stay, increased morbidity, mortality and costs. Healthcare associated urinary tract infections (HA-UTI) accounts for about 20-30% of all HAI's, and with the emergence of multi-resistant urinary tract pathogens, the total burden of HA-UTI will most likely increase.ObjectiveThe aim of the current study was to develop two predictive models, using data from the index admission as well as historic data on a patient, to predict the development of UTI at the time of entry to the hospital and after 48 hours of admission (HA-UTI). The ultimate goal is to predict the individual patient risk of acquiring HA-UTI before it occurs so that health care professionals may take proper actions to prevent it.MethodsRetrospective cohort analysis of approx. 300 000 adult admissions in a Danish region was performed. We developed models for UTI prediction with five machine-learning algorithms using demographic information, laboratory results, data on antibiotic treatment, past medical history (ICD10 codes), and clinical data by transformation of unstructured narrative text in Electronic Medical Records to structured data by Natural Language Processing.ResultsThe five machine-learning algorithms have been evaluated by the performance measures average squared error, cumulative lift, and area under the curve (ROC-index). The algorithms had an area under the curve (ROC-index) ranging from 0.82 to 0.84 for the entry model (T = 0 hours after admission) and from 0.71 to 0.77 for the HA-UTI model (T = 48 hours after admission).ConclusionThe study is proof of concept that it is possible to create machine-learning models that can serve as early warning systems to predict patients at risk of acquiring urinary tract infections during admission. The entry model and the HA-UTI models perform with a high ROC-index indicating a sufficient sensitivity and specificity, which may make both models instrumental in individualized prevention of UTI in hospitalized patients. The favored machine-learning methodology is Decision Trees to ensure the most transparent results and to increase clinical understanding and implementation of the models.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000636354600003,33788888,
J,"Landau, Aviv Y.; Blanchard, Ashley; Cato, Kenrick; Atkins, Nia; Salazar, Stephanie; Patton, Desmond U.; Topaz, Maxim",,,,,"Landau, Aviv/0000-0003-3715-7709",,,Considerations for development of child abuse and neglect phenotype with implications for reduction of racial bias: a qualitative study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,512,519,,10.1093/jamia/ocab275,,,,JAN 29 2022,2022,"Objective The study provides considerations for generating a phenotype of child abuse and neglect in Emergency Departments (ED) using secondary data from electronic health records (EHR). Implications will be provided for racial bias reduction and the development of further decision support tools to assist in identifying child abuse and neglect. Materials and Methods We conducted a qualitative study using in-depth interviews with 20 pediatric clinicians working in a single pediatric ED to gain insights about generating an EHR-based phenotype to identify children at risk for abuse and neglect. Results Three central themes emerged from the interviews: (1) Challenges in diagnosing child abuse and neglect, (2) Health Discipline Differences in Documentation Styles in EHR, and (3) Identification of potential racial bias through documentation. Discussion Our findings highlight important considerations for generating a phenotype for child abuse and neglect using EHR data. First, information-related challenges include lack of proper previous visit history due to limited information exchanges and scattered documentation within EHRs. Second, there are differences in documentation styles by health disciplines, and clinicians tend to document abuse in different document types within EHRs. Finally, documentation can help identify potential racial bias in suspicion of child abuse and neglect by revealing potential discrepancies in quality of care, and in the language used to document abuse and neglect. Conclusions Our findings highlight challenges in building an EHR-based risk phenotype for child abuse and neglect. Further research is needed to validate these findings and integrate them into creation of an EHR-based risk phenotype.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000761451900012,35024857,
J,"Bari, Vitej; Hirsch, Jamie S.; Narvaez, Joseph; Sardinia, Robert; Bock, Kevin R.; Oppenheim, Michael, I; Meytlis, Marsha",,,,,,,,An approach to predicting patient experience through machine learning and social network analysis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1834,1843,,10.1093/jamia/ocaa194,,,,DEC 2020,2020,"Objective: Improving the patient experience has become an essential component of any healthcare system's performance metrics portfolio. In this study, we developed a machine learning model to predict a patient's response to the Hospital Consumer Assessment of Healthcare Providers and Systems survey's Doctor Communications domain questions while simultaneously identifying most impactful providers in a network.Materials and Methods: This is an observational study of patients admitted to a single tertiary care hospital between 2016 and 2020. Using machine learning algorithms, electronic health record data were used to predict patient responses to Hospital Consumer Assessment of Healthcare Providers and Systems survey questions in the doctor domain, and patients who are at risk for responding negatively were identified. Model performance was assessed by area under receiver-operating characteristic curve. Social network analysis metrics were also used to identify providers most impactful to patient experience.Results: Using a random forest algorithm, patients' responses to the following 3 questions were predicted: During this hospital stay how often did doctors. 1) treat you with courtesy and respect? 2) explain things in a way that you could understand? 3) listen carefully to you? with areas under the receiver-operating characteristic curve of 0.876, 0.819, and 0.819, respectively. Social network analysis found that doctors with higher centrality appear to have an outsized influence on patient experience, as measured by rank in the random forest model in the doctor domain.Conclusions: A machine learning algorithm identified patients at risk of a negative experience. Furthermore, a doctor social network framework provides metrics for identifying those providers that are most influential on the patient experience.",,,,,,,,,5,0,0,0,0,0,5,,,1067-5027,1527-974X,,WOS:000606832500002,33104210,
J,"Zhao, Shiyi; Li, Lishuang",,,,,,,,Temporal information extraction with the scalable cross-sentence context for electronic health records.,,,,,,,,Journal of biomedical informatics,,,,128,,,,104052,104052,,10.1016/j.jbi.2022.104052,,,,2022-Apr,2022,"Temporal information is essential for accurate understanding of medical information hidden in electronic health record texts. In the absence of temporal information, it is even impossible to distinguish whether the mentioned symptom is a current condition or past medical history. Hence, identifying the relationship between medical events and document creation time (DCT) is a critical component for medical language comprehension, which can link the mentioned medical information to the time dimension by marking temporal tags. Existing natural language processing (NLP) systems are typically based on the sentence where the medical event is located to extract the DCT relationship. Inevitably, the limited textual context can be insufficient as it is difficult to contain adequate document information. Introducing the surrounding sentences into models is a fitting way to enrich the information. However, in addition to document information, the added context can also bring noise to confuse the models. For effective utilization of the context, we design the DCDR (Dynamic Context and Dynamic Representation) model. Our model consists of two modules, i.e. the dynamic context mechanism and dynamic representation mechanism. The dynamic context mechanism is employed to bring the related texts into our model via the sliding windows and a scoring calculation. For the dynamic representation mechanism, a modified dynamic routing algorithm is adopted to filter the noise and generate an integrated representation for the whole context. Besides, the mentioned medical information is led into the routing process to enhance the dynamic representation module. The experiments show that our proposed model achieves improvement over existing models and achieves an F-score of 85.7% on the commonly used THYME corpus.",,,,,,,,,0,0,0,0,0,0,0,,,,1532-0480,,MEDLINE:35301142,35301142,
J,"Chen, Chi-Jen; Warikoo, Neha; Chang, Yung-Chun; Chen, Jin-Hua; Hsu, Wen-Lian",,,,"Hsu, Wen-Lian/ABB-2851-2020","Hsu, Wen-Lian/0000-0001-7061-3513; Warikoo, Neha/0000-0003-4222-8970; Chang, Yung-Chun/0000-0002-9634-8380",,,Medical knowledge infused convolutional neural networks for cohort selection in clinical trials,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1227,1236,,10.1093/jamia/ocz128,,,,NOV 2019,2019,"Objective: In this era of digitized health records, there has been a marked interest in using de-identified patient records for conducting various health related surveys. To assist in this research effort, we developed a novel clinical data representation model entitled medical knowledge-infused convolutional neural network (MKCNN), which is used for learning the clinical trial criteria eligibility status of patients to participate in cohort studies.Materials and Methods: In this study, we propose a clinical text representation infused with medical knowledge (MK). First, we isolate the noise from the relevant data using a medically relevant description extractor; then we utilize log-likelihood ratio based weights from selected sentences to highlight met and not-met knowledge-infused representations in bichannel setting for each instance. The combined medical knowledge-infused representation (MK) from these modules helps identify significant clinical criteria semantics, which in turn renders effective learning when used with a convolutional neural network architecture.Results: MKCNN outperforms other Medical Knowledge (MK) relevant learning architectures by approximately 3%; notably SVM and XGBoost implementations developed in this study. MKCNN scored 86.1% on F1metric, a gain of 6% above the average performance assessed from the submissions for n2c2 task. Although pattern/rule-based methods show a higher average performance for the n2c2 clinical data set, MKCNN significantly improves performance of machine learning implementations for clinical datasets.Conclusion: MKCNN scored 86.1% on the F1 score metric. In contrast to many of the rule-based systems introduced during the n2c2 challenge workshop, our system presents a model that heavily draws on machine-based learning. In addition, the MK representations add more value to clinical comprehension and interpretation of natural texts.",,,,,,,,,4,0,0,0,2,0,4,,,1067-5027,1527-974X,,WOS:000498169400010,31390470,
J,"Gu, Yang; Leroy, Gondy; Pettygrove, Sydney; Galindo, Maureen Kelly; Kurzius-Spencer, Margaret",,,,,,,,Optimizing Corpus Creation for Training Word Embedding in Low Resource Domains: A Case Study in Autism Spectrum Disorder (ASD).,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,508,517,,,,,,2018,2018,"Automating the extraction of behavioral criteria indicative of Autism Spectrum Disorder (ASD) in electronic health records (EHRs) can contribute significantly to the effort to monitor the condition. Word embedding algorithms such as Word2Vec can encode semantic meanings of words in vectors and assist in automated vocabulary discovery from EHRs. However, text available for training word embeddings for ASD is miniscule compared to the billions of tokens typically used. We evaluate the importance of corpus specificity versus size and hypothesize that for specific domains small corpora can generate excellent word embeddings. We custom-built 6 ASD-themed corpora (N=4482), using ASD EHRs and abstracts from PubMed (N=39K) and PsychInfo (N=69K) and evaluated them. We were able to generate the most useful 200-dimension embeddings based on the small ASD EHR data. Due to diversity in its vocabulary, the abstract-based embeddings generated fewer related terms and saw minimal improvement when the size of the corpus increased.",,,,,,,,,3,0,0,0,2,0,3,,,,1942-597X,,MEDLINE:30815091,30815091,
J,"Noshad, Morteza; Rose, Christian C.; Chen, Jonathan H.",,,,"Rose, Christian/AAP-2569-2021","Rose, Christian/0000-0002-5115-649X",,,Signal from the noise: A mixed graphical and quantitative process mining approach to evaluate care pathways applied to emergency stroke care,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,104004,10.1016/j.jbi.2022.104004,,,,MAR 2022,2022,"Objective: Mapping real-world practice patterns vs. deviations from intended guidelines and protocols is necessary to identify and improve the quality of care for emergent medical conditions like acute ischemic stroke. Most status-quo process identification relies on expert opinion or direct observation, which can be biased or limited in scalability. We propose a mixed graphical and quantitative process mining approach to Electronic Health Record (EHR) event log data as a unique opportunity not only to more easily identify practice patterns, but also to compare real-world care processes and measure their conformance or variability.Materials: Data was obtained from the event log of a major EHR vendor (Epic) for Stanford Health Care Hospital patients aged 18 years and older presenting to the ED from January 1, 2010 through December 31, 2018 and receiving tPA (tissue plasminogen activator) within 4.5 h of presentation.Methods: We developed an unsupervised process-mining algorithm to create a process map from clinical event logs. The method first identifies the most common events across the cohort. Then, all possible ordered events are recorded, and a summarized vector of nodes (events) and edges (events occurring in series) are mapped by their timing and probability. The highest probability ordered pairs are used to identify the most common path. We define measures for individual pathways conformity and average conformity across all encounters.Results: Automatically generated process mining graphs, and specifically it's the most common path, mimicked our institutions recommended code stroke clinical pathway. The average conformity score for our cohort was 0.36 (i.e. paths had an average of 36% overlap with all possible paths), with a range from high of 0.64 and low of 0.20.Discussion: This method allows for unsupervised visualization of the current state of common processes as well as their most common path, which can then be used to calculate the conformity of individual pathways through this process. These results may be used to evaluate the consistency of quality care at a given institution. It may also be extended to other common processes like sepsis or myocardial infarction care or even those which currently lack standardized clinical pathways.Conclusion: Our mixed graphical and quantitative process mining approach represents an essential data analysis step to improve complex care processes by automatically generating qualitative and quantitative process measures from existing event log data which can then be used to target quality improvement initiatives.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000006,35085813,
J,"Dipnall, Joanna F.; Page, Richard; Du, Lan; Costa, Matthew; Lyons, Ronan A.; Cameron, Peter; de Steiger, Richard; Hau, Raphael; Bucknill, Andrew; Oppy, Andrew; Edwards, Elton; Varma, Dinesh; Jung, Myong Chol; Gabbe, Belinda J.",,,,,"Jung, Myong Chol/0000-0002-8715-8120",,,Predicting fracture outcomes from clinical registry data using artificial intelligence supplemented models for evidence-informed treatment (PRAISE) study protocol,,,,,,,,PLOS ONE,,,,16,9,,,,,e0257361,10.1371/journal.pone.0257361,,,,SEP 23 2021,2021,"Background Distal radius (wrist) fractures are the second most common fracture admitted to hospital. The anatomical pattern of these types of injuries is diverse, with variation in clinical management, guidelines for management remain inconclusive, and the uptake of findings from clinical trials into routine practice limited. Robust predictive modelling, which considers both the characteristics of the fracture and patient, provides the best opportunity to reduce variation in care and improve patient outcomes. This type of data is housed in unstructured data sources with no particular format or schema. The Predicting fracture outcomes from clinical Registry data using Artificial Intelligence (AI) Supplemented models for Evidence-informed treatment (PRAISE) study aims to use AI methods on unstructured data to describe the fracture characteristics and test if using this information improves identification of key fracture characteristics and prediction of patient-reported outcome measures and clinical outcomes following wrist fractures compared to prediction models based on standard registry data.Methods and design Adult (16+ years) patients presenting to the emergency department, treated in a short stay unit, or admitted to hospital for >24h for management of a wrist fracture in four Victorian hospitals will be included in this study. The study will use routine registry data from the Victorian Orthopaedic Trauma Outcomes Registry (VOTOR), and electronic medical record (EMR) information (e.g. X-rays, surgical reports, radiology reports, images). A multimodal deep learning fracture reasoning system (DLFRS) will be developed that reasons on EMR information. Machine learning prediction models will test the performance with/without output from the DLFRS.Discussion The PRAISE study will establish the use of AI techniques to provide enhanced information about fracture characteristics in people with wrist fractures. Prediction models using AI derived characteristics are expected to provide better prediction of clinical and patient-reported outcomes following distal radius fracture.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000725694500029,34555069,
J,"Tajgardoon, Mohammadamin; Cooper, Gregory F.; King, Andrew J.; Clermont, Gilles; Hochheiser, Harry; Hauskrecht, Milos; Sittig, Dean F.; Visweswaran, Shyam",,,,"Sittig, Dean F./D-2471-2009; King, Andrew/AAW-5399-2021","Sittig, Dean F./0000-0001-5811-8915; King, Andrew/0000-0002-9809-0563",,,Modeling physician variability to prioritize relevant medical record information,,,,,,,,JAMIA OPEN,,,,3,4,,,602,610,,10.1093/jamiaopen/ooaa058,,FEB 2021,,DEC 2020,2020,"Objective: Patient information can be retrieved more efficiently in electronic medical record (EMR) systems by using machine learning models that predict which information a physician will seek in a clinical context. However, information-seeking behavior varies across EMR users. To explicitly account for this variability, we derived hierarchical models and compared their performance to nonhierarchical models in identifying relevant patient information in intensive care unit (ICU) cases.Materials and methods: Critical care physicians reviewed ICU patient cases and selected data items relevant for presenting at morning rounds. Using patient EMR data as predictors, we derived hierarchical logistic regression (HLR) and standard logistic regression (LR) models to predict their relevance.Results: In 73 pairs of HLR and LR models, the HLR models achieved an area under the receiver operating characteristic curve of 0.81, 95% confidence interval (CI) [0.80-0.82], which was statistically significantly higher than that of LR models (0.75, 95% CI [0.74-0.76]). Further, the HLR models achieved statistically significantly lower expected calibration error (0.07, 95% CI [0.06-0.08]) than LR models (0.16, 95% CI [0.14-0.17]).Discussion: The physician reviewers demonstrated variability in selecting relevant data. Our results show that HLR models perform significantly better than LR models with respect to both discrimination and calibration. This is likely due to explicitly modeling physician-related variability.Conclusion: Hierarchical models can yield better performance when there is physician-related variability as in the case of identifying relevant information in the EMR.",,,,,,,,,1,0,0,0,0,0,1,,,,2574-2531,,WOS:000645440800018,33623894,
J,"Nguyen, Anthony N; Truran, Donna; Kemp, Madonna; Koopman, Bevan; Conlan, David; O'Dwyer, John; Zhang, Ming; Karimi, Sarvnaz; Hassanzadeh, Hamed; Lawley, Michael J; Green, Damian",,,,"Hassanzadeh, Hamed/K-9151-2016","Hassanzadeh, Hamed/0000-0003-2315-1963",,,Computer-Assisted Diagnostic Coding: Effectiveness of an NLP-based approach using SNOMED CT to ICD-10 mappings.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,807,816,,,,,,2018,2018,"Computer-assisted (diagnostic) coding (CAC) aims to improve the operational productivity and accuracy of clinical coders. The level of accuracy, especially for a wide range of complex and less prevalent clinical cases, remains an open research problem. This study investigates this problem on a broad spectrum of diagnostic codes and, in particular, investigates the effectiveness of utilising SNOMED CT for ICD-10 diagnosis coding. Hospital progress notes were used to provide the narrative rich electronic patient records for the investigation. A natural language processing (NLP) approach using mappings between SNOMED CT and ICD-10-AM (Australian Modification) was used to guide the coding. The proposed approach achieved 54.1% sensitivity and 70.2% positive predictive value. Given the complexity of the task, this was encouraging given the simplicity of the approach and what was projected as possible from a manual diagnosis code validation study (76.3% sensitivity). The results show the potential for advanced NLP-based approaches that leverage SNOMED CT to ICD-10 mapping for hospital in-patient coding.",,,,,,,,,12,0,0,0,2,0,12,,,,1942-597X,,MEDLINE:30815123,30815123,
J,"Zhang, Xinmeng; Yan, Chao; Malin, Bradley A.; Patel, Mayur B.; Chen, You",,,,,"Chen, You/0000-0001-8232-8840; Yan, Chao/0000-0002-6719-1388",,,Predicting next-day discharge via electronic health record access logs,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,12,,,2670,2680,,10.1093/jamia/ocab211,,SEP 2021,,DEC 2021,2021,"Objective: Hospital capacity management depends on accurate real-time estimates of hospital-wide discharges. Estimation by a clinician requires an excessively large amount of effort and, even when attempted, accuracy in forecasting next-day patient-level discharge is poor. This study aims to support next-day discharge predictions with machine learning by incorporating electronic health record (EHR) audit log data, a resource that captures EHR users' granular interactions with patients' records by communicating various semantics and has been neglected in outcome predictions.Materials and Methods: This study focused on the EHR data for all adults admitted to Vanderbilt University Medical Center in 2019. We learned multiple advanced models to assess the value that EHR audit log data adds to the daily prediction of discharge likelihood within 24 h and to compare different representation strategies. We applied Shapley additive explanations to identify the most influential types of user-EHR interactions for discharge prediction.Results: The data include 26 283 inpatient stays, 133 398 patient-day observations, and 819 types of user-EHR interactions. The model using the count of each type of interaction in the recent 24 h and other commonly used features, including demographics and admission diagnoses, achieved the highest area under the receiver operating characteristics (AUROC) curve of 0.921 (95% CI: 0.919-0.923). By contrast, the model lacking user-EHR interactions achieved a worse AUROC of 0.862 (0.860-0.865). In addition, 10 of the 20 (50%) most influential factors were user-EHR interaction features.Conclusion: EHR audit log data contain rich information such that it can improve hospital-wide discharge predictions.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000728261700014,34592753,
J,"Denaxas, Spiros; Shah, Anoop D.; Mateen, Bilal A.; Kuan, Valerie; Quint, Jennifer K.; Fitzpatrick, Natalie; Torralbo, Ana; Fatemifar, Ghazaleh; Hemingway, Harry",,,,"Shah, Anoop Dinesh/D-4396-2014; Hemingway, Harry/C-1219-2009","Shah, Anoop Dinesh/0000-0002-8907-5724; Mateen, Bilal Akhter/0000-0003-4423-6472; Denaxas, Spiros/0000-0001-9612-7791; Hemingway, Harry/0000-0003-2279-0624",,,A semi-supervised approach for rapidly creating clinical biomarker phenotypes in the UK Biobank using different primary care EHR and clinical terminology systems,,,,,,,,JAMIA OPEN,,,,3,4,,,545,556,,10.1093/jamiaopen/ooaa047,,,,DEC 2020,2020,"Objectives: The UK Biobank (UKB) is making primary care electronic health records (EHRs) for 500 000 participants available for COVID-19-related research. Data are extracted from four sources, recorded using five clinical terminologies and stored in different schemas. The aims of our research were to: (a) develop a semi-supervised approach for bootstrapping EHR phenotyping algorithms in UKB EHR, and (b) to evaluate our approach by implementing and evaluating phenotypes for 31 common biomarkers.Materials and Methods: We describe an algorithmic approach to phenotyping biomarkers in primary care EHR involving (a) bootstrapping definitions using existing phenotypes, (b) excluding generic, rare, or semantically distant terms, (c) forward-mapping terminology terms, (d) expert review, and (e) data extraction. We evaluated the phenotypes by assessing the ability to reproduce known epidemiological associations with all-cause mortality using Cox proportional hazards models.Results: We created and evaluated phenotyping algorithms for 31 biomarkers many of which are directly related to COVID-19 complications, for example diabetes, cardiovascular disease, respiratory disease. Our algorithm identified 1651 Read v2 and Clinical Terms Version 3 terms and automatically excluded 1228 terms. Clinical review excluded 103 terms and included 44 terms, resulting in 364 terms for data extraction (sensitivity 0.89, specificity 0.92). We extracted 38 190 682 events and identified 220 978 participants with at least one biomarker measured.Discussion and conclusion: Bootstrapping phenotyping algorithms from similar EHR can potentially address pre-existing methodological concerns that undermine the outputs of biomarker discovery pipelines and provide research-quality phenotyping algorithms.",,,,,,,,,2,0,0,0,1,0,2,,,,2574-2531,,WOS:000645440800012,33619467,
J,"Zhang, Yiye; Trepp, Richard; Wang, Weiguang; Luna, Jorge; Vawdrey, David K.; Tiase, Victoria",,,,"Tiase, Victoria/AAE-4076-2020",,,,Developing and maintaining clinical decision support using clinical knowledge and machine learning: the case of order sets,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,11,,,1547,1551,,10.1093/jamia/ocy099,,,,NOV 2018,2018,"Development and maintenance of order sets is a knowledge-intensive task for off-the-shelf machine-learning algorithms alone. We hypothesize that integrating clinical knowledge with machine learning can facilitate effective development and maintenance of order sets while promoting best practices in ordering. To this end, we simulated the revision of an AM Lab Order Set under 6 revision approaches. Revisions included changes in the order set content or default settings through 1) population statistics, 2) individualized prediction using machine learning, and 3) clinical knowledge. Revision criteria were determined using electronic health record (EHR) data from 2014 to 2015. Each revision's clinical appropriateness, workload from using the order set, and generalizability across time were evaluated using EHR data from 2016 and 2017. Our results suggest a potential order set revision approach that jointly leverages clinical knowledge and machine learning to improve usability while updating contents based on latest clinical knowledge and best practices.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000450392500015,30101305,
J,"Wang, Liwei; Wampfler, Jason; Dispenzieri, Angela; Xu, Hua; Yang, Ping; Liu, Hongfang",,,,,,,,Achievability to Extract Specific Date Information for Cancer Research.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,893,902,,,,,,2019,2019,"Accurate identification of temporal information such as date is crucial for advancing cancer research which often requires precise date information associated with related cancer events. However, there is a gap for existing natural language processing (NLP) systems to identify dates for specific cancer research studies. Illustrated with two case studies, we investigated the feasibility, evaluated the performances and discussed the challenges of date information extraction for cancer research.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:32308886,32308886,
J,"Meystre, Stephane M.; Heider, Paul M.; Kim, Youngjun; Davis, Matthew; Obeid, Jihad; Madory, James; Alekseyenko, Alexander, V",,,,"; Obeid, Jihad/P-9793-2016","Davis, Matthew/0000-0001-9111-4932; Alekseyenko, Alexander/0000-0002-5748-2085; Heider, Paul/0000-0002-1589-4567; Obeid, Jihad/0000-0002-7193-7779",,,Natural language processing enabling COVID-19 predictive analytics to support data-driven patient advising and pooled testing,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,1,,,12,21,,10.1093/jamia/ocab186,,OCT 2021,,JAN 2021,2021,"Objective: The COVID-19 (coronavirus disease 2019) pandemic response at the Medical University of South Carolina included virtual care visits for patients with suspected severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection. The telehealth system used for these visits only exports a text note to integrate with the electronic health record, but structured and coded information about COVID-19 (eg, exposure, risk factors, symptoms) was needed to support clinical care and early research as well as predictive analytics for data-driven patient advising and pooled testing.Materials and Methods: To capture COVID-19 information from multiple sources, a new data mart and a new natural language processing (NLP) application prototype were developed. The NLP application combined reused components with dictionaries and rules crafted by domain experts. It was deployed as a Web service for hourly processing of new data from patients assessed or treated for COVID-19. The extracted information was then used to develop algorithms predicting SARS-CoV-2 diagnostic test results based on symptoms and exposure information.Results: The dedicated data mart and NLP application were developed and deployed in a mere 10-day sprint in March 2020. The NLP application was evaluated with good accuracy (85.8% recall and 81.5% precision). The SARS-CoV-2 testing predictive analytics algorithms were configured to provide patients with data-driven COVID-19 testing advices with a sensitivity of 81% to 92% and to enable pooled testing with a negative predictive value of 90% to 91%, reducing the required tests to about 63%.Conclusions: SARS-CoV-2 testing predictive analytics and NLP successfully enabled data-driven patient advising and pooled testing.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000740719600003,34415311,
J,"Carlin, Cameron S.; Ho, Long V.; Ledbetter, David R.; Aczon, Melissa D.; Wetzel, Randall C.",,,,,"Ledbetter, David/0000-0003-0382-5086",,,Predicting individual physiologically acceptable states at discharge from a pediatric intensive care unit,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,12,,,1600,1607,,10.1093/jamia/ocy122,,,,DEC 2018,2018,"Objective: Quantify physiologically acceptable PICU-discharge vital signs and develop machine learning models to predict these values for individual patients throughout their PICU episode.Methods: EMR data from 7256 survivor PICU episodes (5632 patients) collected between 2009 and 2017 at Children's Hospital Los Angeles was analyzed. Each episode contained 375 variables representing physiology, labs, interventions, and drugs. Between medical and physical discharge, when clinicians determined the patient was ready for ICU discharge, they were assumed to be in a physiologically acceptable state space (PASS) for discharge. Each patient's heart rate, systolic blood pressure, diastolic blood pressure in the PASS window were measured and compared to age-normal values, regression-quantified PASS predictions, and recurrent neural network (RNN) PASS predictions made 12 hours after PICU admission.Results: Mean absolute errors (MAEs) between individual PASS values and age-normal values (HR: 21.0 bpm; SBP: 10.8 mm Hg; DBP: 10.6 mm Hg) were greater (p < .05) than regression prediction MAEs (HR: 15.4 bpm; SBP: 9.9 mm Hg; DBP: 8.6 mm Hg). The RNN models best approximated individual PASS values (HR: 12.3 bpm; SBP: 7.6 mm Hg; DBP: 7.0 mm Hg).Conclusions: The RNN model predictions better approximate patient-specific PASS values than regression and age-normal values.",,,,,,,,,9,0,0,0,3,0,9,,,1067-5027,1527-974X,,WOS:000457590600005,30295770,
J,"Kang, Ah Reum; Lee, Jihyun; Jung, Woohyun; Lee, Misoon; Park, Sun Young; Woo, Jiyoung; Kim, Sang Hyun",,,,,"Kang, Ah Reum/0000-0002-0732-5313; Jung, Woohyun/0000-0002-7786-7679; Park, Sun Young/0000-0003-2588-3324",,,Development of a prediction model for hypotension after induction of anesthesia using machine learning,,,,,,,,PLOS ONE,,,,15,4,,,,,e0231172,10.1371/journal.pone.0231172,,,,APR 16 2020,2020,"Arterial hypotension during the early phase of anesthesia can lead to adverse outcomes such as a prolonged postoperative stay or even death. Predicting hypotension during anesthesia induction is complicated by its diverse causes. We investigated the feasibility of developing a machine-learning model to predict postinduction hypotension. Naive Bayes, logistic regression, random forest, and artificial neural network models were trained to predict postinduction hypotension, occurring between tracheal intubation and incision, using data for the period from between the start of anesthesia induction and immediately before tracheal intubation obtained from an anesthesia monitor, a drug administration infusion pump, an anesthesia machine, and from patients' demographics, together with preexisting disease information from electronic health records. Among 222 patients, 126 developed postinduction hypotension. The random-forest model showed the best performance, with an area under the receiver operating characteristic curve of 0.842 (95% confidence interval [CI]: 0.736-0.948). This was higher than that for the Naive Bayes (0.778; 95% CI: 0.65-0.898), logistic regression (0.756; 95% CI: 0.630-0.881), and artificial-neural-network (0.760; 95% CI: 0.640-0.880) models. The most important features affecting the accuracy of machine-learning prediction were a patient's lowest systolic blood pressure, lowest mean blood pressure, and mean systolic blood pressure before tracheal intubation. We found that machine-learning models using data obtained from various anesthesia machines between the start of anesthesia induction and immediately before tracheal intubation can predict hypotension occurring during the period between tracheal intubation and incision.",,,,,,,,,11,0,0,0,4,0,11,,,1932-6203,,,WOS:000536011400029,32298292,
J,"Hernandez-Boussard, Tina; Monda, Keri L.; Crespo, Blai Coll; Riskin, Dan",,,,,,,,Real world evidence in cardiovascular medicine: ensuring data validity in electronic health record-based studies,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1189,1194,,10.1093/jamia/ocz119,,,,NOV 2019,2019,"Objective: With growing availability of digital health data and technology, health-related studies are increasingly augmented or implemented using real world data (RWD). Recent federal initiatives promote the use of RWD to make clinical assertions that influence regulatory decision-making. Our objective was to determine whether traditional real world evidence (RWE) techniques in cardiovascular medicine achieve accuracy sufficient for credible clinical assertions, also known as regulatory-grade RWE.Design: Retrospective observational study using electronic health records (EHR), 2010-2016.Methods: A predefined set of clinical concepts was extracted from EHR structured (EHR-S) and unstructured (EHR-U) data using traditional query techniques and artificial intelligence (AI) technologies, respectively. Performance was evaluated against manually annotated cohorts using standard metrics. Accuracy was compared to pre-defined criteria for regulatory-grade. Differences in accuracy were compared using Chi-square test.Results: The dataset included 10 840 clinical notes. Individual concept occurrence ranged from 194 for coronary artery bypass graft to 4502 for diabetes mellitus. In EHR-S, average recall and precision were 51.7% and 98.3%, respectively and 95.5% and 95.3% in EHR-U, respectively. For each clinical concept, EHR-S accuracy was below regulatory-grade, while EHR-U met or exceeded criteria, with the exception of medications.Conclusions: Identifying an appropriate RWE approach is dependent on cohorts studied and accuracy required. In this study, recall varied greatly between EHR-S and EHR-U. Overall, EHR-S did not meet regulatory grade criteria, while EHR-U did. These results suggest that recall should be routinely measured in EHR-based studes intended for regulatory use. Furthermore, advanced data and technologies may be required to achieve regulatory grade results.",,,,,,,,,14,0,0,0,5,0,14,,,1067-5027,1527-974X,,WOS:000498169400005,31414700,
J,"Ma, Hui; Guo, Xuyang; Ping, Yuan; Wang, Baocang; Yang, Yuehua; Zhang, Zhili; Zhou, Jingxian",,,,,,,,PPCD: Privacy-preserving clinical decision with cloud support,,,,,,,,PLOS ONE,,,,14,5,,,,,e0217349,10.1371/journal.pone.0217349,,,,MAY 29 2019,2019,"With the prosperity of machine learning and cloud computing, meaningful information can be mined from mass electronic medical data which help physicians make proper disease diagnosis for patients. However, using medical data and disease information of patients frequently raise privacy concerns. In this paper, based on single-layer perceptron, we propose a scheme of privacy-preserving clinical decision with cloud support (PPCD), which securely conducts disease model training and prediction for the patient. Each party learns nothing about the other's private information. In PPCD, a lightweight secure multiplication is presented and introduced to improve the model training. Security analysis and experimental results on real data confirm the high accuracy of disease prediction achieved by the proposed PPCD without the risk of privacy disclosure.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000469323000052,31141561,
J,"Masino, Aaron J.; Harris, Mary Catherine; Forsyth, Daniel; Ostapenko, Svetlana; Srinivasan, Lakshmi; Bonafide, Christopher P.; Balamuth, Fran; Schmatz, Melissa; Grundmeier, Robert W.",,,,,"Bonafide, Christopher/0000-0003-2823-5883; Harris, Mary Catherine/0000-0001-6287-0026; Grundmeier, Robert/0000-0002-8290-5588",,,Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data,,,,,,,,PLOS ONE,,,,14,2,,,,,e0212665,10.1371/journal.pone.0212665,,,,FEB 22 2019,2019,"BackgroundRapid antibiotic administration is known to improve sepsis outcomes, however early diagnosis remains challenging due to complex presentation. Our objective was to develop a model using readily available electronic health record (EHR) data capable of recognizing infant sepsis at least 4 hours prior to clinical recognition.Methods and findingsWe performed a retrospective case control study of infants hospitalized. 48 hours in the Neonatal Intensive Care Unit (NICU) at the Children's Hospital of Philadelphia between September 2014 and November 2017 who received at least one sepsis evaluation before 12 months of age. We considered two evaluation outcomes as cases: culture positive-positive blood culture for a known pathogen (110 evaluations); and clinically positive-negative cultures but antibiotics administered for. 120 hours (265 evaluations). Case data was taken from the 44-hour window ending 4 hours prior to evaluation. We randomly sampled 1,100 44-hour windows of control data from all times. 10 days removed from any evaluation. Model inputs consisted of up to 36 features derived from routine EHR data. Using 10-fold nested cross-validation, 8 machine learning models were trained to classify inputs as sepsis positive or negative. When tasked with discriminating culture positive cases from controls, 6 models achieved a mean area under the receiver operating characteristic (AUC) between 0.80-0.82 with no significant differences between them. Including both culture and clinically positive cases, the same 6 models achieved an AUC between 0.85-0.87, again with no significant differences.ConclusionsMachine learning models can identify infants with sepsis in the NICU hours prior to clinical recognition. Learning curves indicate model improvement may be achieved with additional training examples. Additional input features may also improve performance. Further research is warranted to assess potential performance improvements and clinical efficacy in a prospective trial.",,,,,,,,,45,1,1,0,16,0,47,,,1932-6203,,,WOS:000459709100108,30794638,
J,"Yu, Sheng; Ma, Yumeng; Gronsbell, Jessica; Cai, Tianrun; Ananthakrishnan, Ashwin N.; Gainer, Vivian S.; Churchill, Susanne E.; Szolovits, Peter; Murphy, Shawn N.; Kohane, Isaac S.; Liao, Katherine P.; Cai, Tianxi",,,,,,,,Enabling phenotypic big data with PheNorm,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,1,,,54,60,,10.1093/jamia/ocx111,,,,JAN 2018,2018,"Electronic health record (EHR)-based phenotyping infers whether a patient has a disease based on the information in his or her EHR. A human-annotated training set with gold-standard disease status labels is usually required to build an algorithm for phenotyping based on a set of predictive features. The time intensiveness of annotation and feature curation severely limits the ability to achieve high-throughput phenotyping. While previous studies have successfully automated feature curation, annotation remains a major bottleneck. In this paper, we present PheNorm, a phenotyping algorithm that does not require expert-labeled samples for training.The most predictive features, such as the number of International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) codes or mentions of the target phenotype, are normalized to resemble a normal mixture distribution with high area under the receiver operating curve (AUC) for prediction. The transformed features are then denoised and combined into a score for accurate disease classification.We validated the accuracy of PheNorm with 4 phenotypes: coronary artery disease, rheumatoid arthritis, Crohn's disease, and ulcerative colitis. The AUCs of the PheNorm score reached 0.90, 0.94, 0.95, and 0.94 for the 4 phenotypes, respectively, which were comparable to the accuracy of supervised algorithms trained with sample sizes of 100-300, with no statistically significant difference.The accuracy of the PheNorm algorithms is on par with algorithms trained with annotated samples. PheNorm fully automates the generation of accurate phenotyping algorithms and demonstrates the capacity for EHR-driven annotations to scale to the next level - phenotypic big data.",,,,,,,,,34,1,0,0,15,0,34,,,1067-5027,1527-974X,,WOS:000419605800010,29126253,
J,"Raisaro, J. L.; Marino, Francesco; Troncoso-Pastoriza, Juan; Beau-Lejdstrom, Raphaelle; Bellazzi, Riccardo; Murphy, Robert; Bernstam, Elmer, V; Wang, Henry; Bucalo, Mauro; Chen, Yong; Gottlieb, Assaf; Harmanci, Arif; Kim, Miran; Kim, Yejin; Klann, Jeffrey; Klersy, Catherine; Malin, Bradley A.; Mean, Marie; Prasser, Fabian; Scudeller, Luigia; Torkamani, Ali; Vaucher, Julien; Puppala, Mamta; Wong, Stephen T. C.; Frenkel-Morgenstern, Milana; Xu, Hua; Musa, Maiyaki; Habib, Abdulrazaq G.; Cohen, Trevor; Wilcox, Adam; Salihu, Hamisu M.; Sofia, Heidi; Jiang, Xiaoqian; Hubaux, J. P.",,,,"klersy, catherine/AAA-3003-2019; Bellazzi, Riccardo/J-6432-2018; Scudeller, Luigia/K-9625-2014","klersy, catherine/0000-0003-0314-8548; Bellazzi, Riccardo/0000-0002-6974-9808; Vaucher, Julien/0000-0002-3230-3693; Scudeller, Luigia/0000-0001-7240-9567; Prasser, Fabian/0000-0003-3172-3095; Kim, Miran/0000-0003-3564-6090",,,SCOR: A secure international informatics infrastructure to investigate COVID-19,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,11,,,1721,1726,,10.1093/jamia/ocaa172,,,,NOV 2020,2020,"Global pandemics call for large and diverse healthcare data to study various risk factors, treatment options, and disease progression patterns. Despite the enormous efforts of many large data consortium initiatives, scientific community still lacks a secure and privacy-preserving infrastructure to support auditable data sharing and facilitate automated and legally compliant federated analysis on an international scale. Existing health informatics systems do not incorporate the latest progress in modern security and federated machine learning algorithms, which are poised to offer solutions. An international group of passionate researchers came together with a joint mission to solve the problem with our finest models and tools. The SCOR Consortium has developed a ready-to-deploy secure infrastructure using world-class privacy and security technologies to reconcile the privacy/utility conflicts. We hope our effort will make a change and accelerate research in future pandemics with broad and diverse samples on an international scale.",,,,,,,,,12,0,0,0,4,0,12,,,1067-5027,1527-974X,,WOS:000594986600012,32918447,
J,"Gao, Shang; Alawad, Mohammed; Schaefferkoetter, Noah; Penberthy, Lynne; Wu, Xiao-Cheng; Durbin, Eric B.; Coyle, Linda; Ramanathan, Arvind; Tourassi, Georgia",,,,,"Gao, Shang/0000-0003-1803-1457; Durbin, Eric/0000-0002-5600-7645",,,Using case-level context to classify cancer pathology reports,,,,,,,,PLOS ONE,,,,15,5,,,,,e0232840,10.1371/journal.pone.0232840,,,,MAY 12 2020,2020,"Individual electronic health records (EHRs) and clinical reports are often part of a larger sequence-for example, a single patient may generate multiple reports over the trajectory of a disease. In applications such as cancer pathology reports, it is necessary not only to extract information from individual reports, but also to capture aggregate information regarding the entire cancer case based off case-level context from all reports in the sequence. In this paper, we introduce a simple modular add-on for capturing case-level context that is designed to be compatible with most existing deep learning architectures for text classification on individual reports. We test our approach on a corpus of 431,433 cancer pathology reports, and we show that incorporating case-level context significantly boosts classification accuracy across six classification tasks-site, subsite, laterality, histology, behavior, and grade. We expect that with minimal modifications, our add-on can be applied towards a wide range of other clinical text-based tasks.",,,,,,,,,1,0,0,0,1,0,1,,,1932-6203,,,WOS:000537475000020,32396579,
J,"Bejan, Cosmin A.; Angiolillo, John; Conway, Douglas; Nash, Robertson; Shirey-Rice, Jana K.; Lipworth, Loren; Cronin, Robert M.; Pulley, Jill; Kripalani, Sunil; Barkin, Shari; Johnson, Kevin B.; Denny, Joshua C.",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332",,,Mining 100 million notes to find homelessness and adverse childhood experiences: 2 case studies of rare and severe social determinants of health in electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,1,,,61,71,,10.1093/jamia/ocx059,,,,JAN 2018,2018,"Understanding how to identify the social determinants of health from electronic health records (EHRs) could provide important insights to understand health or disease outcomes. We developed a methodology to capture 2 rare and severe social determinants of health, homelessness and adverse childhood experiences (ACEs), from a large EHR repository.We first constructed lexicons to capture homelessness and ACE phenotypic profiles. We employed word2vec and lexical associations to mine homelessness-related words. Next, using relevance feedback, we refined the 2 profiles with iterative searches over 100 million notes from the Vanderbilt EHR. Seven assessors manually reviewed the top-ranked results of 2544 patient visits relevant for homelessness and 1000 patients relevant for ACE.word2vec yielded better performance (area under the precision-recall curve [AUPRC] of 0.94) than lexical associations (AUPRC = 0.83) for extracting homelessness-related words. A comparative study of searches for the 2 phenotypes revealed a higher performance achieved for homelessness (AUPRC = 0.95) than ACE (AUPRC = 0.79). A temporal analysis of the homeless population showed that the majority experienced chronic homelessness. Most ACE patients suffered sexual (70%) and/or physical (50.6%) abuse, with the top-ranked abuser keywords being father (21.8%) and mother (15.4%). Top prevalent associated conditions for homeless patients were lack of housing (62.8%) and tobacco use disorder (61.5%), while for ACE patients it was mental disorders (36.6%-47.6%).We provide an efficient solution for mining homelessness and ACE information from EHRs, which can facilitate large clinical and genetic studies of these social determinants of health.",,,,,,,,,30,0,0,0,7,0,30,,,1067-5027,1527-974X,,WOS:000419605800011,29016793,
J,"Levine, Matthew E.; Albers, David J.; Hripcsak, George",,,,,"Levine, Matthew/0000-0002-5627-3169",,,Methodological variations in lagged regression for detecting physiologic drug effects in EHR data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,86,,,,149,159,,10.1016/j.jbi.2018.08.014,,,,OCT 2018,2018,"We studied how lagged linear regression can be used to detect the physiologic effects of drugs from data in the electronic health record (EHR). We systematically examined the effect of methodological variations ((i) time series construction, (ii) temporal parameterization, (iii) intra-subject normalization, (iv) differencing (lagged rates of change achieved by taking differences between consecutive measurements), (v) explanatory variables, and (vi) regression models) on performance of lagged linear methods in this context. We generated two gold standards (one knowledge-base derived, one expert-curated) for expected pairwise relationships between 7 drugs and 4 labs, and evaluated how the 64 unique combinations of methodological perturbations reproduce the gold standards. Our 28 cohorts included patients in the Columbia University Medical Center/NewYork-Presbyterian Hospital clinical database, and ranged from 2820 to 79,514 patients with between 8 and 209 average time points per patient. The most accurate methods achieved AUROC of 0.794 for knowledge-base derived gold standard (95%CI (0.741, 0.847]) and 0.705 for expert-curated gold standard (95% CI [0.629, 0.781]). We observed a mean AUROC of 0.633 (95%CI [0.610, 0.657], expert-curated gold standard) across all methods that re-parameterize time according to sequence and use either a joint autoregressive model with time-series differencing or an independent lag model without differencing. The complement of this set of methods achieved a mean AUROC close to 0.5, indicating the importance of these choices. We conclude that time series analysis of EHR data will likely rely on some of the beneficial pre-processing and modeling methodologies identified, and will certainly benefit from continued careful analysis of methodological perturbations. This study found that methodological variations, such as pre-processing and representations, have a large effect on results, exposing the importance of thoroughly evaluating these components when comparing machine-learning methods.",,,,,,,,,5,0,0,0,3,0,5,,,1532-0464,1532-0480,,WOS:000460600800015,30172760,
J,"Harris, Daniel R; Henderson, Darren W; Corbeau, Alexandria",,,,,,,,Improving the Utility of Tobacco-Related Problem List Entries Using Natural Language Processing.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,534,543,,,,,,2020,2020,"We present findings on using natural language processing to classify tobacco-related entries from problem lists found within patient's electronic health records. Problem lists describe health-related issues recorded during a patient's medical visit; these problems are typically followed up upon during subsequent visits and are updated for relevance or accuracy. The mechanics of problem lists vary across different electronic health record systems. In general, they either manifest as pre-generated generic problems that may be selected from a master list or as text boxes where a healthcare professional may enter free text describing the problem. Using commonly-available natural language processing tools, we classified tobacco-related problems into three classes: active-user, former-user, and non-user; we further demonstrate that rule-based post-processing may significantly increase precision in identifying these classes (+32%, +22%, +35% respectively). We used these classes to generate tobacco time-spans that reconstruct a patient's tobacco-use history and better support secondary data analysis. We bundle this as an open-source toolkit with flow visualizations indicating how patient tobacco-related behavior changes longitudinally, which can also capture and visualize contradicting information such as smokers being flagged as having never smoked.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936427,33936427,
J,"Payrovnaziri, Seyedeh Neelufar; Chen, Zhaoyi; Rengifo-Moreno, Pablo; Miller, Tim; Bian, Jiang; Chen, Jonathan H.; Liu, Xiuwen; He, Zhe",,,,"He, Zhe/J-2336-2014","He, Zhe/0000-0003-3608-0244; Chen, Jonathan H./0000-0002-4387-8740",,,Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,7,,,1173,1185,,10.1093/jamia/ocaa053,,,,JUL 2020,2020,"Objective: To conduct a systematic scoping review of explainable artificial intelligence (XAI) models that use real-world electronic health record data, categorize these techniques according to different biomedical applications, identify gaps of current studies, and suggest future research directions.Materials and Methods: We searched MEDLINE, IEEE Xplore, and the Association for Computing Machinery (ACM) Digital Library to identify relevant papers published between January 1, 2009 and May 1, 2019. We summarized these studies based on the year of publication, prediction tasks, machine learning algorithm, dataset(s) used to build the models, the scope, category, and evaluation of the XAI methods. We further assessed the reproducibility of the studies in terms of the availability of data and code and discussed open issues and challenges.Results: Forty-two articles were included in this review. We reported the research trend and most-studied diseases. We grouped XAI methods into 5 categories: knowledge distillation and rule extraction (N=13), intrinsically interpretable models (N=9), data dimensionality reduction (N=8), attention mechanism (N=7), and feature interaction and importance (N=5).Discussion: XAI evaluation is an open issue that requires a deeper focus in the case of medical applications. We also discuss the importance of reproducibility of research work in this field, as well as the challenges and opportunities of XAI from 2 medical professionals' point of view.Conclusion: Based on our review, we found that XAI evaluation in medicine has not been adequately and formally practiced. Reproducibility remains a critical concern. Ample opportunities exist to advance XAI research in medicine.",,,,,,,,,35,1,0,0,5,0,36,,,1067-5027,1527-974X,,WOS:000612220200026,32417928,
J,"Pacheco, Jennifer A.; Rasmussen, Luke V.; Kiefer, Richard C.; Campion, Thomas R.; Speltz, Peter; Carroll, Robert J.; Stallings, Sarah C.; Mo, Huan; Ahuja, Monika; Jiang, Guoqian; LaRose, Eric R.; Peissig, Peggy L.; Shang, Ning; Benoit, Barbara; Gainer, Vivian S.; Borthwick, Kenneth; Jackson, Kathryn L.; Sharma, Ambrish; Wu, Andy Yizhou; Kho, Abel N.; Roden, Dan M.; Pathak, Jyotishman; Denny, Joshua C.; Thompson, William K.",,,,"Roden, Dan/ABD-5412-2021; Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Pacheco, Jennifer/0000-0001-8021-5818; Shang, Ning/0000-0001-7040-5204; Rasmussen, Luke/0000-0002-4497-8049; Mo, Huan/0000-0001-6029-458X",,,A case study evaluating the portability of an executable computable phenotype algorithm across multiple institutions and electronic health record environments,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,11,,,1540,1546,,10.1093/jamia/ocy101,,,,NOV 2018,2018,"Electronic health record (EHR) algorithms for defining patient cohorts are commonly shared as free-text descriptions that require human intervention both to interpret and implement. We developed the Phenotype Execution and Modeling Architecture (PhEMA, http://projectphema.org) to author and execute standardized computable phenotype algorithms. With PhEMA, we converted an algorithm for benign prostatic hyperplasia, developed for the electronic Medical Records and Genomics network (eMERGE), into a standards-based computable format. Eight sites (7 within eMERGE) received the computable algorithm, and 6 successfully executed it against local data warehouses and/or i2b2 instances. Blinded random chart review of cases selected by the computable algorithm shows PPV >= 90%, and 3 out of 5 sites had >90% overlap of selected cases when comparing the computable algorithm to their original eMERGE implementation. This case study demonstrates potential use of PhEMA computable representations to automate phenotyping across different EHR systems, but also highlights some ongoing challenges.",,,,,,,,,12,0,0,0,6,0,12,,,1067-5027,1527-974X,,WOS:000450392500014,30124903,
J,"Guan, Meijian; Cho, Samuel; Petro, Robin; Zhang, Wei; Pasche, Boris; Topaloglu, Umit",,,,,,,,Natural language processing and recurrent network models for identifying genomic mutation-associated cancer treatment change from patient progress notes,,,,,,,,JAMIA OPEN,,,,2,1,,,139,149,,10.1093/jamiaopen/ooy061,,,,APR 2019,2019,"Objectives: Natural language processing (NLP) and machine learning approaches were used to build classifiers to identify genomic-related treatment changes in the free-text visit progress notes of cancer patients.Methods: We obtained 5889 deidentified progress reports (2439 words on average) for 755 cancer patients who have undergone a clinical next generation sequencing (NGS) testing in Wake Forest Baptist Comprehensive Cancer Center for our data analyses. An NLP system was implemented to process the free-text data and extract NGS-related information. Three types of recurrent neural network (RNN) namely, gated recurrent unit, long short-term memory (LSTM), and bidirectional LSTM (LSTM_Bi) were applied to classify documents to the treatment-change and no-treatment-change groups. Further, we compared the performances of RNNs to 5 machine learning algorithms including Naive Bayes, K-nearest Neighbor, Support Vector Machine for classification, Random forest, and Logistic Regression.Results: Our results suggested that, overall, RNNs outperformed traditional machine learning algorithms, and LSTM_Bi showed the best performance among the RNNs in terms of accuracy, precision, recall, and F1 score. In addition, pre-trained word embedding can improve the accuracy of LSTM by 3.4% and reduce the training time by more than 60%.Discussion and Conclusion: NLP and RNN-based text mining solutions have demonstrated advantages in information retrieval and document classification tasks for unstructured clinical progress notes.",,,,,,,,,9,0,0,0,1,0,9,,,,2574-2531,,WOS:000645417700019,30944913,
J,"Afshar, Majid; Dligach, Dmitriy; Sharma, Brihat; Cai, Xiaoyuan; Boyda, Jason; Birch, Steven; Valdez, Daniel; Zelisko, Suzan; Joyce, Cara; Modave, Francois; Price, Ron",,,,,"Afshar, Majid/0000-0002-6368-4652",,,Development and application of a high throughput natural language processing architecture to convert all clinical documents in a clinical data warehouse into standardized medical vocabularies,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1364,1369,,10.1093/jamia/ocz068,,,,NOV 2019,2019,"Objective: Natural language processing (NLP) engines such as the clinical Text Analysis and Knowledge Extraction System are a solution for processing notes for research, but optimizing their performance for a clinical data warehouse remains a challenge. We aim to develop a high throughput NLP architecture using the clinical Text Analysis and Knowledge Extraction System and present a predictive model use case.Materials and Methods: The CDW was comprised of 1 103 038 patients across 10 years. The architecture was constructed using the Hadoop data repository for source data and 3 large-scale symmetric processing servers for NLP. Each named entity mention in a clinical document was mapped to the Unified Medical Language System concept unique identifier (CUI).Results: The NLP architecture processed 83 867 802 clinical documents in 13.33 days and produced 37 721 886 606 CUIs across 8 standardized medical vocabularies. Performance of the architecture exceeded 500 000 documents per hour across 30 parallel instances of the clinical Text Analysis and Knowledge Extraction System including 10 instances dedicated to documents greater than 20 000 bytes. In a use-case example for predicting 30-day hospital readmission, a CUI-based model had similar discrimination to n-grams with an area under the curve receiver operating characteristic of 0.75 (95% CI, 0.74-0.76).Discussion and Conclusion: Our health system's high throughput NLP architecture may serve as a benchmark for large-scale clinical research using a CUI-based approach.",,,,,,,,,8,0,0,0,3,0,8,,,1067-5027,1527-974X,,WOS:000498169400026,31145455,
J,"Uzuner, Ozlem; Stubbs, Amber; Lenert, Leslie",,,,,,,,Advancing the state of the art in automatic extraction of adverse drug events from narratives,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,1,2,,10.1093/jamia/ocz206,,,,JAN 2020,2020,,,,,,,,,,5,0,0,0,0,0,5,,,1067-5027,1527-974X,,WOS:000548300200001,31841150,
J,"Fitzgerald, Oisin; Perez-Concha, Oscar; Gallego, Blanca; Saxena, Manoj K.; Rudd, Lachlan; Metke-Jimenez, Alejandro; Jorm, Louisa",,,,,"Saxena, Manoj/0000-0002-0385-6731",,,Incorporating real-world evidence into the development of patient blood glucose prediction algorithms for the ICU,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,8,,,1642,1650,,10.1093/jamia/ocab060,,APR 2021,,AUG 2021,2021,"Objective: Glycemic control is an important component of critical care. We present a data-driven method for predicting intensive care unit (ICU) patient response to glycemic control protocols while accounting for patient heterogeneity and variations in care.Materials and Methods: Using electronic medical records (EMRs) of 18 961 ICU admissions from the MIMIC-III dataset, including 318 574 blood glucose measurements, we train and validate a gradient boosted tree machine learning (ML) algorithm to forecast patient blood glucose and a 95% prediction interval at 2-hour intervals. The model uses as inputs irregular multivariate time series data relating to recent in-patient medical history and glycemic control, including previous blood glucose, nutrition, and insulin dosing.Results: Our forecasting model using routinely collected EMRs achieves performance comparable to previous models developed in planned research studies using continuous blood glucose monitoring. Model error, expressed as mean absolute percentage error is 16.5%-16.8%, with Clarke error grid analysis demonstrating that 97% of predictions would be clinically acceptable. The 95% prediction intervals achieve near intended coverage at 93%-94%.Discussion: ML algorithms built on observational data sources, such as EMRs, present a promising approach for personalization and automation of glycemic control in critical care. Future research may benefit from applying a combination of methodologies and data sources to develop robust methodologies that account for the variations seen in ICU patients and difficultly in detecting the extremes of observed blood glucose values.Conclusion: We demonstrate that EMRs can be used to train ML algorithms that may be suitable for incorporation into ICU decision support systems.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000733838500005,33871017,
J,"Wang, Jason K.; Hom, Jason; Balasubramanian, Santhosh; Schuler, Alejandro; Shah, Nigam H.; Goldstein, Mary K.; Baiocchi, Michael T. M.; Chen, Jonathan H.",,,,,"Wang, Jason/0000-0002-5559-4323; Chen, Jonathan H./0000-0002-4387-8740",,,An evaluation of clinical order patterns machine-learned from clinician cohorts stratified by patient mortality outcomes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,86,,,,109,119,,10.1016/j.jbi.2018.09.005,,,,OCT 2018,2018,"Objective: Evaluate the quality of clinical order practice patterns machine-learned from clinician cohorts stratified by patient mortality outcomes.Materials and methods: Inpatient electronic health records from 2010 to 2013 were extracted from a tertiary academic hospital. Clinicians (n = 1822) were stratified into low-mortality (21.8%, n = 397) and high-mortality (6.0%, n = 110) extremes using a two-sided P-value score quantifying deviation of observed vs. expected 30-day patient mortality rates. Three patient cohorts were assembled: patients seen by low-mortality clinicians, high-mortality clinicians, and an unfiltered crowd of all clinicians (n = 1046, 1046, and 5230 post-propensity score matching, respectively). Predicted order lists were automatically generated from recommender system algorithms trained on each patient cohort and evaluated against (i) real-world practice patterns reflected in patient cases with better-than-expected mortality outcomes and (ii) reference standards derived from clinical practice guidelines.Results: Across six common admission diagnoses, order lists learned from the crowd demonstrated the greatest alignment with guideline references (AUROC range = 0.86-0.91), performing on par or better than those learned from low-mortality clinicians (0.79-0.84, P < 10(-5)) or manually-authored hospital order sets (0.65-0.77, P < 10(-3)). The same trend was observed in evaluating model predictions against better-than-expected patient cases, with the crowd model (AUROC mean = 0.91) outperforming the low-mortality model (0.87, P < 10(-16)) and order set benchmarks (0.78, P < 10(-35)).Discussion: Whether machine-learning models are trained on all clinicians or a subset of experts illustrates a bias variance tradeoff in data usage. Defining robust metrics to assess quality based on internal (e.g. practice patterns from better-than-expected patient cases) or external reference standards (e.g. clinical practice guidelines) is critical to assess decision support content.Conclusion: Learning relevant decision support content from all clinicians is as, if not more, robust than learning from a select subgroup of clinicians favored by patient outcomes.",,,,,,,,,8,1,0,0,2,0,9,,,1532-0464,1532-0480,,WOS:000460600800011,30195660,
J,"Soto, Xabier; Perez-de-Vinaspre, Olatz; Labaka, Gorka; Oronoz, Maite",,,,"; Labaka, Gorka/G-8236-2011","ORONOZ ANCHORDOQUI, MAITE/0000-0001-9097-6047; Perez de Vinaspre, Olatz/0000-0002-0933-2461; Soto, Xabier/0000-0002-3622-6496; Labaka, Gorka/0000-0003-4611-2502",,,Neural machine translation of clinical texts between long distance languages,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1478,1487,,10.1093/jamia/ocz110,,,,DEC 2019,2019,"Objective: To analyze techniques for machine translation of electronic health records (EHRs) between long distance languages, using Basque and Spanish as a reference. We studied distinct configurations of neural machine translation systems and used different methods to overcome the lack of a bilingual corpus of clinical texts or health records in Basque and Spanish.Materials and Methods: We trained recurrent neural networks on an out-of-domain corpus with different hyperparameter values. Subsequently, we used the optimal configuration to evaluate machine translation of EHR templates between Basque and Spanish, using manual translations of the Basque templates into Spanish as a standard. We successively added to the training corpus clinical resources, including a Spanish-Basque dictionary derived from resources built for the machine translation of the Spanish edition of SNOMED CT into Basque, artificial sentences in Spanish and Basque derived from frequently occurring relationships in SNOMED CT, and Spanish monolingual EHRs. Apart from calculating bilingual evaluation understudy (BLEU) values, we tested the performance in the clinical domain by human evaluation.Results: We achieved slight improvements from our reference system by tuning some hyperparameters using an out-of-domain bilingual corpus, obtaining 10.67 BLEU points for Basque-to-Spanish clinical domain translation. The inclusion of clinical terminology in Spanish and Basque and the application of the back-translation technique on monolingual EHRs significantly improved the performance, obtaining 21.59 BLEU points. This was confirmed by the human evaluation performed by 2 clinicians, ranking our machine translations close to the human translations.Discussion: We showed that, even after optimizing the hyperparameters out-of-domain, the inclusion of available resources from the clinical domain and applied methods were beneficial for the described objective, managing to obtain adequate translations of EHR templates.Conclusion: We have developed a system which is able to properly translate health record templates from Basque to Spanish without making use of any bilingual corpus of clinical texts or health records.",,,,,,,,,4,0,0,0,0,0,4,,,1067-5027,1527-974X,,WOS:000515125300007,31334764,
J,"Gandin, Ilaria; Scagnetto, Arjuna; Romani, Simona; Barbati, Giulia",,,,"Barbati, Giulia/N-8418-2014; Gandin, Ilaria/B-2634-2017","Barbati, Giulia/0000-0001-8942-5686; Gandin, Ilaria/0000-0003-3196-2491",,,Interpretability of time-series deep learning models: A study in cardiovascular patients admitted to Intensive care unit,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,121,,,,,,103876,10.1016/j.jbi.2021.103876,,AUG 2021,,SEP 2021,2021,"Interpretability is fundamental in healthcare problems and the lack of it in deep learning models is currently the major barrier in the usage of such powerful algorithms in the field. The study describes the implementation of an attention layer for Long Short-Term Memory (LSTM) neural network that provides a useful picture on the influence of the several input variables included in the model. A cohort of 10,616 patients with cardiovascular diseases is selected from the MIMIC III dataset, an openly available database of electronic health records (EHRs) including all patients admitted to an ICU at Boston's Medical Centre. For each patient, we consider a 10-length sequence of 1-hour windows in which 48 clinical parameters are extracted to predict the occurrence of death in the next 7 days. Inspired from the recent developments in the field of attention mechanisms for sequential data, we implement a recurrent neural network with LSTM cells incorporating an attention mechanism to identify features driving model's decisions over time. The performance of the LSTM model, measured in terms of AUC, is 0.790 (SD = 0.015). Regard our primary objective, i.e. model interpretability, we investigate the role of attention weights. We find good correspondence with driving predictors of a transparent model (r = 0.611, 95% CI [0.395, 0.763]). Moreover, most influential features identified at the cohort-level emerge as known risk factors in the clinical context. Despite the limitations of study dataset, this work brings further evidence of the potential of attention mechanisms in making deep learning model more interpretable and suggests the application of this strategy for the sequential analysis of EHRs.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000694715700003,34325021,
J,"Szymonifka, Jackie; Conderino, Sarah; Cigolle, Christine; Ha, Jinkyung; Kabeto, Mohammed; Yu, Jaehong; Dodson, John A.; Thorpe, Lorna; Blaum, Caroline; Zhong, Judy",,,,,,,,Cardiovascular disease risk prediction for people with type 2 diabetes in a population-based cohort and in electronic health record data,,,,,,,,JAMIA OPEN,,,,3,4,,,583,592,,10.1093/jamiaopen/ooaa059,,,,DEC 2020,2020,"Objective: Electronic health records (EHRs) have become a common data source for clinical risk prediction, offering large sample sizes and frequently sampled metrics. There may be notable differences between hospital-based EHR and traditional cohort samples: EHR data often are not population-representative random samples, even for particular diseases, as they tend to be sicker with higher healthcare utilization, while cohort studies often sample healthier subjects who typically are more likely to participate. We investigate heterogeneities between EHR- and cohort-based inferences including incidence rates, risk factor identifications/quantifications, and absolute risks.Materials and methods: This is a retrospective cohort study of older patients with type 2 diabetes using EHR from New York University Langone Health ambulatory care (NYULH-EHR, years 2009-2017) and from the Health and Retirement Survey (HRS, 1995-2014) to study subsequent cardiovascular disease (CVD) risks. We used the same eligibility criteria, outcome definitions, and demographic covariates/biomarkers in both datasets. We compared subsequent CVD incidence rates, hazard ratios (HRs) of risk factors, and discrimination/calibration performances of CVD risk scores.Results: The estimated subsequent total CVD incidence rate was 37.5 and 90.6 per 1000 person-years since T2DM onset in HRS and NYULH-EHR respectively. HR estimates were comparable between the datasets for most demographic covariates/biomarkers. Common CVD risk scores underestimated observed total CVD risks in NYULH-EHR.Discussion and conclusion: EHR-estimated HRs of demographic and major clinical risk factors for CVD were mostly consistent with the estimates from a national cohort, despite high incidences and absolute risks of total CVD outcome in the EHR samples.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000645440800016,33623893,
J,"Duong, Son Q.; Zheng, Le; Xia, Minjie; Jin, Bo; Liu, Modi; Li, Zhen; Hao, Shiying; Alfreds, Shaun T.; Sylvester, Karl G.; Widen, Eric; Teuteberg, Jeffery J.; McElhinney, Doff B.; Ling, Xuefeng B.",,,,,"Hao, Shiying/0000-0002-7527-2460; Alfreds, Shaun T./0000-0003-1752-4823",,,Identification of patients at risk of new onset heart failure: Utilizing a large statewide health information exchange to train and validate a risk prediction model,,,,,,,,PLOS ONE,,,,16,12,,,,,e0260885,10.1371/journal.pone.0260885,,,,DEC 10 2021,2021,"Background New-onset heart failure (HF) is associated with poor prognosis and high healthcare utilization. Early identification of patients at increased risk incident-HF may allow for focused allocation of preventative care resources. Health information exchange (HIE) data span the entire spectrum of clinical care, but there are no HIE-based clinical decision support tools for diagnosis of incident-HF. We applied machine-learning methods to model the one-year risk of incident-HF from the Maine statewide-HIE.Methods and results We included subjects aged >= 40 years without prior HF ICD9/10 codes during a three-year period from 2015 to 2018, and incident-HF defined as assignment of two outpatient or one inpatient code in a year. A tree-boosting algorithm was used to model the probability of incident-HF in year two from data collected in year one, and then validated in year three. 5,668 of 521,347 patients (1.09%) developed incident-HF in the validation cohort. In the validation cohort, the model c-statistic was 0.824 and at a clinically predetermined risk threshold, 10% of patients identified by the model developed incident-HF and 29% of all incident-HF cases in the state of Maine were identified.Conclusions Utilizing machine learning modeling techniques on passively collected clinical HIE data, we developed and validated an incident-HF prediction tool that performs on par with other models that require proactively collected clinical data. Our algorithm could be integrated into other HIEs to leverage the EMR resources to provide individuals, systems, and payors with a risk stratification tool to allow for targeted resource allocation to reduce incident-HF disease burden on individuals and health care systems.",,,,,,,,,0,0,1,0,0,0,1,,,1932-6203,,,WOS:000747293600021,34890438,
J,"Chen, Jimmy; Goldstein, Isaac H; Lin, Wei-Chun; Chiang, Michael F; Hribar, Michelle R",,,,,,,,Application of Machine Learning to Predict Patient No-Shows in an Academic Pediatric Ophthalmology Clinic.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,293,302,,,,,,2020,2020,"Patient no-shows are missed appointments resulting in clinical inefficiencies, revenue loss, and discontinuity of care. Using secondary electronic health record (EHR) data, we used machine learning to predict patient no-shows in follow-up and new patient visits in pediatric ophthalmology and to evaluate features for importance. The best model, XGBoost, had an area under the receiver operating characteristics curve (AUC) score of 0.90 for predicting no-shows in follow-up visits. The key findings from this study are: (1) secondary use of EHR data can be used to build datasets for predictive modeling and successfully predict patient no-shows in pediatric ophthalmology, (2) models predicting no-shows for follow-up visits are more accurate than those for new patient visits, and (3) the performance of predictive models is more robust in predicting no-shows compared to individual important features. We hope these models will be used for more effective interventions to mitigate the impact ofpatient no-shows.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936401,33936401,
J,"Vydiswaran, V. G. Vinod; Strayhorn, Asher; Zhao, Xinyan; Robinson, Phil; Agarwal, Mahesh; Bagazinski, Erin; Essiet, Madia; Iott, Bradley E.; Joo, Hyeon; Ko, PingJui; Lee, Dahee; Lu, Jin Xiu; Liu, Jinghui; Murali, Adharsh; Sasagawa, Koki; Wang, Tianshi; Yuan, Nalingna",,,,,"Joo, Hyeon/0000-0003-4844-2417",,,Hybrid bag of approaches to characterize selection criteria for cohort identification,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1172,1180,,10.1093/jamia/ocz079,,,,NOV 2019,2019,"Objective: The 2018 National NLP Clinical Challenge (2018 n2c2) focused on the task of cohort selection for clinical trials, where participating systems were tasked with analyzing longitudinal patient records to determine if the patients met or did not meet any of the 13 selection criteria. This article describes our participation in this shared task.Materials and Methods: We followed a hybrid approach combining pattern-based, knowledge-intensive, and feature weighting techniques. After preprocessing the notes using publicly available natural language processing tools, we developed individual criterion-specific components that relied on collecting knowledge resources relevant for these criteria and pattern-based and weighting approaches to identify met and not met cases.Results: As part of the 2018 n2c2 challenge, 3 runs were submitted. The overall micro-averaged F1 on the training set was 0.9444. On the test set, the micro-averaged F1 for the 3 submitted runs were 0.9075, 0.9065, and 0.9056. The best run was placed second in the overall challenge and all 3 runs were statistically similar to the top-ranked system. A reimplemented system achieved the best overall F1 of 0.9111 on the test set.Discussion: We highlight the need for a focused resource-intensive effort to address the class imbalance in the cohort selection identification task.Conclusion: Our hybrid approach was able to identify all selection criteria with high F1 performance on both training and test sets. Based on our participation in the 2018 n2c2 task, we conclude that there is merit in continuing a focused criterion-specific analysis and developing appropriate knowledge resources to build a quality cohort selection system.",,,,,,,,,8,0,0,0,1,0,8,,,1067-5027,1527-974X,,WOS:000498169400003,31197354,
J,"Lee, Junghwan; Liu, Cong; Kim, Jae Hyun; Butler, Alex; Shang, Ning; Pang, Chao; Natarajan, Karthik; Ryan, Patrick; Ta, Casey; Weng, Chunhua",,,,,"Lee, Junghwan/0000-0002-1240-7655; Shang, Ning/0000-0001-7040-5204",,,Comparative effectiveness of medical concept embedding for feature engineering in phenotyping,,,,,,,,JAMIA OPEN,,,,4,2,,,,,ooab028,10.1093/jamiaopen/ooab028,,JUN 2021,,APR 2021,2021,"Objective: Feature engineering is a major bottleneck in phenotyping. Properly learned medical concept embeddings (MCEs) capture the semantics of medical concepts, thus are useful for retrieving relevant medical features in phenotyping tasks. We compared the effectiveness of MCEs learned from knowledge graphs and electronic healthcare records (EHR) data in retrieving relevant medical features for phenotyping tasks.Materials and Methods: We implemented 5 embedding methods including node2vec, singular value decomposition (SVD), LINE, skip-gram, and GloVe with 2 data sources: (1) knowledge graphs obtained from the observational medical outcomes partnership (OMOP) common data model; and (2) patient-level data obtained from the OMOP compatible electronic health records (EHR) from Columbia University Irving Medical Center (CUIMC). We used phenotypes with their relevant concepts developed and validated by the electronic medical records and genomics (eMERGE) network to evaluate the performance of learned MCEs in retrieving phenotyperelevant concepts. Hits@k% in retrieving phenotype-relevant concepts based on a single and multiple seed concept(s) was used to evaluate MCEs.Results: Among all MCEs, MCEs learned by using node2vec with knowledge graphs showed the best performance. Of MCEs based on knowledge graphs and EHR data, MCEs learned by using node2vec with knowledge graphs and MCEs learned by using GloVe with EHR data outperforms other MCEs, respectively.Conclusion: MCE enables scalable feature engineering tasks, thereby facilitating phenotyping. Based on current phenotyping practices, MCEs learned by using knowledge graphs constructed by hierarchical relationships among medical concepts outperformed MCEs learned by using EHR data.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731861400008,34142015,
J,"Fohner, Alison E.; Greene, John D.; Lawson, Brian L.; Chen, Jonathan H.; Kipnis, Patricia; Escobar, Gabriel J.; Liu, Vincent X.",,,,,"Chen, Jonathan H./0000-0002-4387-8740; Fohner, Alison/0000-0003-4231-3331",,,Assessing clinical heterogeneity in sepsis through treatment patterns and machine learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1466,1477,,10.1093/jamia/ocz106,,,,DEC 2019,2019,"Objective: To use unsupervised topic modeling to evaluate heterogeneity in sepsis treatment patterns contained within granular data of electronic health records.Materials and Methods: A multicenter, retrospective cohort study of 29 253 hospitalized adult sepsis patients between 2010 and 2013 in Northern California. We applied an unsupervised machine learning method, Latent Dirichlet Allocation, to the orders, medications, and procedures recorded in the electronic health record within the first 24 hours of each patient's hospitalization to uncover empiric treatment topics across the cohort and to develop computable clinical signatures for each patient based on proportions of these topics. We evaluated how these topics correlated with common sepsis treatment and outcome metrics including inpatient mortality, time to first antibiotic, and fluids given within 24 hours.Results: Mean age was 70 +/- 17 years with hospital mortality of 9.6%. We empirically identified 42 clinically recognizable treatment topics (eg, pneumonia, cellulitis, wound care, shock). Only 43.1% of hospitalizations had a single dominant topic, and a small minority (7.3%) had a single topic comprising at least 80% of their overall clinical signature. Across the entire sepsis cohort, clinical signatures were highly variable.Discussion: Heterogeneity in sepsis is a major barrier to improving targeted treatments, yet existing approaches to characterizing clinical heterogeneity are narrowly defined. A machine learning approach captured substantial patient- and population-level heterogeneity in treatment during early sepsis hospitalization.Conclusion: Using topic modeling based on treatment patterns may enable more precise clinical characterization in sepsis and better understanding of variability in sepsis presentation and outcomes.",,,,,,,,,16,0,0,0,7,0,16,,,1067-5027,1527-974X,,WOS:000515125300006,31314892,
J,"Almagro, Mario; Martinez, Raquel; Montalvo, Soto; Fresno, Victor",,,,"Montalvo, Soto/AAA-4546-2019","Montalvo, Soto/0000-0001-8158-7939; Almagro, Mario/0000-0003-4339-2959",,,A cross-lingual approach to automatic ICD-10 coding of death certificates by exploring machine translation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,94,,,,,,103207,10.1016/j.jbi.2019.103207,,,,JUN 2019,2019,"Automatic ICD-10 coding is an unresolved challenge in terms of Machine Learning tasks. Despite hospitals generating an enormous amount of clinical documents, data is considerably sparse, associated with a very skewed and unbalanced code distribution, what entails reduced interoperability. In addition, in some languages the availability of coded documents is very limited. This paper proposes a cross-lingual approach based on Machine Translation methods to code death certificates with ICD-10 using supervised learning. The aim of this approach is to increase the availability of coded documents by combining collections of different languages, which may also contribute to reduce their possible bias in the ICD distribution, i.e. to avoid the promotion of a subset of codes due to service or environmental factors. A significant improvement in system performance is achieved for those labels with few occurrences.",,,,,,,,,6,0,0,0,1,0,6,,,1532-0464,1532-0480,,WOS:000525692600002,31077817,
J,"Yu, Ying; Li, Min; Liu, Liangliang; Fei, Zhihui; Wu, Fang-Xiang; Wang, Jianxin",,,,,"Wu, Fang-Xiang/0000-0002-4593-9332",,,Automatic ICD code assignment of Chinese clinical notes based on multilayer attention BiRNN,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,91,,,,,,103114,10.1016/j.jbi.2019.103114,,,,MAR 2019,2019,"International Classification of Diseases (ICD) code is an important label of electronic health record. The automatic ICD code assignment based on the narrative of clinical documents is an essential task which has drawn much attention recently. When Chinese clinical notes are the input corpus, the nature of Chinese brings some issues that need to be considered, such as the accuracy of word segmentation and the representation of single Chinese characters which contain semantics. Taking the lengthy text of patient notes and the representation of Chinese words into account, we present a multilayer attention bidirectional recurrent neural network (MA-BiRNN) model to implement the assignment of disease codes. A hierarchical approach is used to represent the feature of discharge summaries without manual feature engineering. The combination of character level embedding and word level embedding can improve the representation of words. Attention mechanism is introduced into bidirectional long short term memory networks, which helps to solve the performance dropping problem when plain recurrent neural networks encounter long text sequences. The experiment is carried out on a real-world dataset containing 7732 admission records in Chinese and 1177 unique ICD-10 labels. The proposed model achieves 0.639 and 0.766 in F1-score on full-level code and block-level code, respectively. It outperforms the baseline neural network models and achieves the lowest Hamming loss value. Ablation analysis indicates that the multilevel attention mechanism plays a decisive role in the system for dealing with Chinese clinical notes.",,,,,,,,,19,0,0,0,8,0,19,,,1532-0464,1532-0480,,WOS:000525688200004,30768971,
J,"Liu, Hao; Chi, Yuan; Butler, Alex; Sun, Yingcheng; Weng, Chunhua",,,,,"Sun, Yingcheng/0000-0002-8693-5768",,,A knowledge base of clinical trial eligibility criteria,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103771,10.1016/j.jbi.2021.103771,,APR 2021,,MAY 2021,2021,"Objective: We present the Clinical Trial Knowledge Base, a regularly updated knowledge base of discrete clinical trial eligibility criteria equipped with a web-based user interface for querying and aggregate analysis of common eligibility criteria.Materials and methods: We used a natural language processing (NLP) tool named Criteria2Query (Yuan et al., 2019) to transform free text clinical trial eligibility criteria from ClinicalTrials.gov into discrete criteria concepts and attributes encoded using the widely adopted Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) and stored in a relational SQL database. A web application accessible via RESTful APIs was implemented to enable queries and visual aggregate analyses. We demonstrate CTKB's potential role in EHR phenotype knowledge engineering using ten validated phenotyping algorithms.Results: At the time of writing, CTKB contained 87,504 distinctive OMOP CDM standard concepts, including Condition (47.82%), Drug (23.01%), Procedure (13.73%), Measurement (24.70%) and Observation (5.28%), with 34.78% for inclusion criteria and 65.22% for exclusion criteria, extracted from 352,110 clinical trials. The average hit rate of criteria concepts in eMERGE phenotype algorithms is 77.56%.Conclusion: CTKB is a novel comprehensive knowledge base of discrete eligibility criteria concepts with the potential to enable knowledge engineering for clinical trial cohort definition, clinical trial population representativeness assessment, electronical phenotyping, and data gap analyses for using electronic health records to support clinical trial recruitment.",,,,,,,,,2,0,0,0,1,0,2,,,1532-0464,1532-0480,,WOS:000651364200004,33813032,
J,"Lybarger, Kevin; Ostendorf, Mari; Thompson, Matthew; Yetisgen, Meliha",,,,,,,,Extracting COVID-19 diagnoses and symptoms from clinical text: A new annotated corpus and neural event extraction framework,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103761,10.1016/j.jbi.2021.103761,,APR 2021,,MAY 2021,2021,"Coronavirus disease 2019 (COVID-19) is a global pandemic. Although much has been learned about the novel coronavirus since its emergence, there are many open questions related to tracking its spread, describing symptomology, predicting the severity of infection, and forecasting healthcare utilization. Free-text clinical notes contain critical information for resolving these questions. Data-driven, automatic information extraction models are needed to use this text-encoded information in large-scale studies. This work presents a new clinical corpus, referred to as the COVID-19 Annotated Clinical Text (CACT) Corpus, which comprises 1,472 notes with detailed annotations characterizing COVID-19 diagnoses, testing, and clinical presentation. We introduce a span-based event extraction model that jointly extracts all annotated phenomena, achieving high performance in identifying COVID-19 and symptom events with associated assertion values (0.83-0.97 F1 for events and 0.73-0.79 F1 for assertions). Our span-based event extraction model outperforms an extractor built on MetaMapLite for the identification of symptoms with assertion values. In a secondary use application, we predicted COVID-19 test results using structured patient data (e.g. vital signs and laboratory results) and automatically extracted symptom information, to explore the clinical presentation of COVID-19. Automatically extracted symptoms improve COVID-19 prediction performance, beyond structured data alone.",,,,,,,,,3,0,0,0,2,0,3,,,1532-0464,1532-0480,,WOS:000663076900011,33781918,
J,"Gligorijevic, Jelena; Gligorijevic, Djordje; Pavlovski, Martin; Milkovits, Elizabeth; Glass, Lucas; Grier, Kevin; Vankireddy, Praveen; Obradovic, Zoran",,,,,"Obradovic, Zoran/0000-0002-2051-0142",,,Optimizing clinical trials recruitment via deep learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1195,1202,,10.1093/jamia/ocz064,,,,NOV 2019,2019,"Objective: Clinical trials, prospective research studies on human participants carried out by a distributed team of clinical investigators, play a crucial role in the development of new treatments in health care. This is a complex and expensive process where investigators aim to enroll volunteers with predetermined characteristics, administer treatment(s), and collect safety and efficacy data. Therefore, choosing top-enrolling investigators is essential for efficient clinical trial execution and is 1 of the primary drivers of drug development cost.Materials and Methods: To facilitate clinical trials optimization, we propose DeepMatch (DM), a novel approach that builds on top of advances in deep learning. DM is designed to learn from both investigator and trial-related heterogeneous data sources and rank investigators based on their expected enrollment performance on new clinical trials.Results: Large-scale evaluation conducted on 2618 studies provides evidence that the proposed ranking-based framework improves the current state-of-the-art by up to 19% on ranking investigators and up to 10% on detecting top/bottom performers when recruiting investigators for new clinical trials.Discussion: The extensive experimental section suggests that DM can provide substantial improvement over current industry standards in several regards: (1) the enrollment potential of the investigator list, (2) the time it takes to generate the list, and (3) data-informed decisions about new investigators.Conclusion: Due to the great significance of the problem at hand, related research efforts are set to shift the paradigm of how investigators are chosen for clinical trials, thereby optimizing and automating them and reducing the cost of new therapies.",,,,,,,,,4,0,0,0,2,0,4,,,1067-5027,1527-974X,,WOS:000498169400006,31188432,
J,"Redfield, Colby; Tlimat, Abdulhakim; Halpern, Yoni; Schoenfeld, David W.; Ullman, Edward; Sontag, David A.; Nathanson, Larry A.; Horng, Steven",,,,,"Horng, Steven/0000-0002-0958-1820",,,Derivation and validation of a machine learning record linkage algorithm between emergency medical services and the emergency department,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,147,153,,10.1093/jamia/ocz176,,,,JAN 2020,2020,"Objective: Linking emergency medical services (EMS) electronic patient care reports (ePCRs) to emergency department (ED) records can provide clinicians access to vital information that can alter management. It can also create rich databases for research and quality improvement. Unfortunately, previous attempts at ePCR and ED record linkage have had limited success. In this study, we use supervised machine learning to derive and validate an automated record linkage algorithm between EMS ePCRs and ED records.Materials and Methods: All consecutive ePCRs from a single EMS provider between June 2013 and June 2015 were included. A primary reviewer matched ePCRs to a list of ED patients to create a gold standard. Age, gender, last name, first name, social security number, and date of birth were extracted. Data were randomly split into 80% training and 20% test datasets. We derived missing indicators, identical indicators, edit distances, and percent differences. A multivariate logistic regression model was trained using 5-fold cross-validation, using label k-fold, L2 regularization, and class reweighting.Results: A total of 14 032 ePCRs were included in the study. Interrater reliability between the primary and secondary reviewer had a kappa of 0.9. The algorithm had a sensitivity of 99.4%, a positive predictive value of 99.9%, and an area under the receiver-operating characteristic curve of 0.99 in both the training and test datasets. Date-of-birth match had the highest odds ratio of 16.9, followed by last name match (10.6). Social security number match had an odds ratio of 3.8.Conclusions: We were able to successfully derive and validate a record linkage algorithm from a single EMS ePCR provider to our hospital EMR.",,,,,,,,,3,0,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000548300200018,31605488,
J,"Si, Yuqi; Roberts, Kirk",,,,,"Si, Yuqi/0000-0002-8123-8947",,,A Frame-Based NLP System for Cancer-Related Information Extraction.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1524,1533,,,,,,2018,2018,"We propose a frame-based natural language processing (NLP) method that extracts cancer-related information from clinical narratives. We focus on three frames: cancer diagnosis, cancer therapeutic procedure, and tumor description. We utilize a deep learning-based approach, bidirectional Long Short-term Memory (LSTM) Conditional Random Field (CRF), which uses both character and word embeddings. The system consists of two constituent sequence classifiers: a frame identification (lexical unit) classifier and a frame element classifier. The classifier achieves an F1 of 93.70 for cancer diagnosis, 96.33 for therapeutic procedure, and 87.18 for tumor description. These represent improvements of 10.72, 0.85, and 8.04 over a baseline heuristic, respectively. Additionally, we demonstrate that the combination of both GloVe and MIMIC-III embeddings has the best representational effect. Overall, this study demonstrates the effectiveness of deep learning methods to extract frame semantic information from clinical narratives.",,,,,,,,,12,0,0,0,0,0,12,,,,1942-597X,,MEDLINE:30815198,30815198,
J,"Afshar, Majid; Joyce, Cara; Dligach, Dmitriy; Sharma, Brihat; Kania, Robert; Xie, Meng; Swope, Kristin; Salisbury-Afshar, Elizabeth; Karnik, Niranjan S.",,,,"Afshar, Majid/AAD-8365-2019; Joyce, Cara/Z-2075-2018; Karnik, Niranjan/N-4103-2019; Salisbury-Afshar, Elizabeth M/AAK-4180-2020","Afshar, Majid/0000-0002-6368-4652; Joyce, Cara/0000-0003-0468-8271; Karnik, Niranjan/0000-0001-7650-3008; Salisbury-Afshar, Elizabeth/0000-0003-4096-6822; Sharma, Brihat/0000-0003-0417-4553",,,Subtypes in patients with opioid misuse: A prognostic enrichment strategy using electronic health record data in hospitalized patients,,,,,,,,PLOS ONE,,,,14,7,,,,,e0219717,10.1371/journal.pone.0219717,,,,JUL 16 2019,2019,"BackgroundApproaches are needed to better delineate the continuum of opioid misuse that occurs in hospitalized patients. A prognostic enrichment strategy with latent class analysis (LCA) may facilitate treatment strategies in subtypes of opioid misuse. We aim to identify subtypes of patients with opioid misuse and examine the distinctions between the subtypes by examining patient characteristics, topic models from clinical notes, and clinical outcomes.MethodsThis was an observational study of inpatient hospitalizations at a tertiary care center between 2007 and 2017. Patients with opioid misuse were identified using an operational definition applied to all inpatient encounters. LCA with eight class-defining variables from the electronic health record (EHR) was applied to identify subtypes in the cohort of patients with opioid misuse. Comparisons between subtypes were made using the following approaches: (1) descriptive statistics on patient characteristics and healthcare utilization using EHR data and census-level data; (2) topic models with natural language processing (NLP) from clinical notes; (3) association with hospital outcomes.FindingsThe analysis cohort was 6,224 (2.7% of all hospitalizations) patient encounters with opioid misuse with a data corpus of 422,147 clinical notes. LCA identified four subtypes with differing patient characteristics, topics from the clinical notes, and hospital outcomes. Class 1 was categorized by high hospital utilization with known opioid-related conditions (36.5%); Class 2 included patients with illicit use, low socioeconomic status, and psychoses (12.8%); Class 3 contained patients with alcohol use disorders with complications (39.2%); and class 4 consisted of those with low hospital utilization and incidental opioid misuse (11.5%). The following hospital outcomes were the highest for each subtype when compared against the other subtypes: readmission for class 1 (13.9% vs. 10.5%, p<0.01); discharge against medical advice for class 2 (12.3% vs. 5.3%, p<0.01); and in-hospital death for classes 3 and 4 (3.2% vs. 1.9%, p<0.01).ConclusionsA 4-class latent model was the most parsimonious model that defined clinically interpretable and relevant subtypes for opioid misuse. Distinct subtypes were delineated after examining multiple domains of EHR data and applying methods in artificial intelligence. The approach with LCA and readily available class-defining substance use variables from the EHR may be applied as a prognostic enrichment strategy for targeted interventions.",,,,,,,,,9,0,0,0,4,0,9,,,1932-6203,,,WOS:000484969300026,31310611,
J,"Seki, Tomohisa; Kawazoe, Yoshimasa; Ohe, Kazuhiko",,,,,"Seki, Tomohisa/0000-0002-4281-135X",,,"Machine learning-based prediction of in-hospital mortality using admission laboratory data: A retrospective, single-site study using electronic health record data",,,,,,,,PLOS ONE,,,,16,2,,,,,e0246640,10.1371/journal.pone.0246640,,,,FEB 5 2021,2021,"Risk assessment of in-hospital mortality of patients at the time of hospitalization is necessary for determining the scale of required medical resources for the patient depending on the patient's severity. Because recent machine learning application in the clinical area has been shown to enhance prediction ability, applying this technique to this issue can lead to an accurate prediction model for in-hospital mortality prediction. In this study, we aimed to generate an accurate prediction model of in-hospital mortality using machine learning techniques. Patients 18 years of age or older admitted to the University of Tokyo Hospital between January 1, 2009 and December 26, 2017 were used in this study. The data were divided into a training/validation data set (n = 119,160) and a test data set (n = 33,970) according to the time of admission. The prediction target of the model was the in-hospital mortality within 14 days. To generate the prediction model, 25 variables (age, sex, 21 laboratory test items, length of stay, and mortality) were used to predict in-hospital mortality. Logistic regression, random forests, multilayer perceptron, and gradient boost decision trees were performed to generate the prediction models. To evaluate the prediction capability of the model, the model was tested using a test data set. Mean probabilities obtained from trained models with five-fold cross-validation were used to calculate the area under the receiver operating characteristic (AUROC) curve. In a test stage using the test data set, prediction models of in-hospital mortality within 14 days showed AUROC values of 0.936, 0.942, 0.942, and 0.938 for logistic regression, random forests, multilayer perceptron, and gradient boosting decision trees, respectively. Machine learning-based prediction of short-term in-hospital mortality using admission laboratory data showed outstanding prediction capability and, therefore, has the potential to be useful for the risk assessment of patients at the time of hospitalization.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000617991900053,33544775,
J,"Cohen, Aaron M.; Chamberlin, Steven; Deloughery, Thomas; Nguyen, Michelle; Bedrick, Steven; Meninger, Stephen; Ko, John J.; Amin, Jigar J.; Wei, Alex H.; Hersh, William",,,,,,,,"Detecting rare diseases in electronic health records using machine learning and knowledge engineering: Case study of acute hepatic porphyria (vol 15, e0235574, 2020)",,,,,,,,PLOS ONE,,,,15,8,,,,,e0238277,10.1371/journal.pone.0238277,,,,AUG 20 2020,2020,,,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000564315600057,32817711,
J,"Caicedo-Torres, William; Gutierrez, Jairo",,,,,"Gutierrez, Jairo/0000-0002-2103-8636",,,ISeeU: Visually interpretable deep learning for mortality prediction inside the ICU,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103269,10.1016/j.jbi.2019.103269,,,,OCT 2019,2019,"To improve the performance of Intensive Care Units (ICUs), the field of bio-statistics has developed scores which try to predict the likelihood of negative outcomes. These help evaluate the effectiveness of treatments and clinical practice, and also help to identify patients with unexpected outcomes. However, they have been shown by several studies to offer sub-optimal performance. Alternatively, Deep Learning offers state of the art capabilities in certain prediction tasks and research suggests deep neural networks are able to outperform traditional techniques. Nevertheless, a main impediment for the adoption of Deep Learning in healthcare is its reduced interpretability, for in this field it is crucial to gain insight into the why of predictions, to assure that models are actually learning relevant features instead of spurious correlations. To address this, we propose a deep multiscale convolutional architecture trained on the Medical Information Mart for Intensive Care III (MIMIC-III) for mortality prediction, and the use of concepts from coalitional game theory to construct visual explanations aimed to show how important these inputs are deemed by the network. Results show our model attains a ROC AUC of 0.8735 (+/- 0.0025) which is competitive with the state of the art of Deep Learning mortality models trained on MIMIC-III data, while remaining interpretable. Supporting code can be found at https://github.com/williamcaicedo/ISeeU.",,,,,,,,,17,0,0,0,3,0,17,,,1532-0464,1532-0480,,WOS:000525699600009,31430550,
J,"Sholle, Evan T.; Davila, Marcos A.; Kabariti, Joseph; Schwartz, Julian Z.; Varughese, Vinay, I; Cole, Curtis L.; Campion, Thomas R., Jr.",,,,,"Sholle, Evan/0000-0001-9518-4399",,,A scalable method for supporting multiple patient cohort discovery projects using i2b2,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,84,,,,179,183,,10.1016/j.jbi.2018.07.010,,,,AUG 2018,2018,"Although i2b2, a popular platform for patient cohort discovery using electronic health record (EHR) data, can support multiple projects specific to individual disease areas or research interests, the standard approach for doing so duplicates data across projects, requiring additional disk space and processing time, which limits scalability. To address this deficiency, we developed a novel approach that stored data in a single i2b2 fact table and used structured query language (SQL) views to access data for specific projects. Compared to the standard approach, the view-based approach reduced required disk space by 59% and extract-transfer-load (ETL) time by 46%, without substantially impacting query performance. The view-based approach has enabled scalability of multiple i2b2 projects and generalized to another data model at our institution.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000445054800018,30009991,
J,"Roe, Kenneth D.; Jawa, Vibhu; Zhang, Xiaohan; Chute, Christopher G.; Epstein, Jeremy A.; Matelsky, Jordan; Shpitser, Ilya; Taylor, Casey Overby",,,,"Chute, Christopher/AAT-8540-2021","Roe, Kenneth/0000-0002-2619-8911; Chute, Christopher/0000-0001-5437-2545",,,Feature engineering with clinical expert knowledge: A case study assessment of machine learning model complexity and performance,,,,,,,,PLOS ONE,,,,15,4,,,,,e0231300,10.1371/journal.pone.0231300,,,,APR 23 2020,2020,"Incorporating expert knowledge at the time machine learning models are trained holds promise for producing models that are easier to interpret. The main objectives of this study were to use a feature engineering approach to incorporate clinical expert knowledge prior to applying machine learning techniques, and to assess the impact of the approach on model complexity and performance. Four machine learning models were trained to predict mortality with a severe asthma case study. Experiments to select fewer input features based on a discriminative score showed low to moderate precision for discovering clinically meaningful triplets, indicating that discriminative score alone cannot replace clinical input. When compared to baseline machine learning models, we found a decrease in model complexity with use of fewer features informed by discriminative score and filtering of laboratory features with clinical input. We also found a small difference in performance for the mortality prediction task when comparing baseline ML models to models that used filtered features. Encoding demographic and triplet information in ML models with filtered features appeared to show performance improvements from the baseline. These findings indicated that the use of filtered features may reduce model complexity, and with little impact on performance.",,,,,,,,,6,0,0,0,2,0,6,,,1932-6203,,,WOS:000536033700011,32324754,
J,"Corny, Jennifer; Rajkumar, Asok; Martin, Olivier; Dode, Xavier; Lajonchere, Jean-Patrick; Billuart, Olivier; Bezie, Yvonnick; Buronfosse, Anne",,,,,"Buronfosse, Anne/0000-0002-6593-8935; Corny, Jennifer/0000-0003-4303-6479",,,A machine learning-based clinical decision support system to identify prescriptions with a high risk of medication error,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,11,,,1688,1694,,10.1093/jamia/ocaa154,,,,NOV 2020,2020,"Objective: To improve patient safety and clinical outcomes by reducing the risk of prescribing errors, we tested the accuracy of a hybrid clinical decision support system in prioritizing prescription checks.Materials and Methods: Data from electronic health records were collated over a period of 18 months. Inferred scores at a patient level (probability of a patient's set of active orders to require a pharmacist review) were calculated using a hybrid approach (machine learning and a rule-based expert system). A clinical pharmacist analyzed randomly selected prescription orders over a 2-week period to corroborate our findings. Predicted scores were compared with the pharmacist's review using the area under the receiving-operating characteristic curve and area under the precision-recall curve. These metrics were compared with existing tools: computerized alerts generated by a clinical decision support (CDS) system and a literature-based multicriteria query prioritization technique. Data from 10 716 individual patients (133 179 prescription orders) were used to train the algorithm on the basis of 25 features in a development dataset.Results: While the pharmacist analyzed 412 individual patients (3364 prescription orders) in an independent validation dataset, the areas under the receiving-operating characteristic and precision-recall curves of our digital system were 0.81 and 0.75, respectively, thus demonstrating greater accuracy than the CDS system (0.65 and 0.56, respectively) and multicriteria query techniques (0.68 and 0.56, respectively).Discussion: Our innovative digital tool was notably more accurate than existing techniques (CDS system and multicriteria query) at intercepting potential prescription errors.Conclusions: By primarily targeting high-risk patients, this novel hybrid decision support system improved the accuracy and reliability of prescription checks in a hospital setting.",,,,,,,,,14,0,0,0,4,0,14,,,1067-5027,1527-974X,,WOS:000594986600007,32984901,
J,"Yang, Xi; Bian, Jiang; Fang, Ruogu; Bjarnadottir, Ragnhildur, I; Hogan, William R.; Wu, Yonghui",,,,"Fang, Ruogu/AAY-6687-2020; Fang, Ruogu/AAY-8923-2020","Fang, Ruogu/0000-0003-3980-3532; Fang, Ruogu/0000-0003-3980-3532",,,Identifying relations of medications with adverse drug events using recurrent convolutional neural networks and gradient boosting,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,65,72,,10.1093/jamia/ocz144,,,,JAN 2020,2020,"Objective: To develop a natural language processing system that identifies relations of medications with adverse drug events from clinical narratives. This project is part of the 2018 n2c2 challenge.Materials and Methods: We developed a novel clinical named entity recognition method based on an recurrent convolutional neural network and compared it to a recurrent neural network implemented using the long-short term memory architecture, explored methods to integrate medical knowledge as embedding layers in neural networks, and investigated 3 machine learning models, including support vector machines, random forests and gradient boosting for relation classification. The performance of our system was evaluated using annotated data and scripts provided by the 2018 n2c2 organizers.Results: Our system was among the top ranked. Our best model submitted during this challenge (based on recurrent neural networks and support vector machines) achieved lenient F1 scores of 0.9287 for concept extraction (ranked third), 0.9459 for relation classification (ranked fourth), and 0.8778 for the end-to-end relation extraction (ranked second). We developed a novel named entity recognition model based on a recurrent convolutional neural network and further investigated gradient boosting for relation classification. The new methods improved the lenient F1 scores of the 3 subtasks to 0.9292, 0.9633, and 0.8880, respectively, which are comparable to the best performance reported in this challenge.Conclusion: This study demonstrated the feasibility of using machine learning methods to extract the relations of medications with adverse drug events from clinical narratives.",,,,,,,,,10,0,0,0,2,0,10,,,1067-5027,1527-974X,,WOS:000548300200009,31504605,
J,"Erickson, Jennifer; Abbott, Kenneth; Susienka, Lucinda",,,,,"Abbott, Kenneth/0000-0003-0073-1906",,,Automatic address validation and health record review to identify homeless Social Security disability applicants,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,82,,,,41,46,,10.1016/j.jbi.2018.04.012,,,,JUN 2018,2018,"Objective: Homeless patients face a variety of obstacles in pursuit of basic social services. Acknowledging this, the Social Security Administration directs employees to prioritize homeless patients and handle their disability claims with special care. However, under existing manual processes for identification of homelessness, many homeless patients never receive the special service to which they are entitled. In this paper, we explore address validation and automatic annotation of electronic health records to improve identification of homeless patients.Materials and Methods: We developed a sample of claims containing medical records at the moment of arrival in a single office. Using address validation software, we reconciled patient addresses with public directories of homeless shelters, veterans' hospitals and clinics, and correctional facilities. Other tools annotated electronic health records. We trained random forests to identify homeless patients and validated each model with 10-fold cross validation.Results: For our finished model, the area under the receiver operating characteristic curve was 0.942. The random forest improved sensitivity from 0.067 to 0.879 but decreased positive predictive value to 0.382.Discussion: Presumed false positive classifications bore many characteristics of homelessness. Organizations could use these methods to prompt early collection of information necessary to avoid labor-intensive attempts to reestablish contact with homeless individuals. Annually, such methods could benefit tens of thousands of patients who are homeless, destitute, and in urgent need of assistance.Conclusion: We were able to identify many more homeless patients through a combination of automatic address validation and natural language processing of unstructured electronic health records.",,,,,,,,,6,0,0,0,2,0,6,,,1532-0464,1532-0480,,WOS:000445054600004,29705196,
J,"Li, Ruowang; Chen, Yong; Moore, Jason H.",,,,"Moore, Jason H./AAV-9645-2021","Moore, Jason H./0000-0002-5015-1099; Li, Ruowang/0000-0002-7910-4253",,,Integration of genetic and clinical information to improve imputation of data missing from electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,10,,,1056,1063,,10.1093/jamia/ocz041,,,,OCT 2019,2019,"Objective: Clinical data of patients' measurements and treatment history stored in electronic health record (EHR) systems are starting to be mined for better treatment options and disease associations. A primary challenge associated with utilizing EHR data is the considerable amount of missing data. Failure to address this issue can introduce significant bias in EHR-based research. Currently, imputation methods rely on correlations among the structured phenotype variables in the EHR. However, genetic studies have shown that many EHR-based phenotypes have a heritable component, suggesting that measured genetic variants might be useful for imputing missing data. In this article, we developed a computational model that incorporates patients' genetic information to perform EHR data imputation.Materials and Methods: We used the individual single nucleotide polymorphism's association with phenotype variables in the EHR as input to construct a genetic risk score that quantifies the genetic contribution to the phenotype. Multiple approaches to constructing the genetic risk score were evaluated for optimal performance. The genetic score, along with phenotype correlation, is then used as a predictor to impute the missing values.Results: To demonstrate the method performance, we applied our model to impute missing cardiovascular related measurements including low-density lipoprotein, heart failure, and aortic aneurysm disease in the electronic Medical Records and Genomics data. The integration method improved imputation's area-under-the-curve for binary phenotypes and decreased root-mean-square error for continuous phenotypes.Conclusion: Compared with standard imputation approaches, incorporating genetic information offers a novel approach that can utilize more of the EHR data for better performance in missing data imputation.",,,,,,,,,8,0,0,0,2,0,8,,,1067-5027,1527-974X,,WOS:000515123700020,31329892,
J,"Rasmy, Laila; Tiryaki, Firat; Zhou, Yujia; Xiang, Yang; Tao, Cui; Xu, Hua; Zhi, Degui",,,,,"Rasmy, Laila/0000-0002-2644-4908; Tao, Cui/0000-0002-4267-1924",,,Representation of EHR data for predictive modeling: a comparison between UMLS and other terminologies,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,10,,,1593,1599,,10.1093/jamia/ocaa180,,,,OCT 2020,2020,"Objective: Predictive disease modeling using electronic health record data is a growing field. Although clinical data in their raw form can be used directly for predictive modeling, it is a common practice to map data to standard terminologies to facilitate data aggregation and reuse. There is, however, a lack of systematic investigation of how different representations could affect the performance of predictive models, especially in the context of machine learning and deep learning.Materials and Methods: We projected the input diagnoses data in the Cerner HealthFacts database to Unified Medical Language System (UMLS) and 5 other terminologies, including CCS, CCSR, ICD-9, ICD-10, and Phe-WAS, and evaluated the prediction performances of these terminologies on 2 different tasks: the risk prediction of heart failure in diabetes patients and the risk prediction of pancreatic cancer. Two popular models were evaluated: logistic regression and a recurrent neural network.Results: For logistic regression, using UMLS delivered the optimal area under the receiver operating characteristics (AUROC) results in both dengue hemorrhagic fever (81.15%) and pancreatic cancer (80.53%) tasks. For recurrent neural network, UMLS worked best for pancreatic cancer prediction (AUROC 82.24%), second only (AUROC 85.55%) to PheWAS (AUROC 85.87%) for dengue hemorrhagic fever prediction.Discussion/Conclusion: In our experiments, terminologies with larger vocabularies and finer-grained representations were associated with better prediction performances. In particular, UMLS is consistently 1 of the bestperforming ones. We believe that our work may help to inform better designs of predictive models, although further investigation is warranted.",,,,,,,,,3,0,0,0,2,0,3,,,1067-5027,1527-974X,,WOS:000593112700012,32930711,
J,"Digan, William; Neveol, Aurelie; Neuraz, Antoine; Wack, Maxime; Baudoin, David; Burgun, Anita; Rance, Bastien",,,,"Neuraz, Antoine/ABI-6442-2020","Neuraz, Antoine/0000-0001-7142-6728",,,Can reproducibility be improved in clinical natural language processing? A study of 7 clinical NLP suites,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,504,515,,10.1093/jamia/ocaa261,,,,MAR 2021,2021,"Background: The increasing complexity of data streams and computational processes in modern clinical health information systems makes reproducibility challenging. Clinical natural language processing (NLP) pipelines are routinely leveraged for the secondary use of data. Workflow management systems (WMS) have been widely used in bioinformatics to handle the reproducibility bottleneck.Objective: To evaluate if WMS and other bioinformatics practices could impact the reproducibility of clinical NLP frameworks.Materials and Methods: Based on the literature across multiple researcho fields (NLP, bioinformatics and clinical informatics) we selected articles which (1) review reproducibility practices and (2) highlight a set of rules or guidelines to ensure tool or pipeline reproducibility. We aggregate insight from the literature to define reproducibility recommendations. Finally, we assess the compliance of 7 NLP frameworks to the recommendations.Results: We identified 40 reproducibility features from 8 selected articles. Frameworks based on WMS match more than 50% of features (26 features for LAPPS Grid, 22 features for OpenMinted) compared to 18 features for current clinical NLP framework (cTakes, CLAMP) and 17 features for GATE, ScispaCy, and Textflows.Discussion: 34 recommendations are endorsed by at least 2 articles from our selection. Overall, 15 features were adopted by every NLP Framework. Nevertheless, frameworks based on WMS had a better compliance with the features.Conclusion: NLP frameworks could benefit from lessons learned from the bioinformatics field (eg, public repositories of curated tools and workflows or use of containers for shareability) to enhance the reproducibility in a clinical setting.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000637314400010,33319904,
J,"Kim, Jihoon; Neumann, Larissa; Paul, Paulina; Day, Michele E.; Aratow, Michael; Bell, Douglas S.; Doctor, Jason N.; Hinske, Ludwig C.; Jiang, Xiaoqian; Kim, Katherine K.; Matheny, Michael E.; Meeker, Daniella; Pletcher, Mark J.; Schilling, Lisa M.; SooHoo, Spencer; Xu, Hua; Zheng, Kai; Ohno-Machado, Lucila",,R2D2 Consortium,,,"SooHoo, Spencer/0000-0003-3709-5659; Hinske, Ludwig Christian/0000-0001-7273-5899; Mou, Zongyang/0000-0003-3271-4596; Kim, Jihoon/0000-0002-5351-238X; Jiang, Xiaoqian/0000-0001-9933-2205",,,"Privacy-protecting, reliable response data discovery using COVID-19 patient observations",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,8,,,1765,1776,,10.1093/jamia/ocab054,,MAY 2021,,AUG 2021,2021,"Objective: To utilize, in an individual and institutional privacy-preserving manner, electronic health record (EHR) data from 202 hospitals by analyzing answers to COVID-19-related questions and posting these answers online.Materials and Methods: We developed a distributed, federated network of 12 health systems that harmonized their EHRs and submitted aggregate answers to consortia questions posted at https://www.covid19questions.org. Our consortium developed processes and implemented distributed algorithms to produce answers to a variety of questions. We were able to generate counts, descriptive statistics, and build a multivariate, iterative regression model without centralizing individual-level data.Results: Our public website contains answers to various clinical questions, a web form for users to ask questions in natural language, and a list of items that are currently pending responses. The results show, for example, that patients who were taking angiotensin-converting enzyme inhibitors and angiotensin II receptor blockers, within the year before admission, had lower unadjusted in-hospital mortality rates. We also showed that, when adjusted for, age, sex, and ethnicity were not significantly associated with mortality. We demonstrated that it is possible to answer questions about COVID-19 using EHR data from systems that have different policies and must follow various regulations, without moving data out of their health systems.Discussion and Conclusions: We present an alternative or a complement to centralized COVID-19 registries of EHR data. We can use multivariate distributed logistic regression on observations recorded in the process of care to generate results without transferring individual-level data outside the health systems.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000733838500019,34051088,
R,"Lin, Wei-Chun",,,,,,,,Extraction of Active Medications and Adherence Using Natural Language Processing for Glaucoma Patients,,,,,,,,OHSU Digital Commons,,,,,,,,,,,http://dx.doi.org/10.6083/Q524JP38N,,,,2021-08-26,2021,,,,,,,,,,0,0,0,0,0,0,0,,,,,,DRCI:DATA2021194022626325,35308943,
J,"Cava, William La; Bauer, Christopher; Moore, Jason H; Pendergrass, Sarah A",,,,,"La Cava, William/0000-0002-1332-2960",,,Interpretation of machine learning predictions for patient outcomes in electronic health records.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,572,581,,,,,,2019,2019,"Electronic health records are an increasingly important resource for understanding the interactions between patient health, environment, and clinical decisions. In this paper we report an empirical study of predictive modeling of seven patient outcomes using three state-of-the-art machine learning methods. Our primary goal is to validate the models by interpreting the importance of predictors in the final models. Central to interpretation is the use of feature importance scores, which vary depending on the underlying methodology. In order to assess feature importance, we compared univariate statistical tests, information-theoretic measures, permutation testing, and normalized coefficients from multivariate logistic regression models. In general we found poor correlation between methods in their assessment of feature importance, even when their performance is comparable and relatively good. However, permutation tests applied to random forest and gradient boosting models showed the most agreement, and the importance scores matched the clinical interpretation most frequently.",,,,,,,,,5,0,0,0,0,0,5,,,,1942-597X,,MEDLINE:32308851,32308851,
J,"Reeves, Ruth M.; Christensen, Lee; Brown, Jeremiah R.; Conway, Michael; Levis, Maxwell; Gobbel, Glenn T.; Shah, Rashmee U.; Goodrich, Christine; Ricket, Iben; Minter, Freneka; Bohm, Andrew; Bray, Bruce E.; Matheny, Michael E.; Chapman, Wendy",,,,,"Levis, Maxwell/0000-0003-3271-6997; Brown, Jeremiah/0000-0003-4512-9716; Christensen, Lee/0000-0002-1161-9285; Minter, Freneka/0000-0003-4513-2704",,,Adaptation of an NLP system to a new healthcare environment to identify social determinants of health,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,120,,,,,,103851,10.1016/j.jbi.2021.103851,,JUL 2021,,AUG 2021,2021,"Social determinants of health (SDoH) are increasingly important factors for population health, healthcare outcomes, and care delivery. However, many of these factors are not reliably captured within structured electronic health record (EHR) data. In this work, we evaluated and adapted a previously published NLP tool to include additional social risk factors for deployment at Vanderbilt University Medical Center in an Acute Myocardial Infarction cohort. We developed a transformation of the SDoH outputs of the tool into the OMOP common data model (CDM) for re-use across many potential use cases, yielding performance measures across 8 SDoH classes of precision 0.83 recall 0.74 and F-measure of 0.78.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000683527500009,34174396,
J,"Kim, Chungsoo; You, Seng Chan; Reps, Jenna M.; Cheong, Jae Youn; Park, Rae Woong",,,,,"Reps, Jenna/0000-0002-2970-0778; Kim, Chungsoo/0000-0003-1802-1777",,,Machine-learning model to predict the cause of death using a stacking ensemble method for observational data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1098,1107,,10.1093/jamia/ocaa277,,,,JUN 2021,2021,"Objective: Cause of death is used as an important outcome of clinical research; however, access to cause-of-death data is limited. This study aimed to develop and validate a machine-learning model that predicts the cause of death from the patient's last medical checkup.Materials and Methods: To classify the mortality status and each individual cause of death, we used a stacking ensemble method. The prediction outcomes were all-cause mortality, 8 leading causes of death in South Korea, and other causes. The clinical data of study populations were extracted from the national claims (n= 174 747) and electronic health records (n =729 065) and were used for model development and external validation. Moreover, we imputed the cause of death from the data of 3 US claims databases (n =994 518, 995 372, and 407 604, respectively). All databases were formatted to the Observational Medical Outcomes Partnership Common Data Model.Results: The generalized area under the receiver operating characteristic curve (AUROC) of the model predicting the cause of death within 60 days was 0.9511. Moreover, the AUROC of the external validation was 0.8887. Among the causes of death imputed in the Medicare Supplemental database, 11.32% of deaths were due to malignant neoplastic disease.Discussion: This study showed the potential of machine-learning models as a new alternative to address the lack of access to cause-of-death data. All processes were disclosed to maintain transparency, and the model was easily applicable to other institutions.Conclusion: A machine-learning model with competent performance was developed to predict cause of death.",,,,,,,,,4,0,0,0,1,0,4,,,1067-5027,1527-974X,,WOS:000671031900006,33211841,
J,"Bakken, Suzanne",,,,,,,,Patients and consumers (and the data they generate): an underutilized resource,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,675,676,,10.1093/jamia/ocab040,,MAR 2021,,APR 2021,2021,,,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000648977500001,33677514,
J,"Chen, Jingfeng; Sun, Leilei; Guo, Chonghui; Wei, Wei; Xie, Yanming",,,,,"Sun, Leilei/0000-0002-0157-1716",,,A data-driven framework of typical treatment process extraction and evaluation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,83,,,,178,195,,10.1016/j.jbi.2018.06.004,,,,JUL 2018,2018,"Background: A clinical pathway (CP) defines a standardized care process for a well-defined patient group that aims to improve patient outcomes and promote patient safety. However, the construction of a new pathway from scratch is a time-consuming task for medical staff because it involves many factors, including objects, multi-disciplinary collaboration, sequential design, and outcome measurements. Recently, the rapid development of hospital information systems has allowed the storage of large volumes of electronic medical records (EMRs), and this information constitutes an abundant data resource for building CPs using data-mining methods.Methods: We provide an automatic method for extracting typical treatment processes from EMRs that consists of four key steps. First, a novel similarity method is proposed to measure the similarity of two treatment records. Then, we perform an affinity propagation (AP) clustering algorithm to cluster doctor order set sequences (DOSSs). Next, a framework is proposed to extract a high-level description of each treatment cluster. Finally, we evaluate the extracted typical treatment processes by matching the treatment cluster with external information, such as the treatment efficacy, length of stay, and treatment cost.Results: By experiments on EMRs of 8287 cerebral infarction patients, it is concluded that our proposed method can effectively extract typical treatment processes from treatment records, and also has great potential to improve treatment outcome by personalizing the treatment process for patients with different conditions.Conclusion: The extracted typical treatment processes are intuitive and can provide managerial guidance for CP redesign and optimization. In addition, our work can assist clinicians in clearly understanding their routine treatment processes and recommend optimal treatment pathways for patients.",,,,,,,,,15,2,0,0,4,0,15,,,1532-0464,1532-0480,,WOS:000445054700017,29902575,
J,"Smith, Joshua C; Spann, Ashley; McCoy, Allison B; Johnson, Jakobi A; Arnold, Donald H; Williams, Derek J; Weitkamp, Asli O",,,,,,,,Natural Language Processing and Machine Learning to Enable Clinical Decision Support for Treatment of Pediatric Pneumonia.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1130,1139,,,,,,2020,2020,"Pneumonia is the most frequent cause of infectious disease-related deaths in children worldwide. Clinical decision support (CDS) applications can guide appropriate treatment, but the system must first recognize the appropriate diagnosis. To enable CDS for pediatric pneumonia, we developed an algorithm integrating natural language processing (NLP) and random forest classifiers to identify potential pediatric pneumonia from radiology reports. We deployed the algorithm in the EHR of a large children's hospital using real-time NLP. We describe the development and deployment of the algorithm, and evaluate our approach using 9-months of data gathered while the system was in use. Our model, trained on individual radiology reports, had an AUC of 0.954. The intervention, evaluated on patient encounters that could include multiple radiology reports, achieved a sensitivity, specificity, and positive predictive value of0.899, 0.949, and 0.781, respectively.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936489,33936489,
J,"Wang, Liqin; Lakin, Joshua; Riley, Clay; Korach, Zfania; Frain, Laura N; Zhou, Li",,,,,"Lakin, Joshua/0000-0002-7659-6512",,,Disease Trajectories and End-of-Life Care for Dementias: Latent Topic Modeling and Trend Analysis Using Clinical Notes.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1056,1065,,,,,,2018,2018,"Despite the increasing prevalence, growing costs, and high mortality of dementia in older adults in the U.S., little is known about the course of these diseases and what care dementia patients receive in their final years of life. Using a large volume of clinical notes of dementia patients over the last two years of life, we conducted automatic topic modeling to capture the trends of various themes mentioned in care provider notes, including patients' physical function status, mental health, falls, nutrition and feeding, infections, hospital care, intensive care, end-of-life care, and family and social supports. Our research contributes to the adoption and evaluation of an unsupervised machine learning method using large amounts of retrospective free-text electronic health record data to discover and understand illness and health care trajectories.",,,,,,,,,8,0,0,0,3,0,8,,,,1942-597X,,MEDLINE:30815148,30815148,
J,"Kabeshova, Anastasiia; Yu, Yiyang; Lukacs, Bertrand; Bacry, Emmanuel; Gaiffas, Stephane",,,,,,,,ZiMM: A deep learning model for long term and blurry relapses with non-clinical claims data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,110,,,,,,103531,10.1016/j.jbi.2020.103531,,,,OCT 2020,2020,"This paper considers the problems of modeling and predicting a long-term and blurry relapse that occurs after a medical act, such as a surgery. We do not consider a short-term complication related to the act itself, but a long-term relapse that clinicians cannot explain easily, since it depends on unknown sets or sequences of past events that occurred before the act. The relapse is observed only indirectly, in a blurry fashion, through longitudinal prescriptions of drugs over a long period of time after the medical act. We introduce a new model, called ZiMM (Zero-inflated Mixture of Multinomial distributions) in order to capture long-term and blurry relapses. On top of it, we build an end-to-end deep-learning architecture called ZiMM Encoder-Decoder (ZiMM ED) that can learn from the complex, irregular, highly heterogeneous and sparse patterns of health events that are observed through a claims-only database. ZiMM ED is applied on a non-clinical claims database, that contains only timestamped reimbursement codes for drug purchases, medical procedures and hospital diagnoses, the only available clinical feature being the age of the patient. This setting is more challenging than a setting where bedside clinical signals are available. Our motivation for using such a non-clinical claims database is its exhaustivity population-wise, compared to clinical electronic health records coming from a single or a small set of hospitals. Indeed, we consider a dataset containing the claims of almost all French citizens who had surgery for prostatic problems, with a history between 1.5 and 5 years. We consider a long-term (18 months) relapse (urination problems still occur despite surgery), which is blurry since it is observed only through the reimbursement of a specific set of drugs for urination problems. Our experiments show that ZiMM ED improves several baselines, including non-deep learning and deep-learning approaches, and that it allows working on such a dataset with minimal pre-processing work.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000579807600002,32818667,
J,"Mayampurath, Anoop; Sanchez-Pinto, L. Nelson; Carey, Kyle A.; Venable, Laura-Ruth; Churpek, Matthew",,,,"Sanchez-Pinto, L. Nelson/AAO-9748-2021","Sanchez-Pinto, L. Nelson/0000-0002-7434-6747; Churpek, Matthew/0000-0002-4030-5250",,,Combining patient visual timelines with deep learning to predict mortality,,,,,,,,PLOS ONE,,,,14,7,,,,,e0220640,10.1371/journal.pone.0220640,,,,JUL 31 2019,2019,"BackgroundDeep learning algorithms have achieved human-equivalent performance in image recognition. However, the majority of clinical data within electronic health records is inherently in a non-image format. Therefore, creating visual representations of clinical data could facilitate using cutting-edge deep learning models for predicting outcomes such as in-hospital mortality, while enabling clinician interpretability. The objective of this study was to develop a framework that first transforms longitudinal patient data into visual timelines and then utilizes deep learning to predict in-hospital mortality.Methods and findingsAll adult consecutive patient admissions from 2008-2016 at a tertiary care center were included in this retrospective study. Two-dimensional visual representations for each patient were created with clinical variables on one dimension and time on the other. Predictors included vital signs, laboratory results, medications, interventions, nurse examinations, and diagnostic tests collected over the first 48 hours of the hospital stay. These visual timelines were utilized by a convolutional neural network with a recurrent layer model to predict in-hospital mortality. Seventy percent of the cohort was used for model derivation and 30% for independent validation. Of 115,825 hospital admissions, 2,926 (2.5%) suffered in-hospital mortality. Our model predicted in-hospital mortality significantly better than the Modified Early Warning Score (area under the receiver operating characteristic curve [AUC]: 0.91 vs. 0.76, P < 0.001) and the Sequential Organ Failure Assessment score (AUC: 0.91 vs. 0.57, P < 0.001) in the independent validation set. Class-activation heatmaps were utilized to highlight areas of the picture that were most important for making the prediction, thereby providing clinicians with insight into each individual patient's prediction.ConclusionsWe converted longitudinal patient data into visual timelines and applied a deep neural network for predicting in-hospital mortality more accurately than current standard clinical models, while allowing for interpretation. Our framework holds promise for predicting several important outcomes in clinical medicine.",,,,,,,,,8,0,0,0,1,0,8,,,1932-6203,,,WOS:000484983600062,31365580,
J,"Mohammadi, Iman; Mehrabi, Saeed; Sutton, Bryce; Wu, Huanmei",,,,,,,,Word Embedding and Clustering for Patient-Centered Redesign of Appointment Scheduling in Ambulatory Care Settings.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,863,871,,,,,,2021,2021,"Background. A key to a more efficient scheduling systems is to ensure appointments are designed to meet patient's needs and to design and simplify appointment scheduling less prone to error. Electronic Health Records (EHR) consist of valuable information about patient characteristics and their healthcare needs. The aim of this study is to utilize information from structured and unstructured EHR data to redesign appointment scheduling in community health clinics. Methods. We used Global Vectors for Word Representation, a word embedding approach, on free text field scheduler note to cluster patients into groups based on similarities of reasons for appointment. We then redesigned an appointment scheduling template with new types and durations based on the clusters. We compared the current appointment scheduling system and our proposed system by predicting and evaluating clinic performance measures such as patient time spent in-clinic and number of additional patients to accommodate. Results. We collected 17,722 encounters of an urban community health clinic in 2014 including 102 unique types recorded in the EHR. Following data processing, word embedding implementation, and clustering, appointment types were grouped into 10 clusters. The proposed scheduling template could open space to see overall an additional 716 patients per year and decrease patient in-clinic time by 3.6 minutes on average (p-value<0.0001). Conclusions. We found word embedding, that is an NLP approach, can be used to extract information from schedulers notes for improving scheduling systems. Unsupervised machine learning approach can be applied to simplify appointment scheduling in CHCs. Patient-centered appointment scheduling can be achieved by simplifying and redesigning appointment types and durations that could improve performance measures, such as increasing availability of time and patient satisfaction.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308903,35308903,
J,"Martin, Jacob A.; Crane-Droesch, Andrew; Lapite, Folasade C.; Puhl, Joseph C.; Kmiec, Tyler E.; Silvestri, Jasmine A.; Ungar, Lyle H.; Kinosian, Bruce P.; Himes, Blanca E.; Hubbard, Rebecca A.; Diamond, Joshua M.; Ahya, Vivek; Sims, Michael W.; Halpern, Scott D.; Weissman, Gary E.",,,,,"Kmiec, Tyler/0000-0001-5342-0218; Lapite, Folasade/0000-0002-6829-9331",,,Development and validation of a prediction model for actionable aspects of frailty in the text of clinicians' encounter notes,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,1,,,109,119,,10.1093/jamia/ocab248,,NOV 2021,,JAN 2021,2021,"Objective: Frailty is a prevalent risk factor for adverse outcomes among patients with chronic lung disease. However, identifying frail patients who may benefit from interventions is challenging using standard data sources. We therefore sought to identify phrases in clinical notes in the electronic health record (EHR) that describe actionable frailty syndromes.Materials and Methods: We used an active learning strategy to select notes from the EHR and annotated each sentence for 4 actionable aspects of frailty: respiratory impairment, musculoskeletal problems, fall risk, and nutritional deficiencies. We compared the performance of regression, tree-based, and neural network models to predict the labels for each sentence. We evaluated performance with the scaled Brier score (SBS), where 1 is perfect and 0 is uninformative, and the positive predictive value (PPV).Results: We manually annotated 155 952 sentences from 326 patients. Elastic net regression had the best performance across all 4 frailty aspects (SBS 0.52, 95% confidence interval [CI] 0.49-0.54) followed by random forests (SBS 0.49, 95% CI 0.47-0.51), and multi-task neural networks (SBS 0.39, 95% CI 0.37-0.42). For the elastic net model, the PPV for identifying the presence of respiratory impairment was 54.8% (95% CI 53.3%-56.6%) at a sensitivity of 80%.Discussion: Classificationmodels using EHR notes can effectively identify actionable aspects of frailty among patients living with chronic lung disease. Regression performed better than random forest and neural network models.Conclusions: NLP-based models offer promising support to population health management programs that seek to identify and refer community-dwelling patients with frailty for evidence-based interventions.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000740719600013,34791302,
J,"Brignone, Emily; Fargo, Jamison D; Blais, Rebecca K; Gundlapalli, Adi V",,,,,,,,Applying Machine Learning to Linked Administrative and Clinical Data to Enhance the Detection of Homelessness among Vulnerable Veterans.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,305,312,,,,,,2018,2018,"U.S. military veterans who were discharged from service for misconduct are at high risk for homelessness. Stratifying homelessness risk based on both military service factors and clinical characteristics could facilitate targeted provision of preventive services to those at critical risk. Using administrative data from the Department of Defense and Veterans Health Administration for 25,821 misconduct-discharged Veterans, we developed a dataset that included demographic and clinical characteristics corresponding to 12-months, 3-months, and 1-month preceding the first documentation of homelessness (or a matched index encounter for those without homelessness). Clinical time-trend features were extracted and included as additional model inputs. We developed several random forest models to classify homelessness risk. Models based on 1- and 3-months of data performed roughly as well as those based on 12-months of data. In best-performing models, 70% of those identified as at high-risk became homeless; 30% identified as at moderate risk became homeless (AUC=0.80; recall=0.64, specificity=0.82). Findings suggest the viability of risk stratification for targeting resources.",,,,,,,,,1,0,0,0,1,0,1,,,,1942-597X,,MEDLINE:30815069,30815069,
J,"Gillies, Christopher E.; Taylor, Daniel F.; Cummings, Brandon C.; Ansari, Sardar; Islim, Fadi; Kronick, Steven L.; Medlin, Richard P., Jr.; Ward, Kevin R.",,,,,"Medlin, Richard/0000-0002-4029-1717",,,Demonstrating the consequences of learning missingness patterns in early warning systems for preventative health care: A novel simulation and solution,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,110,,,,,,103528,10.1016/j.jbi.2020.103528,,,,OCT 2020,2020,"When using tree-based methods to develop predictive analytics and early warning systems for preventive healthcare, it is important to use an appropriate imputation method to prevent learning the missingness pattern. To demonstrate this, we developed a novel simulation that generated synthetic electronic health record data using a variational autoencoder with a custom loss function, which took into account the high missing rate of electronic health data. We showed that when tree-based methods learn missingness patterns (correlated with adverse events) in electronic health record data, this leads to decreased performance if the system is used in a new setting that has different missingness patterns. Performance is worst in this scenario when the missing rate between those with and without an adverse event is the greatest. We found that randomized and Bayesian regression imputation methods mitigate the issue of learning the missingness pattern for tree-based methods. We used this information to build a novel early warning system for predicting patient deterioration in general wards and telemetry units: PICTURE (Predicting Intensive Care Transfers and other UnfoReseen Events). To develop, tune, and test PICTURE, we used labs and vital signs from electronic health records of adult patients over four years (n = 133,089 encounters). We analyzed primary outcomes of unplanned intensive care unit transfer, emergency vasoactive medication administration, cardiac arrest, and death. We compared PICTURE with existing early warning systems and logistic regression at multiple levels of granularity. When analyzing PICTURE on the testing set using all observations within a hospital encounter (event rate =3.4%), PICTURE had an area under the receiver operating characteristic curve (AUROC) of 0.83 and an adjusted (event rate = 4%) area under the precision-recall curve (AUPR) of 0.27, while the next best tested method-regularized logistic regression-had an AUROC of 0.80 and an adjusted AUPR of 0.22. To ensure system interpretability, we applied a state-of-the-art prediction explainer that provided a ranked list of features contributing most to the prediction. Though it is currently difficult to compare machine learning-based early warning systems, a rudimentary comparison with published scores demonstrated that PICTURE is on par with state-of-the-art machine learning systems. To facilitate more robust comparisons and development of early warning systems in the future, we have released our variational autoencoder's code and weights so researchers can (a) test their models on data similar to our institution and (b) make their own synthetic datasets.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000579807600001,32795506,
J,"Darke, Philip; Cassidy, Sophie; Catt, Michael; Taylor, Roy; Missier, Paolo; Bacardit, Jaume",,,,"Bacardit, Jaume/F-9293-2014","Bacardit, Jaume/0000-0002-2692-7205",,,Curating a longitudinal research resource using linked primary care EHR data-a UK Biobank case study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,546,552,,10.1093/jamia/ocab260,,,,JAN 29 2022,2022,"Primary care EHR data are often of clinical importance to cohort studies however they require careful handling. Challenges include determining the periods during which EHR data were collected. Participants are typically censored when they deregister from a medical practice, however, cohort studies wish to follow participants longitudinally including those that change practice. Using UK Biobank as an exemplar, we developed methodology to infer continuous periods of data collection and maximize follow-up in longitudinal studies. This resulted in longer follow-up for around 40% of participants with multiple registration records (mean increase of 3.8 years from the first study visit). The approach did not sacrifice phenotyping accuracy when comparing agreement between self-reported and EHR data. A diabetes mellitus case study illustrates how the algorithm supports longitudinal study design and provides further validation. We use UK Biobank data, however, the tools provided can be used for other conditions and studies with minimal alteration.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000761451900015,34897458,
J,"Kim, Youngjun; Meystre, Stephane M.",,,,,,,,Ensemble method-based extraction of medication and related information from clinical texts,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,31,38,,10.1093/jamia/ocz100,,,,JAN 2020,2020,"Objective: Accurate and complete information about medications and related information is crucial for effective clinical decision support and precise health care. Recognition and reduction of adverse drug events is also central to effective patient care. The goal of this research is the development of a natural language processing (NLP) system to automatically extract medication and adverse drug event information from electronic health records. This effort was part of the 2018 n2c2 shared task on adverse drug events and medication extraction.Materials and Methods: The new NLP system implements a stacked generalization based on a search-based structured prediction algorithm for concept extraction. We trained 4 sequential classifiers using a variety of structured learning algorithms. To enhance accuracy, we created a stacked ensemble consisting of these concept extraction models trained on the shared task training data. We implemented a support vector machine model to identify related concepts.Results: Experiments with the official test set showed that our stacked ensemble achieved an F1 score of 92.66%. The relation extraction model with given concepts reached a 93.59% F1 score. Our end-to-end system yielded overall micro-averaged recall, precision, and F1 score of 92.52%, 81.88% and 86.88%, respectively. Our NLP system for adverse drug events and medication extraction ranked within the top 5 of teams participating in the challenge.Conclusion: This study demonstrated that a stacked ensemble with a search-based structured prediction algorithm achieved good performance by effectively integrating the output of individual classifiers and could provide a valid solution for other clinical concept extraction tasks.",,,,,,,,,12,0,0,0,2,0,12,,,1067-5027,1527-974X,,WOS:000548300200005,31282932,
J,"Annapragada, Akshaya, V; Donaruma-Kwoh, Marcella M.; Annapragada, Ananth, V; Starosolski, Zbigniew A.",,,,,"Annapragada, Akshaya/0000-0002-9097-6511",,,A natural language processing and deep learning approach to identify child abuse from pediatric electronic medical records,,,,,,,,PLOS ONE,,,,16,2,,,,,e0247404,10.1371/journal.pone.0247404,,,,FEB 26 2021,2021,"Child physical abuse is a leading cause of traumatic injury and death in children. In 2017, child abuse was responsible for 1688 fatalities in the United States, of 3.5 million children referred to Child Protection Services and 674,000 substantiated victims. While large referral hospitals maintain teams trained in Child Abuse Pediatrics, smaller community hospitals often do not have such dedicated resources to evaluate patients for potential abuse. Moreover, identification of abuse has a low margin of error, as false positive identifications lead to unwarranted separations, while false negatives allow dangerous situations to continue. This context makes the consistent detection of and response to abuse difficult, particularly given subtle signs in young, non-verbal patients. Here, we describe the development of artificial intelligence algorithms that use unstructured free-text in the electronic medical record-including notes from physicians, nurses, and social workers-to identify children who are suspected victims of physical abuse. Importantly, only the notes from time of first encounter (e.g.: birth, routine visit, sickness) to the last record before child protection team involvement were used. This allowed us to develop an algorithm using only information available prior to referral to the specialized child protection team. The study was performed in a multi-center referral pediatric hospital on patients screened for abuse within five different locations between 2015 and 2019. Of 1123 patients, 867 records were available after data cleaning and processing, and 55% were abuse-positive as determined by a multi-disciplinary team of clinical professionals. These electronic medical records were encoded with three natural language processing (NLP) algorithms-Bag of Words (BOW), Word Embeddings (WE), and Rules-Based (RB)-and used to train multiple neural network architectures. The BOW and WE encodings utilize the full free-text, while RB selects crucial phrases as identified by physicians. The best architecture was selected by average classification accuracy for the best performing model from each train-test split of a cross-validation experiment. Natural language processing coupled with neural networks detected cases of likely child abuse using only information available to clinicians prior to child protection team referral with average accuracy of 0.90 +/- 0.02 and average area under the receiver operator characteristic curve (ROC-AUC) 0.93 +/- 0.02 for the best performing Bag of Words models. The best performing rules-based models achieved average accuracy of 0.77 +/- 0.04 and average ROCAUC 0.81 +/- 0.05, while a Word Embeddings strategy was severely limited by lack of representative embeddings. Importantly, the best performing model had a false positive rate of 8%, as compared to rates of 20% or higher in previously reported studies. This artificial intelligence approach can help screen patients for whom an abuse concern exists and streamline the identification of patients who may benefit from referral to a child protection team. Furthermore, this approach could be applied to develop computer-aided-diagnosis platforms for the challenging and often intractable problem of reliably identifying pediatric patients suffering from physical abuse.",,,,,,,,,2,1,0,0,0,0,3,,,1932-6203,,,WOS:000624538400041,33635890,
J,"Bompelli, Anusha; Li, Jianfu; Xu, Yiqi; Wang, Nan; Wang, Yanshan; Adam, Terrence; He, Zhe; Zhang, Rui",,,,,,,,Deep Learning Approach to Parse Eligibility Criteria in Dietary Supplements Clinical Trials Following OMOP Common Data Model.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,243,252,,,,,,2020,2020,"Dietary supplements (DSs) have been widely used in the U.S. and evaluated in clinical trials as potential interventions for various diseases. However, many clinical trials face challenges in recruiting enough eligible patients in a timely fashion, causing delays or even early termination. Using electronic health records to find eligible patients who meet clinical trial eligibility criteria has been shown as a promising way to assess recruitment feasibility and accelerate the recruitment process. In this study, we analyzed the eligibility criteria of 100 randomly selected DS clinical trials and identified both computable and non-computable criteria. We mapped annotated entities to OMOP Common Data Model (CDM) with novel entities (e.g., DS). We also evaluated a deep learning model (Bi-LSTM-CRF) for extracting these entities on CLAMP platform, with an average F1 measure of 0.601. This study shows the feasibility of automatic parsing of the eligibility criteria following OMOP CDM for future cohort identification.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936396,33936396,
J,"Chen, You; Kho, Abel N.; Liebovitz, David; Ivory, Catherine; Osmundson, Sarah; Bian, Jiang; Malin, Bradley A.",,,,"Ivory, Catherine/Y-5615-2019; Liebovitz, David/AAI-9398-2020","Liebovitz, David/0000-0002-2518-5940; Bian, Jiang/0000-0002-2238-5429",,,Learning bundled care opportunities from electronic medical records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,77,,,,1,10,,10.1016/j.jbi.2017.11.014,,,,JAN 2018,2018,"Objective: The traditional fee-for-service approach to healthcare can lead to the management of a patient's conditions in a siloed manner, inducing various negative consequences. It has been recognized that a bundled approach to healthcare-one that manages a collection of health conditions together-may enable greater efficacy and cost savings. However, it is not always evident which sets of conditions should be managed in a bundled manner. In this study, we investigate if a data-driven approach can automatically learn potential bundles.Methods: We designed a framework to infer health condition collections (HCCs) based on the similarity of their clinical workflows, according to electronic medical record (EMR) utilization. We evaluated the framework with data from over 16,500 inpatient stays from Northwestern Memorial Hospital in Chicago, Illinois. The plausibility of the inferred HCCs for bundled care was assessed through an online survey of a panel of five experts, whose responses were analyzed via an analysis of variance (ANOVA) at a 95% confidence level. We further assessed the face validity of the HCCs using evidence in the published literature.Results: The framework inferred four HCCs, indicative of (1) fetal abnormalities, (2) late pregnancies, (3) prostate problems, and (4) chronic diseases, with congestive heart failure featuring prominently. Each HCC was substantiated with evidence in the literature and was deemed plausible for bundled care by the experts at a statistically significant level.Conclusions: The findings suggest that an automated EMR data-driven framework conducted can provide a basis for discovering bundled care opportunities. Still, translating such findings into actual care management will require further refinement, implementation, and evaluation.",,,,,,,,,13,0,0,0,0,0,13,,,1532-0464,1532-0480,,WOS:000426221800001,29174994,
J,"Naseri, Hossein; Kafi, Kamran; Skamene, Sonia; Tolba, Marwan; Faye, Mame Daro; Ramia, Paul; Khriguian, Julia; Kildea, John",,,,,"Faye, Mame Daro/0000-0002-3274-2055; Kafi, Kam/0000-0002-3649-081X; Khriguian, Julia/0000-0001-6472-679X; Kildea, John/0000-0002-7084-1425; TOLBA, MARWAN/0000-0003-2812-7348",,,Development of a generalizable natural language processing pipeline to extract physician-reported pain from clinical reports: Generated using publicly-available datasets and tested on institutional clinical reports for cancer patients with bone metastases,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,120,,,,,,103864,10.1016/j.jbi.2021.103864,,JUL 2021,,AUG 2021,2021,"Objective: The majority of cancer patients suffer from severe pain at the advanced stage of their illness. In most cases, cancer pain is underestimated by clinical staff and is not properly managed until it reaches a critical stage. Therefore, detecting and addressing cancer pain early can potentially improve the quality of life of cancer patients. The objective of this research project was to develop a generalizable Natural Language Processing (NLP) pipeline to find and classify physician-reported pain in the radiation oncology consultation notes of cancer patients with bone metastases. Materials and Methods: The texts of 1249 publicly-available hospital discharge notes in the i2b2 database were used as a training and validation set. The MetaMap and NegEx algorithms were implemented for medical terms extraction. Sets of NLP rules were developed to score pain terms in each note. By averaging pain scores, each note was assigned to one of the three verbally-declared pain (VDP) labels, including no pain, pain, and no mention of pain. Without further training, the generalizability of our pipeline in scoring individual pain terms was tested independently using 30 hospital discharge notes from the MIMIC-III database and 30 consultation notes of cancer patients with bone metastasis from our institution's radiation oncology electronic health record. Finally, 150 notes from our institution were used to assess the pipeline's performance at assigning VDP. Results: Our NLP pipeline successfully detected and quantified pain in the i2b2 summary notes with 93% overall precision and 92% overall recall. Testing on the MIMIC-III database achieved precision and recall of 91% and 86% respectively. The pipeline successfully detected pain with 89% precision and 82% recall on our institutional radiation oncology corpus. Finally, our pipeline assigned a VDP to each note in our institutional corpus with 84% and 82% precision and recall, respectively. Conclusion: Our NLP pipeline enables the detection and classification of physician-reported pain in our radiation oncology corpus. This portable and ready-to-use pipeline can be used to automatically extract and classify physician-reported pain from clinical notes where the pain is not otherwise documented through structured data entry.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000683539900001,34265451,
J,"Stemerman, Rachel; Arguello, Jaime; Brice, Jane; Krishnamurthy, Ashok; Houston, Mary; Kitzmiller, Rebecca",,,,,"Kitzmiller, Rebecca/0000-0002-6547-5790",,,Identification of social determinants of health using multi-label classification of electronic health record clinical notes,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooaa069,10.1093/jamiaopen/ooaa069,,,,JUL 2021,2021,"Objectives: Social determinants of health (SDH), key contributors to health, are rarely systematically measured and collected in the electronic health record (EHR). We investigate how to leverage clinical notes using novel applications of multi-label learning (MLL) to classify SDH in mental health and substance use disorder patients who frequent the emergency department.Methods and Materials: We labeled a gold-standard corpus of EHR clinical note sentences (N = 4063) with 6 identified SDH-related domains recommended by the Institute of Medicine for inclusion in the EHR. We then trained 5 classification models: linear-Support Vector Machine, K-Nearest Neighbors, Random Forest, XGBoost, and bidirectional Long Short-Term Memory (BI-LSTM). We adopted 5 common evaluation measures: accuracy, average precision-recall (AP), area under the curve receiver operating characteristic (AUC-ROC), Hamming loss, and log loss to compare the performance of different methods for MLL classification using the F1 score as the primary evaluation metric.Results: Our results suggested that, overall, BI-LSTM outperformed the other classification models in terms of AUC-ROC (93.9), AP (0.76), and Hamming loss (0.12). The AUC-ROC values of MLL models of SDH related domains varied between (0.59-1.0). We found that 44.6% of our study population (N = 1119) had at least one positive documentation of SDH.Discussion and Conclusion: The proposed approach of training an MLL model on an SDH rich data source can produce a high performing classifier using only unstructured clinical notes. We also provide evidence that model performance is associated with lexical diversity by health professionals and the auto-generation of clinical note sentences to document SDH.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500004,34514351,
J,"DeLozier, Sarah; Bland, Sarah; McPheeters, Melissa; Wells, Quinn; Farber-Eger, Eric; Bejan, Cosmin A.; Fabbri, Daniel; Rosenbloom, Trent; Roden, Dan; Johnson, Kevin B.; Wei, Wei-Qi; Peterson, Josh; Bastarache, Lisa",,,,"Roden, Dan/ABD-5412-2021","Bejan, Cosmin/0000-0001-5107-0584; Farber-Eger, Eric/0000-0003-0281-3796",,,Phenotyping coronavirus disease 2019 during a global health pandemic: Lessons learned from the characterization of an early cohort,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103777,10.1016/j.jbi.2021.103777,,APR 2021,,MAY 2021,2021,"From the start of the coronavirus disease 2019 (COVID-19) pandemic, researchers have looked to electronic health record (EHR) data as a way to study possible risk factors and outcomes. To ensure the validity and accuracy of research using these data, investigators need to be confident that the phenotypes they construct are reliable and accurate, reflecting the healthcare settings from which they are ascertained. We developed a COVID19 registry at a single academic medical center and used data from March 1 to June 5, 2020 to assess differences in population-level characteristics in pandemic and non-pandemic years respectively. Median EHR length, previously shown to impact phenotype performance in type 2 diabetes, was significantly shorter in the SARS-CoV-2 positive group relative to a 2019 influenza tested group (median 3.1 years vs 8.7; Wilcoxon rank sum P = 1.3e52). Using three phenotyping methods of increasing complexity (billing codes alone and domain-specific algorithms provided by an EHR vendor and clinical experts), common medical comorbidities were abstracted from COVID-19 EHRs, defined by the presence of a positive laboratory test (positive predictive value 100%, recall 93%). After combining performance data across phenotyping methods, we observed significantly lower false negative rates for those records billed for a comprehensive care visit (p = 4e-11) and those with complete demographics data recorded (p = 7e-5). In an early COVID-19 cohort, we found that phenotyping performance of nine common comorbidities was influenced by median EHR length, consistent with previous studies, as well as by data density, which can be measured using portable metrics including CPT codes. Here we present those challenges and potential solutions to creating deeply phenotyped, acute COVID-19 cohorts.",,,,,,,,,4,0,0,0,1,0,4,,,1532-0464,1532-0480,,WOS:000651364200002,33838341,
J,"Amrollahi, Fatemeh; Shashikumar, Supreeth P; Razmi, Fereshteh; Nemati, Shamim",,,,,,,,Contextual Embeddings from Clinical Notes Improves Prediction of Sepsis.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,197,202,,,,,,2020,2020,"Sepsis, a life-threatening organ dysfunction, is a clinical syndrome triggered by acute infection and affects over 1 million Americans every year. Untreated sepsis can progress to septic shock and organ failure, making sepsis one of the leading causes of morbidity and mortality in hospitals. Early detection of sepsis and timely antibiotics administration is known to save lives. In this work, we design a sepsis prediction algorithm based on data from electronic health records (EHR) using a deep learning approach. While most existing EHR-based sepsis prediction models utilize structured data including vitals, labs, and clinical information, we show that incorporation of features based on clinical texts, using a pre-trained neural language representation model, allows for incorporation of unstructured data without an explicit need for ontology-based named-entity recognition and classification. The proposed model is trained on a large critical care database of over 40,000 patients, including 2805 septic patients, and is compared against competing baseline models. In comparison to a baseline model based on structured data alone, incorporation of clinical texts improved AUC from 0.81 to 0.84. Our findings indicate that incorporation of clinical text features via a pre-trained language representation model can improve early prediction of sepsis and reduce false alarms.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:33936391,33936391,
J,"Wang, Mengqian; Wang, Manhua; Yu, Fei; Yang, Yue; Walker, Jennifer; Mostafa, Javed",,,,"Wang, Manhua/AFT-4506-2022","Wang, Manhua/0000-0002-4400-1393; Bissram, Jennifer S./0000-0003-0248-2616; Yu, Fei/0000-0003-1079-1590; WANG, MENGQIAN/0000-0003-4451-9595",,,A systematic review of automatic text summarization for biomedical literature and EHRs,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2287,2297,,10.1093/jamia/ocab143,,AUG 2021,,OCT 2021,2021,"Objective: Biomedical text summarization helps biomedical information seekers avoid information overload by reducing the length of a document while preserving the contents' essence. Our systematic review investigates the most recent biomedical text summarization researches on biomedical literature and electronic health records by analyzing their techniques, areas of application, and evaluation methods. We identify gaps and propose potential directions for future research.Materials and Methods: This review followed the PRISMA methodology and replicated the approaches adopted by the previous systematic review published on the same topic. We searched 4 databases (PubMed, ACM Digital Library, Scopus, and Web of Science) from January 1, 2013 to April 8, 2021. Two reviewers independently screened title, abstract, and full-text for all retrieved articles. The conflicts were resolved by the third reviewer. The data extraction of the included articles was in 5 dimensions: input, purpose, output, method, and evaluation.Results: Fifty-eight out of 7235 retrieved articles met the inclusion criteria. Thirty-nine systems used single-document biomedical research literature as their input, 17 systems were explicitly designed for clinical support, 47 systems generated extractive summaries, and 53 systems adopted hybrid methods combining computational linguistics, machine learning, and statistical approaches. As for the assessment, 51 studies conducted an intrinsic evaluation using predefined metrics.Discussion and Conclusion: This study found that current biomedical text summarization systems have achieved good performance using hybrid methods. Studies on electronic health records summarization have been increasing compared to a previous survey. However, the majority of the works still focus on summarizing literature.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000745625700028,34338801,
J,"Blumenthal, Wendy; Alimi, Temitope O.; Jones, Sandra F.; Jones, David E.; Rogers, Joseph D.; Benard, Vicki B.; Richardson, Lisa C.",,,,,"Jones, David/0000-0002-6521-3213",,,Using informatics to improve cancer surveillance,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1488,1495,,10.1093/jamia/ocaa149,,,,SEP 2020,2020,"Objectives: This review summarizes past and current informatics activities at the Centers for Disease Control and Prevention National Program of Cancer Registries to inform readers about efforts to improve, standardize, and automate reporting to public health cancer registries.Target audience: The target audience includes cancer registry experts, informaticians, public health professionals, database specialists, computer scientists, programmers, and system developers who are interested in methods to improve public health surveillance through informatics approaches.Scope: This review provides background on central cancer registries and describes the efforts to standardize and automate reporting to these registries. Specific topics include standardized data exchange activities for physician and pathology reporting, software tools for cancer reporting, development of a natural language processing tool for processing unstructured clinical text, and future directions of cancer surveillance informatics.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000593113300021,32941600,
J,"Gong, Jen J.; Soleimani, Hossein; Murray, Sara G.; Adler-Milstein, Julia",,,,,,,,Characterizing styles of clinical note production and relationship to clinical work hours among first-year residents,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,1,,,120,127,,10.1093/jamia/ocab253,,NOV 2021,,JAN 2021,2021,"Objective: To characterize variation in clinical documentation production patterns, how this variation relates to individual resident behavior preferences, and how these choices relate to work hours.Materials and Methods: We used unsupervised machine learning with clinical note metadata for 1265 progress notes written for 279 patient encounters by 50 first-year residents on the Hospital Medicine service in 2018 to uncover distinct note-level and user-level production patterns. We examined average and 95% confidence intervals of median user daily work hours measured from audit log data for each user-level production pattern.Results: Our analysis revealed 10 distinct note-level and 5 distinct user-level production patterns (user styles). Note production patterns varied in when writing occurred and in how dispersed writing was through the day. User styles varied in which note production pattern(s) dominated. We observed suggestive trends in work hours for different user styles: residents who preferred producing notes in dispersed sessions had higher median daily hours worked while residents who preferred producing notes in the morning or in a single uninterrupted session had lower median daily hours worked.Discussion: These relationships suggest that note writing behaviors should be further investigated to understand what practices could be targeted to reduce documentation burden and derivative outcomes such as resident work hour violations.Conclusion: Clinical note documentation is a time-consuming activity for physicians; we identify substantial variation in how first-year residents choose to do this work and suggestive trends between user preferences and work hours.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000740719600014,34963142,
J,"Zhang, Ziqi; Yan, Chao; Malin, Bradley A.",,,,,"Yan, Chao/0000-0002-6719-1388",,,Membership inference attacks against synthetic health data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,125,,,,,,103977,10.1016/j.jbi.2021.103977,,DEC 2021,,JAN 2022,2022,"Synthetic data generation has emerged as a promising method to protect patient privacy while sharing individual-level health data. Intuitively, sharing synthetic data should reduce disclosure risks because no explicit linkage is retained between the synthetic records and the real data upon which it is based. However, the risks associated with synthetic data are still evolving, and what seems protected today may not be tomorrow. In this paper, we show that membership inference attacks, whereby an adversary infers if the data from certain target individuals (known to the adversary a priori) were relied upon by the synthetic data generation process, can be substantially enhanced through state-of-the-art machine learning frameworks, which calls into question the protective nature of existing synthetic data generators. Specifically, we formulate the membership inference problem from the perspective of the data holder, who aims to perform a disclosure risk assessment prior to sharing any health data. To support such an assessment, we introduce a framework for effective membership inference against synthetic health data without specific assumptions about the generative model or a welldefined data structure, leveraging the principles of contrastive representation learning. To illustrate the potential for such an attack, we conducted experiments against synthesis approaches using two datasets derived from several health data resources (Vanderbilt University Medical Center, the All of Us Research Program) to determine the upper bound of risk brought by an adversary who invokes an optimal strategy. The results indicate that partially synthetic data are vulnerable to membership inference at a very high rate. By contrast, fully synthetic data are only marginally susceptible and, in most cases, could be deemed sufficiently protected from membership inference.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000735446400002,34920126,
J,"Huang, Zhengxing; Ge, Zhenxiao; Dong, Wei; He, Kunlun; Duan, Huilong",,,,,"He, Kunlun/0000-0002-3335-5700",,,Probabilistic modeling personalized treatment pathways using electronic health records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,86,,,,33,48,,10.1016/j.jbi.2018.08.004,,,,OCT 2018,2018,"Background: Modeling personalized treatment pathways plays an important role in understanding essential/critical treatment behaviors performed on patients during their hospitalizations and thus provides the opportunity for the improvement of better health service delivery in treatment pathways.Objective: Unlike traditional business process mining, modeling personalized treatment pathways is more challenging because they are typically case-specific. Although several studies have been devoted to modeling patient treatment pathways, limited efforts have been made on the extraction of latent semantics and their transitions behind patient treatment pathways, which are often ambiguous and poorly understood.Methods: In this article, we propose an extension of the Hidden Markov Model to mine and model personalized treatment pathways by extracting latent treatment topics and identifying their sequential dependencies in pathways, in the form of probabilistic distributions and transitions of patients' raw Electronic Health Record (EHR) data.Results: We evaluated the proposed model on 48,024 patients with cardiovascular diseases. A total of 15 treatment topics and their typical transition routes were discovered from EHR data that contained 1,391,251 treatment events with 2786 types of interventions and that were evaluated by ten clinicians manually. The obtained p-values are 0.000146 and 0.009106 in comparison with both Latent Dirichlet Allocation and Sequent Naive Bayes models, respectively; this outcome indicate that our approach achieves a better understanding of human evaluators on modeling personalized treatment pathway than that of benchmark models.Conclusion: The experimental results on a real-world data set clearly suggest that the proposed model has efficiency in mining and modeling personalized treatment pathways. We argue that the discovered treatment topics and their transition routes, as actionable knowledge that represents the practice of treating individual patients in their clinical pathways, can be further exploited to help physicians better understand their specialty and learn from previous experiences for treatment analysis and improvement.",,,,,,,,,10,0,0,0,4,0,10,,,1532-0464,1532-0480,,WOS:000460600800004,30138699,
J,"Xiao, Cao; Ma, Tengfei; Dieng, Adji B.; Blei, David M.; Wang, Fei",,,,,,,,Readmission prediction via deep contextual embedding of clinical concepts,,,,,,,,PLOS ONE,,,,13,4,,,,,e0195024,10.1371/journal.pone.0195024,,,,APR 9 2018,2018,"ObjectiveHospital readmission costs a lot of money every year. Many hospital readmissions are avoidable, and excessive hospital readmissions could also be harmful to the patients. Accurate prediction of hospital readmission can effectively help reduce the readmission risk. However, the complex relationship between readmission and potential risk factors makes readmission prediction a difficult task. The main goal of this paper is to explore deep learning models to distill such complex relationships and make accurate predictions.Materials and methodsWe propose CONTENT, a deep model that predicts hospital readmissions via learning interpretable patient representations by capturing both local and global contexts from patient Electronic Health Records (EHR) through a hybrid Topic Recurrent Neural Network (TopicRNN) model. The experiment was conducted using the EHR of a real world Congestive Heart Failure (CHF) cohort of 5,393 patients.ResultsThe proposed model outperforms state-of-the-art methods in readmission prediction (e.g. 0.6103 +/- 0.0130 vs. second best 0.5998 +/- 0.0124 in terms of ROC-AUC). The derived patient representations were further utilized for patient phenotyping. The learned phenotypes provide more precise understanding of readmission risks.DiscussionEmbedding both local and global context in patient representation not only improves prediction performance, but also brings interpretable insights of understanding readmission risks for heterogeneous chronic clinical conditions.Conclusion This is the first of its kind model that integrates the power of both conventional deep neural network and the probabilistic generative models for highly interpretable deep patient representation learning. Experimental results and case studies demonstrate the improved performance and interpretability of the model.",,,,,,,,,38,1,0,0,13,0,39,,,1932-6203,,,WOS:000429505000022,29630604,
J,"Mirzapour, Mehdi; Abdaoui, Amine; Tchechmedjiev, Andon; Digan, William; Bringay, Sandra; Jonquet, Clement",,,,"Tchechmedjiev, Andon/AAO-5356-2021","Tchechmedjiev, Andon/0000-0003-3749-5521",,,"French FastContext: A publicly accessible system for detecting negation, temporality and experiencer in French clinical notes",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103733,10.1016/j.jbi.2021.103733,,MAR 2021,,MAY 2021,2021,"The context of medical conditions is an important feature to consider when processing clinical narratives. NegEx and its extension ConText became the most well-known rule-based systems that allow determining whether a medical condition is negated, historical or experienced by someone other than the patient in English clinical text. In this paper, we present a French adaptation and enrichment of FastContext which is the most recent, n-trie engine-based implementation of the ConText algorithm. We compiled an extensive list of French lexical cues by automatic and manual translation and enrichment. To evaluate French FastContext, we manually annotated the context of medical conditions present in two types of clinical narratives: (i) death certificates and (ii) electronic health records. Results show good performance across different context values on both types of clinical notes (on average 0.93 and 0.86 F1, respectively). Furthermore, French FastContext outperforms previously reported French systems for negation detection when compared on the same datasets and it is the first implementation of contextual temporality and experiencer identification reported for French. Finally, French FastContext has been implemented within the SIFR Annotator: a publicly accessible Web service to annotate French biomedical text data (http://bioportal.lirmm.fr/annotator). To our knowledge, this is the first implementation of a Web-based ConText-like system in a publicly accessible platform allowing non-natural-language-processing experts to both annotate and contextualize medical conditions in clinical notes.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663077000009,33737205,
J,"Wang, Jonathan X.; Sullivan, Delaney K.; Wells, Alex C.; Chen, Jonathan H.",,,,,"Wang, Jonathan/0000-0001-5208-3352; Chen, Jonathan H./0000-0002-4387-8740",,,ClinicNet: machine learning for personalized clinical order set recommendations,,,,,,,,JAMIA OPEN,,,,3,2,,,216,224,,10.1093/jamiaopen/ooaa021,,,,JUL 2020,2020,"Objective: This study assessesA whether neural networks trained on electronic health record (EHR) data can anticipate what individual clinical orders and existing institutional order set templates clinicians will use more accurately than existing decision support tools.Materials and Methods: We process 57 624 patients worth of clinical event EHR data from 2008 to 2014. We train a feed-forward neural network (ClinicNet) and logistic regression applied to the traditional problem structure of predicting individual clinical items as well as our proposed workflow of predicting existing institutional order set template usage.Results: ClinicNet predicts individual clinical orders (precision = 0.32, recall = 0.47) better than existing institutional order sets (precision = 0.15, recall = 0.46). The ClinicNet model predicts clinician usage of existing institutional order sets (avg. precision = 0.31) with higher average precision than a baseline of order set usage frequencies (avg. precision = 0.20) or a logistic regression model (avg. precision = 0.12).Discussion: Machine learning methods can predict clinical decision-making patterns with greater accuracy and less manual effort than existing static order set templates. This can streamline existing clinical workflows, but may not fit if historical clinical ordering practices are incorrect. For this reason, manually authored content such as order set templates remain valuable for the purposeful design of care pathways. ClinicNet's capability of predicting such personalized order set templates illustrates the potential of combining both top-down and bottomup approaches to delivering clinical decision support content.Conclusion: ClinicNet illustrates the capability for machine learning methods applied to the EHR to anticipate both individual clinical orders and existing order set templates, which has the potential to improve upon current standards of practice in clinical order entry.",,,,,,,,,1,0,0,0,0,0,1,,,,2574-2531,,WOS:000645439900014,32734162,
J,"Geva, Alon; Liu, Molei; Panickan, Vidul A.; Avillach, Paul; Cai, Tianxi; Mandl, Kenneth D.",,,,,"Geva, Alon/0000-0002-8574-0133",,,A high-throughput phenotyping algorithm is portable from adult to pediatric populations,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1265,1269,,10.1093/jamia/ocaa343,,FEB 2021,,JUN 2021,2021,"Objective: Multimodal automated phenotyping (MAP) is a scalable, high-throughput phenotyping method, developed using electronic health record (EHR) data from an adult population. We tested transportability of MAP to a pediatric population.Materials and Methods: Without additional feature engineering or supervised training, we applied MAP to a pediatric population enrolled in a biobank and evaluated performance against physician-reviewed medical records. We also compared performance of MAP at the pediatric institution and the original adult institution where MAP was developed, including for 6 phenotypes validated at both institutions against physician-reviewed medical records.Results: MAP performed equally well in the pediatric setting (average AUC 0.98) as it did at the general adult hospital system (average AUC 0.96). MAP's performance in the pediatric sample was similar across the 6 specific phenotypes also validated against gold-standard labels in the adult biobank.Conclusions: MAP is highly transportable across diverse populations and has potential for wide-scale use.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000671031900024,33594412,
J,"Dymek, Christine; Kim, Bryan; Melton, Genevieve B.; Payne, Thomas H.; Singh, Hardeep; Hsiao, Chun-Ju",,,,,"Payne, Thomas/0000-0002-3416-5474; SINGH, HARDEEP/0000-0002-4419-8974",,,Building the evidence-base to reduce electronic health record-related clinician burden,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,5,,,1057,1061,,10.1093/jamia/ocaa238,,,,MAY 2021,2021,"Clinicians face competing pressures of being clinically productive while using imperfect electronic health record (EHR) systems and maximizing face-to-face time with patients. EHR use is increasingly associated with clinician burnout and underscores the need for interventions to improve clinicians' experiences. With an aim of addressing this need, we share evidence-based informatics approaches, pragmatic next steps, and future research directions to improve 3 of the highest contributors to EHR burden: (1) documentation, (2) chart review, and (3) inbox tasks. These approaches leverage speech recognition technologies, natural language processing, artificial intelligence, and redesign of EHR workflow and user interfaces. We also offer a perspective on how EHR vendors, healthcare system leaders, and policymakers all play an integral role while sharing responsibility in helping make evidence-based sociotechnical solutions available and easy to use.",,,,,,,,,7,0,0,0,1,0,7,,,1067-5027,1527-974X,,WOS:000648977800024,33340326,
J,"Galozy, Alexander; Nowaczyk, Slawomir",,,,,"Galozy, Alexander/0000-0002-7453-9186",,,Prediction and pattern analysis of medication refill adherence through electronic health records and dispensation data.,,,,,,,,Journal of biomedical informatics,,,,112S,,,,100075,100075,,10.1016/j.yjbinx.2020.100075,,,,2020,2020,"BACKGROUND AND PURPOSE: Low adherence to medication in chronic disease patients leads to increased morbidity, mortality, and healthcare costs. The widespread adoption of electronic prescription and dispensation records allows a more comprehensive overview of medication utilization. In combination with electronic health records (EHR), such data provides new opportunities for identifying patients at risk of nonadherence and provide more targeted and effective interventions. The purpose of this article is to study the predictability of medication adherence for a cohort of hypertensive patients, focusing on healthcare utilization factors under various predictive scenarios. Furthermore, we discover common proportion of days covered patterns (PDC-patterns) for patients with index prescriptions and simulate medication-taking behaviours that might explain observed patterns.PROCEDURES: We predict refill adherence focusing on factors of healthcare utilization, such as visits, prescription information and demographics of patient and prescriber. We train models with machine learning algorithms, using four different data splits: stratified random, patient, temporal forward prediction with and without index patients. We extract frequent, two-year long PDC-patterns using K-means clustering and investigate five simple models of medication-taking that can generate such PDC-patterns.FINDINGS: Model performance varies between data splits (AUC test set: 0.77-0.89). Including historical information increases the performance slightly in most cases (approx. 1-2% absolute AUC uplift). Models show low predictive performance (AUC test set: 0.56-0.66) on index-prescriptions and patients with sudden drops in PDC (Recall: 0.58-0.63). We find 21 distinct two-year PDC-patterns, ranging from good adherence to intermittent gaps and early discontinuation in the first or second year. Simulations show that observed PDC-patterns can only be explained by specific medication consumption behaviours.CONCLUSIONS: Prediction models developed using EHR exhibit bias towards patients with high healthcare utilization. Even though actual medication-taking is not observable, consumption patterns may not be as arbitrary, provided that medication refilling and consumption is linked.",,,,,,,,,1,0,0,0,1,0,1,,,,1532-0480,,MEDLINE:34417009,34417009,
J,"Nelson, Charlotte A.; Bove, Riley; Butte, Atul J.; Baranzini, Sergio E.",,,,,"Baranzini, Sergio/0000-0003-0067-194X",,,Embedding electronic health records onto a knowledge network recognizes prodromal features of multiple sclerosis and predicts diagnosis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,424,434,,10.1093/jamia/ocab270,,,,JAN 29 2022,2022,"Objective Early identification of chronic diseases is a pillar of precision medicine as it can lead to improved outcomes, reduction of disease burden, and lower healthcare costs. Predictions of a patient's health trajectory have been improved through the application of machine learning approaches to electronic health records (EHRs). However, these methods have traditionally relied on black box algorithms that can process large amounts of data but are unable to incorporate domain knowledge, thus limiting their predictive and explanatory power. Here, we present a method for incorporating domain knowledge into clinical classifications by embedding individual patient data into a biomedical knowledge graph. Materials and Methods A modified version of the Page rank algorithm was implemented to embed millions of deidentified EHRs into a biomedical knowledge graph (SPOKE). This resulted in high-dimensional, knowledge-guided patient health signatures (ie, SPOKEsigs) that were subsequently used as features in a random forest environment to classify patients at risk of developing a chronic disease. Results Our model predicted disease status of 5752 subjects 3 years before being diagnosed with multiple sclerosis (MS) (AUC = 0.83). SPOKEsigs outperformed predictions using EHRs alone, and the biological drivers of the classifiers provided insight into the underpinnings of prodromal MS. Conclusion Using data from EHR as input, SPOKEsigs describe patients at both the clinical and biological levels. We provide a clinical use case for detecting MS up to 5 years prior to their documented diagnosis in the clinic and illustrate the biological features that distinguish the prodromal MS state.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000761451900003,34915552,
J,"Rosnati, Margherita; Fortuin, Vincent",,,,,"Fortuin, Vincent/0000-0002-0640-2671",,,MGP-AttTCN: An interpretable machine learning model for the prediction of sepsis,,,,,,,,PLOS ONE,,,,16,5,,,,,e0251248,10.1371/journal.pone.0251248,,,,MAY 7 2021,2021,"With a mortality rate of 5.4 million lives worldwide every year and a healthcare cost of more than 16 billion dollars in the USA alone, sepsis is one of the leading causes of hospital mortality and an increasing concern in the ageing western world. Recently, medical and technological advances have helped re-define the illness criteria of this disease, which is otherwise poorly understood by the medical society. Together with the rise of widely accessible Electronic Health Records, the advances in data mining and complex nonlinear algorithms are a promising avenue for the early detection of sepsis. This work contributes to the research effort in the field of automated sepsis detection with an open-access labelling of the medical MIMIC-III data set. Moreover, we propose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep learning model to early predict the occurrence of sepsis in an interpretable manner. We show that our model outperforms the current state-of-the-art and present evidence that different labelling heuristics lead to discrepancies in task difficulty. For instance, when predicting sepsis five hours prior to onset on our new realistic labels, our proposed model achieves an area under the ROC curve of 0.660 and an area under the PR curve of 0.483, whereas the (less interpretable) previous state-of-the-art model (MGP-TCN) achieves 0.635 AUROC and 0.460 AUPR and the popular commercial InSight model achieves 0.490 AUROC and 0.359 AUPR.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000665471900043,33961681,
J,"Steitz, Bryan D.; Sulieman, Lina; Warner, Jeremy L.; Fabbri, Daniel; Brown, J. Thomas; Davis, Alyssa L.; Unertl, Kim M.",,,,,"Steitz, Bryan/0000-0003-2066-8692; Unertl, Kim/0000-0003-0094-3677",,,Classification and analysis of asynchronous communication content between care team members involved in breast cancer treatment,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab049,10.1093/jamiaopen/ooab049,,,,JUL 2021,2021,"Objective: A growing research literature has highlighted the work of managing and triaging clinical messages as a major contributor to professional exhaustion and burnout. The goal of this study was to discover and quantify the distribution of message content sent among care team members treating patients with breast cancer.Materials and Methods: We analyzed nearly two years of communication data from the electronic health record (EHR) between care team members at Vanderbilt University Medical Center. We applied natural language processing to perform sentence-level annotation into one of five information types: clinical, medical logistics, nonmedical logistics, social, and other. We combined sentence-level annotations for each respective message. We evaluated message content by team member role and clinic activity.Results: Our dataset included 81 857 messages containing 613 877 sentences. Across all roles, 63.4% and 21.8% of messages contained logistical information and clinical information, respectively. Individuals in administrative or clinical staff roles sent 81% of all messages containing logistical information. There were 33.2% of messages sent by physicians containing clinical information-the most of any role.Discussion and Conclusion: Our results demonstrate that EHR-based asynchronous communication is integral to coordinate care for patients with breast cancer. By understanding the content of messages sent by care team members, we can devise informatics initiatives to improve physicians' clerical burden and reduce unnecessary interruptions.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500018,34396056,
J,"Fialoke, Suruchi; Malarstig, Anders; Miller, Melissa R; Dumitriu, Alexandra",,,,,,,,Application of Machine Learning Methods to Predict Non-Alcoholic Steatohepatitis (NASH) in Non-Alcoholic Fatty Liver (NAFL) Patients.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,430,439,,,,,,2018,2018,"Non-alcoholic fatty liver disease (NAFLD) is the leading cause of chronic liver disease worldwide. NAFLD patients have excessive liver fat (steatosis), without other liver diseases and without excessive alcohol consumption. NAFLD consists of a spectrum of conditions: benign steatosis or non-alcoholic fatty liver (NAFL), steatosis accompanied by inflammation and fibrosis or nonalcoholic steatohepatitis (NASH), and cirrhosis. Given a lack of clinical biomarkers and its asymptomatic nature, NASH is under-diagnosed. We use electronic health records from the Optum Analytics to (1) identify patients diagnosed with benign steatosis and NASH, and (2) train machine learning classifiers for NASH and healthy (non-NASH) populations to (3) predict NASH disease status on patients diagnosed with NAFL. Summarized temporal lab data for alanine aminotransferase, aspartate aminotransferase, and platelet counts, with basic demographic information and type 2 diabetes status were included in the models.",,,,,,,,,23,1,0,0,8,0,23,,,,1942-597X,,MEDLINE:30815083,30815083,
J,"Simon, Gregory E.; Shortreed, Susan M.; Johnson, Eric; Rossom, Rebecca C.; Lynch, Frances L.; Ziebell, Rebecca; Penfold, Robert B.",,,,,"Rossom, Rebecca/0000-0002-9531-914X",,,What health records data are required for accurate prediction of suicidal behavior?,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1458,1465,,10.1093/jamia/ocz136,,,,DEC 2019,2019,"Objective: The study sought to evaluate how availability of different types of health records data affect the accuracy of machine learning models predicting suicidal behavior.Materials and Methods: Records from 7 large health systems identified 19 061 056 outpatient visits to mental health specialty or general medical providers between 2009 and 2015. Machine learning models (logistic regression with penalized LASSO [least absolute shrinkage and selection operator] variable selection) were developed to predict suicide death (n = 1240) or probable suicide attempt (n = 24 133) in the following 90 days. Base models were used only historical insurance claims data and were then augmented with data regarding sociodemographic characteristics (race, ethnicity, and neighborhood characteristics), past patient-reported outcome questionnaires from electronic health records, and data (diagnoses and questionnaires) recorded during the visit.Results: For prediction of any attempt following mental health specialty visits, a model limited to historical insurance claims data performed approximately as well (C-statistic 0.843) as a model using all available data (C-statistic 0.850). For prediction of suicide attempt following a general medical visit, addition of data recorded during the visit yielded a meaningful improvement over a model using all data up to the prior day (C-statistic 0.853 vs 0.838).Discussion: Results may not generalize to setting with less comprehensive data or different patterns of care. Even the poorest-performing models were superior to brief self-report questionnaires or traditional clinical assessment.Conclusions: Implementation of suicide risk prediction models in mental health specialty settings may be less technically demanding than expected. In general medical settings, however, delivery of optimal risk predictions at the point of care may require more sophisticated informatics capability.",,,,,,,,,11,0,0,0,3,0,11,,,1067-5027,1527-974X,,WOS:000515125300005,31529095,
J,"Eickelberg, Garrett; Sanchez-Pinto, L. Nelson; Luo, Yuan",,,,"Sanchez-Pinto, L. Nelson/AAO-9748-2021; Luo, Yuan/K-5563-2016","Sanchez-Pinto, L. Nelson/0000-0002-7434-6747; Luo, Yuan/0000-0003-0195-7456",,,Predictive modeling of bacterial infections and antibiotic therapy needs in critically ill adults,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,109,,,,,,103540,10.1016/j.jbi.2020.103540,,,,SEP 2020,2020,"Unnecessary antibiotic regimens in the intensive care unit (ICU) are associated with adverse patient outcomes and antimicrobial resistance. Bacterial infections (BI) are both common and deadly in ICUs, and as a result, patients with a suspected BI are routinely started on broad-spectrum antibiotics prior to having confirmatory microbiologic culture results or when an occult BI is suspected, a practice known as empiric antibiotic therapy (EAT). However, EAT guidelines lack consensus and existing methods to quantify patient-level BI risk rely largely on clinical judgement and inaccurate biomarkers or expensive diagnostic tests. As a consequence, patients with low risk of BI often are continued on EAT, exposing them to unnecessary side effects. Augmenting current intuition-based practices with data-driven predictions of BI risk could help inform clinical decisions to shorten the duration of unnecessary EAT and improve patient outcomes. We propose a novel framework to identify ICU patients with low risk of BI as candidates for earlier EAT discontinuation. For this study, patients suspected of having a community-acquired BI were identified in the Medical Information Mart for Intensive Care III (MIMIC-III) dataset and categorized based on microbiologic culture results and EAT duration. Using structured longitudinal data collected up to 24-, 48-, and 72-hours after starting EAT, our best models identified patients at low risk of BI with AUROCs up to 0.8 and negative predictive values >93%. Overall, these results demonstrate the feasibility of forecasting BI risk in a critical care setting using patient features found in the electronic health record and call for more extensive research in this promising, yet relatively understudied, area.",,,,,,,,,5,0,0,0,1,0,5,,,1532-0464,1532-0480,,WOS:000575072400012,32814200,
J,"Prosperi, Mattia; Guo, Yi; Bian, Jiang",,,,,,,,Bagged random causal networks for interventional queries on observational biomedical datasets,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,115,,,,,,103689,10.1016/j.jbi.2021.103689,,FEB 2021,,MAR 2021,2021,"Learning causal effects from observational data, e.g. estimating the effect of a treatment on survival by datamining electronic health records (EHRs), can be biased due to unmeasured confounders, mediators, and colliders. When the causal dependencies among features/covariates are expressed in the form of a directed acyclic graph, using do-calculus it is possible to identify one or more adjustment sets for eliminating the bias on a given causal query under certain assumptions. However, prior knowledge of the causal structure might be only partial; algorithms for causal structure discovery often provide ambiguous solutions, and their computational complexity becomes practically intractable when the feature sets grow large. We hypothesize that the estimation of the true causal effect of a causal query on to an outcome can be approximated as an ensemble of lower complexity estimators, namely bagged random causal networks. A bagged random causal network is an ensemble of subnetworks constructed by sampling the feature subspaces (with the query, the outcome, and a random number of other features), drawing conditional dependencies among the features, and inferring the corresponding adjustment sets. The causal effect can be then estimated by any regression function of the outcome by the query paired with the adjustment sets. Through simulations and a real-world clinical dataset (class III malocclusion data), we show that the bagged estimator is ?in most cases? consistent with the true causal effect if the structure is known, has a good variance/bias trade-off when the structure is unknown (estimated using heuristics), has lower computational complexity than learning a full network, and outperforms boosted regression. In conclusion, the bagged random causal network is well-suited to estimate query-target causal effects from observational studies on EHR and other high-dimensional biomedical databases.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000640492500001,33548542,
J,"Sutter, Thomas; Roth, Jan A.; Chin-Cheong, Kieran; Hug, Balthasar L.; Vogt, Julia E.",,,,,"Hug, Balthasar/0000-0003-4235-1995",,,A comparison of general and disease-specific machine learning models for the prediction of unplanned hospital readmissions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,868,873,,10.1093/jamia/ocaa299,,,,APR 2021,2021,"Unplanned hospital readmissions are a burden to patients and increase healthcare costs. A wide variety of machine learning (ML) models have been suggested to predict unplanned hospital readmissions. These ML models were often specifically trained on patient populations with certain diseases. However, it is unclear whether these specialized ML models-trained on patient subpopulations with certain diseases or defined by other clinical characteristics-are more accurate than a general ML model trained on an unrestricted hospital cohort. In this study based on an electronic health record cohort of consecutive inpatient cases of a single tertiary care center, we demonstrate that accurate prediction of hospital readmissions may be obtained by general, disease-independent, ML models. This general approach may substantially decrease the cost of development and deployment of respective ML models in daily clinical routine, as all predictions are obtained by the use of a single model.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000648977500024,33338231,
J,"Brown, Jeffrey S.; Maro, Judith C.; Nguyen, Michael; Ball, Robert",,,,,"Maro, Judith/0000-0001-9900-2142",,,Using and improving distributed data networks to generate actionable evidence: the case of real-world outcomes in the Food and Drug Administration's Sentinel system,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,5,,,793,797,,10.1093/jamia/ocaa028,,,,MAY 2020,2020,"The US Food and Drug Administration (FDA) Sentinel System uses a distributed data network, a common data model, curated real-world data, and distributed analytic tools to generate evidence for FDA decision-making. Sentinel system needs include analytic flexibility, transparency, and reproducibility while protecting patient privacy. Based on over a decade of experience, a critical system limitation is the inability to identify enough medical conditions of interest in observational data to a satisfactory level of accuracy. Improving the system's ability to use computable phenotypes will require an all of the above approach that improves use of electronic health data while incorporating the growing array of complementary electronic health record data sources. FDA recently funded a Sentinel System Innovation Center and a Community Building and Outreach Center that will provide a platform for collaboration across disciplines to promote better use of real-world data for decision-making.",,,,,,,,,6,0,0,0,3,0,6,,,1067-5027,1527-974X,,WOS:000537475700016,32279080,
J,"Torii, Manabu; Yang, Elly W; Doan, Son",,,,,,,,A Preliminary Study of Clinical Concept Detection Using Syntactic Relations.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1028,1035,,,,,,2018,2018,"Concept detection is an integral step in natural language processing (NLP) applications in the clinical domain. Clinical concepts are detailed (e.g., pain in left/right upper/lower arm/leg) and expressed in diverse phrase types (e.g., noun, verb, adjective, or prepositional phrase). There are rich terminological resources in the clinical domain that include many concept synonyms. Even with these resources, concept detection remains challenging due to discontinuous and/or permuted phrase occurrences. To overcome this challenge, we investigated an approach to exploiting syntactic information. Syntactic patterns of concept phrases were mined from continuous, non-permuted forms of synonyms, and these patterns were used to detect discontinuous and/or permuted concept phrases. Experiments on 790 de-identified clinical notes showed that the proposed approach can potentially boost a recall of concept detection. Meanwhile, challenges and limitations were noticed. In this paper, we report and discuss our preliminary analysis and finding.",,,,,,,,,1,0,0,0,1,0,1,,,,1942-597X,,MEDLINE:30815146,30815146,
J,"Guo, Yi; Zhang, Yahan; Lyu, Tianchen; Prosperi, Mattia; Wang, Fei; Xu, Hua; Bian, Jiang",,,,,"Bian, Jiang/0000-0002-2238-5429",,,The application of artificial intelligence and data integration in COVID-19 studies: a scoping review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,9,,,2050,2067,,10.1093/jamia/ocab098,,,,SEP 2021,2021,"Objective: To summarize how artificial intelligence (AI) is being applied in COVID-19 research and determine whether these AI applications integrated heterogenous data from different sources for modeling.Materials and Methods: We searched 2 major COVID-19 literature databases, the National Institutes of Health's LitCovid and the World Health Organization's COVID-19 database on March 9, 2021. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline, 2 reviewers independently reviewed all the articles in 2 rounds of screening.Results: In the 794 studies included in the final qualitative analysis, we identified 7 key COVID-19 research areas in which AI was applied, including disease forecasting, medical imaging-based diagnosis and prognosis, early detection and prognosis (non-imaging), drug repurposing and early drug discovery, social media data analysis, genomic, transcriptomic, and proteomic data analysis, and other COVID-19 research topics. We also found that there was a lack of heterogenous data integration in these AI applications.Discussion: Risk factors relevant to COVID-19 outcomes exist in heterogeneous data sources, including electronic health records, surveillance systems, sociodemographic datasets, and many more. However, most AI applications in COVID-19 research adopted a single-sourced approach that could omit important risk factors and thus lead to biased algorithms. Integrating heterogeneous data for modeling will help realize the full potential of AI algorithms, improve precision, and reduce bias.Conclusion: There is a lack of data integration in the AI applications in COVID-19 research and a need for a multilevel AI framework that supports the analysis of heterogeneous data from different sources.",,,,,,,,,3,0,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000692577000031,34151987,
J,"Jiang, Yichen; Wang, Chenghong; Wu, Zhixuan; Du, Xin; Wang, Shuang",,,,,,,,Privacy-preserving biomedical data dissemination via a hybrid approach.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1176,1185,,,,,,2018,2018,"Sharing medical data can benefit many aspects of biomedical research studies. However, medical data usually contains sensitive patient information, which cannot be shared directly. Summary statistics, like histogram, are widely used in medical research which serves as a sanitized synopsis of the raw health dataset such as Electrical Health Records (EHR). Such synopsized representation is then be used to support advanced operations over health dataset such as counting queries and learning based tasks. While privacy becomes an increasingly important issue for generating and publishing health data based histograms. Previous solutions show promise on securely generating histogram via differential privacy, however such methods only consider a centralized solution and the accuracy is still a limitation for real world applications. In this paper, we propose a novel hybrid solution to combine two rigorous theoretical models (homomorphic encryption and differential privacy) for securely generating synthetic V-optimal histograms over distributed datasets. Our results demonstrated accuracy improvement over previous study over real medical datasets.",,,,,,,,,4,0,0,0,0,0,4,,,,1942-597X,,MEDLINE:30815160,30815160,
J,"Song, Wenyu; Kang, Min-Jeoung; Zhang, Linying; Jung, Wonkyung; Song, Jiyoun; Bates, David W.; Dykes, Patricia C.",,,,,"Song, Jiyoun/0000-0003-0362-0670",,,Predicting pressure injury using nursing assessment phenotypes and machine learning methods,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,759,765,,10.1093/jamia/ocaa336,,FEB 2021,,APR 2021,2021,"Objective: Pressure injuries are common and serious complications for hospitalized patients. The pressure injury rate is an important patient safety metric and an indicator of the quality of nursing care. Timely and accurate prediction of pressure injury risk can significantly facilitate early prevention and treatment and avoid adverse outcomes. While many pressure injury risk assessment tools exist, most were developed before there was access to large clinical datasets and advanced statistical methods, limiting their accuracy. In this paper, we describe the development of machine learning-based predictive models, using phenotypes derived from nurse-entered direct patient assessment data.Methods: We utilized rich electronic health record data, including full assessment records entered by nurses, from 5 different hospitals affiliated with a large integrated healthcare organization to develop machine learning-based prediction models for pressure injury. Five-fold cross-validation was conducted to evaluate model performance.Results: Two pressure injury phenotypes were defined for model development: nonhospital acquired pressure injury (N =4398) and hospital acquired pressure injury (N = 1767), representing 2 distinct clinical scenarios. A total of 28 clinical features were extracted and multiple machine learning predictive models were developed for both pressure injury phenotypes. The random forest model performed best and achieved an AUC of 0.92 and 0.94 in 2 test sets, respectively. The Glasgow coma scale, a nurse-entered level of consciousness measurement, was the most important feature for both groups.Conclusions: This model accurately predicts pressure injury development and, if validated externally, may be helpful in widespread pressure injury prevention.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000648977500011,33517452,
J,"Demner-Fushman, Dina; Mrabet, Yassine; Ben Abacha, Asma",,,,"Abacha, Asma Ben/ABF-3585-2020",,,,Consumer health information and question answering: helping consumers find answers to their health-related information needs,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,194,201,,10.1093/jamia/ocz152,,,,FEB 2020,2020,"Objective: Consumers increasingly turn to the internet in search of health-related information; and they want their questions answered with short and precise passages, rather than needing to analyze lists of relevant documents returned by search engines and reading each document to find an answer. We aim to answer consumer health questions with information from reliable sources.Materials and Methods: We combine knowledge-based, traditional machine and deep learning approaches to understand consumers' questions and select the best answers from consumer-oriented sources. We evaluate the end-to-end system and its components on simple questions generated in a pilot development of MedlinePlus Alexa skill, as well as the short and long real-life questions submitted to the National Library of Medicine by consumers.Results: Our system achieves 78.7% mean average precision and 87.9% mean reciprocal rank on simple Alexa questions, and 44.5% mean average precision and 51.6% mean reciprocal rank on real-life questions submitted by National Library of Medicine consumers.Discussion: The ensemble of deep learning, domain knowledge, and traditional approaches recognizes question type and focus well in the simple questions, but it leaves room for improvement on the real-life consumers' questions. Information retrieval approaches alone are sufficient for finding answers to simple Alexa questions. Answering real-life questions, however, benefits from a combination of information retrieval and inference approaches.Conclusion: A pilot practical implementation of research needed to help consumers find reliable answers to their health-related questions demonstrates that for most questions the reliable answers exist and can be found automatically with acceptable accuracy.",,,,,,,,,10,0,0,0,1,0,10,,,1067-5027,1527-974X,,WOS:000515121300003,31592532,
J,"Ni, Yizhao; Alwell, Kathleen; Moomaw, Charles J.; Woo, Daniel; Adeoye, Opeolu; Flaherty, Matthew L.; Ferioli, Simona; Mackey, Jason; La Rosa, Felipe De Los Rios; Martini, Sharyl; Khatri, Pooja; Kleindorfer, Dawn; Kissela, Brett M.",,,,,"Kissela, Brett/0000-0002-9773-4013; Ni, Yizhao/0000-0001-8599-454X",,,Towards phenotyping stroke: Leveraging data from a large-scale epidemiological study to detect stroke diagnosis,,,,,,,,PLOS ONE,,,,13,2,,,,,e0192586,10.1371/journal.pone.0192586,,,,FEB 14 2018,2018,"Objective1) To develop a machine learning approach for detecting stroke cases and subtypes from hospitalization data, 2) to assess algorithm performance and predictors on real-world data collected by a large-scale epidemiology study in the US; and 3) to identify directions for future development of high-precision stroke phenotypic signatures.Materials and methodsWe utilized 8,131 hospitalization events (ICD-9 codes 430 +/- 438) collected from the Greater Cincinnati/Northern Kentucky Stroke Study in 2005 and 2010. Detailed information from patients' medical records was abstracted for each event by trained research nurses. By analyzing the broad list of demographic and clinical variables, the machine learning algorithms predicted whether an event was a stroke case and, if so, the stroke subtype. The performance was validated on gold-standard labels adjudicated by stroke physicians, and results were compared with stroke classifications based on ICD-9 discharge codes, as well as labels determined by study nurses.ResultsThe best performing machine learning algorithm achieved a performance of 88.57%/93.81%/92.80%/93.30%/89.84%/98.01% (accuracy/precision/recall/F-measure/area under ROC curve/area under precision-recall curve) on stroke case detection. For detecting stroke subtypes, the algorithm yielded an overall accuracy of 87.39% and greater than 85% precision on individual subtypes. The machine learning algorithms significantly outperformed the ICD-9 method on all measures (P value<0.001). Their performance was comparable to that of study nurses, with better tradeoff between precision and recall. The feature selection uncovered a subset of predictive variables that could facilitate future development of effective stroke phenotyping algorithms.Discussion and conclusionsBy analyzing a broad array of patient data, the machine learning technologies held promise for improving detection of stroke diagnosis, thus unlocking high statistical power for subsequent genetic and genomic studies.",,,,,,,,,8,0,0,0,3,0,8,,,1932-6203,,,WOS:000425183500075,29444182,
J,"Zhang, Lingjiao; Ding, Xiruo; Ma, Yanyuan; Muthu, Naveen; Ajmal, Imran; Moore, Jason H.; Herman, Daniel S.; Chen, Jinbo",,,,"Moore, Jason H./AAV-9645-2021","Moore, Jason H./0000-0002-5015-1099; Muthu, Naveen/0000-0002-8259-6965; Zhang, Lingjiao/0000-0003-0700-4584",,,A maximum likelihood approach to electronic health record phenotyping using positive and unlabeled patients,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,119,126,,10.1093/jamia/ocz170,,,,JAN 2020,2020,"Objective: Phenotyping patients using electronic health record (EHR) data conventionally requires labeled cases and controls. Assigning labels requires manual medical chart review and therefore is labor intensive. For some phenotypes, identifying gold-standard controls is prohibitive. We developed an accurate EHR phenotyping approach that does not require labeled controls.Materials and Methods: Our framework relies on a random subset of cases, which can be specified using an anchor variable that has excellent positive predictive value and sensitivity independent of predictors. We proposed a maximum likelihood approach that efficiently leverages data from the specified cases and unlabeled patients to develop logistic regression phenotypingmodels, and compare model performance with existing algorithms.Results: Our method outperformed the existing algorithms on predictive accuracy in Monte Carlo simulation studies, application to identify hypertension patients with hypokalemia requiring oral supplementation using a simulated anchor, and application to identify primary aldosteronism patients using real-world cases and anchor variables. Our method additionally generated consistent estimates of 2 important parameters, phenotype prevalence and the proportion of true cases that are labeled.Discussion: Upon identification of an anchor variable that is scalable and transferable to different practices, our approach should facilitate development of scalable, transferable, and practice-specific phenotyping models.Conclusions: Our proposed approach enables accurate semiautomated EHR phenotyping with minimal manual labeling and therefore should greatly facilitate EHR clinical decision support and research.",,,,,,,,,2,1,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000548300200015,31722396,
J,"Hu, Zhiyong; Du, Dongping",,,,,,,,A new analytical framework for missing data imputation and classification with uncertainty: Missing data imputation and heart failure readmission prediction,,,,,,,,PLOS ONE,,,,15,9,,,,,e0237724,10.1371/journal.pone.0237724,,,,SEP 21 2020,2020,"Background The wide adoption of electronic health records (EHR) system has provided vast opportunities to advance health care services. However, the prevalence of missing values in EHR system poses a great challenge on data analysis to support clinical decision-making. The objective of this study is to develop a new methodological framework that can address the missing data challenge and provide a reliable tool to predict the hospital readmission among Heart Failure patients. Methods We used Gaussian Process Latent Variable Model (GPLVM) to impute the missing values. Specifically, a lower dimensional embedding was learned from a small complete dataset and then used to impute the missing values in the incomplete dataset. The GPLVM-based missing data imputation can provide both the mean estimate and the uncertainty associated with the mean estimate. To incorporate the uncertainty in prediction, a constrained support vector machine (cSVM) was developed to obtain robust predictions. We first sampled multiple datasets from the distributions of input uncertainty and trained a support vector machine for each dataset. Then an optimal classifier was identified by selecting the support vectors that maximize the separation margin of a newly sampled dataset and minimize the similarity with the pre-trained support vectors. Results The proposed model was derived and validated using Physionet MIMIC-III clinical database. The GPLVM imputation provided normalized mean absolute errors of 0.11 and 0.12 respectively when 20% and 30% of instances contained missing values, and the confidence bounds of the estimations captures 97% of the true values. The cSVM model provided an average Area Under Curve of 0.68, which improves the prediction accuracy by 7% as compared to some existing classifiers. Conclusions The proposed method provides accurate imputation of missing values and has a better prediction performance as compared to existing models that can only deal with deterministic inputs.",,,,,,,,,4,0,0,0,0,0,4,,,1932-6203,,,WOS:000574571500033,32956366,
J,"Miller, Hailey N.; Gleason, Kelly T.; Juraschek, Stephen P.; Plante, Timothy B.; Lewis-Land, Cassie; Woods, Bonnie; Appel, Lawrence J.; Ford, Daniel E.; Himmelfarb, Cheryl R. Dennison",,,,"Gleason, Kelly/P-1820-2018","Gleason, Kelly/0000-0002-4203-6517; Miller, Hailey/0000-0001-6045-6542; Juraschek, Stephen/0000-0003-4168-2696; Plante, Timothy/0000-0001-9992-9597",,,"Electronic medical record-based cohort selection and direct-to-patient, targeted recruitment: early efficacy and lessons learned",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1209,1217,,10.1093/jamia/ocz168,,,,NOV 2019,2019,"Objective: The study sought to characterize institution-wide participation in secure messaging (SM) at a large academic health network, describe our experience with electronic medical record (EMR)-based cohort selection, and discuss the potential roles of SM for research recruitment.Materials and Methods: Study teams defined eligibility criteria to create a computable phenotype, structured EMR data, to identify and recruit participants. Patients with SM accounts matching this phenotype received recruitment messages. We compared demographic characteristics across SM users and the overall health system. We also tabulated SM activation and use, characteristics of individual studies, and efficacy of the recruitment methods.Results: Of the 1 308 820 patients in the health network, 40% had active SM accounts. SM users had a greater proportion of white and non-Hispanic patients than nonactive SM users id. Among the studies included (n=13), 77% recruited participants with a specific disease or condition. All studies used demographic criteria for their phenotype, while 46% (n=6) used demographic, disease, and healthcare utilization criteria. The average SM response rate was 2.9%, with higher rates among condition-specific (3.4%) vs general health (1.4%) studies. Those studies with a more inclusive comprehensive phenotype had a higher response rate.Discussion: Target population and EMR queries (computable phenotypes) affect recruitment efficacy and should be considered when designing an EMR-based recruitment strategy.Conclusions: SM guided by EMR-based cohort selection is a promising approach to identify and enroll research participants. Efforts to increase the number of active SM users and response rate should be implemented to enhance the effectiveness of this recruitment strategy.",,,,,,,,,8,0,0,0,3,0,8,,,1067-5027,1527-974X,,WOS:000498169400008,31553434,
J,"Duarte, Francisco; Martins, Bruno; Pinto, Catia Sousa; Silva, Mario J.",,,,"Silva, Mário J/A-3567-2010","Silva, Mário J/0000-0002-5452-6185",,,Deep neural models for ICD-10 coding of death certificates and autopsy reports in free-text,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,80,,,,64,77,,10.1016/j.jbi.2018.02.011,,,,APR 2018,2018,"We address the assignment of ICD-10 codes for causes of death by analyzing free-text descriptions in death certificates, together with the associated autopsy reports and clinical bulletins, from the Portuguese Ministry of Health. We leverage a deep neural network that combines word embeddings, recurrent units, and neural attention, for the generation of intermediate representations of the textual contents. The neural network also explores the hierarchical nature of the input data, by building representations from the sequences of words within individual fields, which are then combined according to the sequences of fields that compose the inputs. Moreover, we explore innovative mechanisms for initializing the weights of the final nodes of the network, leveraging co-occurrences between classes together with the hierarchical structure of ICD-10. Experimental results attest to the contribution of the different neural network components. Our best model achieves accuracy scores over 89%, 81%, and 76%, respectively for ICD-10 chapters, blocks, and full-codes. Through examples, we also show that our method can produce interpretable results, useful for public health surveillance.",,,,,,,,,19,1,0,0,7,0,20,,,1532-0464,1532-0480,,WOS:000430035000007,29496630,
J,"Malmasi, Shervin; Ge, Wendong; Hosomura, Naoshi; Turchin, Alexander",,,,,,,,Comparing information extraction techniques for low-prevalence concepts: The case of insulin rejection by patients,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103306,10.1016/j.jbi.2019.103306,,,,NOV 2019,2019,"Objective: To comparatively evaluate a range of Natural Language Processing (NLP) approaches for Information Extraction (IE) of low-prevalence concepts in clinical notes on the example of decline of insulin therapy recommendation by patients.Materials and methods: We evaluated the accuracy of detection of documentation of decline of insulin therapy by patients using sentence-level naive Bayes, logistic regression and support vector machine (SVM)-based classification (with and without SMOTE oversampling), token-level sequence labelling using conditional random fields (CRFs), uni- and bi-directional recurrent neural network (RNN) models with GRU and LSTM cells, and rule-based detection using Canary platform. All models were trained using the same manually annotated 50,046-document training set and evaluated on the same 1501-document held-out set. Hyperparameter optimization was performed using 10-fold cross-validation.Results: At the sentence level, prevalence of documentation of decline of insulin therapy by patients was 0.02% in both training and held-out sets. Naive Bayes and logistic regression models did not achieve F-1 score >= 0.5 on the training set and were not further evaluated. Among the other models, evaluation against the held-out test set showed that SVM identified decline of insulin therapy by patients with F-1 score of 0.61, CRF with F-1 of 0.51, RNN with F-1 of 0.67 and Canary rule-based model with F-1 of 0.97.Conclusions: Identification of low-prevalence concepts can present challenges in medical language processing. Rule-based systems that include the designer's background knowledge of language may be able to achieve higher accuracy under these circumstances.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000525701400010,31618679,
J,"Datta, Surabhi; Si, Yuqi; Rodriguez, Laritza; Shooshan, Sonya E.; Demner-Fushman, Dina; Roberts, Kirk",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213; Si, Yuqi/0000-0002-8123-8947",,,"Understanding spatial language in radiology: Representation framework, annotation, and spatial relation extraction from chest X-ray reports using deep learning",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103473,10.1016/j.jbi.2020.103473,,,,AUG 2020,2020,"Radiology reports contain a radiologist's interpretations of images, and these images frequently describe spatial relations. Important radiographic findings are mostly described in reference to an anatomical location through spatial prepositions. Such spatial relationships are also linked to various differential diagnoses and often described through uncertainty phrases. Structured representation of this clinically significant spatial information has the potential to be used in a variety of downstream clinical informatics applications. Our focus is to extract these spatial representations from the reports. For this, we first define a representation framework based on the Spatial Role Labeling (SpRL) scheme, which we refer to as Rad-SpRL. In Rad-SpRL, common radiological entities tied to spatial relations are encoded through four spatial roles: TRAJECTOR, LANDMARK, DIAGNOSIS, and HEDGE, all identified in relation to a spatial preposition (or SPATIAL INDICATOR). We annotated a total of 2,000 chest X-ray reports following Rad-SpRL. We then propose a deep learning-based natural language processing (NLP) method involving word and character-level encodings to first extract the SPATIAL INDICATORS followed by identifying the corresponding spatial roles. Specifically, we use a bidirectional long short-term memory (Bi-LSTM) conditional random field (CRF) neural network as the baseline model. Additionally, we incorporate contextualized word representations from pre-trained language models (BERT and XLNet) for extracting the spatial information. We evaluate both gold and predicted SPATIAL INDICATORS to extract the four types of spatial roles. The results are promising, with the highest average F1 measure for SPATIAL INDICATOR extraction being 91.29 (XLNet); the highest average overall F1 measure considering all the four spatial roles being 92.9 using gold INDICATORS (XLNet); and 85.6 using predicted INDICATORS (BERT pre-trained on MIMIC notes).The corpus is available in Mendeley at http://dx.doi.org/10.17632/yhb26hfz8n.1 and https://github.com/krobertslab/datasets/blob/master/Rad-SpRL.xml.",,,,,,,,,7,0,0,0,3,0,7,,,1532-0464,1532-0480,,WOS:000564595700015,32562898,
J,"Haendel, Melissa A.; Chute, Christopher G.; Bennett, Tellen D.; Eichmann, David A.; Guinney, Justin; Kibbe, Warren A.; Payne, Philip R. O.; Pfaff, Emily R.; Robinson, Peter N.; Saltz, Joel H.; Spratt, Heidi; Suver, Christine; Wilbanks, John; Wilcox, Adam B.; Williams, Andrew E.; Wu, Chunlei; Blacketer, Clair; Bradford, Robert L.; Cimino, James J.; Clark, Marshall; Colmenares, Evan W.; Francis, Patricia A.; Gabriel, Davera; Graves, Alexis; Hemadri, Raju; Hong, Stephanie S.; Hripscak, George; Jiao, Dazhi; Klann, Jeffrey G.; Kostka, Kristin; Lee, Adam M.; Lehmann, Harold P.; Lingrey, Lora; Miller, Robert T.; Morris, Michele; Murphy, Shawn N.; Natarajan, Karthik; Palchuk, Matvey B.; Sheikh, Usman; Solbrig, Harold; Visweswaran, Shyam; Walden, Anita; Walters, Kellie M.; Weber, Griffin M.; Zhang, Xiaohan Tanner; Zhu, Richard L.; Amor, Benjamin; Girvin, Andrew T.; Manna, Amin; Qureshi, Nabeel; Kurilla, Michael G.; Michael, Sam G.; Portilla, Lili M.; Rutter, Joni L.; Austin, Christopher P.; Gersing, Ken R.",,N3C Consortium,,"Coffee, Megan/AAY-6752-2020; Nyland, Jennifer E./AAV-3412-2020; Rahnavard, Gholamali (Ali)/P-6260-2019; Chute, Christopher/AAT-8540-2021; Kamaleswaran, Rishikesan/T-1695-2019; Kibbe, Warren/B-2106-2010; Kharrazi, Hadi/Q-1725-2015; Hill, Elaine/R-3871-2017","Coffee, Megan/0000-0002-4581-111X; Nyland, Jennifer E./0000-0002-4549-3617; Rahnavard, Gholamali (Ali)/0000-0002-9710-0248; Kamaleswaran, Rishikesan/0000-0001-8366-4811; Kibbe, Warren/0000-0001-5622-7659; Chute, Christopher/0000-0001-5437-2545; Robinson, Peter/0000-0002-0736-9199; Kharrazi, Hadi/0000-0003-1481-4323; Pfaff, Emily/0000-0002-6840-9756; Colmenares, Evan/0000-0002-4993-2269; Eichmann, David/0000-0003-3150-8758; Unni, Deepak/0000-0002-3583-7340; McMurry, Julie/0000-0002-9353-5498; Bennett, Tellen/0000-0003-1483-4236; Khanipov, Kamil/0000-0002-3881-737X; Clifford, Gari/0000-0002-5709-201X; Guinney, Justin H/0000-0003-1477-1888; Haendel, Melissa/0000-0001-9114-8737; Saltz, Joel/0000-0002-3451-2165; Hill, Elaine/0000-0003-2494-317X; Girvin, Andrew/0000-0002-2031-9209; Weber, Griffin/0000-0002-2597-881X",,,"The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,427,443,,10.1093/jamia/ocaa196,,,,MAR 2021,2021,"Objective: Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers.Materials and Methods: The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics.Results: Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access.Conclusions: The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-term impacts of COVID-19.",,,,,,,,,60,0,0,0,8,0,59,,,1067-5027,1527-974X,,WOS:000637314400002,32805036,
J,"Luo, Yuan; Cheng, Yu; Uzuner, Ozlem; Szolovits, Peter; Starren, Justin",,,,"Luo, Yuan/K-5563-2016","Luo, Yuan/0000-0003-0195-7456",,,Segment convolutional neural networks (Seg-CNNs) for classifying relations in clinical notes,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,1,,,93,98,,10.1093/jamia/ocx090,,,,JAN 2018,2018,"We propose Segment Convolutional Neural Networks (Seg-CNNs) for classifying relations from clinical notes. Seg-CNNs use only word-embedding features without manual feature engineering. Unlike typical CNN models, relations between 2 concepts are identified by simultaneously learning separate representations for text segments in a sentence: preceding, concept(1), middle, concept(2), and succeeding. We evaluate Seg-CNN on the i2b2/VA relation classification challenge dataset. We show that Seg-CNN achieves a state-of-the-art micro-average F-measure of 0.742 for overall evaluation, 0.686 for classifying medical problem-treatment relations, 0.820 for medical problem-test relations, and 0.702 for medical problem-medical problem relations. We demonstrate the benefits of learning segment-level representations. We show that medical domain word embeddings help improve relation classification. Seg-CNNs can be trained quickly for the i2b2/VA dataset on a graphics processing unit (GPU) platform. These results support the use of CNNs computed over segments of text for classifying medical relations, as they show state-of-the-art performance while requiring no manual feature engineering.",,,,,,,,,38,5,0,0,10,0,43,,,1067-5027,1527-974X,,WOS:000419605800015,29025149,
J,"Shen, Feichen; Peng, Suyuan; Fan, Yadan; Wen, Andrew; Liu, Sijia; Wang, Yanshan; Wang, Liwei; Liu, Hongfang",,,,"Peng, Suyuan/ABI-6014-2020","Peng, Suyuan/0000-0002-8221-7574; Liu, Sijia/0000-0001-9763-1164",,,HPO2Vec+: Leveraging heterogeneous knowledge resources to enrich node embeddings for the Human Phenotype Ontology,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,96,,,,,,103246,10.1016/j.jbi.2019.103246,,,,AUG 2019,2019,"Background: In precision medicine, deep phenotyping is defined as the precise and comprehensive analysis of phenotypic abnormalities, aiming to acquire a better understanding of the natural history of a disease and its genotype-phenotype associations. Detecting phenotypic relevance is an important task when translating precision medicine into clinical practice, especially for patient stratification tasks based on deep phenotyping. In our previous work, we developed node embeddings for the Human Phenotype Ontology (HPO) to assist in phenotypic relevance measurement incorporating distributed semantic representations. However, the derived HPO embeddings hold only distributed representations for IS-A relationships among nodes, hampering the ability to fully explore the graph.Methods: In this study, we developed a framework, HPO2Vec +, to enrich the produced HPO embeddings with heterogeneous knowledge resources (i.e., DECIPHER, OMIM, and Orphanet) for detecting phenotypic relevance. Specifically, we parsed disease-phenotype associations contained in these three resources to enrich non-inheritance relationships among phenotypic nodes in the HPO. To generate node embeddings for the HPO, no-de2vec was applied to perform node sampling on the enriched HPO graphs based on random walk followed by feature learning over the sampled nodes to generate enriched node embeddings. Four HPO embeddings were generated based on different graph structures, which we hereafter label as HPOEmb-Original, HPOEmb-DECIPHER, HPOEmb-OMIM, and HPOEmb-Orphanet. We evaluated the derived embeddings quantitatively through an HPO link prediction task with four edge embeddings operations and six machine learning algorithms. The resulting best embeddings were then evaluated for patient stratification of 10 rare diseases using electronic health records (EHR) collected at Mayo Clinic. We assessed our framework qualitatively by visualizing phenotypic clusters and conducting a use case study on primary hyperoxaluria (PH), a rare disease, on the task of inferring relevant phenotypes given 22 annotated PH related phenotypes.Results: The quantitative link prediction task shows that HPOEmb-Orphanet achieved an optimal AUROC of 0.92 and an average precision of 0.94. In addition, HPOEmb-Orphanet achieved an optimal F1 score of 0.86. The quantitative patient similarity measurement task indicates that HPOEmb-Orphanet achieved the highest average detection rate for similar patients over 10 rare diseases and performed better than other similarity measures implemented by an existing tool, HPOSim, especially for pairwise patients with fewer shared common phenotypes. The qualitative evaluation shows that the enriched HPO embeddings are generally able to detect relationships among nodes with fine granularity and HPOEmb-Orphanet is particularly good at associating phenotypes across different disease systems. For the use case of detecting relevant phenotypic characterizations for given PH related phenotypes, HPOEmb-Orphanet outperformed the other three HPO embeddings by achieving the highest average P@5 of 0.81 and the highest P@10 of 0.79. Compared to seven conventional similarity measurements provided by HPOSim, HPOEmb-Orphanet is able to detect more relevant phenotypic pairs, especially for pairs not in inheritance relationships.Conclusion: We drew the following conclusions based on the evaluation results. First, with additional non-inheritance edges, enriched HPO embeddings can detect more associations between fine granularity phenotypic nodes regardless of their topological structures in the HPO graph. Second, HPOEmb-Orphanet not only can achieve the optimal performance through link prediction and patient stratification based on phenotypic similarity, but is also able to detect relevant phenotypes closer to domain expert's judgments than other embeddings and conventional similarity measurements. Third, incorporating heterogeneous knowledge resources do not necessarily result in better performance for detecting relevant phenotypes. From a clinical perspective, in our use case study, clinical-oriented knowledge resources (e.g., Orphanet) can achieve better performance in detecting relevant phenotypic characterizations compared to biomedical-oriented knowledge resources (e.g., DECIPHER and OMIM).",,,,,,,,,10,1,0,0,6,0,11,,,1532-0464,1532-0480,,WOS:000525698100007,31255713,
J,"Singhal, Lakshya; Garg, Yash; Yang, Philip; Tabaie, Azade; Wong, A. Ian; Mohammed, Akram; Chinthala, Lokesh; Kadaria, Dipen; Sodhi, Amik; Holder, Andre L.; Esper, Annette; Blum, James M.; Davis, Robert L.; Clifford, Gari D.; Martin, Greg S.; Kamaleswaran, Rishikesan",,,,"Mohammed, Akram/F-8068-2015","Mohammed, Akram/0000-0001-8093-8637; Clifford, Gari/0000-0002-5709-201X; Holder, Andre/0000-0003-2635-3923; Yang, Philip/0000-0001-5142-1137",,,eARDS: A multi-center validation of an interpretable machine learning algorithm of early onset Acute Respiratory Distress Syndrome (ARDS) among critically ill adults with COVID-19,,,,,,,,PLOS ONE,,,,16,9,,,,,e0257056,10.1371/journal.pone.0257056,,,,SEP 24 2021,2021,"We present an interpretable machine learning algorithm called 'eARDS' for predicting ARDS in an ICU population comprising COVID-19 patients, up to 12-hours before satisfying the Berlin clinical criteria. The analysis was conducted on data collected from the Intensive care units (ICU) at Emory Healthcare, Atlanta, GA and University of Tennessee Health Science Center, Memphis, TN and the Cerner (R) Health Facts Deidentified Database, a multi-site COVID-19 EMR database. The participants in the analysis consisted of adults over 18 years of age. Clinical data from 35,804 patients who developed ARDS and controls were used to generate predictive models that identify risk for ARDS onset up to 12-hours before satisfying the Berlin criteria. We identified salient features from the electronic medical record that predicted respiratory failure among this population. The machine learning algorithm which provided the best performance exhibited AUROC of 0.89 (95% CI = 0.88-0.90), sensitivity of 0.77 (95% CI = 0.75-0.78), specificity 0.85 (95% CI = 085-0.86). Validation performance across two separate health systems (comprising 899 COVID-19 patients) exhibited AUROC of 0.82 (0.81-0.83) and 0.89 (0.87, 0.90). Important features for prediction of ARDS included minimum oxygen saturation (SpO(2)), standard deviation of the systolic blood pressure (SBP), O-2 flow, and maximum respiratory rate over an observational window of 16-hours. Analyzing the performance of the model across various cohorts indicates that the model performed best among a younger age group (18-40) (AUROC = 0.93 [0.92-0.94]), compared to an older age group (80+) (AUROC = 0.81 [0.81-0.82]). The model performance was comparable on both male and female groups, but performed significantly better on the severe ARDS group compared to the mild and moderate groups. The eARDS system demonstrated robust performance for predicting COVID19 patients who developed ARDS at least 12-hours before the Berlin clinical criteria, across two independent health systems.",,,,,,,,,2,0,0,0,0,0,2,,,1932-6203,,,WOS:000754657900014,34559819,
J,"Guo, Guan N.; Jonnagaddala, Jitendra; Farshid, Sanjay; Huser, Vojtech; Reich, Christian; Liaw, Siaw-Teng",,,,,"Guo, Guan Nan/0000-0002-2164-0053; Farshid, Sanjay/0000-0002-5334-2130",,,Comparison of the cohort selection performance of Australian Medicines Terminology to Anatomical Therapeutic Chemical mappings,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1237,1246,,10.1093/jamia/ocz143,,,,NOV 2019,2019,"Objective: Electronic health records are increasingly utilized for observational and clinical research. Identification of cohorts using electronic health records is an important step in this process. Previous studies largely focused on the methods of cohort selection, but there is little evidence on the impact of underlying vocabularies and mappings between vocabularies used for cohort selection. We aim to compare the cohort selection performance using Australian Medicines Terminology to Anatomical Therapeutic Chemical (ATC) mappings from 2 different sources. These mappings were taken from the Observational Medical Outcomes Partnership Common Data Model (OMOP-CDM) and the Pharmaceutical Benefits Scheme (PBS) schedule.Materials and Methods: We retrieved patients from the electronic Practice Based Research Network data repository using 3 ATC classification groups (A10, N02A, N06A). The retrieved patients were further verified manually and pooled to form a reference standard which was used to assess the accuracy of mappings using precision, recall, and F measure metrics.Results: The OMOP-CDM mappings identified 2.6%, 15.2%, and 24.4% more drugs than the PBS mappings in the A10, N02A and N06A groups respectively. Despite this, the PBS mappings generally performed the same in cohort selection as OMOP-CDM mappings except for the N02A Opioids group, where a significantly greater number of patients were retrieved. Both mappings exhibited variable recall, but perfect precision, with all drugs found to be correctly identified.Conclusion: We found that 1 of the 3 ATC groups had a significant difference and this affected cohort selection performance. Our findings highlighted that underlying terminology mappings can greatly impact cohort selection accuracy. Clinical researchers should carefully evaluate vocabulary mapping sources including methodologies used to develop those mappings.",,,,,,,,,1,0,0,0,1,0,1,,,1067-5027,1527-974X,,WOS:000498169400011,31545380,
J,"Huang, Kexin; Gray, Tamryn F.; Romero-Brufau, Santiago; Tulsky, James A.; Lindvall, Charlotta",,,,,,,,Using nursing notes to improve clinical outcome prediction in intensive care patients: A retrospective cohort study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,8,,,1660,1666,,10.1093/jamia/ocab051,,APR 2021,,AUG 2021,2021,"Objective: Electronic health record documentation by intensive care unit (ICU) clinicians may predict patient outcomes. However, it is unclear whether physician and nursing notes differ in their ability to predict short-term ICU prognosis. We aimed to investigate and compare the ability of physician and nursing notes, written in the first 48 hours of admission, to predict ICU length of stay and mortality using 3 analytical methods.Materials and Methods: This was a retrospective cohort study with split sampling for model training and testing. We included patients >= 18 years of age admitted to the ICU at Beth Israel Deaconess Medical Center in Boston, Massachusetts, from 2008 to 2012. Physician or nursing notes generated within the first 48 hours of admission were used with standard machine learning methods to predict outcomes.Results: For the primary outcome of composite score of ICU length of stay >= 7 days or in-hospital mortality, the gradient boosting model had better performance than the logistic regression and random forest models. Nursing and physician notes achieved area under the curves (AUCs) of 0.826 and 0.796, respectively, with even better predictive power when combined (AUC, 0.839).Discussion: Models using only nursing notes more accurately predicted short-term prognosis than did models using only physician notes, but in combination, the models achieved the greatest accuracy in prediction.Conclusions: Our findings demonstrate that statistical models derived from text analysis in the first 48 hours of ICU admission can predict patient outcomes. Physicians' and nurses' notes are both uniquely important in mortality prediction and combining these notes can produce a better predictive model.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000733838500007,33880557,
J,"Colicchio, Tiago K.; Dissanayake, Pavithra, I; Cimino, James J.",,,,,"Cimino, James/0000-0003-4101-1622; Colicchio, Tiago/0000-0003-3405-1538",,,Formal representation of patients' care context data: the path to improving the electronic health record,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,11,,,1648,1657,,10.1093/jamia/ocaa134,,,,NOV 2020,2020,"Objective: To develop a collection of concept-relationship-concept tuples to formally represent patients' care context data to inform electronic health record (EHR) development.Materials and Methods: We reviewed semantic relationships reported in the literature and developed a manual annotation schema. We used the initial schema to annotate sentences extracted from narrative note sections of cardiology, urology, and ear, nose, and throat (ENT) notes. We audio recorded ENT visits and annotated their parsed transcripts. We combined the results of each annotation into a consolidated set of concept-relationshipconcept tuples. We then compared the tuples used within and across the multiple data sources.Results: We annotated a total of 626 sentences. Starting with 8 relationships from the literature, we annotated 182 sentences from 8 inpatient consult notes (initial set of tuples = 43). Next, we annotated 232 sentences from 10 outpatient visit notes (enhanced set of tuples = 75). Then, we annotated 212 sentences from transcripts of 5 outpatient visits (final set of tuples = 82). The tuples from the visit transcripts covered 103 (74%) concepts documented in the notes of their respective visits. There were 20 (24%) tuples used across all data sources, 10 (12%) used only in inpatient notes, 15 (18%) used only in visit notes, and 7 (9%) used only in the visit transcripts.Conclusions: We produced a robust set of 82 tuples useful to represent patients' care context data. We propose several applications of our tuples to improve EHR navigation, data entry, learning health systems, and decision support.",,,,,,,,,1,0,0,0,1,0,1,,,1067-5027,1527-974X,,WOS:000594986600003,32935127,
J,"Adekkanattu, Prakash; Jiang, Guoqian; Luo, Yuan; Kingsbury, Paul R; Xu, Zhenxing; Rasmussen, Luke V; Pacheco, Jennifer A; Kiefer, Richard C; Stone, Daniel J; Brandt, Pascal S; Yao, Liang; Zhong, Yizhen; Deng, Yu; Wang, Fei; Ancker, Jessica S; Campion, Thomas R; Pathak, Jyotishman",,,,"; Luo, Yuan/K-5563-2016","Brandt, Pascal/0000-0001-5116-0555; Luo, Yuan/0000-0003-0195-7456",,,"Evaluating the Portability of an NLP System for Processing Echocardiograms: A Retrospective, Multi-site Observational Study.",,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,190,199,,,,,,2019,2019,"While natural language processing (NLP) of unstructured clinical narratives holds the potential for patient care and clinical research, portability of NLP approaches across multiple sites remains a major challenge. This study investigated the portability of an NLP system developed initially at the Department of Veterans Affairs (VA) to extract 27 key cardiac concepts from free-text or semi-structured echocardiograms from three academic edical centers: Weill Cornell Medicine, Mayo Clinic and Northwestern Medicine. While the NLP system showed high precision and recall easurements for four target concepts (aortic valve regurgitation, left atrium size at end systole, mitral valve regurgitation, tricuspid valve regurgitation) across all sites, we found moderate or poor results for the remaining concepts and the NLP system performance varied between individual sites.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:32308812,32308812,
J,"Bastarache, Lisa; Hughey, Jacob J.; Goldstein, Jeffrey A.; Bastraache, Julie A.; Das, Satya; Zaki, Neil Charles; Zeng, Chenjie; Tang, Leigh Anne; Roden, Dan M.; Denny, Joshua C.",,,,"Denny, Josh/AAL-3359-2021; Roden, Dan/ABD-5412-2021","Denny, Josh/0000-0002-3049-7332; Zeng, Chenjie/0000-0002-0149-5661; Goldstein, Jeffery/0000-0002-4086-057X; Hughey, Jacob/0000-0002-1558-6089",,,Improving the phenotype risk score as a scalable approach to identifying patients with Mendelian disease,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1437,1447,,10.1093/jamia/ocz179,,,,DEC 2019,2019,"Objective: The Phenotype Risk Score (PheRS) is a method to detect Mendelian disease patterns using phenotypes from the electronic health record (EHR). We compared the performance of different approaches mapping EHR phenotypes to Mendelian disease features.Materials and Methods: PheRS utilizes Mendelian diseases descriptions annotated with Human Phenotype Ontology (HPO) terms. In previous work, we presented a map linking phecodes (based on International Classification of Diseases [ICD]-Ninth Revision) to HPO terms. For this study, we integrated ICD-Tenth Revision codes and lab data. We also created a new map between HPO terms using customized groupings of ICD codes. We compared the performance with cases and controls for 16 Mendelian diseases using 2.5 million de-identified medical records.Results: PheRS effectively distinguished cases from controls for all 15 positive controls and all approaches tested (P < 4 x 10(16)). Adding lab data led to a statistically significant improvement for 4 of 14 diseases. The custom ICD groupings improved specificity, leading to an average 8% increase for precision at 100 (-2% to 22%). Eight of 10 adults with cystic fibrosis tested had PheRS in the 95th percentile prio to diagnosis.Discussion: Both phecodes and custom ICD groupings were able to detect differences between affected cases and controls at the population level. The ICD map showed better precision for the highest scoring individuals. Adding lab data improved performance at detecting population-level differences.Conclusions: PheRS is a scalable method to study Mendelian disease at the population level using electronic health record data and can potentially be used to find patients with undiagnosed Mendelian disease.",,,,,,,,,8,0,0,0,6,0,8,,,1067-5027,1527-974X,,WOS:000515125300003,31609419,
J,"Landau, Aviv Y.; Ferrarello, Susi; Blanchard, Ashley; Cato, Kenrick; Atkins, Nia; Salazar, Stephanie; Patton, Desmond U.; Topaz, Maxim",,,,,"Landau, Aviv/0000-0003-3715-7709",,,Developing machine learning-based models to help identify child abuse and neglect: key ethical challenges and recommended solutions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,576,580,,10.1093/jamia/ocab286,,,,JAN 29 2022,2022,Child abuse and neglect are public health issues impacting communities throughout the United States. The broad adoption of electronic health records (EHR) in health care supports the development of machine learning-based models to help identify child abuse and neglect. Employing EHR data for child abuse and neglect detection raises several critical ethical considerations. This article applied a phenomenological approach to discuss and provide recommendations for key ethical issues related to machine learning-based risk models development and evaluation: (1) biases in the data; (2) clinical documentation system design issues; (3) lack of centralized evidence base for child abuse and neglect; (4) lack of gold standard in assessment and diagnosis of child abuse and neglect; (5) challenges in evaluation of risk prediction performance; (6) challenges in testing predictive models in practice; and (7) challenges in presentation of machine learning-based prediction to clinicians and patients. We provide recommended solutions to each of the 7 ethical challenges and identify several areas for further policy and research.,,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000761451900018,35024859,
J,"Minh Nguyen; Jankovic, Ivana; Kalesinskas, Laurynas; Baiocchi, Michael; Chen, Jonathan H.",,,,,"Nguyen, Minh/0000-0001-7149-849X",,,Machine learning for initial insulin estimation in hospitalized patients,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2212,2219,,10.1093/jamia/ocab099,,JUL 2021,,OCT 2021,2021,"Objective: The study sought to determine whether machine learning can predict initial inpatient total daily dose (TDD) of insulin from electronic health records more accurately than existing guideline-based dosing recommendations.Materials and Methods: Using electronic health records from a tertiary academic center between 2008 and 2020 of 16,848 inpatients receiving subcutaneous insulin who achieved target blood glucose control of 100-180 mg/dL on a calendar day, we trained an ensemble machine learning algorithm consisting of regularized regression, random forest, and gradient boosted tree models for 2-stage TDD prediction. We evaluated the ability to predict patients requiring more than 6 units TDD and their point-value TDDs to achieve target glucose control.Results: The method achieves an area under the receiver-operating characteristic curve of 0.85 (95% confidence interval [CI], 0.84-0.87) and area under the precision-recall curve of 0.65 (95% CI, 0.64-0.67) for classifying patients who require more than 6 units TDD. For patients requiring more than 6 units TDD, the mean absolute percent error in dose prediction based on standard clinical calculators using patient weight is in the range of 136%-329%, while the regression model based on weight improves to 60% (95% CI, 57%-63%), and the full ensemble model further improves to 51% (95% CI, 48%-54%).Discussion: Owingto the narrow therapeutic window and wide individual variability, insulin dosing requires adaptive and predictive approaches that can be supported through data-driven analytic tools.Conclusions: Machine learning approaches based on readily available electronic medical records can discriminate which inpatients will require more than 6 units TDD and estimate individual doses more accurately than standard guidelines and practices.",,,,,,,,,1,0,0,0,1,0,1,,,1067-5027,1527-974X,,WOS:000745625700018,34279615,
J,"Xu, Zhenxing; Chou, Jingyuan; Zhang, Xi Sheryl; Luo, Yuan; Isakova, Tamara; Adekkanattu, Prakash; Ancker, Jessica S.; Jiang, Guoqian; Kiefer, Richard C.; Pacheco, Jennifer A.; Rasmussen, Luke, V; Pathak, Jyotishman; Wang, Fei",,,,"Luo, Yuan/K-5563-2016","Luo, Yuan/0000-0003-0195-7456",,,Identifying sub-phenotypes of acute kidney injury using structured and unstructured electronic health record data with memory networks,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103361,10.1016/j.jbi.2019.103361,,,,FEB 2020,2020,"Acute Kidney Injury (AKI) is a common clinical syndrome characterized by the rapid loss of kidney excretory function, which aggravates the clinical severity of other diseases in a large number of hospitalized patients. Accurate early prediction of AKI can enable in-time interventions and treatments. However, AKI is highly heterogeneous, thus identification of AKI sub-phenotypes can lead to an improved understanding of the disease pathophysiology and development of more targeted clinical interventions. This study used a memory network-based deep learning approach to discover AKI sub-phenotypes using structured and unstructured electronic health record (EHR) data of patients before AKI diagnosis. We leveraged a real world critical care EHR corpus including 37,486 ICU stays. Our approach identified three distinct sub-phenotypes: sub-phenotype I is with an average age of 63.03 +/- 17.25 years, and is characterized by mild loss of kidney excretory function (Serum Creatinine (SCr) 1.55 +/- 0.34 mg/dL, estimated Glomerular Filtration Rate Test (eGFR) 107.65 +/- 54.98 mL/min/1.73 m(2)). These patients are more likely to develop stage I AKI. Sub-phenotype II is with average age 66.81 +/- 10.43 years, and was characterized by severe loss of kidney excretory function (SCr 1.96 +/- 0.49 mg/dL, eGFR 82.19 +/- 55.92 mL/min/1.73 m(2)). These patients are more likely to develop stage III AKI. Sub-phenotype III is with average age 65.07 +/- 11.32 years, and was characterized moderate loss of kidney excretory function and thus more likely to develop stage II AKI (SCr 1.69 +/- 0.32 mg/dL, eGFR 93.97 +/- 56.53 mL/min/1.73 m(2)). Both SCr and eGFR are significantly different across the three sub-phenotypes with statistical testing plus postdoc analysis, and the conclusion still holds after age adjustment.",,,,,,,,,12,0,0,0,3,0,12,,,1532-0464,1532-0480,,WOS:000525735200007,31911172,
J,"Lu, Shuyu; Chen, Ruoyu; Wei, Wei; Belovsky, Mia; Lu, Xinghua",,,,,,,,Understanding Heart Failure Patients EHR Clinical Features via SHAP Interpretation of Tree-Based Machine Learning Model Predictions.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,813,822,,,,,,2021,2021,"Heart failure (HF) is a major cause of mortality. Accurately monitoring HF progress and adjusting therapies are critical for improving patient outcomes. An experienced cardiologist can make accurate HF stage diagnoses based on combination of symptoms, signs, and lab results from the electronic health records (EHR) of a patient, without directly measuring heart function. We examined whether machine learning models, more specifically the XGBoost model, can accurately predict patient stage based on EHR, and we further applied the SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy. SHAP analyses identified informative features and revealed potential clinical subtypes of HF. Our findings provide insights on how to design computing systems to accurately monitor disease progression of HF patients through continuously mining patients' EHR data.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308970,35308970,
J,"Lou, Sunny S.; Liu, Hanyang; Warner, Benjamin C.; Harford, Derek; Lu, Chenyang; Kannampallil, Thomas",,,,,"Lou, Sunny/0000-0002-4215-605X",,,Predicting physician burnout using clinical activity logs: Model performance and lessons learned,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,104015,10.1016/j.jbi.2022.104015,,,,MAR 2022,2022,"Background: Burnout is a significant public health concern affecting more than half of the healthcare workforce; however, passive screening tools to detect burnout are lacking. We investigated the ability of machine learning (ML) techniques to identify burnout using passively collected electronic health record (EHR)-based audit log data.Method: Physician trainees participated in a longitudinal study where they completed monthly burnout surveys and provided access to their EHR-based audit logs. Using the monthly burnout scores as the target outcome, we trained ML models using combinations of features derived from audit log data-aggregate measures of clinical workload, time series-based temporal measures of EHR use, and the baseline burnout score. Five ML models were constructed to predict burnout as a continuous score: penalized linear regression, support vector machine, neural network, random forest, and gradient boosting machine.Results: 88 trainee physicians participated and completed 416 surveys; greater than10 million audit log actions were collected (Mean [Standard Deviation] = 25,691 [14,331] actions per month, per physician). The workload feature set predicted burnout score with a mean absolute error (MAE) of 0.602 (95% Confidence Interval (CI), 0.412-0.826), and was able to predict burnout status with an average AUROC of 0.595 (95% CI 0.355-0.808) and average accuracy 0.567 (95% CI 0.393-0.742). The temporal feature set had a similar performance, with MAE 0.596 (95% CI 0.391-0.826), and AUROC 0.581 (95% CI 0.343-0.790). The addition of the baseline burnout score to the workload features improved the model performance to a mean AUROC of 0.829 (95% CI 0.607-0.996) and mean accuracy of 0.781 (95% CI 0.587-0.936); however, this performance was not meaningfully different than using the baseline burnout score alone.Conclusions: Current findings illustrate the complexities of predicting burnout exclusively based on clinical work activities as captured in the EHR, highlighting its multi-factorial and individualized nature. Future prediction studies of burnout should account for individual factors (e.g., resilience, physiological measurements such as sleep) and associated system-level factors (e.g., leadership).",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000016,35134568,
J,"Shi, Xue; Yi, Yingping; Xiong, Ying; Tang, Buzhou; Chen, Qingcai; Wang, Xiaolong; Ji, Zongcheng; Zhang, Yaoyun; Xu, Hua",,,,,"Tang, Buzhou/0000-0003-0271-8246",,,Extracting entities with attributes in clinical text via joint deep learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1584,1591,,10.1093/jamia/ocz158,,,,DEC 2019,2019,"Objective: Extracting clinical entities and their attributes is a fundamental task of natural language processing (NLP) in the medical domain. This task is typically recognized as 2 sequential subtasks in a pipeline, clinical entity or attribute recognition followed by entity-attribute relation extraction. One problem of pipeline methods is that errors from entity recognition are unavoidably passed to relation extraction. We propose a novel joint deep learning method to recognize clinical entities or attributes and extract entity-attribute relations simultaneously.Materials and Methods: The proposed method integrates 2 state-of-the-art methods for named entity recognition and relation extraction, namely bidirectional long short-term memory with conditional random field and bidirectional long short-term memory, into a unified framework. In this method, relation constraints between clinical entities and attributes and weights of the 2 subtasks are also considered simultaneously. We compare the method with other related methods (ie, pipeline methods and other joint deep learning methods) on an existing English corpus from SemEval-2015 and a newly developed Chinese corpus.Results: Our proposed method achieves the best F1 of 74.46% on entity recognition and the best F1 of 50.21% on relation extraction on the English corpus, and 89.32% and 88.13% on the Chinese corpora, respectively, which outperform the other methods on both tasks.Conclusions: The joint deep learning-based method could improve both entity recognition and relation extraction from clinical text in both English and Chinese, indicating that the approach is promising.",,,,,,,,,2,1,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000515125300018,31550346,
J,"Datta, Suparno; Sachs, Jan Philipp; Cruz, Harry FreitasDa; Martensen, Tom; Bode, Philipp; Sasso, Ariane Morassi; Glicksberg, Benjamin S.; Boettinger, Erwin",,,,,"Datta, Suparno/0000-0002-2714-3250",,,FIBER: enabling flexible retrieval of electronic health records data for clinical predictive modeling,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab048,10.1093/jamiaopen/ooab048,,,,JUL 2021,2021,"Objectives: The development of clinical predictive models hinges upon the availability of comprehensive clinical data. Tapping into such resources requires considerable effort from clinicians, data scientists, and engineers. Specifically, these efforts are focused on data extraction and preprocessing steps required prior to modeling, including complex database queries. A handful of software libraries exist that can reduce this complexity by building upon data standards. However, a gap remains concerning electronic health records (EHRs) stored in star schema clinical data warehouses, an approach often adopted in practice. In this article, we introduce the FlexIBle EHR Retrieval (FIBER) tool: a Python library built on top of a star schema (i2b2) clinical data warehouse that enables flexible generation of modeling-ready cohorts as data frames.Materials and Methods: FIBER was developed on top of a large-scale star schema EHR database which contains data from 8 million patients and over 120 million encounters. To illustrate FIBER's capabilities, we present its application by building a heart surgery patient cohort with subsequent prediction of acute kidney injury (AKI) with various machine learning models.Results: Using FIBER, we were able to build the heart surgery cohort (n = 12 061), identify the patients that developed AKI (n = 1005), and automatically extract relevant features (n = 774). Finally, we trained machine learning models that achieved area under the curve values of up to 0.77 for this exemplary use case.Conclusion: FIBER is an open-source Python library developed for extracting information from star schema clinical data warehouses and reduces time-to-modeling, helping to streamline the clinical modeling process.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500017,34350388,
J,"Gensheimer, Michael F.; Aggarwal, Sonya; Benson, Kathryn R. K.; Carter, Justin N.; Henry, A. Solomon; Wood, Douglas J.; Soltys, Scott G.; Hancock, Steven; Pollom, Erqi; Shah, Nigam H.; Chang, Daniel T.",,,,,"Gensheimer, Michael/0000-0002-4897-3843; Chang, Daniel/0000-0003-2760-1554; Benson, Kathryn/0000-0003-2440-9495",,,Automated model versus treating physician for predicting survival time of patients with metastatic cancer,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1108,1116,,10.1093/jamia/ocaa290,,,,JUN 2021,2021,"Objective: Being able to predict a patient's life expectancy can help doctors and patients prioritize treatments and supportive care. For predicting life expectancy, physicians have been shown to outperform traditional models that use only a few predictor variables. It is possible that a machine learning model that uses many predictor variables and diverse data sources from the electronic medical record can improve on physicians' performance. For patients with metastatic cancer, we compared accuracy of life expectancy predictions by the treating physician, a machine learning model, and a traditional model.Materials and Methods: A machine learning model was trained using 14 600 metastatic cancer patients' data to predict each patient's distribution of survival time. Data sources included note text, laboratory values, and vital signs. From 2015-2016, 899 patients receiving radiotherapy for metastatic cancer were enrolled in a study in which their radiation oncologist estimated life expectancy. Survival predictions were also made by the machine learning model and a traditional model using only performance status. Performance was assessed with area under the curve for 1-year survival and calibration plots.Results: The radiotherapy study included 1190 treatment courses in 899 patients. A total of 879 treatment courses in 685 patients were included in this analysis. Median overall survival was 11.7 months. Physicians, machine learning model, and traditional model had area under the curve for 1-year survival of 0.72 (95% CI 0.63-0.81), 0.77 (0.73-0.81), and 0.68 (0.65-0.71), respectively.Conclusions: The machine learning model's predictions were more accurate than those of the treating physician or a traditional model.",,,,,,,,,4,0,0,0,0,0,4,,,1067-5027,1527-974X,,WOS:000671031900007,33313792,
J,"Goss, Foster R.; Lai, Kenneth H.; Topaz, Maxim; Acker, Warren W.; Kowalski, Leigh; Plasek, Joseph M.; Blumenthal, Kimberly G.; Seger, Diane L.; Slight, Sarah P.; Fung, Kin Wah; Chang, Frank Y.; Bates, David W.; Zhou, Li",,,,"Topaz, Maxim/AAQ-7121-2021; Blumenthal, Kimberly G./AAG-8290-2019; Bates, David/AAE-7283-2019; Plasek, Joseph/AAI-8263-2020","Topaz, Maxim/0000-0002-2358-9837; Plasek, Joseph/0000-0002-9686-3876; Slight, Sarah P/0000-0002-0339-846X",,,A value set for documenting adverse reactions in electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,6,,,661,669,,10.1093/jamia/ocx139,,,,JUN 2018,2018,"Objective: To develop a comprehensive value set for documenting and encoding adverse reactions in the allergy module of an electronic health record.Materials and Methods: We analyzed 2 471 004 adverse reactions stored in Partners Healthcare's Enterprise-wide Allergy Repository (PEAR) of 2.7 million patients. Using the Medical Text Extraction, Reasoning, and Mapping System, we processed both structured and free-text reaction entries and mapped them to Systematized Nomenclature of Medicine -Clinical Terms. We calculated the frequencies of reaction concepts, including rare, severe, and hypersensitivity reactions. We compared PEAR concepts to a Federal Health Information Modeling and Standards value set and University of Nebraska Medical Center data, and then created an integrated value set.Results: We identified 787 reaction concepts in PEAR. Frequently reported reactions included: rash (14.0%), hives (8.2%), gastrointestinal irritation (5.5%), itching (3.2%), and anaphylaxis (2.5%). We identified an additional 320 concepts from Federal Health Information Modeling and Standards and the University of Nebraska Medical Center to resolve gaps due to missing and partial matches when comparing these external resources to PEAR. This yielded 1106 concepts in our final integrated value set. The presence of rare, severe, and hypersensitivity reactions was limited in both external datasets. Hypersensitivity reactions represented roughly 20% of the reactions within our data.Discussion: We developed a value set for encoding adverse reactions using a large dataset from one health system, enriched by reactions from 2 large external resources. This integrated value set includes clinically important severe and hypersensitivity reactions.Conclusion: This work contributes a value set, harmonized with existing data, to improve the consistency and accuracy of reaction documentation in electronic health records, providing the necessary building blocks for more intelligent clinical decision support for allergies and adverse reactions.",,,,,,,,,16,0,0,0,5,0,16,,,1067-5027,1527-974X,,WOS:000434113600007,29253169,
J,"Percha, Bethany; Pisapati, Kereeti; Gao, Cynthia; Schmidt, Hank",,,,,,,,Natural language inference for curation of structured clinical registries from unstructured text,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,1,,,97,108,,10.1093/jamia/ocab243,,NOV 2021,,JAN 2021,2021,"Objective: Clinical registries-structured databases of demographic, diagnosis, and treatment information-play vital roles in retrospective studies, operational planning, and assessment of patient eligibility for research, including clinical trials. Registry curation, a manual and time-intensive process, is always costly and often impossible for rare or underfunded diseases. Our goal was to evaluate the feasibility of natural language inference (NLI) as a scalable solution for registry curation.Materials and Methods: We applied five state-of-the-art, pretrained, deep learning-based NLI models to clinical, laboratory, and pathology notes to infer information about 43 different breast oncology registry fields. Model inferences were evaluated against a manually curated, 7439 patient breast oncology research database.Results: NLI models showed considerable variation in performance, both within and across fields. One model, ALBERT, outperformed the others (BART, RoBERTa, XLNet, and ELECTRA) on 22 out of 43 fields. A detailed error analysis revealed that incorrect inferences primarily arose through models' tendency to misinterpret historical findings, as well as confusion based on abbreviations and subtle term variants common in clinical text.Discussion and Conclusion: Traditional natural language processing methods require specially annotated training sets or the construction of a separate model for each registry field. In contrast, a single pretrained NLI model can curate dozens of different fields simultaneously. Surprisingly, NLI methods remain unexplored in the clinical domain outside the realm of shared tasks and benchmarks. Modern NLI models could increase the efficiency of registry curation, even when applied out of the box with no additional training.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000740719600012,34791282,
J,"Tong, Jiayi; Huang, Jing; Chubak, Jessica; Wang, Xuan; Moore, Jason H.; Hubbard, Rebecca A.; Chen, Yong",,,,"Moore, Jason H./AAV-9645-2021; Wang, Xuan/AAY-7642-2021; Wang, Xuan/AAR-2888-2021; Hubbard, Rebecca/Y-6500-2019","Moore, Jason H./0000-0002-5015-1099; Wang, Xuan/0000-0002-0011-5663; Hubbard, Rebecca/0000-0003-0879-0994",,,An augmented estimation procedure for EHR-based association studies accounting for differential misclassification,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,244,253,,10.1093/jamia/ocz180,,,,FEB 2020,2020,"Objectives: The ability to identify novel risk factors for health outcomes is a key strength of electronic health record (EHR)-based research. However, the validity of such studies is limited by error in EHR-derived phenotypes. The objective of this study was to develop a novel procedure for reducing bias in estimated associations between risk factors and phenotypes in EHR data.Materials and Methods: The proposed method combines the strengths of a gold-standard phenotype obtained through manual chart review for a small validation set of patients and an automatically-derived phenotype that is available for all patients but is potentially error-prone (hereafter referred to as the algorithm-derived phenotype). An augmented estimator of associations is obtained by optimally combining these 2 phenotypes. We conducted simulation studies to evaluate the performance of the augmented estimator and conducted an analysis of risk factors for second breast cancer events using data on a cohort from Kaiser Permanente Washington.Results: The proposed method was shown to reduce bias relative to an estimator using only the algorithm-derived phenotype and reduce variance compared to an estimator using only the validation data.Discussion: Our simulation studies and real data application demonstrate that, compared to the estimator using validation data only, the augmented estimator has lower variance (ie, higher statistical efficiency). Compared to the estimator using error-prone EHR-derived phenotypes, the augmented estimator has smaller bias.Conclusions: The proposed estimator can effectively combine an error-prone phenotype with gold-standard data from a limited chart review in order to improve analyses of risk factors using EHR data.",,,,,,,,,3,0,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000515121300008,31617899,
J,"Moramarco, Francesco; Juric, Damir; Savkov, Aleksandar; Flann, Jack; Lehl, Maria; Boda, Kristian; Grafen, Tessa; Zhelezniak, Vitalii; Gohil, Sunir; Korfiatis, Alex Papadopoulos; Hammerla, Nils",,,,,,,,Towards more patient friendly clinical notes through language models and ontologies.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,881,890,,,,,,2021,2021,"Clinical notes are an efficient way to record patient information but are notoriously hard to decipher for non-experts. Automatically simplifying medical text can empower patients with valuable information about their health, while saving clinicians time. We present a novel approach to automated simplification of medical text based on word frequencies and language modelling, grounded on medical ontologies enriched with layman terms. We release a new dataset of pairs of publicly available medical sentences and a version of them simplified by clinicians. Also, we define a novel text simplification metric and evaluation framework, which we use to conduct a large-scale human evaluation of our method against the state of the art. Our method based on a language model trained on medical forum data generates simpler sentences while preserving both grammar and the original meaning, surpassing the current state of the art.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308976,35308976,
J,"He, Jianqin; Hu, Yong; Zhang, Xiangzhou; Wu, Lijuan; Waitman, Lemuel R.; Liu, Mei",,,,"Zhang, Xiangzhou/N-3699-2013","Zhang, Xiangzhou/0000-0003-3752-0045",,,Multi-perspective predictive modeling for acute kidney injury in general hospital populations using electronic medical records,,,,,,,,JAMIA OPEN,,,,2,1,,,115,122,,10.1093/jamiaopen/ooy043,,,,APR 2019,2019,"Objectives: Acute kidney injury (AKI) in hospitalized patients puts them at much higher risk for developing future health problems such as chronic kidney disease, stroke, and heart disease. Accurate AKI prediction would allow timely prevention and intervention. However, current AKI prediction researches pay less attention to model building strategies that meet complex clinical application scenario. This study aims to build and evaluate AKI prediction models from multiple perspectives that reflect different clinical applications.Materials and Methods: A retrospective cohort of 76 957 encounters and relevant clinical variables were extracted from a tertiary care, academic hospital electronic medical record (EMR) system between November 2007 and December 2016. Five machine learning methods were used to build prediction models. Prediction tasks from 4 clinical perspectives with different modeling and evaluation strategies were designed to build and evaluate the models.Results: Experimental analysis of the AKI prediction models built from 4 different clinical perspectives suggest a realistic prediction performance in cross-validated area under the curve ranging from 0.720 to 0.764.Discussion: Results show that models built at admission is effective for predicting AKI events in the next day; models built using data with a fixed lead time to AKI onset is still effective in the dynamic clinical application scenario in which each patient's lead time to AKI onset is different.Conclusion: To our best knowledge, this is the first systematic study to explore multiple clinical perspectives in building predictive models for AKI in the general inpatient population to reflect real performance in clinical application.",,,,,,,,,6,1,0,0,1,0,7,,,,2574-2531,,WOS:000645417700016,30976758,
J,"Huang, Jing; Duan, Rui; Hubbard, Rebecca A.; Wu, Yonghui; Moore, Jason H.; Xu, Hua; Chen, Yong",,,,"Hubbard, Rebecca/Y-6500-2019; Moore, Jason H./AAV-9645-2021","Hubbard, Rebecca/0000-0003-0879-0994; Moore, Jason H./0000-0002-5015-1099",,,PIE: A prior knowledge guided integrated likelihood estimation method for bias reduction in association studies using electronic health records data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,3,,,345,352,,10.1093/jamia/ocx137,,,,MAR 2018,2018,"This study proposes a novel Prior knowledge guided Integrated likelihood Estimation (PIE) method to correct bias in estimations of associations due to misclassification of electronic health record (EHR)-derived binary phenotypes, and evaluates the performance of the proposed method by comparing it to 2 methods in common practice.We conducted simulation studies and data analysis of real EHR-derived data on diabetes from Kaiser Permanente Washington to compare the estimation bias of associations using the proposed method, the method ignoring phenotyping errors, the maximum likelihood method with misspecified sensitivity and specificity, and the maximum likelihood method with correctly specified sensitivity and specificity (gold standard). The proposed method effectively leverages available information on phenotyping accuracy to construct a prior distribution for sensitivity and specificity, and incorporates this prior information through the integrated likelihood for bias reduction.Our simulation studies and real data application demonstrated that the proposed method effectively reduces the estimation bias compared to the 2 current methods. It performed almost as well as the gold standard method when the prior had highest density around true sensitivity and specificity. The analysis of EHR data from Kaiser Permanente Washington showed that the estimated associations from PIE were very close to the estimates from the gold standard method and reduced bias by 60%-100% compared to the 2 commonly used methods in current practice for EHR data.This study demonstrates that the proposed method can effectively reduce estimation bias caused by imperfect phenotyping in EHR-derived data by incorporating prior information through integrated likelihood.",,,,,,,,,5,0,0,0,4,0,5,,,1067-5027,1527-974X,,WOS:000426850500017,29206922,
J,"Hripcsak, George; Shang, Ning; Peissig, Peggy L.; Rasmussen, Luke, V; Liu, Cong; Benoit, Barbara; Carroll, Robert J.; Carrell, David S.; Denny, Joshua C.; Dikilitas, Ozan; Gainer, Vivian S.; Howell, Kayla Marie; Klann, Jeffrey G.; Kullo, Iftikhar J.; Lingren, Todd; Mentch, Frank D.; Murphy, Shawn N.; Natarajan, Karthik; Pacheco, Jennifer A.; Wei, Wei-Qi; Wiley, Ken; Weng, Chunhua",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Rasmussen, Luke/0000-0002-4497-8049; Carrell, David S./0000-0002-8471-0928",,,Facilitating phenotype transfer using a common data model,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,96,,,,,,103253,10.1016/j.jbi.2019.103253,,,,AUG 2019,2019,"Background: Implementing clinical phenotypes across a network is labor intensive and potentially error prone. Use of a common data model may facilitate the process.Methods: Electronic Medical Records and Genomics (eMERGE) sites implemented the Observational Health Data Sciences and Informatics (OHDSI) Observational Medical Outcomes Partnership (OMOP) Common Data Model across their electronic health record (EHR)-linked DNA biobanks. Two previously implemented eMERGE phenotypes were converted to OMOP and implemented across the network.Results: It was feasible to implement the common data model across sites, with laboratory data producing the greatest challenge due to local encoding. Sites were then able to execute the OMOP phenotype in less than one day, as opposed to weeks of effort to manually implement an eMERGE phenotype in their bespoke research EHR databases. Of the sites that could compare the current OMOP phenotype implementation with the original eMERGE phenotype implementation, specific agreement ranged from 100% to 43%, with disagreements due to the original phenotype, the OMOP phenotype, changes in data, and issues in the databases. Using the OMOP query as a standard comparison revealed differences in the original implementations despite starting from the same definitions, code lists, flowcharts, and pseudocode.Conclusion: Using a common data model can dramatically speed phenotype implementation at the cost of having to populate that data model, though this will produce a net benefit as the number of phenotype implementations increases. Inconsistencies among the implementations of the original queries point to a potential benefit of using a common data model so that actual phenotype code and logic can be shared, mitigating human error in reinterpretation of a narrative phenotype definition.",,,,,,,,,22,0,0,0,7,0,22,,,1532-0464,1532-0480,,WOS:000525698100005,31325501,
J,"Schwartz, Jessica M.; Moy, Amanda J.; Rossetti, Sarah C.; Elhadad, Noemie; Cato, Kenrick D.",,,,,"Schwartz, Jessica/0000-0002-1457-5724; Rossetti, Sarah/0000-0003-2632-8867",,,Clinician involvement in research on machine learning-based predictive clinical decision support for the hospital setting: A scoping review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,653,663,,10.1093/jamia/ocaa296,,,,MAR 2021,2021,"Objective: The study sought to describe the prevalence and nature of clinical expert involvement in the development, evaluation, and implementation of clinical decision support systems (CDSSs) that utilize machine learning to analyze electronic health record data to assist nurses and physicians in prognostic and treatment decision making (ie, predictive CDSSs) in the hospital.Materials and Methods: A systematic search of PubMed, CINAHL, and IEEE Xplore and hand-searching of relevant conference proceedings were conducted to identify eligible articles. Empirical studies of predictive CDSSs using electronic health record data for nurses or physicians in the hospital setting published in the last 5 years in peer-reviewed journals or conference proceedings were eligible for synthesis. Data from eligible studies regarding clinician involvement, stage in system design, predictive CDSS intention, and target clinician were charted and summarized.Results: Eighty studies met eligibility criteria. Clinical expert involvement was most prevalent at the beginning and late stages of system design. Most articles (95%) described developing and evaluating machine learning models, 28% of which described involving clinical experts, with nearly half functioning to verify the clinical correctness or relevance of the model (47%). Discussion: Involvement of clinical experts in predictive CDSS design should be explicitly reported in publications and evaluated for the potential to overcome predictive CDSS adoption challenges.Conclusions: If present, clinical expert involvement is most prevalent when predictive CDSS specifications are made or when system implementations are evaluated. However, clinical experts are less prevalent in developmental stages to verify clinical correctness, select model features, preprocess data, or serve as a gold standard.",,,,,,,,,7,0,0,0,0,0,7,,,1067-5027,1527-974X,,WOS:000637314400029,33325504,
J,"Koenig, Maximilian; Sander, Andre; Demuth, Ilja; Diekmann, Daniel; Steinhagen-Thiessen, Elisabeth",,,,"Demuth, Ilja/ABD-5352-2021; König, Maximilian/AAD-8221-2021","Demuth, Ilja/0000-0002-4340-2523; König, Maximilian/0000-0003-4873-5519",,,Knowledge-based best of breed approach for automated detection of clinical events based on German free text digital hospital discharge letters,,,,,,,,PLOS ONE,,,,14,11,,,,,e0224916,10.1371/journal.pone.0224916,,,,NOV 27 2019,2019,"ObjectivesThe secondary use of medical data contained in electronic medical records, such as hospital discharge letters, is a valuable resource for the improvement of clinical care (e.g. in terms of medication safety) or for research purposes. However, the automated processing and analysis of medical free text still poses a huge challenge to available natural language processing (NLP) systems. The aim of this study was to implement a knowledge-based best of breed approach, combining a terminology server with integrated ontology, a NLP pipeline and a rules engine.MethodsWe tested the performance of this approach in a use case. The clinical event of interest was the particular drug-disease interaction proton-pump inhibitor [PPI] use and osteoporosis. Cases were to be identified based on free text digital discharge letters as source of information. Automated detection was validated against a gold standard.ResultsPrecision of recognition of osteoporosis was 94.19%, and recall was 97.45%. PPIs were detected with 100% precision and 97.97% recall. The F-score for the detection of the given drug-disease-interaction was 96,13%.ConclusionWe could show that our approach of combining a NLP pipeline, a terminology server, and a rules engine for the purpose of automated detection of clinical events such as drug-disease interactions from free text digital hospital discharge letters was effective. There is huge potential for the implementation in clinical and research contexts, as this approach enables analyses of very high numbers of medical free text documents within a short time period.",,,,,,,,,3,0,0,0,1,0,3,,,1932-6203,,,WOS:000533896400020,31774830,
J,"Bhattacharya, Moumita; Jurkovitz, Claudine; Shatkay, Hagit",,,,,"Jurkovitz, Claudine/0000-0002-8957-0100",,,Co-occurrence of medical conditions: Exposing patterns through probabilistic topic modeling of snomed codes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,82,,,,31,40,,10.1016/j.jbi.2018.04.008,,,,JUN 2018,2018,"Patients associated with multiple co-occurring health conditions often face aggravated complications and less favorable outcomes. Co-occurring conditions are especially prevalent among individuals suffering from kidney disease, an increasingly widespread condition affecting 13% of the general population in the US. This study aims to identify and characterize patterns of co-occurring medical conditions in patients employing a probabilistic framework. Specifically, we apply topic modeling in a non-traditional way to find associations across SNOMED-CT codes assigned and recorded in the EHRs of > 13,000 patients diagnosed with kidney disease. Unlike most prior work on topic modeling, we apply the method to codes rather than to natural language. Moreover, we quantitatively evaluate the topics, assessing their tightness and distinctiveness, and also assess the medical validity of our results. Our experiments show that each topic is succinctly characterized by a few highly probable and unique disease codes, indicating that the topics are tight. Furthermore, inter-topic distance between each pair of topics is typically high, illustrating distinctiveness. Last, most coded conditions grouped together within a topic, are indeed reported to co-occur in the medical literature. Notably, our results uncover a few indirect associations among conditions that have hitherto not been reported as correlated in the medical literature.",,,,,,,,,3,0,0,0,2,0,3,,,1532-0464,1532-0480,,WOS:000445054600003,29655947,
J,"Parthipan, Arjun; Banerjee, Imon; Humphreys, Keith; Asch, Steven M.; Curtin, Catherine; Carroll, Ian; Hernandez-Boussard, Tina",,,,,"Hernandez-Boussard, Tina/0000-0001-6553-3455",,,Predicting inadequate postoperative pain management in depressed patients: A machine learning approach,,,,,,,,PLOS ONE,,,,14,2,,,,,e0210575,10.1371/journal.pone.0210575,,,,FEB 6 2019,2019,"Widely-prescribed prodrug opioids (e.g., hydrocodone) require conversion by liver enzyme CYP-2D6 to exert their analgesic effects. The most commonly prescribed antidepressant, selective serotonin reuptake inhibitors (SSRIs), inhibits CYP-2D6 activity and therefore may reduce the effectiveness of prodrug opioids. We used a machine learning approach to identify patients prescribed a combination of SSRIs and prodrug opioids postoperatively and to examine the effect of this combination on postoperative pain control. Using EHR data from an academic medical center, we identified patients receiving surgery over a 9-year period. We developed and validated natural language processing (NLP) algorithms to extract depression-related information (diagnosis, SSRI use, symptoms) from structured and unstructured data elements. The primary outcome was the difference between preoperative pain score and postoperative pain at discharge, 3-week and 8-week time points. We developed computational models to predict the increase or decrease in the postoperative pain across the 3 time points by using the patient's EHR data (e.g. medications, vitals, demographics) captured before surgery. We evaluate the generalizability of the model using 10-fold cross-validation method where the holdout test method is repeated 10 times and mean area-under-the-curve (AUC) is considered as evaluation metrics for the prediction performance. We identified 4,306 surgical patients with symptoms of depression. A total of 14.1% were prescribed both an SSRI and a prodrug opioid, 29.4% were prescribed an SSRI and a non-prodrug opioid, 18.6% were prescribed a prodrug opioid but were not on SSRIs, and 37.5% were prescribed a non-prodrug opioid but were not on SSRIs. Our NLP algorithm identified depression with a F1 score of 0.95 against manual annotation of 300 randomly sampled clinical notes. On average, patients receiving prodrug opioids had lower average pain scores (p<0.05), with the exception of the SSRI+ group at 3-weeks postoperative follow-up. However, SSRI+/Prodrug+ had significantly worse pain control at discharge, 3 and 8-week follow-up (p < .01) compared to SSRI+/Prodrug- patients, whereas there was no difference in pain control among the SSRI- patients by prodrug opioid (p>0.05). The machine learning algorithm accurately predicted the increase or decrease of the discharge, 3-week and 8-week follow-up pain scores when compared to the pre-operative pain score using 10-fold cross validation (mean area under the receiver operating characteristic curve 0.87, 0.81, and 0.69, respectively). Preoperative pain, surgery type, and opioid tolerance were the strongest predictors of postoperative pain control. We provide the first direct clinical evidence that the known ability of SSRIs to inhibit prodrug opioid effectiveness is associated with worse pain control among depressed patients. Current prescribing patterns indicate that prescribers may not account for this interaction when choosing an opioid. The study results imply that prescribers might instead choose direct acting opioids (e.g. oxycodone or morphine) in depressed patients on SSRIs.",,,,,,,,,21,1,0,0,7,0,22,,,1932-6203,,,WOS:000457874000021,30726237,
J,"Betts, Kim S.; Kisely, Steve; Alati, Rosa",,,,,,,,Predicting neonatal respiratory distress syndrome and hypoglycaemia prior to discharge: Leveraging health administrative data and machine learning,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,114,,,,,,103651,10.1016/j.jbi.2020.103651,,JAN 2021,,FEB 2021,2021,"Objectives: A major challenge for hospitals and clinicians is the early identification of neonates at risk of developing adverse conditions. We develop a model based on routinely collected administrative data, which accurately predicts two common disorders among early term and preterm (<39 weeks) neonates prior to discharge. Study design. The data included all inpatient live births born prior to 39 weeks (n = 154,755) occurring in the Australian state of Queensland between January 2009 and December 2015. Predictor variables included all maternal data captured in administrative records from the beginning of gestation up to, and including, the delivery, as well as neonatal data recorded at the delivery. Gradient boosted trees were used to predict neonatal respiratory distress syndrome and hypoglycaemia prior to discharge, with model performance benchmarked against a logistic regression models. Results: The gradient boosted trees model achieved very high discrimination for respiratory distress syndrome [AUC = 0.923, 95% CI (0.917, 0.928)] and good discrimination for hypoglycaemia [AUC = 0.832, 95% CI (0.827, 0.837)] in the validation data, as well as outperforming the logistic regression models. Conclusion: Our study suggests that routinely collected health data have the potential to play an important role in assisting clinicians to identify neonates at risk of developing selected disorders shortly after birth. Despite achieving high levels of discrimination, many issues remain before such models can be implemented in practice, which we discuss in relation to our findings.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000695470600004,33285308,
J,"Coombes, Caitlin E.; Liu, Xin; Abrams, Zachary B.; Coombes, Kevin R.; Brock, Guy",,,,,,,,Simulation-derived best practices for clustering clinical data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,118,,,,,,103788,10.1016/j.jbi.2021.103788,,MAY 2021,,JUN 2021,2021,"Introduction: Clustering analyses in clinical contexts hold promise to improve the understanding of patient phenotype and disease course in chronic and acute clinical medicine. However, work remains to ensure that solutions are rigorous, valid, and reproducible. In this paper, we evaluate best practices for dissimilarity matrix calculation and clustering on mixed-type, clinical data.Methods: We simulate clinical data to represent problems in clinical trials, cohort studies, and EHR data, including single-type datasets (binary, continuous, categorical) and 4 data mixtures. We test 5 single distance metrics (Jaccard, Hamming, Gower, Manhattan, Euclidean) and 3 mixed distance metrics (DAISY, Supersom, and Mercator) with 3 clustering algorithms (hierarchical (HC), k-medoids, self-organizing maps (SOM)). We quantitatively and visually validate by Adjusted Rand Index (ARI) and silhouette width (SW). We applied our best methods to two real-world data sets: (1) 21 features collected on 247 patients with chronic lymphocytic leukemia, and (2) 40 features collected on 6000 patients admitted to an intensive care unit.Results: HC outperformed k-medoids and SOM by ARI across data types. DAISY produced the highest mean ARI for mixed data types for all mixtures except unbalanced mixtures dominated by continuous data. Compared to other methods, DAISY with HC uncovered superior, separable clusters in both real-world data sets.Discussion: Selecting an appropriate mixed-type metric allows the investigator to obtain optimal separation of patient clusters and get maximum use of their data. Superior metrics for mixed-type data handle multiple data types using multiple, type-focused distances. Better subclassification of disease opens avenues for targeted treatments, precision medicine, clinical decision support, and improved patient outcomes.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000663600500016,33862229,
J,"Wang, Junjie; Yu, Shun; Davoudi, Anahita; Mowery, Danielle L",,,,,,,,A Preliminary Characterization of Canonicalized and Non-Canonicalized Section Headers Across Variable Clinical Note Types.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1268,1276,,,,,,2020,2020,"In the electronic health record, the majority of clinically relevant information is stored within clinical notes. Most clinical notes follow a set organizational structure composed of canonicalized section headers that facilitate clinical review and information gathering. Standardized section header terminologies such as the SecTag terminology permit the identification and standardization of headers to a canonicalized form. Although the SecTag terminology has been evaluated extensively for history & physical notes, the coverage of canonical section header terms has not been assessed across other note types. For this pilot study, we conducted a coverage study and characterization of canonical section headers across 5 common, clinical note types and a generalizability study of canonical section headers detected within two types of clinical notes from Penn Medicine.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936503,33936503,
J,"Almeida, Joao Rafael; Silva, Joao Figueira; Matos, Sergio; Oliveira, Jose Luis",,,,,,,,A two-stage workflow to extract and harmonize drug mentions from clinical notes into observational databases,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,120,,,,,,103849,10.1016/j.jbi.2021.103849,,JUL 2021,,AUG 2021,2021,"Background: The content of the clinical notes that have been continuously collected along patients' health history has the potential to provide relevant information about treatments and diseases, and to increase the value of structured data available in Electronic Health Records (EHR) databases. EHR databases are currently being used in observational studies which lead to important findings in medical and biomedical sciences. However, the information present in clinical notes is not being used in those studies, since the computational analysis of this unstructured data is much complex in comparison to structured data. Methods: We propose a two-stage workflow for solving an existing gap in Extraction, Transformation and Loading (ETL) procedures regarding observational databases. The first stage of the workflow extracts prescriptions present in patient's clinical notes, while the second stage harmonises the extracted information into their standard definition and stores the resulting information in a common database schema used in observational studies. Results: We validated this methodology using two distinct data sets, in which the goal was to extract and store drug related information in a new Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) database. We analysed the performance of the used annotator as well as its limitations. Finally, we described some practical examples of how users can explore these datasets once migrated to OMOP CDM databases. Conclusion: With this methodology, we were able to show a strategy for using the information extracted from the clinical notes in business intelligence tools, or for other applications such as data exploration through the use of SQL queries. Besides, the extracted information complements the data present in OMOP CDM databases which was not directly available in the EHR database.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000683527500007,34214696,
J,"Kong, Jun; Zhang, Leixin; Jiang, Min; Liu, Tianshan",,,,,,,,Incorporating multi-level CNN and attention mechanism for Chinese clinical named entity recognition,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,116,,,,,,103737,10.1016/j.jbi.2021.103737,,MAR 2021,,APR 2021,2021,"Named entity recognition (NER) is a fundamental task in Chinese natural language processing (NLP) tasks. Recently, Chinese clinical NER has also attracted continuous research attention because it is an essential preparation for clinical data mining. The prevailing deep learning method for Chinese clinical NER is based on long short-term memory (LSTM) network. However, the recurrent structure of LSTM makes it difficult to utilize GPU parallelism which to some extent lowers the efficiency of models. Besides, when the sentence is long, LSTM can hardly capture global context information. To address these issues, we propose a novel and efficient model completely based on convolutional neural network (CNN) which can fully utilize GPU parallelism to improve model efficiency. Moreover, we construct multi-level CNN to capture short-term and long-term context information. We also design a simple attention mechanism to obtain global context information which is conductive to improving model performance in sequence labeling tasks. Besides, a data augmentation method is proposed to expand the data volume and try to explore more semantic information. Extensive experiments show that our model achieves competitive performance with higher efficiency compared with other remarkable clinical NER models.",,,,,,,,,3,0,0,0,0,0,3,,,1532-0464,1532-0480,,WOS:000640446800012,33737207,
J,"Yang, Xi; Bian, Jiang; Hogan, William R.; Wu, Yonghui",,,,,"Hogan, William/0000-0002-9881-1017",,,Clinical concept extraction using transformers,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1935,1942,,10.1093/jamia/ocaa189,,,,DEC 2020,2020,"Objective: The goal of this study is to explore transformer-based models (eg, Bidirectional Encoder Representations from Transformers [BERT]) for clinical concept extraction and develop an open-source package with pretrained clinical models to facilitate concept extraction and other downstream natural language processing (NLP) tasks in the medical domain.Methods: We systematically explored 4 widely used transformer-based architectures, including BERT, RoBERTa, ALBERT, and ELECTRA, for extracting various types of clinical concepts using 3 public datasets from the 2010 and 2012 i2b2 challenges and the 2018 n2c2 challenge. We examined general transformer models pretrained using general English corpora as well as clinical transformer models pretrained using a clinical corpus and compared them with a long short-term memory conditional random fields (LSTM-CRFs) mode as a baseline. Furthermore, we integrated the 4 clinical transformer-based models into an open-source package.Results and Conclusion: The RoBERTa-MIMIC model achieved state-of-the-art performance on 3 public clinical concept extraction datasets with F1-scores of 0.8994, 0.8053, and 0.8907, respectively. Compared to the baseline LSTM-CRFs model, RoBERTa-MIMIC remarkably improved the F1-score by approximately 4% and 6% on the 2010 and 2012 i2b2 datasets. This study demonstrated the efficiency of transformer-based models for clinical concept extraction. Our methods and systems can be applied to other clinical tasks. The clinical transformer package with 4 pretrained clinical models is publicly available at https://github.com/uf-hobi-informatics-lab/ClinicalTransformerNER. We believe this package will improve current practice on clinical concept extraction and other tasks in the medical domain.",,,,,,,,,10,0,0,0,4,0,10,,,1067-5027,1527-974X,,WOS:000606832500013,33120431,
J,"Kwak, Heeyoung; Chang, Jooyoung; Choe, Byeongjin; Park, Sangmin; Jung, Kyomin",,,,,,,,Interpretable disease prediction using heterogeneous patient records with self-attentive fusion encoder,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2155,2164,,10.1093/jamia/ocab109,,JUL 2021,,OCT 2021,2021,"Objective: We propose an interpretable disease prediction model that efficiently fuses multiple types of patient records using a self-attentive fusion encoder. We assessed the model performance in predicting cardiovascular disease events, given the records of a general patient population.Materials and Methods: We extracted 7981 1 1 ses and 67 623 controls from the sample cohort database and nationwide healthcare claims data of South Korea. Among the information provided, our model used the sequential records of medical codes and patient characteristics, such as demographic profiles and the most recent health examination results. These two types of patient records were combined in our self-attentive fusion module, whereas previously dominant methods aggregated them using a simple concatenation. The prediction performance was compared to state-of-the-art recurrent neural network-based approaches and other widely used machine learning approaches.Results: Our model outperformed all the other compared methods in predicting cardiovascular disease events. It achieved an area under the curve of 0.839, while the other compared methods achieved between 0.74111 d 0.830. Moreover, our model consistently outperformed the other methods in a more challenging setting in which we tested the model's ability to draw an inference from more nonobvious, diverse factors.Discussion: We also interpreted the attention weights provided by our model as the relative importance of each time step in the sequence. We showed that our model reveals the informative parts of the patients' history by measuring the attention weights.Conclusion: We suggest an interpretable disease prediction model that efficiently fuses heterogeneous patient records and demonstrates superior disease prediction performance.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000745625700012,34198329,
J,"Kulshrestha, Sujay; Dligach, Dmitriy; Joyce, Cara; Gonzalez, Richard; O'Rourke, Ann P.; Glazer, Joshua M.; Stey, Anne; Kruser, Jacqueline M.; Churpek, Matthew M.; Afshar, Majid",,,,,"Kulshrestha, Sujay/0000-0002-2074-4010",,,Comparison and interpretability of machine learning models to predict severity of chest injury,,,,,,,,JAMIA OPEN,,,,4,1,,,,,ooab015,10.1093/jamiaopen/ooab015,,MAR 2021,,JAN 2021,2021,"Objective: Trauma quality improvement programs and registries improve care and outcomes for injured patients. Designated trauma centers calculate injury scores using dedicated trauma registrars; however, many injuries arrive at nontrauma centers, leaving a substantial amount of data uncaptured. We propose automated methods to identify severe chest injury using machine learning (ML) and natural language processing (NLP) methods from the electronic health record (EHR) for quality reporting.Materials and Methods: A level I trauma center was queried for patients presenting after injury between 2014 and 2018. Prediction modeling was performed to classify severe chest injury using a reference dataset labeled by certified registrars. Clinical documents from trauma encounters were processed into concept unique identifiers for inputs to ML models: logistic regression with elastic net (EN) regularization, extreme gradient boosted (XGB) machines, and convolutional neural networks (CNN). The optimal model was identified by examining predictive and face validity metrics using global explanations.Results: Of 8952 encounters, 542 (6.1%) had a severe chest injury. CNN and EN had the highest discrimination, with an area under the receiver operating characteristic curve of 0.93 and calibration slopes between 0.88 and 0.97. CNN had better performance across risk thresholds with fewer discordant cases. Examination of global explanations demonstrated the CNN model had better face validity, with top features including contusion of lung and hemopneumothorax. Discussion: The CNN model featured optimal discrimination, calibration, and clinically relevant features selected.Conclusion: NLP and ML methods to populate trauma registries for quality analyses are feasible.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731860400013,33709067,
J,"Deferio, Joseph J.; Breitinger, Scott; Khullar, Dhruv; Sheth, Amit; Pathak, Jyotishman",,,,"Sheth, Amit/ABC-4600-2020","Sheth, Amit/0000-0002-0021-5293",,,Social determinants of health in mental health care and research: a case for greater inclusion,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,8-9,,,895,899,,10.1093/jamia/ocz049,,,,AUG-SEP 2019,2019,"Social determinants of health (SDOH) are known to influence mental health outcomes, which are independent risk factors for poor health status and physical illness. Currently, however, existing SDOH data collection methods are ad hoc and inadequate, and SDOH data are not systematically included in clinical research or used to inform patient care. Social contextual data are rarely captured prospectively in a structured and comprehensive manner, leaving large knowledge gaps. Extraction methods are now being developed to facilitate the collection, standardization, and integration of SDOH data into electronic health records. If successful, these efforts may have implications for health equity, such as reducing disparities in access and outcomes. Broader use of surveys, natural language processing, and machine learning methods to harness SDOH may help researchers and clinical teams reduce barriers to mental health care.",,,,,,,,,7,0,0,0,1,0,7,,,1067-5027,1527-974X,,WOS:000493114800024,31329877,
J,"Bean, Daniel M.; Teo, James; Wu, Honghan; Oliveira, Ricardo; Patel, Raj; Bendayan, Rebecca; Shah, Ajay M.; Dobson, Richard J. B.; Scott, Paul A.",,,,"Bean, Daniel/AFQ-4601-2022; Teo, James T/ABA-1819-2020; Wu, Honghan/AAT-6084-2020; Teo, James T/D-9696-2011; dobson, richard/C-9269-2011","Teo, James T/0000-0002-6899-8319; Teo, James T/0000-0002-6899-8319; Bendayan, Rebecca/0000-0003-1461-556X; Wu, Honghan/0000-0002-0213-5668; Bean, Daniel/0000-0002-8594-7804; Shah, Ajay/0000-0002-6547-0631; dobson, richard/0000-0003-4224-9245",,,Semantic computational analysis of anticoagulation use in atrial fibrillation from real world data,,,,,,,,PLOS ONE,,,,14,11,,,,,e0225625,10.1371/journal.pone.0225625,,,,NOV 25 2019,2019,"Atrial fibrillation (AF) is the most common arrhythmia and significantly increases stroke risk. This risk is effectively managed by oral anticoagulation. Recent studies using national registry data indicate increased use of anticoagulation resulting from changes in guidelines and the availability of newer drugs. The aim of this study is to develop and validate an open source risk scoring pipeline for free-text electronic health record data using natural language processing. AF patients discharged from 1(st) January 2011 to 1(st) October 2017 were identified from discharge summaries (N = 10,030, 64.6% male, average age 75.3 +/- 12.3 years). A natural language processing pipeline was developed to identify risk factors in clinical text and calculate risk for ischaemic stroke (CHA(2)DS(2)-VASc) and bleeding (HAS-BLED). Scores were validated vs two independent experts for 40 patients. Automatic risk scores were in strong agreement with the two independent experts for CHA(2)DS(2)-VASc (average kappa 0.78 vs experts, compared to 0.85 between experts). Agreement was lower for HAS-BLED (average kappa 0.54 vs experts, compared to 0.74 between experts). In high-risk patients (CHA(2)DS(2)-VASc >= 2) OAC use has increased significantly over the last 7 years, driven by the availability of DOACs and the transitioning of patients from AP medication alone to OAC. Factors independently associated with OAC use included components of the CHA(2)DS(2)-VASc and HAS-BLED scores as well as discharging specialty and frailty. OAC use was highest in patients discharged under cardiology (69%). Electronic health record text can be used for automatic calculation of clinical risk scores at scale. Open source tools are available today for this task but require further validation. Analysis of routinely collected EHR data can replicate findings from large-scale curated registries.",,,,,,,,,6,0,0,0,0,0,6,,,1932-6203,,,WOS:000501236800001,31765395,
J,"Bozkurt, Selen; Park, Jung In; Kan, Kathleen Mary; Ferrari, Michelle; Rubin, Daniel L; Brooks, James D; Hernandez-Boussard, Tina",,,,,,,,An Automated Feature Engineering for Digital Rectal Examination Documentation using Natural Language Processing.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,288,294,,,,,,2018,2018,"Digital rectal examination (DRE) is considered a quality metric for prostate cancer care. However, much of the DRE related rich information is documented as free-text in clinical narratives. Therefore, we aimed to develop a natural language processing (NLP) pipeline for automatic documentation of DRE in clinical notes using a domain-specific dictionary created by clinical experts and an extended version of the same dictionary learned by clinical notes using distributional semantics algorithms. The proposed pipeline was compared to a baseline NLP algorithm and the results of the proposed pipeline were found superior in terms of precision (0.95) and recall (0.90) for documentation of DRE. We believe the rule-based NLP pipeline enriched with terms learned from the whole corpus can provide accurate and efficient identification of this quality metric.",,,,,,,,,1,0,0,0,1,0,1,,,,1942-597X,,MEDLINE:30815067,30815067,
J,"Henry, Sam; Buchan, Kevin; Filannino, Michele; Stubbs, Amber; Uzuner, Ozlem",,,,,"Henry, Sam/0000-0002-7246-1151",,,2018 n2c2 shared task on adverse drug events and medication extraction in electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,3,12,,10.1093/jamia/ocz166,,,,JAN 2020,2020,"Objective: This article summarizes the preparation, organization, evaluation, and results of Track 2 of the 2018 National NLP Clinical Challenges shared task. Track 2 focused on extraction of adverse drug events (ADEs) from clinical records and evaluated 3 tasks: concept extraction, relation classification, and end-to-end systems. We perform an analysis of the results to identify the state of the art in these tasks, learn from it, and build on it.Materials and Methods: For all tasks, teams were given raw text of narrative discharge summaries, and in all the tasks, participants proposed deep learning-based methods with hand-designed features. In the concept extraction task, participants used sequence labelling models (bidirectional long short-term memory being the most popular), whereas in the relation classification task, they also experimented with instance-based classifiers (namely support vector machines and rules). Ensemble methods were also popular.Results: A total of 28 teams participated in task 1, with 21 teams in tasks 2 and 3. The best performing systems set a high performance bar with F1 scores of 0.9418 for concept extraction, 0.9630 for relation classification, and 0.8905 for end-to-end. However, the results were much lower for concepts and relations of Reasons and ADEs. These were often missed because local context is insufficient to identify them.Conclusions: This challenge shows that clinical concept extraction and relation classification systems have a high performance for many concept types, but significant improvement is still required for ADEs and Reasons. Incorporating the larger context or outside knowledge will likely improve the performance of future systems.",,,,,,,,,30,0,0,0,6,0,30,,,1067-5027,1527-974X,,WOS:000548300200002,31584655,
J,"Gan, Ryan W.; Sun, Diana; Tatro, Amanda R.; Cohen-Mekelburg, Shirley; Wiitala, Wyndy L.; Zhu, Ji; Waljee, Akbar K.",,,,"Waljee, Akbar K/G-2067-2010","Waljee, Akbar K/0000-0003-1964-8790; Cohen-Mekelburg, Shirley/0000-0001-5058-5527",,,Replicating prediction algorithms for hospitalization and corticosteroid use in patients with inflammatory bowel disease,,,,,,,,PLOS ONE,,,,16,9,,,,,e0257520,10.1371/journal.pone.0257520,,,,SEP 20 2021,2021,"Introduction Previous work had shown that machine learning models can predict inflammatory bowel disease (IBD)-related hospitalizations and outpatient corticosteroid use based on patient demographic and laboratory data in a cohort of United States Veterans. This study aimed to replicate this modeling framework in a nationally representative cohort.Methods A retrospective cohort design using Optum Electronic Health Records (EHR) were used to identify IBD patients, with at least 12 months of follow-up between 2007 and 2018. IBD flare was defined as an inpatient/emergency visit with a diagnosis of IBD or an outpatient corticosteroid prescription for IBD. Predictors included demographic and laboratory data. Logistic regression and random forest (RF) models were used to predict IBD flare within 6 months of each visit. A 70% training and 30% validation approach was used.Results A total of 95,878 patients across 780,559 visits were identified. Of these, 22,245 (23.2%) patients had at least one IBD flare. Patients were predominantly White (87.7%) and female (57.1%), with a mean age of 48.0 years. The logistic regression model had an area under the receiver operating curve (AuROC) of 0.66 (95% CI: 0.65-0.66), sensitivity of 0.69 (95% CI: 0.68-0.70), and specificity of 0.74 (95% CI: 0.73-0.74) in the validation cohort. The RF model had an AuROC of 0.80 (95% CI: 0.80-0.81), sensitivity of 0.74 (95% CI: 0.73-0.74), and specificity of 0.72 (95% CI: 0.72-0.72) in the validation cohort. Important predictors of IBD flare in the RF model were the number of previous flares, age, potassium, and white blood cell count.Conclusion The machine learning modeling framework was replicated and results showed a similar predictive accuracy in a nationally representative cohort of IBD patients. This modeling framework could be embedded in routine practice as a tool to distinguish high-risk patients for disease activity.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000707078200042,34543353,
J,"Johnson, Steven G; Pruinelli, Lisiane; Westra, Bonnie L",,,,,"Johnson, Steven/0000-0002-2983-6384",,,Machine Learned Mapping of Local EHR Flowsheet Data to Standard Information Models using Topic Model Filtering.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,504,513,,,,,,2019,2019,"Electronic health record (EHR) data must be mapped to standard information models for interoperability and to support research across organizations. New information models are being developed and validated for data important to nursing, but a significant problem remains for how to correctly map the information models to an organization's specific flowsheet data implementation. This paper describes an approach for automating the mapping process by using stacked machine learning models. A first model uses a topic model keyword filter to identify the most likely flowsheet rows that map to a concept. A second model is a support vector machine (SVM) that is trained to be a more accurate classifier for each concept. The stacked combination results in a classifier that is good at mapping flowsheets to information models with an overall f2 score of 0.74. This approach is generalizable to mapping other data types that have short text descriptions.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:32308844,32308844,
J,"Nguyen, Minh; Corbin, Conor K.; Eulalio, Tiffany; Ostberg, Nicolai P.; Machiraju, Gautam; Marafino, Ben J.; Baiocchi, Michael; Rose, Christian; Chen, Jonathan H.",,,,"Rose, Christian/AAP-2569-2021","Rose, Christian/0000-0002-5115-649X; Ostberg, Nicolai/0000-0002-8223-4585; Eulalio, Tiffany/0000-0002-7084-9646; Nguyen, Minh/0000-0001-7149-849X",,,Developing machine learning models to personalize care levels among emergency room patients for hospital admission,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2423,2432,,10.1093/jamia/ocab118,,AUG 2021,,NOV 2021,2021,"Objective: To develop prediction models for intensive care unit (ICU) vs non-ICU level-of-care need within 24 hours of inpatient admission for emergency department (ED) patients using electronic health record data.Materials and Methods: Using records of 41 654 ED visits to a tertiary academic center from 2015 to 2019, we tested 4 algorithms-feed-forward neural networks, regularized regression, random forests, and gradient-boosted trees-to predict ICU vs non-ICU level-of-care within 24 hours and at the 24th hour following admission. Simple-feature models included patient demographics, Emergency Severity Index (ESI), and vital sign summary. Complex-feature models added all vital signs, lab results, and counts of diagnosis, imaging, procedures, medications, and lab orders.Results: The best-performing model, a gradient-boosted tree using a full feature set, achieved an AUROC of 0.88 (95%CI: 0.87-0.89) and AUPRC of 0.65 (95%CI: 0.63-0.68) for predicting ICU care need within 24 hours of admission. The logistic regression model using ESI achieved an AUROC of 0.67 (95%CI: 0.65-0.70) and AUPRC of 0.37 (95%CI: 0.35-0.40). Using a discrimination threshold, such as 0.6, the positive predictive value, negative predictive value, sensitivity, and specificity were 85%, 89%, 30%, and 99%, respectively. Vital signs were the most important predictors.Discussion and Conclusions: Undertriaging admitted ED patients who subsequently require ICU care is common and associated with poorer outcomes. Machine learning models using readily available electronic health record data predict subsequent need for ICU admission with good discrimination, substantially better than the benchmarking ESI system. The results could be used in a multitiered clinical decision-support system to improve ED triage.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000711702400013,34402507,
J,"Kalyan, Katikapalli Subramanyam; Rajasekharan, Ajit; Sangeetha, Sivanesan",,,,,,,,AMMU: A survey of transformer-based biomedical pretrained language models,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,126,,,,,,103982,10.1016/j.jbi.2021.103982,,,,FEB 2022,2022,"Transformer-based pretrained language models (PLMs) have started a new era in modern natural language processing (NLP). These models combine the power of transformers, transfer learning, and self-supervised learning (SSL). Following the success of these models in the general domain, the biomedical research commu-nity has developed various in-domain PLMs starting from BioBERT to the latest BioELECTRA and BioALBERT models. We strongly believe there is a need for a survey paper that can provide a comprehensive survey of various transformer-based biomedical pretrained language models (BPLMs). In this survey, we start with a brief overview of foundational concepts like self-supervised learning, embedding layer and transformer encoder layers. We discuss core concepts of transformer-based PLMs like pretraining methods, pretraining tasks, fine-tuning methods, and various embedding types specific to biomedical domain. We introduce a taxonomy for transformer-based BPLMs and then discuss all the models. We discuss various challenges and present possible solutions. We conclude by highlighting some of the open issues which will drive the research community to further improve transformer-based BPLMs. The list of all the publicly available transformer-based BPLMs along with their links is provided at https://mr-nlp.github.io/posts/2021/05/transformer-based-biomedical-pretra ined-language-models-list/.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000742136900002,34974190,
J,"Khattak, Faiza Khan; Jeblee, Serena; Pou-Prom, Chloe; Abdalla, Mohamed; Meaney, Christopher; Rudzicz, Frank",,,,,"Khattak, Faiza/0000-0002-9902-0583",,,A survey of word embeddings for clinical text.,,,,,,,,Journal of biomedical informatics,,,,100S,,,,100057,100057,,10.1016/j.yjbinx.2019.100057,,,,2019,2019,"Representing words as numerical vectors based on the contexts in which they appear has become the de facto method of analyzing text with machine learning. In this paper, we provide a guide for training these representations on clinical text data, using a survey of relevant research. Specifically, we discuss different types of word representations, clinical text corpora, available pre-trained clinical word vector embeddings, intrinsic and extrinsic evaluation, applications, and limitations of these approaches. This work can be used as a blueprint for clinicians and healthcare workers who may want to incorporate clinical text features in their own models and applications.",,,,,,,,,40,0,0,0,10,0,40,,,,1532-0480,,MEDLINE:34384583,34384583,
J,"Fu, Julia T.; Sholle, Evan; Krichevsky, Spencer; Scandura, Joseph; Campion, Thomas R.",,,,,,,,Extracting and classifying diagnosis dates from clinical notes: A case study,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,110,,,,,,103569,10.1016/j.jbi.2020.103569,,,,OCT 2020,2020,"Myeloproliferative neoplasms (MPNs) are chronic hematologic malignancies that may progress over long disease courses. The original date of diagnosis is an important piece of information for patient care and research, but is not consistently documented. We describe an attempt to build a pipeline for extracting dates with natural language processing (NLP) tools and techniques and classifying them as relevant diagnoses or not. Inaccurate and incomplete date extraction and interpretation impacted the performance of the overall pipeline. Existing lightweight Python packages tended to have low specificity for identifying and interpreting partial and relative dates in clinical text. A rules-based regular expression (regex) approach achieved recall of 83.0% on dates manually annotated as diagnosis dates, and 77.4% on all annotated dates. With only 3.8% of annotated dates representing initial MPN diagnoses, additional methods of targeting candidate date instances may alleviate noise and class imbalance.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000579807600023,32949781,
J,"Zhang, Ying; Cui, Shaoze; Gao, Huiying",,,,"Cui, Shaoze/ABE-4152-2021","Cui, Shaoze/0000-0002-9635-0181; Gao, Huiying/0000-0003-1762-4744; Zhang, Ying/0000-0001-5982-9559",,,Adverse drug reaction detection on social media with deep linguistic features,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,106,,,,,,103437,10.1016/j.jbi.2020.103437,,,,JUN 2020,2020,"Adverse reactions caused by drugs are one of the most important public health problems. Social media has encouraged more patients to share their drug use experiences and has become a major source for the detection of professionally unreported adverse drug reactions (ADRs). Since a large number of user posts do not mention any ADR, accurate detection of the presence of ADRs in each user post is necessary before further research can be conducted. Previous feature-based methods focus on extracting more shallow linguistic features that are unable to capture deep and subtle information in the context, ultimately failing to provide satisfactory accuracy. To overcome the limitations of previous studies, this paper proposes a novel method that can extract deep linguistic features and then combine them with shallow linguistic features for ADR detection. We first extract predicate-ADR pairs under the guidance of extended syntactic dependencies and ADR lexicon. Then, we extract semantic and part-of-speech (POS) features for each pair and pool the features of different pairs to generate a holistic representation of deep linguistic features. Finally, we use the collection of deep features and several shallow features to train the predictive models. A series of experiments are performed on data sets collected from DailyStrength and Twitter. Our approach can achieve AUCs of 94.44% and 88.97% on the two data sets, respectively, outperforming other state-of-the-art methods. The results demonstrate the potential benefits of deep linguistic features for ADR detection on social data. This method can be applied to multiple other healthcare and text analysis tasks and can be used to support pharmacovigilance research.",,,,,,,,,7,0,0,0,0,0,7,,,1532-0464,1532-0480,,WOS:000540241000010,32360987,
J,"Patrick, Matthew T.; Bardhi, Redina; Raja, Kalpana; He, Kevin; Tsoi, Lam C.",,,,,"Tsoi, Lam Cheung/0000-0003-1627-5722; Patrick, Matthew/0000-0002-6174-9002",,,Advancement in predicting interactions between drugs used to treat psoriasis and its comorbidities by integrating molecular and clinical resources,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1159,1167,,10.1093/jamia/ocaa335,,FEB 2021,,JUN 2021,2021,"Objective: Drug-drug interactions (DDIs) can result in adverse and potentially life-threatening health consequences; however, it is challenging to predict potential DDIs in advance. We introduce a new computational approach to comprehensively assess the drug pairs which may be involved in specific DDI types by combining information from large-scale gene expression (984 transcriptomic datasets), molecular structure (2159 drugs), and medical claims (150 million patients).Materials and Methods: Features were integrated using ensemble machine learning techniques, and we evaluated the DDIs predicted with a large hospital-based medical records dataset. Our pipeline integrates information from >30 different resources, including >10 000 drugs and >1.7 million drug-gene pairs. We applied our technique to predict interactions between 37 611 drug pairs used to treat psoriasis and its comorbidities.Results: Our approach achieves >0.9 area under the receiver operator curve (AUROC) for differentiating 11 861 known DDIs from 25 750 non-DDI drug pairs. Significantly, we demonstrate that the novel DDIs we predict can be confirmed through independent data sources and supported using clinical medical records.Conclusions: By applying machine learning and taking advantage of molecular, genomic, and health record data, we are able to accurately predict potential new DDIs that can have an impact on public health.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000671031900012,33544847,
J,"Goodwin, Travis R.; Demner-Fushman, Dina",,,,"Goodwin, Travis/ABA-1799-2020","Goodwin, Travis/0000-0002-0047-1078",,,A customizable deep learning model for nosocomial risk prediction from critical care notes with indirect supervision,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,4,,,567,576,,10.1093/jamia/ocaa004,,,,APR 2020,2020,"Objective: Reliable longitudinal risk prediction for hospitalized patients is needed to provide quality care. Our goal is to develop a generalizable model capable of leveraging clinical notes to predict healthcare-associated diseases 24-96 hours in advance.Methods: We developed a reCurrent Additive Network for Temporal RIsk Prediction (CANTRIP) to predict the risk of hospital acquired (occurring >= 48 hours after admission) acute kidney injury, pressure injury, or anemia >= 24 hours before it is implicated by the patient's chart, labs, or notes. We rely on the MIMIC III critical care database and extract distinct positive and negative cohorts for each disease. We retrospectively determine the date-of-event using structured and unstructured criteria and use it as a form of indirect supervision to train and evaluate CANTRIP to predict disease risk using clinical notes.Results: Our experiments indicate that CANTRIP, operating on text alone, obtains 74%-87% area under the curve and 77%-85% Specificity. Baseline shallow models showed lower performance on all metrics, while bidirectional long short-term memory obtained the highest Sensitivity at the cost of significantly lower Specificity and Precision.Discussion: Proper model architecture allows clinical text to be successfully harnessed to predict nosocomial disease, outperforming shallow models and obtaining similar performance to disease-specific models reported in the literature.Conclusion: Clinical text on its own can provide a competitive alternative to traditional structured features (eg, lab values, vital signs).",,,,,,,,,2,1,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000548306200009,32065628,
J,"Venkataraman, Guhan Ram; Pineda, Arturo Lopez; Bear, Oliver J.; Zehnder, Ashley M.; Ayyar, Sandeep; Page, Rodney L.; Bustamante, Carlos D.; Rivas, Manuel A.",,,,"Rivas, Manuel/ABE-8173-2020; Lopez Pineda, Arturo/B-1610-2015","Rivas, Manuel/0000-0003-1457-9925; Bustamante, Carlos D./0000-0002-4187-7920; Lopez Pineda, Arturo/0000-0002-3409-1815",,,FasTag: Automatic text classification of unstructured medical narratives,,,,,,,,PLOS ONE,,,,15,6,,,,,e0234647,10.1371/journal.pone.0234647,,,,JUN 22 2020,2020,"Unstructured clinical narratives are continuously being recorded as part of delivery of care in electronic health records, and dedicated tagging staff spend considerable effort manually assigning clinical codes for billing purposes. Despite these efforts, however, label availability and accuracy are both suboptimal. In this retrospective study, we aimed to automate the assignment of top-level International Classification of Diseases version 9 (ICD-9) codes to clinical records from human and veterinary data stores using minimal manual labor and feature curation. Automating top-level annotations could in turn enable rapid cohort identification, especially in a veterinary setting. To this end, we trained long short-term memory (LSTM) recurrent neural networks (RNNs) on 52,722 human and 89,591 veterinary records. We investigated the accuracy of both separate-domain and combined-domain models and probed model portability. We established relevant baseline classification performances by training Decision Trees (DT) and Random Forests (RF). We also investigated whether transforming the data using MetaMap Lite, a clinical natural language processing tool, affected classification performance. We showed that the LSTM-RNNs accurately classify veterinary and human text narratives into top-level categories with an average weighted macro F1 score of 0.74 and 0.68 respectively. In the neoplasia category, the model trained on veterinary data had a high validation accuracy in veterinary data and moderate accuracy in human data, with F1 scores of 0.91 and 0.70 respectively. Our LSTM method scored slightly higher than that of the DT and RF models. The use of LSTM-RNN models represents a scalable structure that could prove useful in cohort identification for comparative oncology studies. Digitization of human and veterinary health information will continue to be a reality, particularly in the form of unstructured narratives. Our approach is a step forward for these two domains to learn from and inform one another.",,,,,,,,,6,0,0,0,2,0,6,,,1932-6203,,,WOS:000543547900023,32569327,
J,"Ferryman, Kadija",,,,,,,,Addressing health disparities in the Food and Drug Administration's artificial intelligence and machine learning regulatory framework,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,2016,2019,,10.1093/jamia/ocaa133,,,,DEC 2020,2020,"The exponential growth of health data from devices, health applications, and electronic health records coupled with the development of data analysis tools such as machine learning offer opportunities to leverage these data to mitigate health disparities. However, these tools have also been shown to exacerbate inequities faced by marginalized groups. Focusing on health disparities should be part of good machine learning practice and regulatory oversight of software as medical devices. Using the Food and Drug Administration (FDA)'s proposed framework for regulating machine learning tools in medicine, I show that addressing health disparities during the premarket and postmarket stages of review can help anticipate and mitigate group harms.",,,,,,,,,9,0,0,0,1,0,9,,,1067-5027,1527-974X,,WOS:000606832500023,32951036,
J,"Weissman, Gary E.; Ungar, Lyle H.; Harhay, Michael O.; Courtright, Katherine R.; Halpern, Scott D.",,,,,"Weissman, Gary/0000-0001-9588-3819",,,Construct validity of six sentiment analysis methods in the text of encounter notes of patients with critical illness,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,89,,,,114,121,,10.1016/j.jbi.2018.12.001,,,,JAN 2019,2019,"Sentiment analysis may offer insights into patient outcomes through the subjective expressions made by clinicians in the text of encounter notes. We analyzed the predictive, concurrent, convergent, and content validity of six sentiment methods in a sample of 793,725 multidisciplinary clinical notes among 41,283 hospitalizations associated with an intensive care unit stay. None of these approaches improved early prediction of in-hospital mortality using logistic regression models, but did improve both discrimination and calibration when using random forests. Additionally, positive sentiment measured by the CoreNLP (OR 0.04, 95% CI 0.002-0.55), Pattern (OR 0.09, 95% CI 0.04-0.17), sentimentr (OR 0.37, 95% CI 0.25-0.63), and Opinion (OR 0.25, 95% CI 0.07-0.89) methods were inversely associated with death on the concurrent day after adjustment for demographic characteristics and illness severity. Median daily lexical coverage ranged from 5.4% to 20.1%. While sentiment between all methods was positively correlated, their agreement was weak. Sentiment analysis holds promise for clinical applications but will require a novel domain-specific method applicable to clinical text.",,,,,,,,,12,0,0,0,1,0,12,,,1532-0464,1532-0480,,WOS:000462243300009,30557683,
J,"Velupillai, Sumithra; Suominen, Hanna; Liakata, Maria; Roberts, Angus; Shah, Anoop D.; Morley, Katherine; Osborn, David; Hayes, Joseph; Stewart, Robert; Downs, Johnny; Chapman, Wendy; Dutta, Rina",,,,"Shah, Anoop Dinesh/D-4396-2014; Downs, Johnny/AAC-8287-2021; Morley, Katherine/A-2986-2011; Osborn, David/B-8165-2009","Shah, Anoop Dinesh/0000-0002-8907-5724; Downs, Johnny/0000-0002-8061-295X; Roberts, Angus/0000-0002-4570-9801; Morley, Katherine/0000-0002-2725-5535; Osborn, David/0000-0003-2519-1539; Velupillai, Sumithra/0000-0002-4178-2980; Dutta, Rina/0000-0002-5614-8659; Suominen, Hanna/0000-0002-4195-1641",,,Using clinical Natural Language Processing for health outcomes research: Overview and actionable suggestions for future advances,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,88,,,,11,19,,10.1016/j.jbi.2018.10.005,,,,DEC 2018,2018,"The importance of incorporating Natural Language Processing (NLP) methods in clinical informatics research has been increasingly recognized over the past years, and has led to transformative advances.Typically, clinical NLP systems are developed and evaluated on word, sentence, or document level annotations that model specific attributes and features, such as document content (e.g., patient status, or report type), document section types (e.g., current medications, past medical history, or discharge summary), named entities and concepts (e.g., diagnoses, symptoms, or treatments) or semantic attributes (e.g., negation, severity, or temporality).From a clinical perspective, on the other hand, research studies are typically modelled and evaluated on a patient-or population-level, such as predicting how a patient group might respond to specific treatments or patient monitoring over time. While some NLP tasks consider predictions at the individual or group user level, these tasks still constitute a minority. Owing to the discrepancy between scientific objectives of each field, and because of differences in methodological evaluation priorities, there is no clear alignment between these evaluation approaches.Here we provide a broad summary and outline of the challenging issues involved in defining appropriate intrinsic and extrinsic evaluation methods for NLP research that is to be used for clinical outcomes research, and vice versa. A particular focus is placed on mental health research, an area still relatively understudied by the clinical NLP research community, but where NLP methods are of notable relevance. Recent advances in clinical NLP method development have been significant, but we propose more emphasis needs to be placed on rigorous evaluation for the field to advance further. To enable this, we provide actionable suggestions, including a minimal protocol that could be used when reporting clinical NLP method development and its evaluation.",,,,,,,,,51,0,0,0,13,1,51,,,1532-0464,1532-0480,,WOS:000460600200002,30368002,
J,"Nelson, Sarah J.; Drury, Bethany; Hood, Daniel; Harper, Jeremy; Bernard, Tiffany; Weng, Chunhua; Kennedy, Nan; LaSalle, Bernie; Gouripeddi, Ramkiran; Wilkins, Consuelo H.; Harris, Paul",,,,,"Nelson, Sarah/0000-0001-7015-8442",,,EHR-based cohort assessment for multicenter RCTs: a fast and flexible model for identifying potential study sites,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,4,,,652,659,,10.1093/jamia/ocab265,,,,MAR 15 2022,2022,"Objective The Recruitment Innovation Center (RIC), partnering with the Trial Innovation Network and institutions in the National Institutes of Health-sponsored Clinical and Translational Science Awards (CTSA) Program, aimed to develop a service line to retrieve study population estimates from electronic health record (EHR) systems for use in selecting enrollment sites for multicenter clinical trials. Our goal was to create and field-test a low burden, low tech, and high-yield method. Materials and Methods In building this service line, the RIC strove to complement, rather than replace, CTSA hubs' existing cohort assessment tools. For each new EHR cohort request, we work with the investigator to develop a computable phenotype algorithm that targets the desired population. CTSA hubs run the phenotype query and return results using a standardized survey. We provide a comprehensive report to the investigator to assist in study site selection. Results From 2017 to 2020, the RIC developed and socialized 36 phenotype-dependent cohort requests on behalf of investigators. The average response rate to these requests was 73%. Discussion Achieving enrollment goals in a multicenter clinical trial requires that researchers identify study sites that will provide sufficient enrollment. The fast and flexible method the RIC has developed, with CTSA feedback, allows hubs to query their EHR using a generalizable, vetted phenotype algorithm to produce reliable counts of potentially eligible study participants. Conclusion The RIC's EHR cohort assessment process for evaluating sites for multicenter trials has been shown to be efficient and helpful. The model may be replicated for use by other programs.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000769066500010,34850917,
J,"Weeks, Hannah L.; Beck, Cole; McNeer, Elizabeth; Williams, Michael L.; Bejan, Cosmin A.; Denny, Joshua C.; Choi, Leena",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Beck, Cole/0000-0002-6849-6255; Williams, Michael/0000-0003-4991-2329; Weeks, Hannah/0000-0002-0262-6790",,,"medExtractR: A targeted, customizable approach to medication extraction from electronic health records",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,3,,,407,418,,10.1093/jamia/ocz207,,,,MAR 2020,2020,"Objective: We developed medExtractR, a natural language processing system to extract medication information from clinical notes. Using a targeted approach, medExtractR focuses on individual drugs to facilitate creation of medication-specific research datasets from electronic health records.Materials and Methods: Written using the R programming language, medExtractR combines lexicon dictionaries and regular expressions to identify relevant medication entities (eg, drug name, strength, frequency). MedExtractR was developed on notes from Vanderbilt University Medical Center, using medications prescribed with varying complexity. We evaluated medExtractR and compared it with 3 existing systems: MedEx, MedXN, and CLAMP (Clinical Language Annotation, Modeling, and Processing). We also demonstrated how medExtractR can be easily tuned for better performance on an outside dataset using the MIMIC-III (Medical Information Mart for Intensive Care III) database.Results: On 50 test notes per development drug and 110 test notes for an additional drug, medExtractR achieved high overall performance (F-measures >0.95), exceeding performance of the 3 existing systems across all drugs. MedExtractR achieved the highest F-measure for each individual entity, except drug name and dose amount for allopurinol. With tuning and customization, medExtractR achieved F-measures >0.90 in the MIMIC-III dataset.Discussion: The medExtractR system successfully extracted entities for medications of interest. High performance in entity-level extraction provides a strong foundation for developing robust research datasets for pharmacological research. When working with new datasets, medExtractR should be tuned on a small sample of notes before being broadly applied.Conclusions: The medExtractR system achieved high performance extracting specific medications from clinical text, leading to higher-quality research datasets for drug-related studies than some existing general-purpose medication extraction tools.",,,,,,,,,8,0,0,0,2,0,8,,,1067-5027,1527-974X,,WOS:000548302800008,31943012,
J,"Ibrahim, Zina M.; Wu, Honghan; Hamoud, Ahmed; Stappen, Lukas; Dobson, Richard J. B.; Agarossi, Andrea",,,,"Hamoud, Ahmed A./AAQ-8324-2021; Hamoud, Ahmed A./L-4118-2019; Wu, Honghan/AAT-6084-2020; HAMOUD, AHMED A./J-5568-2016; dobson, richard/C-9269-2011","Hamoud, Ahmed A./0000-0002-8877-7337; HAMOUD, AHMED A./0000-0002-8877-7337; dobson, richard/0000-0003-4224-9245; Ibrahim, Zina/0000-0001-6203-2727; Wu, Honghan/0000-0002-0213-5668",,,On classifying sepsis heterogeneity in the ICU: insight using machine learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,3,,,437,443,,10.1093/jamia/ocz211,,,,MAR 2020,2020,"Objectives: Current machine learning models aiming to predict sepsis from electronic health records (EHR) do not account 20 for the heterogeneity of the condition despite its emerging importance in prognosis and treatment. This work demonstrates the added value of stratifying the types of organ dysfunction observed in patients who develop sepsis in the intensive care unit (ICU) in improving the ability to recognize patients at risk of sepsis from their EHR data.Materials and Methods: Using an ICU dataset of 13 728 records, we identify clinically significant sepsis sub-populations with distinct organ dysfunction patterns. We perform classification experiments with random forest, gradient boost trees, and support vector machines, using the identified subpopulations to distinguish patients who develop sepsis in the ICU from those who do not.Results: The classification results show that features selected using sepsis subpopulations as background knowledge yield a superior performance in distinguishing septic from non-septic patients regardless of the classification model used. The improved performance is especially pronounced in specificity, which is a current bottleneck in sepsis prediction machine learning models.Conclusion: Our findings can steer machine learning efforts toward more personalized models for complex conditions including sepsis.",,,,,,,,,10,0,0,0,2,0,10,,,1067-5027,1527-974X,,WOS:000548302800011,31951005,
J,"Loughlin, Anita M.; Lin, Nancy; Abler, Victor; Carroll, Benjamin",,,,,,,,Tardive dyskinesia among patients using antipsychotic medications in customary clinical care in the United States,,,,,,,,PLOS ONE,,,,14,6,,,,,e0216044,10.1371/journal.pone.0216044,,,,JUN 4 2019,2019,"BackgroundTardive dyskinesia (TD) is a movement disorder resulting from treatment with typical and atypical antipsychotics. An estimated 16-50% of patients treated with antipsychotics have TD, but this number may be underestimated. The objectives of this study were to build an algorithm for use in electronic health records (EHRs) for the detection and characterization of TD patients, and to estimate the prevalence of TD in a population of patients exposed to antipsychotic medications.MethodsThis retrospective observational study included patients identified in the Optum EHR Database who received a new or refill prescription for an antipsychotic medication between January 2011 and December 2015 (follow-up through June 2016). TD mentions were identified in the natural language-processed clinical notes, and an algorithm was built to classify the likelihood that the mention represented documentation of a TD diagnosis as probable, possible, unlikely, or negative. The final TD population comprised a subgroup identified using this algorithm, with >= 1 probable TD mention (highly likely TD).Results164,417 patients were identified for the antipsychotic population, with1,314 comprising the final TD population. Conservatively, the estimated average annual prevalence of TD in patients receiving antipsychotics was 0.8% of the antipsychotic user population. The average annual prevalence may be as high as 1.9% per antipsychotic user per year, allowing for a more-inclusive algorithm using both probable and possible TD. Most TD patients were prescribed atypical antipsychotics (1049/1314, 79.8%). Schizophrenia (601/1314, 45.7%), and paranoid and schizophrenia-like disorders (277/1314, 21.1%) were more prevalent in the TD population compared with the entire antipsychotic drug cohort (13,308/164,417; 8.1% and 19,359/164,417; 11.8%, respectively).ConclusionsDespite a lower TD prevalence than previously estimated and the predominant use of atypical antipsychotics, identified TD patients appear to have a substantial comorbidity burden that requires special treatment and management consideration.",,,,,,,,,14,0,1,0,6,0,15,,,1932-6203,,,WOS:000470086200005,31163035,
J,"Pandey, Mohit; Xu, Zhuoran; Sholle, Evan; Maliakal, Gabriel; Singh, Gurpreet; Fatima, Zahra; Larine, Daria; Lee, Benjamin C.; Wang, Jing; van Rosendael, Alexander R.; Baskaran, Lohendran; Shaw, Leslee J.; Min, James K.; Al'Aref, Subhi J.",,,,"Baskaran, Lohendran/AAE-8338-2019","Baskaran, Lohendran/0000-0003-0565-7151; Sholle, Evan/0000-0001-9518-4399",,,Extraction of radiographic findings from unstructured thoracoabdominal computed tomography reports using convolutional neural network based natural language processing,,,,,,,,PLOS ONE,,,,15,7,,,,,e0236827,10.1371/journal.pone.0236827,,,,JUL 30 2020,2020,"Background Heart failure (HF) is a major cause of morbidity and mortality. However, much of the clinical data is unstructured in the form of radiology reports, while the process of data collection and curation is arduous and time-consuming. Purpose We utilized a machine learning (ML)-based natural language processing (NLP) approach to extract clinical terms from unstructured radiology reports. Additionally, we investigate the prognostic value of the extracted data in predicting all-cause mortality (ACM) in HF patients. Materials and methods This observational cohort study utilized 122,025 thoracoabdominal computed tomography (CT) reports from 11,808 HF patients obtained between 2008 and 2018. 1,560 CT reports were manually annotated for the presence or absence of 14 radiographic findings, in addition to age and gender. Thereafter, a Convolutional Neural Network (CNN) was trained, validated and tested to determine the presence or absence of these features. Further, the ability of CNN to predict ACM was evaluated using Cox regression analysis on the extracted features. Results 11,808 CT reports were analyzed from 11,808 patients (mean age 72.8 +/- 14.8 years; 52.7% (6,217/11,808) male) from whom 3,107 died during the 10.6-year follow-up. The CNN demonstrated excellent accuracy for retrieval of the 14 radiographic findings with area-under-the-curve (AUC) ranging between 0.83-1.00 (F1 score 0.84-0.97). Cox model showed the time-dependent AUC for predicting ACM was 0.747 (95% confidence interval [CI] of 0.704-0.790) at 30 days. Conclusion An ML-based NLP approach to unstructured CT reports demonstrates excellent accuracy for the extraction of predetermined radiographic findings, and provides prognostic value in HF patients.",,,,,,,,,2,0,0,0,0,0,2,,,1932-6203,,,WOS:000556884700064,32730362,
J,"Rider, Nicholas L.; Cahill, Gina; Motazedi, Tina; Wei, Lei; Kurian, Ashok; Noroski, Lenora M.; Seeborg, Filiz O.; Chinn, Ivan K.; Roberts, Kirk",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213",,,PI Prob: A risk prediction and clinical guidance system for evaluating patients with recurrent infections,,,,,,,,PLOS ONE,,,,16,2,,,,,e0237285,10.1371/journal.pone.0237285,,,,FEB 16 2021,2021,"BackgroundPrimary immunodeficiency diseases represent an expanding set of heterogeneous conditions which are difficult to recognize clinically. Diagnostic rates outside of the newborn period have not changed appreciably. This concern underscores a need for novel methods of disease detection.ObjectiveWe built a Bayesian network to provide real-time risk assessment about primary immunodeficiency and to facilitate prescriptive analytics for initiating the most appropriate diagnostic work up. Our goal is to improve diagnostic rates for primary immunodeficiency and shorten time to diagnosis. We aimed to use readily available health record data and a small training dataset to prove utility in diagnosing patients with relatively rare features.MethodsWe extracted data from the Texas Children's Hospital electronic health record on a large population of primary immunodeficiency patients (n = 1762) and appropriately-matched set of controls (n = 1698). From the cohorts, clinically relevant prior probabilities were calculated enabling construction of a Bayesian network probabilistic model(PI Prob). Our model was constructed with clinical-immunology domain expertise, trained on a balanced cohort of 100 cases-controls and validated on an unseen balanced cohort of 150 cases-controls. Performance was measured by area under the receiver operator characteristic curve (AUROC). We also compared our network performance to classic machine learning model performance on the same dataset.ResultsPI Prob was accurate in classifying immunodeficiency patients from controls (AUROC = 0.945; p<0.0001) at a risk threshold of >= 6%. Additionally, the model was 89% accurate for categorizing validation cohort members into appropriate International Union of Immunological Societies diagnostic categories. Our network outperformed 3 other machine learning models and provides superior transparency with a prescriptive output element.ConclusionArtificial intelligence methods can classify risk for primary immunodeficiency and guide management. PI Prob enables accurate, objective decision making about risk and guides the user towards the appropriate diagnostic evaluation for patients with recurrent infections. Probabilistic models can be trained with small datasets underscoring their utility for rare disease detection given appropriate domain expertise for feature selection and network construction.",,,,,,,,,2,0,0,0,0,0,2,,,1932-6203,,,WOS:000620632800067,33591972,
J,"Tang, Shengpu; Davarmanesh, Parmida; Song, Yanmeng; Koutra, Danai; Sjoding, Michael W.; Wiens, Jenna",,,,"Tang, Shengpu/ABA-5692-2021","Tang, Shengpu/0000-0002-4213-2015",,,Democratizing EHR analyses with FIDDLE: a flexible data-driven preprocessing pipeline for structured clinical data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1921,1934,,10.1093/jamia/ocaa139,,,,DEC 2020,2020,"Objective: In applying machine learning (ML) to electronic health record (EHR) data, many decisions must be made before any ML is applied; such preprocessing requires substantial effort and can be labor-intensive. As the role of ML in health care grows, there is an increasing need for systematic and reproducible preprocessing techniques for EHR data. Thus, we developed FIDDLE (Flexible Data-Driven Pipeline), an open-source framework that streamlines the preprocessing of data extracted from the EHR.Materials and Methods: Largely data-driven, FIDDLE systematically transforms structured EHR data into feature vectors, limiting the number of decisions a user must make while incorporating good practices from the literature. To demonstrate its utility and flexibility, we conducted a proof-of-concept experiment in which we applied FIDDLE to 2 publicly available EHR data sets collected from intensive care units: MIMIC-III and the eICU Collaborative Research Database. We trained different ML models to predict 3 clinically important outcomes: inhospital mortality, acute respiratory failure, and shock. We evaluated models using the area under the receiver operating characteristics curve (AUROC), and compared it to several baselines.Results: Across tasks, FIDDLE extracted 2,528 to 7,403 features from MIMIC-III and eICU, respectively. On all tasks, FIDDLE-based models achieved good discriminative performance, with AUROCs of 0.757-0.886, comparable to the performance of MIMIC-Extract, a preprocessing pipeline designed specifically for MIMIC-III. Furthermore, our results showed that FIDDLE is generalizable across different prediction times, ML algorithms, and data sets, while being relatively robust to different settings of user-defined arguments.Conclusions: FIDDLE, an open-source preprocessing pipeline, facilitates applying ML to structured EHR data. By accelerating and standardizing labor-intensive preprocessing, FIDDLE can help stimulate progress in building clinically useful ML tools for EHR data.",,,,,,,,,8,0,0,0,3,0,8,,,1067-5027,1527-974X,,WOS:000606832500012,33040151,
J,"Hubbard, Rebecca A.; Xu, Jinyu; Siegel, Robert; Chen, Yong; Eneli, Ihuoma",,,,,"eneli, ihuoma/0000-0002-4436-7141",,,Studying pediatric health outcomes with electronic health records using Bayesian clustering and trajectory analysis,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103654,10.1016/j.jbi.2020.103654,,,,JAN 2021,2021,"Use of routinely collected data from electronic health records (EHR) can expedite longitudinal studies that investigate childhood exposures and rare pediatric health outcomes. For instance, characteristics of the body mass index (BMI) trajectory early in life may be associated with subsequent development of type 2 diabetes. Past studies investigating these relationships have used longitudinal cohort data collected over the course of many years to investigate the connection between BMI trajectory and subsequent development of diabetes. In contrast, EHR data from routine clinical care can provide longitudinal information on early-life BMI trajectories as well as subsequent health outcomes without requiring any additional data collection. In this study, we introduce a Bayesian joint phenotyping and BMI trajectory model to address data quality challenges in an EHR-based study of early-life BMI and type 2 diabetes in adolescence. We compared this joint modeling approach to traditional approaches using a computable phenotype for type 2 diabetes or separately estimated BMI trajectories and type 2 diabetes phenotypes. In a sample of 49,062 children derived from the PEDSnet consortium of pediatric healthcare systems, a median 8 (interquartile range [IQR] 5-13) BMI measurements were available to characterize the early-life BMI trajectory. The joint modeling and computable phenotype approaches found that age at adiposity rebound between 5 and 9 years was associated with higher odds of type 2 diabetes in adolescence compared to age at adiposity rebound between 2 and 5 years (joint model odds ratio [OR] = 1.77; computable phenotype OR = 1.88) and that BMI in excess of 140% of the 95th percentile for age and sex at age 9 years was associated with higher odds of type 2 diabetes in adolescence relative to children with BMI from 100 to 120% of the 95th percentile (joint model OR = 6.22; computable phenotype OR = 13.25). Estimates from the separate phenotyping and trajectory model were substantially attenuated towards the null. These results demonstrate that EHR data coupled with modern methodologic approaches can improve efficiency and timeliness of studies of childhood exposures and rare health outcomes.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000615920800005,33309993,
J,"Xu, Sonnet; Arnetz, Judith E; Arnetz, Bengt B",,,,"Arnetz, Bengt/G-1685-2011","Arnetz, Bengt/0000-0001-7173-4333",,,Applying machine learning to explore the association between biological stress and near misses in emergency medicine residents.,,,,,,,,PloS one,,,,17,3,,,e0264957,e0264957,,10.1371/journal.pone.0264957,,,,2022,2022,"Physician stress is associated with near misses and adverse medical events. However, little is known about physiological mechanisms linking stress to such events. We explored the utility of machine learning to determine whether the catabolic stress hormone cortisol and the anabolic, anti-stress hormone dehydroepiandrosterone sulfate (DHEA-S), as well as the cortisol to DHEA-S ratio relate to near misses in emergency medicine residents during active duty in a trauma 1 emergency department. Compared to statistical models better suited for inference, machine learning models allow for prediction in situations that have not yet occurred, and thus better suited for clinical applications. This exploratory study used multiple machine learning models to determine possible relationships between biomarkers and near misses. Of the various models tested, support vector machine with radial bias function kernels and support vector machine with linear kernels performed the best, with training accuracies of 85% and 79% respectively. When evaluated on a test dataset, both models had prediction accuracies of around 80%. The pre-shift cortisol to DHEA-S ratio was shown to be the most important predictor in interpretable models tested. Results suggest that interventions that help emergency room physicians relax before they begin their shift could reduce risk of errors and improve patient and physician outcomes. This pilot demonstrates promising results regarding using machine learning to better understand the stress biology of near misses. Future studies should use larger groups and relate these variables to information in electronic medical records, such as objective and patient-reported quality measures.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35259166,35259166,
J,"Jhee, Jong Hyun; Lee, SungHee; Park, Yejin; Lee, Sang Eun; Kim, Young Ah; Kang, Shin-Wook; Kwon, Ja-Young; Park, Jung Tak",,,,,"Kwon, Ja-Young/0000-0003-3009-6325; Park, Yejin/0000-0002-0545-7267; Kang, Shin-Wook/0000-0002-5677-4756; Park, Jung Tak/0000-0002-2325-8982",,,Prediction model development of late-onset preeclampsia using machine learning-based methods,,,,,,,,PLOS ONE,,,,14,8,,,,,e0221202,10.1371/journal.pone.0221202,,,,AUG 23 2019,2019,"Preeclampsia is one of the leading causes of maternal and fetal morbidity and mortality. Due to the lack of effective preventive measures, its prediction is essential to its prompt management. This study aimed to develop models using machine learning to predict late-onset preeclampsia using hospital electronic medical record data. The performance of the machine learning based models and models using conventional statistical methods were also compared. A total of 11,006 pregnant women who received antenatal care at Yonsei University Hospital were included. Maternal data were retrieved from electronic medical records during the early second trimester to 34 weeks. The prediction outcome was late-onset preeclampsia occurrence after 34 weeks' gestation. Pattern recognition and cluster analysis were used to select the parameters included in the prediction models. Logistic regression, decision tree model, naive Bayes classification, support vector machine, random forest algorithm, and stochastic gradient boosting method were used to construct the prediction models. C-statistics was used to assess the performance of each model. The overall preeclampsia development rate was 4.7% (474 patients). Systolic blood pressure, serum blood urea nitrogen and creatinine levels, platelet counts, serum potassium level, white blood cell count, serum calcium level, and urinary protein were the most influential variables included in the prediction models. C-statistics for the decision tree model, naive Bayes classification, support vector machine, random forest algorithm, stochastic gradient boosting method, and logistic regression models were 0.857, 0.776, 0.573, 0.894, 0.924, and 0.806, respectively. The stochastic gradient boosting model had the best prediction performance with an accuracy and false positive rate of 0.973 and 0.009, respectively. The combined use of maternal factors and common antenatal laboratory data of the early second trimester through early third trimester could effectively predict late-onset preeclampsia using machine learning algorithms. Future prospective studies are needed to verify the clinical applicability algorithms.",,,,,,,,,19,0,1,0,6,0,20,,,1932-6203,,,WOS:000485041400026,31442238,
J,"Dong, Xinyu; Deng, Jianyuan; Rashidian, Sina; Abell-Hart, Kayley; Hou, Wei; Rosenthal, Richard N.; Saltz, Mary; Saltz, Joel H.; Wang, Fusheng",,,,"Rosenthal, Richard Nelson/AAD-3629-2022","Rosenthal, Richard Nelson/0000-0002-6011-809X; Rashidian, Sina/0000-0003-1210-2939",,,Identifying risk of opioid use disorder for patients taking opioid medications with deep learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,8,,,1683,1693,,10.1093/jamia/ocab043,,APR 2021,,AUG 2021,2021,"Objective: The United States is experiencing an opioid epidemic. In recent years, there were more than 10 million opioid misusers aged 12 years or older annually. Identifying patients at high risk of opioid use disorder (OUD) can help to make early clinical interventions to reduce the risk of OUD. Our goal is to develop and evaluate models to predict OUD for patients on opioid medications using electronic health records and deep learning methods. The resulting models help us to better understand OUD, providing new insights on the opioid epidemic. Further, these models provide a foundation for clinical tools to predict OUD before it occurs, permitting early interventions.Methods: Electronic health records of patients who have been prescribed with medications containing active opioid ingredients were extracted from Cerner's Health Facts database for encounters between January 1, 2008, and December 31, 2017. Long short-term memory models were applied to predict OUD risk based on five recent prior encounters before the target encounter and compared with logistic regression, random forest, decision tree, and dense neural network. Prediction performance was assessed using F1 score, precision, recall, and area under the receiver-operating characteristic curve.Results: The long short-term memory (LSTM) model provided promising prediction results which outperformed other methods, with an F1 score of 0.8023 (about 0.016 higher than dense neural network (DNN)) and an area under the receiver-operating characteristic curve (AUROC) of 0.9369 (about 0.145 higher than DNN).Conclusions: LSTM-based sequential deep learning models can accurately predict OUD using a patient's history of electronic health records, with minimal prior domain knowledge. This tool has the potential to improve clinical decision support for early intervention and prevention to combat the opioid epidemic.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000733838500010,33930132,
J,"Zolnoori, Maryam; Fung, Kin Wah; Patrick, Timothy B.; Fontelo, Paul; Kharrazi, Hadi; Faiola, Anthony; Wu, Yi Shuan Shirley; Eldredge, Christina E.; Luo, Jake; Conway, Mike; Zhu, Jiaxi; Park, Soo Kyung; Xu, Kelly; Moayyed, Hamideh; Goudarzvand, Somaieh",,,,"Kharrazi, Hadi/Q-1725-2015","Kharrazi, Hadi/0000-0003-1481-4323; Luo, Jake/0000-0002-3900-643X; Wu, Yi Shuan Shirley/0000-0001-8754-7962",,,A systematic approach for developing a corpus of patient reported adverse drug events: A case study for SSRI and SNRI medications,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,90,,,,,,103091,10.1016/j.jbi.2018.12.005,,,,FEB 2019,2019,"Psychiatric Treatment Adverse Reactions (PsyTAR) corpus is an annotated corpus that has been developed using patients narrative data for psychiatric medications, particularly SSRIs (Selective Serotonin Reuptake Inhibitor) and SNRIs (Serotonin Norepinephrine Reuptake Inhibitor) medications. This corpus consists of three main components: sentence classification, entity identification, and entity normalization. We split the review posts into sentences and labeled them for presence of adverse drug reactions (ADRs) (2168 sentences), withdrawal symptoms (WDs) (438 sentences), sign/symptoms/illness (SSIs) (789 sentences), drug indications (517), drug effectiveness (EF) (1087 sentences), and drug infectiveness (INF) (337 sentences). In the entity identification phase, we identified and extracted ADRs (4813 mentions), WDs (590 mentions), SSIs (1219 mentions), and DIs (792). In the entity normalization phase, we mapped the identified entities to the corresponding concepts in both UMLS (918 unique concepts) and SNOMED CT (755 unique concepts). Four annotators double coded the sentences and the span of identified entities by strictly following guidelines rules developed for this study. We used the PsyTAR sentence classification component to automatically train a range of supervised machine learning classifiers to identifying text segments with the mentions of ADRs, WDs, DIs, SSIs, EF, and INF. SVMs classifiers had the highest performance with F-Score 0.90. We also measured performance of the cTAKES (clinical Text Analysis and Knowledge Extraction System) in identifying patients' expressions of ADRs and WDs with and without adding PsyTAR dictionary to the core dictionary of cTAKES. Augmenting cTAKES dictionary with PsyTAR improved the F-score cTAKES by 25%. The findings imply that PsyTAR has significant implications for text mining algorithms aimed to identify information about adverse drug events and drug effectiveness from patients' narratives data, by linking the patients' expressions of adverse drug events to medical standard vocabularies. The corpus is publicly available at Zolnoori et al. [30].",,,,,,,,,17,0,0,0,4,0,17,,,1532-0464,1532-0480,,WOS:000462243700004,30611893,
J,"Altieri, Nicholas; Park, Briton; Olson, Mara; DeNero, John; Odisho, Anobel Y.; Yu, Bin",,,,,"DeNero, John/0000-0001-9152-3891; Odisho, Anobel/0000-0003-0975-0812; Park, Briton/0000-0003-2623-8810",,,Supervised line attention for tumor attribute classification from pathology reports: Higher performance with less data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,122,,,,,,103872,10.1016/j.jbi.2021.103872,,SEP 2021,,OCT 2021,2021,"Objective: We aim to build an accurate machine learning-based system for classifying tumor attributes from cancer pathology reports in the presence of a small amount of annotated data, motivated by the expensive and time-consuming nature of pathology report annotation. An enriched labeling scheme that includes the location of relevant information along with the final label is used along with a corresponding hierarchical method for classifying reports that leverages these enriched annotations. Materials and methods: Our data consists of 250 colon cancer and 250 kidney cancer pathology reports from 2002 to 2019 at the University of California, San Francisco. For each report, we classify attributes such as procedure performed, tumor grade, and tumor site. For each attribute and document, an annotator trained by an oncologist labeled both the value of that attribute as well as the specific lines in the document that indicated the value. We develop a model that uses these enriched annotations that first predicts the relevant lines of the document, then predicts the final value given the predicted lines. We compare our model to multiple state-of-the-art methods for classifying tumor attributes from pathology reports. Results: Our results show that across colon and kidney cancers and varying training set sizes, our hierarchical method consistently outperforms state-of-the-art methods. Furthermore, performance comparable to these methods can be achieved with approximately half the amount of labeled data. Conclusion: Document annotations that are enriched with location information are shown to greatly increase the sample efficiency of machine learning methods for classifying attributes of pathology reports.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000703562100006,34411709,
J,"Hussan, Hisham; Zhao, Jing; Badu-Tawiah, Abraham K; Stanich, Peter; Tabung, Fred; Gray, Darrell; Ma, Qin; Kalady, Matthew; Clinton, Steven K",,,,,"Hussan, Hisham/0000-0002-8646-8370",,,Utility of machine learning in developing a predictive model for early-age-onset colorectal neoplasia using electronic health records.,,,,,,,,PloS one,,,,17,3,,,e0265209,e0265209,,10.1371/journal.pone.0265209,,,,2022,2022,"BACKGROUND AND AIMS: The incidence of colorectal cancer (CRC) is increasing in adults younger than 50, and early screening remains challenging due to cost and under-utilization. To identify individuals aged 35-50 years who may benefit from early screening, we developed a prediction model using machine learning and electronic health record (EHR)-derived factors.METHODS: We enrolled 3,116 adults aged 35-50 at average-risk for CRC and underwent colonoscopy between 2017-2020 at a single center. Prediction outcomes were (1) CRC and (2) CRC or high-risk polyps. We derived our predictors from EHRs (e.g., demographics, obesity, laboratory values, medications, and zip code-derived factors). We constructed four machine learning-based models using a training set (random sample of 70% of participants): regularized discriminant analysis, random forest, neural network, and gradient boosting decision tree. In the testing set (remaining 30% of participants), we measured predictive performance by comparing C-statistics to a reference model (logistic regression).RESULTS: The study sample was 55.1% female, 32.8% non-white, and included 16 (0.05%) CRC cases and 478 (15.3%) cases of CRC or high-risk polyps. All machine learning models predicted CRC with higher discriminative ability compared to the reference model [e.g., C-statistics (95%CI); neural network: 0.75 (0.48-1.00) vs. reference: 0.43 (0.18-0.67); P = 0.07] Furthermore, all machine learning approaches, except for gradient boosting, predicted CRC or high-risk polyps significantly better than the reference model [e.g., C-statistics (95%CI); regularized discriminant analysis: 0.64 (0.59-0.69) vs. reference: 0.55 (0.50-0.59); P<0.0015]. The most important predictive variables in the regularized discriminant analysis model for CRC or high-risk polyps were income per zip code, the colonoscopy indication, and body mass index quartiles.DISCUSSION: Machine learning can predict CRC risk in adults aged 35-50 using EHR with improved discrimination. Further development of our model is needed, followed by validation in a primary-care setting, before clinical application.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35271664,35271664,
J,"Zheutlin, Amanda B.; Vieira, Luciana; Shewcraft, Ryan A.; Li, Shilong; Wang, Zichen; Schadt, Emilio; Kao, Yu-Han; Gross, Susan; Dolan, Siobhan M.; Stone, Joanne; Schadt, Eric; Li, Li",,,,,"Vieira, Luciana/0000-0002-6397-4692; Li, Li/0000-0001-6746-4297; Zheutlin, Amanda/0000-0001-6987-1435",,,A comprehensive digital phenotype for postpartum hemorrhage,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,2,,,321,328,,10.1093/jamia/ocab181,,SEP 2021,,FEB 2021,2021,"Objective: We aimed to establish a comprehensive digital phenotype for postpartum hemorrhage (PPH). Current guidelines rely primarily on estimates of blood loss, which can be inaccurate and biased and ignore complementary information readily available in electronic medical records (EMR). Inaccurate and incomplete phenotyping contributes to ongoing challenges in tracking PPH outcomes, developing more accurate risk assessments, and identifying novel interventions.Materials and Methods: We constructed a cohort of 71 944 deliveries from the Mount Sinai Health System. Estimates of postpartum blood loss, shifts in hematocrit, administration of uterotonics, surgical interventions, and diagnostic codes were combined to identify PPH, retrospectively. Clinical features were extracted from EMRs and mapped to common data models for maximum interoperability across hospitals. Blinded chart review was done by a physician on a subset of PPH and non-PPH patients and performance was compared to alternate PPH phenotypes. PPH was defined as clinical diagnosis of postpartum hemorrhage documented in the patient's chart upon chart review.Results: We identified 6639 PPH deliveries (9% prevalence) using our phenotype-more than 3 times as many as using blood loss alone (N=1,747), supporting the need to incorporate other diagnostic and intervention data. Chart review revealed our phenotype had 89% accuracy and an F1-score of 0.92. Alternate phenotypes were less accurate, including a common blood loss-based definition (67%) and a previously published digital phenotype (74%).Conclusion: We have developed a scalable, accurate, and valid digital phenotype that may be of significant use for tracking outcomes and ongoing clinical research to deliver better preventative interventions for PPH.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000749569600010,34559880,
J,"Changolkar, Sujatha; Rewley, Jeffrey; Balachandran, Mohan; Rareshide, Charles A. L.; Snider, Christopher K.; Day, Susan C.; Patel, Mitesh S.",,,,,,,,Phenotyping physician practice patterns and associations with response to a nudge in the electronic health record for influenza vaccination: A quasi-experimental study,,,,,,,,PLOS ONE,,,,15,5,,,,,e0232895,10.1371/journal.pone.0232895,,,,MAY 20 2020,2020,"BackgroundHealth systems routinely implement changes to the design of electronic health records (EHRs). Physician behavior may vary in response and methods to identify this variation could help to inform future interventions. The objective of this study was to phenotype primary care physician practice patterns and evaluate associations with response to an EHR nudge for influenza vaccination.Methods and findingsDuring the 2016-2017 influenza season, 3 primary care practices at Penn Medicine implemented an active choice intervention in the EHR that prompted medical assistants to template influenza vaccination orders for physicians to review during the visit. We used latent class analysis to identify physician phenotypes based on 9 demographic, training, and practice pattern variables, which were obtained from the EHR and publicly available sources. A quasi-experimental approach was used to evaluate response to the intervention relative to control practices over time in each of the physician phenotype groups. For each physician latent class, a generalized linear model with logit link was fit to the binary outcome of influenza vaccination at the patient visit level. The sample comprised 45,410 patients with a mean (SD) age of 58.7 (16.3) years, 67.1% were white, and 22.1% were black. The sample comprised 56 physicians with mean (SD) of 24.6 (10.2) years of experience and 53.6% were male. The model segmented physicians into groups that had higher (n = 41) and lower (n = 15) clinical workloads. Physicians in the higher clinical workload group had a mean (SD) of 818.8 (429.1) patient encounters, 11.6 (4.7) patient appointments per day, and 4.0 (1.1) days per week in clinic. Physicians in the lower clinical workload group had a mean (SD) of 343.7 (129.0) patient encounters, 8.0 (2.8) patient appointments per day, and 3.1 (1.2) days per week in clinic. Among the higher clinical workload group, the EHR nudge was associated with a significant increase in influenza vaccination (adjusted difference-in-difference in percentage points, 7.9; 95% CI, 0.4-9.0; P =.01). Among the lower clinical workload group, the EHR nudge was not associated with a significant difference in influenza vaccination rates (adjusted difference-in-difference in percentage points, -1.0; 95% CI, -5.3-5.8; P =.90).ConclusionsA model-based approach categorized physician practice patterns into higher and lower clinical workload groups. The higher clinical workload group was associated with a significant response to an EHR nudge for influenza vaccination.",,,,,,,,,3,0,0,0,0,0,3,,,1932-6203,,,WOS:000537510100024,32433678,
J,"Hassaine, Abdelaali; Canoy, Dexter; Solares, Jose Roberto Ayala; Zhu, Yajie; Rao, Shishir; Li, Yikuan; Zottoli, Mariagrazia; Rahimi, Kazem; Salimi-Khorshidi, Gholamreza",,,,"Rahimi, Kazem/AAA-4250-2022; Rahimi, Kazem/Q-1279-2015","Rahimi, Kazem/0000-0002-4807-4610",,,Learning multimorbidity patterns from electronic health records using Non-negative Matrix Factorisation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,112,,,,,,103606,10.1016/j.jbi.2020.103606,,,,DEC 2020,2020,"Multimorbidity, or the presence of several medical conditions in the same individual, has been increasing in the population - both in absolute and relative terms. Nevertheless, multimorbidity remains poorly understood, and the evidence from existing research to describe its burden, determinants and consequences has been limited. Previous studies attempting to understand multimorbidity patterns are often cross-sectional and do not explicitly account for multimorbidity patterns' evolution over time; some of them are based on small datasets and/or use arbitrary and narrow age ranges; and those that employed advanced models, usually lack appropriate benchmarking and validations. In this study, we (1) introduce a novel approach for using Non negative Matrix Factorisation (NMF) for temporal phenotyping (i.e., simultaneously mining disease clusters and their trajectories); (2) provide quantitative metrics for the evaluation of these clusters and trajectories; and (3) demonstrate how the temporal characteristics of the disease clusters that result from our model can help mine multimorbidity networks and generate new hypotheses for the emergence of various multimorbidity patterns over time. We trained and evaluated our models on one of the world's largest electronic health records (EHR) datasets, containing more than 7 million patients, from which over 2 million where relevant to, and hence included in this study.",,,,,,,,,3,1,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000615718600008,33127447,
J,"Bozkurt, Selen; Cahan, Eli M.; Seneviratne, Martin G.; Sun, Ran; Lossio-Ventura, Juan A.; Ioannidis, John P. A.; Hernandez-Boussard, Tina",,,,"Ioannidis, John P. A./G-9836-2011","Ioannidis, John P./0000-0003-3118-6859; Lossio-Ventura, Juan Antonio/0000-0003-0996-2356",,,Reporting of demographic data and representativeness in machine learning models using electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1878,1884,,10.1093/jamia/ocaa164,,,,DEC 2020,2020,"Objective: The development of machine learning (ML) algorithms to address a variety of issues faced in clinical practice has increased rapidly. However, questions have arisen regarding biases in their development that can affect their applicability in specific populations. We sought to evaluate whether studies developing ML models from electronic health record (EHR) data report sufficient demographic data on the study populations to demonstrate representativeness and reproducibility.Materials and Methods: We searched PubMed for articles applying ML models to improve clinical decision-making using EHR data. We limited our search to papers published between 2015 and 2019.Results: Across the 164 studies reviewed, demographic variables were inconsistently reported and/or included as model inputs. Race/ethnicity was not reported in 64%; gender and age were not reported in 24% and 21% of studies, respectively. Socioeconomic status of the population was not reported in 92% of studies. Studies that mentioned these variables often did not report if they were included as model inputs. Few models (12%) were validated using external populations. Few studies (17%) open-sourced their code. Populations in the ML studies include higher proportions of White and Black yet fewer Hispanic subjects compared to the general US population.Discussion: The demographic characteristics of study populations are poorly reported in the ML literature based on EHR data. Demographic representativeness in training data and model transparency is necessary to ensure that ML models are deployed in an equitable and reproducible manner. Wider adoption of reporting guidelines is warranted to improve representativeness and reproducibility.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000606832500007,32935131,
J,"Manocha, Ankush; Kumar, Gulshan; Bhatia, Munish; Sharma, Amit",,,,"Sharma, Dr. Amit/K-4203-2017","Sharma, Dr. Amit/0000-0003-1451-5892; Manocha, Ankush/0000-0001-5054-1655",,,Video-assisted smart health monitoring for affliction determination based on fog analytics,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,109,,,,,,103513,10.1016/j.jbi.2020.103513,,,,SEP 2020,2020,"Satisfying the expectations of quality living is essential for smart healthcare. Therefore, the determination of health afflictions in real-time has been considered as one of the most necessary parts of medical or assistive-care domain. In this article, a novel fog analytic-assisted deep learning-enabled physical stance-based irregularity recognition framework is presented to enhance personal living satisfaction of an individual. To increase the utility of the proposed framework for assistive-care, an attempt has been made to record predicted activity scores on cloud by following the continuous time series policy to provide future health references to authorized medical specialist. Furthermore, a smart two-phased decision generation mechanism is proposed to intimate medical specialist and caretakers about the current physical status of an individual in real-time. The generation of the alert is directly proportional to the predicted physical irregularity and the scale of health severity. The experimental results highlight the advantages of fog analytics that helps to increase the recognition rate up to 46.45% for 40 FPS and 45.72% for 30 FPS against cloud-based monitoring solutions. The calculated outcomes justify the superiority of the proposed fog analytics monitoring solution over the conventional cloud-based monitoring solutions by achieving high activity prediction accuracy and less latency rate in decision making.",,,,,,,,,3,0,0,0,0,0,3,,,1532-0464,1532-0480,,WOS:000575072400004,32712156,
J,"Si, Yuqi; Wang, Jingqi; Xu, Hua; Roberts, Kirk",,,,"Roberts, Kirk/AAZ-4169-2021","Roberts, Kirk/0000-0001-6525-5213; Si, Yuqi/0000-0002-8123-8947",,,Enhancing clinical concept extraction with contextual embeddings,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1297,1304,,10.1093/jamia/ocz096,,,,NOV 2019,2019,"Objective: Neural network-based representations (embeddings) have dramatically advanced natural language processing (NLP) tasks, including clinical NLP tasks such as concept extraction. Recently, however, more advanced embedding methods and representations (eg, ELMo, BERT) have further pushed the state of the art in NLP, yet there are no common best practices for how to integrate these representations into clinical tasks. The purpose of this study, then, is to explore the space of possible options in utilizing these new models for clinical concept extraction, including comparing these to traditional word embedding methods (word2vec, GloVe, fastText).Materials and Methods: Both off-the-shelf, open-domain embeddings and pretrained clinical embeddings from MIMIC-III (Medical Information Mart for Intensive Care III) are evaluated. We explore a battery of embedding methods consisting of traditional word embeddings and contextual embeddings and compare these on 4 concept extraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We also analyze the impact of the pretraining time of a large language model like ELMo or BERT on the extraction performance. Last, we present an intuitive way to understand the semantic information encoded by contextual embeddings.Results: Contextual embeddings pretrained on a large clinical corpus achieves new state-of-the-art performances across all concept extraction tasks. The best-performing model outperforms all state-of-the-art methods with respective F1-measures of 90.25, 93.18 (partial), 80.74, and 81.65.Conclusions: We demonstrate the potential of contextual embeddings through the state-of-the-art performance these methods achieve on clinical concept extraction. Additionally, we demonstrate that contextual embeddings encode valuable semantic information not accounted for in traditional word representations.",,,,,,,,,56,0,0,0,19,0,56,,,1067-5027,1527-974X,,WOS:000498169400018,31265066,
J,"Burger, Franziska; Neerincx, Mark A.; Brinkman, Willem-Paul",,,,"; Brinkman, Willem-Paul/H-8159-2013","Neerincx, Mark/0000-0002-8161-5722; Burger, Franziska/0000-0003-0184-382X; Brinkman, Willem-Paul/0000-0001-8485-7092",,,Natural language processing for cognitive therapy: Extracting schemas from thought records,,,,,,,,PLOS ONE,,,,16,10,,,,,e0257832,10.1371/journal.pone.0257832,,,,OCT 18 2021,2021,"The cognitive approach to psychotherapy aims to change patients' maladaptive schemas, that is, overly negative views on themselves, the world, or the future. To obtain awareness of these views, they record their thought processes in situations that caused pathogenic emotional responses. The schemas underlying such thought records have, thus far, been largely manually identified. Using recent advances in natural language processing, we take this one step further by automatically extracting schemas from thought records. To this end, we asked 320 healthy participants on Amazon Mechanical Turk to each complete five thought records consisting of several utterances reflecting cognitive processes. Agreement between two raters on manually scoring the utterances with respect to how much they reflect each schema was substantial (Cohen's kappa = 0.79). Natural language processing software pretrained on all English Wikipedia articles from 2014 (GLoVE embeddings) was used to represent words and utterances, which were then mapped to schemas using k-nearest neighbors algorithms, support vector machines, and recurrent neural networks. For the more frequently occurring schemas, all algorithms were able to leverage linguistic patterns. For example, the scores assigned to the Competence schema by the algorithms correlated with the manually assigned scores with Spearman correlations ranging between 0.64 and 0.76. For six of the nine schemas, a set of recurrent neural networks trained separately for each of the schemas outperformed the other algorithms. We present our results here as a benchmark solution, since we conducted this research to explore the possibility of automatically processing qualitative mental health data and did not aim to achieve optimal performance with any of the explored models. The dataset of 1600 thought records comprising 5747 utterances is published together with this article for researchers and machine learning enthusiasts to improve upon our outcomes. Based on our promising results, we see further opportunities for using free-text input and subsequent natural language processing in other common therapeutic tools, such as ecological momentary assessments, automated case conceptualizations, and, more generally, as an alternative to mental health scales.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000733985600005,34662350,
J,"Awan, Saqib E.; Bennamoun, Mohammed; Sohel, Ferdous; Sanfilippo, Frank M.; Chow, Benjamin J.; Dwivedi, Girish",,,,"Dwivedi, Girish/AAF-2726-2021; Sanfilippo, Frank/H-9334-2013; Bennamoun, Mohammed/C-2789-2013; Sohel, Ferdous/C-2428-2013","Dwivedi, Girish/0000-0003-0717-740X; Sanfilippo, Frank/0000-0003-3639-0787; Bennamoun, Mohammed/0000-0002-6603-3257; Sohel, Ferdous/0000-0003-1557-4907",,,Feature selection and transformation by machine learning reduce variable numbers and improve prediction for heart failure readmission or death,,,,,,,,PLOS ONE,,,,14,6,,,,,e0218760,10.1371/journal.pone.0218760,,,,JUN 26 2019,2019,"BackgroundThe prediction of readmission or death after a hospital discharge for heart failure (HF) remains a major challenge. Modern healthcare systems, electronic health records, and machine learning (ML) techniques allow us to mine data to select the most significant variables (allowing for reduction in the number of variables) without compromising the performance of models used for prediction of readmission and death. Moreover, ML methods based on transformation of variables may potentially further improve the performance.ObjectiveTo use ML techniques to determine the most relevant and also transform variables for the prediction of 30-day readmission or death in HF patients.MethodsWe identified all Western Australian patients aged 65 years and above admitted for HF between 2003-2008 in linked administrative data. We evaluated variables associated with HF readmission or death using standard statistical and ML based selection techniques. We also tested the new variables produced by transformation of the original variables. We developed multi-layer perceptron prediction models and compared their predictive performance using metrics such as Area Under the receiver operating characteristic Curve (AUC), sensitivity and specificity.ResultsFollowing hospital discharge, the proportion of 30-day readmissions or death was 23.7% in our cohort of 10,757 HF patients. The prediction model developed by us using a smaller set of variables (n = 8) had comparable performance (AUC 0.62) to the traditional model (n = 47, AUC 0.62). Transformation of the original 47 variables further improved (p<0.001) the performance of the predictive model (AUC 0.66).ConclusionsA small set of variables selected using ML matched the performance of the model that used the full set of 47 variables for predicting 30-day readmission or death in HF patients. Model performance can be further significantly improved by transforming the original variables using ML methods.",,,,,,,,,5,1,0,0,1,0,5,,,1932-6203,,,WOS:000482883600051,31242238,
J,"Hong, Na; Wen, Andrew; Mojarad, Majid Rastegar; Sohn, Sunghwan; Liu, Hongfang; Jiang, Guoqian",,,,,,,,Standardizing Heterogeneous Annotation Corpora Using HL7 FHIR for Facilitating their Reuse and Integration in Clinical NLP.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,574,583,,,,,,2018,2018,"Manually annotated clinical corpora are commonly used as the gold standards for the training and evaluation of clinical natural language processing (NLP) tools. The creation of these manual annotation corpora, however, is both costly and time-consuming. There is an emerging need in the clinical NLP community for reusing existing annotation corpora across different clinical NLP tasks. The objective of this study is to design, develop and evaluate a framework and accompanying tools to support the standardization and integration of annotation corpora using the HL7 Fast Healthcare Interoperability Resources (FHIR) specification. The framework contains two main modules: 1) an automatic schema transformation module, in which the annotation schema in each corpus is automatically transformed into the FHIR-based schema; 2) an expert-based verification and annotation module, in which existing annotations can be verified and new annotations can be added for new elements defined in FHIR. We evaluated the framework using various annotation corpora created as part of different clinical NLP projects at the Mayo Clinic. We demonstrated that it is feasible to leverage FHIR as a standard data model for standardizing heterogeneous annotation corpora for their reuse and integration in advanced clinical NLP research and practices.",,,,,,,,,8,0,1,0,0,1,9,,,,1942-597X,,MEDLINE:30815098,30815098,
J,"Ni, Yizhao; Lingren, Todd; Hall, Eric S.; Leonard, Matthew; Melton, Kristin; Kirkendall, Eric S.",,,,"Hall, Eric S./F-2814-2015; Melton, Kristin/AAV-9738-2020","Hall, Eric S./0000-0002-9477-8619; Melton, Kristin/0000-0001-6170-0404; Ni, Yizhao/0000-0001-8599-454X",,,Designing and evaluating an automated system for real-time medication administration error detection in a neonatal intensive care unit,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,5,,,555,563,,10.1093/jamia/ocx156,,,,MAY 2018,2018,"Background: Timely identification of medication administration errors (MAEs) promises great benefits for mitigating medication errors and associated harm. Despite previous efforts utilizing computerized methods to monitor medication errors, sustaining effective and accurate detection of MAEs remains challenging. In this study, we developed a real-time MAE detection system and evaluated its performance prior to system integration into institutional workflows.Methods: Our prospective observational study included automated MAE detection of 10 high-risk medications and fluids for patients admitted to the neonatal intensive care unit at Cincinnati Children's Hospital Medical Center during a 4-month period. The automated system extracted real-time medication use information from the institutional electronic health records and identified MAEs using logic-based rules and natural language processing techniques. The MAE summary was delivered via a real-time messaging platform to promote reduction of patient exposure to potential harm. System performance was validated using a physician-generated gold standard of MAE events, and results were compared with those of current practice (incident reporting and trigger tools).Results: Physicians identified 116 MAEs from 10 104 medication administrations during the study period. Compared to current practice, the sensitivity with automated MAE detection was improved significantly from 4.3% to 85.3% (P=.009), with a positive predictive value of 78.0%. Furthermore, the system showed potential to reduce patient exposure to harm, from 256 min to 35 min (P<.001).Conclusions: The automated system demonstrated improved capacity for identifying MAEs while guarding against alert fatigue. It also showed promise for reducing patient exposure to potential harm following MAE events.",,,,,,,,,14,0,0,0,3,2,14,,,1067-5027,1527-974X,,WOS:000434113200013,29329456,
J,"Mahdavi, Mahdi; Choubdar, Hadi; Zabeh, Erfan; Rieder, Michael; Safavi-Naeini, Safieddin; Jobbagy, Zsolt; Ghorbani, Amirata; Abedini, Atefeh; Kiani, Arda; Khanlarzadeh, Vida; Lashgari, Reza; Kamrani, Ehsan",,,,"Ghorbani, Amirata/AFU-2782-2022","Zabeh, Erfan/0000-0002-9312-9617; Choubdar Parvin, Hadi/0000-0001-9609-1354; Mahdavi, Mahdi/0000-0002-1951-738X; Kamrani, Ehsan/0000-0002-0919-1179",,,A machine learning based exploration of COVID-19 mortality risk,,,,,,,,PLOS ONE,,,,16,7,,,,,e0252384,10.1371/journal.pone.0252384,,,,JUL 2 2021,2021,"Early prediction of patient mortality risks during a pandemic can decrease mortality by assuring efficient resource allocation and treatment planning. This study aimed to develop and compare prognosis prediction machine learning models based on invasive laboratory and noninvasive clinical and demographic data from patients' day of admission. Three Support Vector Machine (SVM) models were developed and compared using invasive, non-invasive, and both groups. The results suggested that non-invasive features could provide mortality predictions that are similar to the invasive and roughly on par with the joint model. Feature inspection results from SVM-RFE and sparsity analysis displayed that, compared with the invasive model, the non-invasive model can provide better performances with a fewer number of features, pointing to the presence of high predictive information contents in several non-invasive features, including SPO2, age, and cardiovascular disorders. Furthermore, while the invasive model was able to provide better mortality predictions for the imminent future, non-invasive features displayed better performance for more distant expiration intervals. Early mortality prediction using non-invasive models can give us insights as to where and with whom to intervene. Combined with novel technologies, such as wireless wearable devices, these models can create powerful frameworks for various medical assignments and patient triage.",,,,,,,,,3,0,0,0,1,0,3,,,1932-6203,,,WOS:000671718200003,34214101,
J,"Kumar, Andre; Aikens, Rachael C.; Hom, Jason; Shieh, Lisa; Chiang, Jonathan; Morales, David; Saini, Divya; Musen, Mark; Baiocchi, Michael; Altman, Russ; Goldstein, Mary K.; Asch, Steven; Chen, Jonathan H.",,,,,"Musen, Mark/0000-0003-3325-793X; Chen, Jonathan H./0000-0002-4387-8740",,,OrderRex clinical user testing: a randomized trial of recommender system decision support on simulated cases,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,12,,,1850,1859,,10.1093/jamia/ocaa190,,,,DEC 2020,2020,"Objective: To assess usability and usefulness of a machine learning-based order recommender system applied to simulated clinical cases.Materials and Methods: 43 physicians entered orders for 5 simulated clinical cases using a clinical order entry interface with or without access to a previously developed automated order recommender system. Cases were randomly allocated to the recommender system in a 3:2 ratio. A panel of clinicians scored whether the orders placed were clinically appropriate. Our primary outcome included the difference in clinical appropriateness scores. Secondary outcomes included total number of orders, case time, and survey responses.Results: Clinical appropriateness scores per order were comparable for cases randomized to the order recommender system (mean difference -0.11 order per score, 95% CI: [-0.41, 0.20]). Physicians using the recommender placed more orders (median 16 vs 15 orders, incidence rate ratio 1.09, 95%CI: [1.01-1.17]). Case times were comparable with the recommender system. Order suggestions generated from the recommender system were more likely to match physician needs than standard manual search options. Physicians used recommender suggestions in 98% of available cases. Approximately 95% of participants agreed the system would be useful for their workflows.Discussion: User testing with a simulated electronic medical record interface can assess the value of machine learning and clinical decision support tools for clinician usability and acceptance before live deployments.Conclusions: Clinicians can use and accept machine learned clinical order recommendations integrated into an electronic order entry interface in a simulated setting. The clinical appropriateness of orders entered was comparable even when supported by automated recommendations.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000606832500004,33106874,
J,"Steitz, Bryan D.; Unertl, Kim M.; Levy, Mia A.",,,,,"Unertl, Kim/0000-0003-0094-3677",,,Characterizing communication patterns among members of the clinical care team to deliver breast cancer treatment,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,236,243,,10.1093/jamia/ocz151,,,,FEB 2020,2020,"Objective: Research to date focused on quantifying team collaboration has relied on identifying shared patients but does not incorporate the major role of communication patterns. The goal of this study was to describe the patterns and volume of communication among care team members involved in treating breast cancer patients.Materials and Methods: We analyzed 4 years of communications data from the electronic health record between care team members at Vanderbilt University Medical Center (VUMC). Our cohort of patients diagnosed with breast cancer was identified using the VUMC tumor registry. We classified each care team member participating in electronic messaging by their institutional role and classified physicians by specialty. To identify collaborative patterns, we modeled the data as a social network.Results: Our cohort of 1181 patients was the subject of 322 424 messages sent in 104 210 unique communication threads by 5620 employees. On average, each patient was the subject of 88.2 message threads involving 106.4 employees. Each employee, on average, sent 72.9 messages and was connected to 24.6 collaborators. Nurses and physicians were involved in 98% and 44% of all message threads, respectively.Discussion and Conclusion: Our results suggest that many providers in our study may experience a high volume of messaging work. By using data routinely generated through interaction with the electronic health record, we can begin to evaluate how to iteratively implement and assess initiatives to improve the efficiency of care coordination and reduce unnecessary messaging work across all care team roles.",,,,,,,,,2,0,0,0,1,0,2,,,1067-5027,1527-974X,,WOS:000515121300007,31682267,
J,"Wright, Adam; Wright, Aileen P.; Aaron, Skye; Sittig, Dean F.",,,,"Sittig, Dean F./D-2471-2009","Sittig, Dean F./0000-0001-5811-8915",,,Smashing the strict hierarchy: three cases of clinical decision support malfunctions involving carvedilol,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,11,,,1552,1555,,10.1093/jamia/ocy091,,,,NOV 2018,2018,"Clinical vocabularies allow for standard representation of clinical concepts, and can also contain knowledge structures, such as hierarchy, that facilitate the creation of maintainable and accurate clinical decision support (CDS). A key architectural feature of clinical hierarchies is how they handle parent-child relationships -specifically whether hierarchies are strict hierarchies (allowing a single parent per concept) or polyhierarchies (allowing multiple parents per concept). These structures handle subsumption relationships (ie, ancestor and descendant relationships) differently. In this paper, we describe three real-world malfunctions of clinical decision support related to incorrect assumptions about subsumption checking for beta-blocker, specifically carvedilol, a non-selective b-blocker that also has a-blocker activity. We recommend that 1) CDS implementers should learn about the limitations of terminologies, hierarchies, and classification, 2) CDS implementers should thoroughly test CDS, with a focus on special or unusual cases, 3) CDS implementers should monitor feedback from users, and 4) electronic health record (EHR) and clinical content developers should offer and support polyhierarchical clinical terminologies, especially for medications.",,,,,,,,,3,0,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000450392500016,30060109,
J,"Rasmussen, Luke V.; Smith, Maureen E.; Almaraz, Federico; Persell, Stephen D.; Rasmussen-Torvik, Laura J.; Pacheco, Jennifer A.; Chisholm, Rex L.; Christensen, Carl; Herr, Timothy M.; Wehbe, Firas H.; Starren, Justin B.",,,,"Wehbe, Firas/Q-6176-2019; Chisholm, Rex/B-3418-2009","Wehbe, Firas/0000-0002-3984-9584; Rasmussen, Luke/0000-0002-4497-8049; Rasmussen-Torvik, Laura/0000-0002-0820-7300; Chisholm, Rex/0000-0002-5638-3990",,,An ancillary genomics system to support the return of pharmacogenomic results,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,4,,,306,310,,10.1093/jamia/ocy187,,,,APR 2019,2019,"Existing approaches to managing genetic and genomic test results from external laboratories typically include filing of text reports within the electronic health record, making them unavailable in many cases for clinical decision support. Even when structured computable results are available, the lack of adopted standards requires considerations for processing the results into actionable knowledge, in addition to storage and management of the data. Here, we describe the design and implementation of an ancillary genomics system used to receive and process heterogeneous results from external laboratories, which returns a descriptive phenotype to the electronic health record in support of pharmacogenetic clinical decision support.",,,,,,,,,9,0,0,0,5,0,9,,,1067-5027,1527-974X,,WOS:000461148100005,30778576,
J,"Zhang, Luwan; Zhang, Yichi; Cai, Tianrun; Ahuja, Yuri; He, Zeling; Ho, Yuk-Lam; Beam, Andrew; Cho, Kelly; Carroll, Robert; Denny, Joshua; Kohane, Isaac; Liao, Katherine; Cai, Tianxi",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332",,,Automated grouping of medical codes via multiview banded spectral clustering,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103322,10.1016/j.jbi.2019.103322,,,,DEC 2019,2019,"Objective: With its increasingly widespread adoption, electronic health records (EHR) have enabled phenotypic information extraction at an unprecedented granularity and scale. However, often a medical concept (e.g. diagnosis, prescription, symptom) is described in various synonyms across different EHR systems, hindering data integration for signal enhancement and complicating dimensionality reduction for knowledge discovery. Despite existing ontologies and hierarchies, tremendous human effort is needed for curation and maintenance - a process that is both unscalable and susceptible to subjective biases. This paper aims to develop a data-driven approach to automate grouping medical terms into clinically relevant concepts by combining multiple up-to-date data sources in an unbiased manner.Methods: We present a novel data-driven grouping approach - multi-view banded spectral clustering (mvBSC) combining summary data from multiple healthcare systems. The proposed method consists of a banding step that leverages the prior knowledge from the existing coding hierarchy, and a combining step that performs spectral clustering on an optimally weighted matrix.Results: We apply the proposed method to group ICD-9 and ICD-10-CM codes together by integrating data from two healthcare systems. We show grouping results and hierarchies for 13 representative disease categories. Individual grouping qualities were evaluated using normalized mutual information, adjusted Rand index, and F-1-measure, and were found to consistently exhibit great similarity to the existing manual grouping counterpart. The resulting ICD groupings also enjoy comparable interpretability and are well aligned with the current ICD hierarchy.Conclusion: The proposed approach, by systematically leveraging multiple data sources, is able to overcome bias while maximizing consensus to achieve generalizability. It has the advantage of being efficient, scalable, and adaptive to the evolving human knowledge reflected in the data, showing a significant step toward automating medical knowledge integration.",,,,,,,,,3,0,0,0,2,0,3,,,1532-0464,1532-0480,,WOS:000525702900006,31672532,
J,"Zadeh Kharrat, Fatemeh Gholi; Brandao Miyoshi, Newton Shydeo; Cobre, Juliana; De Azevedo-Marques, Joao Mazzoncini; de Azevedo-Marques, Paulo Mazzoncini; Botazzo Delbem, Alexandre Claudio",,,,"de azevedo marques, joão mazzoncini/AAQ-8464-2020",,,,Feature sensitivity criterion-based sampling strategy from the Optimization based on Phylogram Analysis (Fs-OPA) and Cox regression applied to mental disorder datasets,,,,,,,,PLOS ONE,,,,15,7,,,,,e0235147,10.1371/journal.pone.0235147,,,,JUL 1 2020,2020,"Digital datasets in several health care facilities, as hospitals and prehospital services, accumulated data from thousands of patients for more than a decade. In general, there is no local team with enough experts with the required different skills capable of analyzing them in entirety. The integration of those abilities usually demands a relatively long-period and is cost. Considering that scenario, this paper proposes a new Feature Sensitivity technique that can automatically deal with a large dataset. It uses a criterion-based sampling strategy from the Optimization based on Phylogram Analysis. Called FS-opa, the new approach seems proper for dealing with any types of raw data from health centers and manipulate their entire datasets. Besides, FS-opa can find the principal features for the construction of inference models without depending on expert knowledge of the problem domain. The selected features can be combined with usual statistical or machine learning methods to perform predictions. The new method can mine entire datasets from scratch. FS-opa was evaluated using a relatively large dataset from electronic health records of mental disorder prehospital services in Brazil. Cox's approach was integrated to FS-opa to generate survival analysis models related to the length of stay (LOS) in hospitals, assuming that it is a relevant aspect that can benefit estimates of the efficiency of hospitals and the quality of patient treatments. Since FS-opa can work with raw datasets, no knowledge from the problem domain was used to obtain the preliminary prediction models found. Results show that FS-opa succeeded in performing a feature sensitivity analysis using only the raw data available. In this way, FS-opa can find the principal features without bias of an inference model, since the proposed method does not use it. Moreover, the experiments show that FS-opa can provide models with a useful trade-off according to their representativeness and parsimony. It can benefit further analyses by experts since they can focus on aspects that benefit problem modeling.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000546994200047,32609749,
J,"Liu, Luchen; Liu, Zequn; Wu, Haoxian; Wang, Zichang; Shen, Jianhao; Song, Yipiing; Zhang, Ming",,,,,,,,Multi-task Learning via Adaptation to Similar Tasks for Mortality Prediction of Diverse Rare Diseases.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,763,772,,,,,,2020,2020,"The mortality prediction of diverse rare diseases using electronic health record (EHR) data is a crucial task for intelligent healthcare. However, data insufficiency and the clinical diversity of rare diseases make it hard for deep learning models to be trained. Mortality prediction for these patients with different diseases can be viewed as a multi-task learning problem with insufficient data but a large number of tasks. On the other hand, insufficient training data makes it difficult to train task-specific modules in multi-task learning models. To address the challenges of data insufficiency and task diversity, we propose an initialization-sharing multi-task learning method (Ada-SiT). Ada-Sit can learn the parameter initialization and dynamically measure the tasks' similarities, used for fast adaptation. We use Ada-SiT to train long short-term memory networks (LSTM) based prediction models on longitudinal EHR data. The experimental results demonstrate that the proposed model is effective for mortality prediction of diverse rare diseases.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936451,33936451,
J,"Ahuja, Yuri; Zhou, Doudou; He, Zeling; Sun, Jiehuan; Castro, Victor M.; Gainer, Vivian; Murphy, Shawn N.; Hong, Chuan; Cai, Tianxi",,,,,"Ahuja, Yuri/0000-0002-8528-0421",,,sureLDA: A multidisease automated phenotyping method for the electronic health record,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,8,,,1235,1243,,10.1093/jamia/ocaa079,,,,AUG 2020,2020,"Objective: A major bottleneck hindering utilization of electronic health record data for translational research is the lack of precise phenotype labels. Chart review as well as rule-based and supervised phenotyping approaches require laborious expert input, hampering applicability to studies that require many phenotypes to be defined and labeled de novo. Though International Classification of Diseases codes are often used as surrogates for true labels in this setting, these sometimes suffer from poor specificity. We propose a fully automated topic modeling algorithm to simultaneously annotate multiple phenotypes.Materials and Methods: Surrogate-guided ensemble latent Dirichlet allocation (sureLDA) is a label-free multidimensional phenotyping method. It first uses the PheNorm algorithm to initialize probabilities based on 2 surrogate features for each target phenotype, and then leverages these probabilities to constrain the LDA topic model to generate phenotype-specific topics. Finally, it combines phenotype-feature counts with surrogates via clustering ensemble to yield final phenotype probabilities.Results: sureLDA achieves reliably high accuracy and precision across a range of simulated and real-world phenotypes. Its performance is robust to phenotype prevalence and relative informativeness of surogate vs nonsurrogate features. It also exhibits powerful feature selection properties.Discussion: sureLDA combines attractive properties of PheNorm and LDA to achieve high accuracy and precision robust to diverse phenotype characteristics. It offers particular improvement for phenotypes insufficiently captured by a few surrogate features. Moreover, sureLDA's feature selection ability enables it to handle high feature dimensions and produce interpretable computational phenotypes.Conclusions: sureLDA is well suited toward large-scale electronic health record phenotyping for highly multiphenotype applications such as phenome-wide association studies.",,,,,,,,,7,0,0,0,1,0,7,,,1067-5027,1527-974X,,WOS:000584507600007,32548637,
J,"Gao, Junyi; Xiao, Cao; Glass, Lucas M.; Sun, Jimeng",,,,,,,,Dr. Agent: Clinical predictive model via mimicked second opinions,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,7,,,1084,1091,,10.1093/jamia/ocaa074,,,,JUL 2020,2020,"Objective: Prediction of disease phenotypes and their outcomes is a difficult task. In practice, patients routinely seek second opinions from multiple clinical experts for complex disease diagnosis. Our objective is to mimic such a practice of seeking second opinions by training 2 agents with different focuses: the primary agent studies the most recent visit of the patient to learn the current health status, and then the second-opinion agent considers the entire patient history to obtain a more global view.Materials and Methods: Our approach Dr. Agent augments recurrent neural networks with 2 policy gradient agents. Moreover, Dr. Agent is customized with various patient demographics information and learns a dynamic skip connection to focus on the relevant information over time. We trained Dr. Agent to perform 4 clinical prediction tasks on the publicly available MIMIC-III (Medical Information Mart for Intensive Care) database: (1) in-hospital mortality prediction, (2) acute care phenotype classification, (3) physiologic decompensation prediction, and (4) forecasting length of stay. We compared the performance of Dr. Agent against 4 baseline clinical predictive models.Results: Dr. Agent outperforms baseline clinical prediction models across all 4 tasks in terms of all metrics. Compared with the best baseline model, Dr. Agent achieves up to 15% higher area under the precision-recall curve on different tasks.Conclusions: Dr. Agent can comprehensively model the long-term dependencies of patients' health status while considering patients' demographics using 2 agents, and therefore achieves better prediction performance on different clinical prediction tasks.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000612220200013,32548622,
J,"Wang, Li; Zhang, Yaoyun; Jiang, Min; Wang, Jingqi; Dong, Jiancheng; Liu, Yun; Tao, Cui; Jiang, Guoqian; Zhou, Yi; Xu, Hua",,,,,"DONG, Jiancheng/0000-0002-9646-2853; Tao, Cui/0000-0002-4267-1924",,,Toward a normalized clinical drug knowledge base in China-applying the RxNorm model to Chinese clinical drugs,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,7,,,809,818,,10.1093/jamia/ocy020,,,,JUL 2018,2018,"Objective: In recent years, electronic health record systems have been widely implemented in China, making clinical data available electronically. However, little effort has been devoted to making drug information exchangeable among these systems. This study aimed to build a Normalized Chinese Clinical Drug (NCCD) knowledge base, by applying and extending the information model of RxNorm to Chinese clinical drugs.Methods: Chinese drugs were collected from 4 major resources-China Food and Drug Administration, China Health Insurance Systems, Hospital Pharmacy Systems, and China Pharmacopoeia-for integration and normalization in NCCD. Chemical drugs were normalized using the information model in RxNorm without much change. Chinese patent drugs (i.e., Chinese herbal extracts), however, were represented using an expanded RxNorm model to incorporate the unique characteristics of these drugs. A hybrid approach combining automated natural language processing technologies and manual review by domain experts was then applied to drug attribute extraction, normalization, and further generation of drug names at different specification levels. Lastly, we reported the statistics of NCCD, as well as the evaluation results using several sets of randomly selected Chinese drugs.Results: The current version of NCCD contains 16 976 chemical drugs and 2663 Chinese patent medicines, resulting in 19 639 clinical drugs, 250 267 unique concepts, and 2 602 760 relations. By manual review of 1700 chemical drugs and 250 Chinese patent drugs randomly selected from NCCD (about 10%), we showed that the hybrid approach could achieve an accuracy of 98.60% for drug name extraction and normalization. Using a collection of 500 chemical drugs and 500 Chinese patent drugs from other resources, we showed that NCCD achieved coverages of 97.0% and 90.0% for chemical drugs and Chinese patent drugs, respectively.Conclusion: Evaluation results demonstrated the potential to improve interoperability across various electronic drug systems in China.",,,,,,,,,6,1,0,0,3,0,7,,,1067-5027,1527-974X,,WOS:000440954800006,29635469,
J,"Li, Fang; Du, Jingcheng; He, Yongqun; Song, Hsing-Yi; Madkour, Mohcine; Rao, Guozheng; Xiang, Yang; Luo, Yi; Chen, Henry W.; Liu, Sijia; Wang, Liwei; Liu, Hongfang; Xu, Hua; Tao, Cui",,,,,"Tao, Cui/0000-0002-4267-1924; Li, Fang/0000-0001-8865-7717; Chen, Henry/0000-0002-6199-0736; Du, Jingcheng/0000-0002-0322-4566",,,Time event ontology (TEO): to support semantic representation and reasoning of complex temporal relations of clinical events,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,7,,,1046,1056,,10.1093/jamia/ocaa058,,,,JUL 2020,2020,"Objective: The goal of this study is to develop a robust Time Event Ontology (TEO), which can formally represent and reason both structured and unstructured temporal information.Materials and Methods: Using our previous Clinical Narrative Temporal Relation Ontology 1.0 and 2.0 as a starting point, we redesigned concept primitives (clinical events and temporal expressions) and enriched temporal relations. Specifically, 2 sets of temporal relations (Allen's interval algebra and a novel suite of basic time relations) were used to specify qualitative temporal order relations, and a Temporal Relation Statement was designed to formalize quantitative temporal relations. Moreover, a variety of data properties were defined to represent diversified temporal expressions in clinical narratives.Results: TEO has a rich set of classes and properties (object, data, and annotation). When evaluated with real electronic health record data from the Mayo Clinic, it could faithfully represent more than 95% of the temporal expressions. Its reasoning ability was further demonstrated on a sample drug adverse event report annotated with respect to TEO. The results showed that our Java-based TEO reasoner could answer a set of frequently asked time-related queries, demonstrating that TEO has a strong capability of reasoning complex temporal relations.Conclusion: TEO can support flexible temporal relation representation and reasoning. Our next step will be to apply TEO to the natural language processing field to facilitate automated temporal information annotation, extraction, and timeline reasoning to better support time-based clinical decision-making.",,,,,,,,,4,1,0,0,1,0,5,,,1067-5027,1527-974X,,WOS:000612220200009,32626903,
J,"Bishop, Jennifer A.; Javed, Hamza A.; El-Bouri, Rasheed; Zhu, Tingting; Taylor, Thomas; Peto, Tim; Watkinson, Peter; Eyre, David W.; Clifton, David A.",,,,,"Taylor, Thomas/0000-0002-4017-7113",,,Improving patient flow during infectious disease outbreaks using machine learning for real-time prediction of patient readiness for discharge,,,,,,,,PLOS ONE,,,,16,11,,,,,e0260476,10.1371/journal.pone.0260476,,,,NOV 23 2021,2021,"BackgroundDelays in patient flow and a shortage of hospital beds are commonplace in hospitals during periods of increased infection incidence, such as seasonal influenza and the COVID-19 pandemic. The objective of this study was to develop and evaluate the efficacy of machine learning methods at identifying and ranking the real-time readiness of individual patients for discharge, with the goal of improving patient flow within hospitals during periods of crisis.Methods and performanceElectronic Health Record data from Oxford University Hospitals was used to train independent models to classify and rank patients' real-time readiness for discharge within 24 hours, for patient subsets according to the nature of their admission (planned or emergency) and the number of days elapsed since their admission. A strategy for the use of the models' inference is proposed, by which the model makes predictions for all patients in hospital and ranks them in order of likelihood of discharge within the following 24 hours. The 20% of patients with the highest ranking are considered as candidates for discharge and would therefore expect to have a further screening by a clinician to confirm whether they are ready for discharge or not. Performance was evaluated in terms of positive predictive value (PPV), i.e., the proportion of these patients who would have been correctly deemed as 'ready for discharge' after having the second screening by a clinician. Performance was high for patients on their first day of admission (PPV = 0.96/0.94 for planned/emergency patients respectively) but dropped for patients further into a longer admission (PPV = 0.66/0.71 for planned/emergency patients still in hospital after 7 days).ConclusionWe demonstrate the efficacy of machine learning methods at making operationally focused, next-day discharge readiness predictions for all individual patients in hospital at any given moment and propose a strategy for their use within a decision-support tool during crisis periods.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000755756800037,34813632,
J,"Soni, Sarvesh; Gudala, Meghana; Wang, Daisy Zhe; Roberts, Kirk",,,,,,,,Using FHIR to Construct a Corpus of Clinical Questions Annotated with Logical Forms and Answers.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,1207,1215,,,,,,2019,2019,"This paper describes a novel technique for annotating logical forms and answers for clinical questions by utilizing Fast Healthcare Interoperability Resources (FHIR). Such annotations are widely used in building the semantic parsing models (which aim at understanding the precise meaning of natural language questions by converting them to machine-understandable logical forms). These systems focus on reducing the time it takes for a user to get to information present in electronic health records (EHRs). Directly annotating questions with logical forms is a challenging task and involves a time-consuming step of concept normalization annotation. We aim to automate this step using the normalized codes present in a FHIR resource. Using the proposed approach, two annotators curated an annotated dataset of 1000 questions in less than 1 week. To assess the quality of these annotations, we trained a semantic parsing model which achieved an accuracy of 94.2% on this corpus.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:32308918,32308918,
J,"Lyudovyk, Olga; Shen, Yufeng; Tatonetti, Nicholas P.; Hsiao, Susan J.; Mansukhani, Mahesh M.; Weng, Chunhua",,,,,"Weng, Chunhua/0000-0002-9624-0214",,,Pathway analysis of genomic pathology tests for prognostic cancer subtyping,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103286,10.1016/j.jbi.2019.103286,,,,OCT 2019,2019,"Genomic test results collected during the provision of medical care and stored in Electronic Health Record (EHR) systems represent an opportunity for clinical research into disease heterogeneity and clinical outcomes. In this paper, we evaluate the use of genomic test reports ordered for cancer patients in order to derive cancer subtypes and to identify biological pathways predictive of poor survival outcomes. A novel method is proposed to calculate patient similarity based on affected biological pathways rather than gene mutations. We demonstrate that this approach identifies subtypes of prognostic value and biological pathways linked to survival, with implications for precision treatment selection and a better understanding of the underlying disease. We also share lessons learned regarding the opportunities and challenges of secondary use of observational genomic data to conduct such research.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000525699600011,31499184,
J,"Jiang, Guoqian; Dhruva, Sanket S.; Chen, Jiajing; Schulz, Wade L.; Doshi, Amit A.; Noseworthy, Peter A.; Zhang, Shumin; Yu, Yue; Young, H. Patrick; Brandt, Eric; Ervin, Keondae R.; Shah, Nilay D.; Ross, Joseph S.; Coplan, Paul; Drozda, Joseph P., Jr.",,,,,"Dhruva, Sanket/0000-0003-0674-2032; Brandt, Eric/0000-0001-5463-4533",,,Feasibility of capturing real-world data from health information technology systems at multiple centers to assess cardiac ablation device outcomes: A fit-for-purpose informatics analysis report,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2241,2250,,10.1093/jamia/ocab117,,JUL 2021,,OCT 2021,2021,"Objective: The study sought to conduct an informatics analysis on the National Evaluation System for Health Technology Coordinating Center test case of cardiac ablation catheters and to demonstrate the role of informatics approaches in the feasibility assessment of capturing real-world data using unique device identifiers (UDIs) that are fit for purpose for label extensions for 2 cardiac ablation catheters from the electronic health records and other health information technology systems in a multicenter evaluation.Materials and Methods: We focused on data capture and transformation and data quality maturity model specified in the National Evaluation System for Health Technology Coordinating Center data quality framework. The informatics analysis included 4 elements: the use of UDIs for identifying device exposure data, the use of standardized codes for defining computable phenotypes, the use of natural language processing for capturing unstructured data elements from clinical data systems, and the use of common data models for standardizing data collection and analyses.Results: We found that, with the UDI implementation at 3 health systems, the target device exposure data could be effectively identified, particularly for brand-specific devices. Computable phenotypes for study outcomes could be defined using codes; however, ablation registries, natural language processing tools, and chart reviews were required for validating data quality of the phenotypes. The common data model implementation status varied across sites. The maturity level of the key informatics technologies was highly aligned with the data quality maturity model.Conclusions: We demonstrated that the informatics approaches can be feasibly used to capture safety and effectiveness outcomes in real-world data for use in medical device studies supporting label extensions.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000745625700022,34313748,
J,"Levy-Fix, Gal; Gorman, Sharon Lipsky; Sepulveda, Jorge L.; Elhadad, Noemie",,,,,,,,When to re-order laboratory tests? Learning laboratory test shelf-life,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,85,,,,21,29,,10.1016/j.jbi.2018.07.019,,,,SEP 2018,2018,"Most laboratory results are valid for only a certain time period (laboratory tests shelf-life), after which they are outdated and the test needs to be re-administered. Currently, laboratory test shelf-lives are not centrally available anywhere but the implicit knowledge of doctors. In this work we propose an automated method to learn laboratory test-specific shelf-life by identifying prevalent laboratory test order patterns in electronic health records. The resulting shelf-lives performed well in the evaluation of internal validity, clinical interpretability, and external validity.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000460600100003,30036675,
J,"Ogunyemi, Omolola, I; Gandhi, Meghal; Lee, Martin; Teklehaimanot, Senait; Daskivich, Lauren Patty; Hindman, David; Lopez, Kevin; Taira, Ricky K.",,,,,"Ogunyemi, Omolola/0000-0002-1388-244X",,,"Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system",,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab066,10.1093/jamiaopen/ooab066,,,,JUL 2021,2021,"Objective: Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem.Materials and Methods: Using electronic health record data from 40 631 unique diabetic patients seen at Los Angeles County Department of Health Services healthcare facilities between January 1, 2015 and December 31, 2017, we compared ten machine learning environments, including five classifier models, for assessing the presence or absence of DR. We also used data from a distinct set of 9300 diabetic patients seen between January 1, 2018 and December 31, 2018 as an external validation set.Results: Following feature subset selection, the classifier with the best AUC on the external validation set was a deep neural network using majority class undersampling, with an AUC of 0.8, the sensitivity of 72.17%, and specificity of 74.2%.Discussion: A deep neural network produced the best AUCs and sensitivity results on the test set and external validation set. Models are intended to be used to screen guideline noncompliant diabetic patients in an urban safety-net setting.Conclusion: Machine learning on diabetic patients' routinely collected clinical data could help clinicians in safety-net settings to identify and target unscreened diabetic patients who potentially have undiagnosed DR.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500035,34423259,
J,"Apostolova, Emilia; Uppal, Amit; Galarraga, Jessica E; Koutroulis, Ioannis; Tschampel, Tim; Wang, Tony; Velez, Tom",,,,,"Galarraga, Jessica/0000-0003-3654-9436",,,Towards Reliable ARDS Clinical Decision Support: ARDS Patient Analytics with Free-text and Structured EMR Data.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,228,237,,,,,,2019,2019,"In this work, we utilize a combination of free-text and structured data to build Acute Respiratory Distress Syndrome(ARDS) prediction models and ARDS phenotype clusters. We derived 'Patient Context Vectors' representing patientspecific contextual ARDS risk factors, utilizing deep-learning techniques on ICD and free-text clinical notes data. The Patient Context Vectors were combined with structured data from the first 24 hours of admission, such as vital signs and lab results, to build an ARDS patient prediction model and an ARDS patient mortality prediction model achieving AUC of 90.16 and 81.01 respectively. The ability of Patient Context Vectors to summarize patients' medical history and current conditions is also demonstrated by the automatic clustering of ARDS patients into clinically meaningful phenotypes based on comorbidities, patient history, and presenting conditions. To our knowledge, this is the first study to successfully combine free-text and structured data, without any manual patient risk factor curation, to build real-time ARDS prediction models.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:32308815,32308815,
J,"Finch, Anthony; Crowell, Alexander; Chang, Yung-Chieh; Parameshwarappa, Pooja; Martinez, Jose; Horberg, Michael",,,,"Crowell, Alexander/AAN-7227-2020","Crowell, Alexander/0000-0002-2866-8139",,,A comparison of attentional neural network architectures for modeling with electronic medical records,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab064,10.1093/jamiaopen/ooab064,,,,JUL 2021,2021,"Objective: Attention networks learn an intelligent weighted averaging mechanism over a series of entities, providing increases to both performance and interpretability. In this article, we propose a novel time-aware transformer-based network and compare it to another leading model with similar characteristics. We also decompose model performance along several critical axes and examine which features contribute most to our model's performance.Materials and methods: Using data sets representing patient records obtained between 2017 and 2019 by the Kaiser Permanente Mid-Atlantic States medical system, we construct four attentional models with varying levels of complexity on two targets (patient mortality and hospitalization). We examine how incorporating transfer learning and demographic features contribute to model success. We also test the performance of a model proposed in recent medical modeling literature. We compare these models with out-of-sample data using the area under the receiver-operator characteristic (AUROC) curve and average precision as measures of performance. We also analyze the attentional weights assigned by these models to patient diagnoses.Results: We found that our model significantly outperformed the alternative on a mortality prediction task (91.96% AUROC against 73.82% AUROC). Our model also outperformed on the hospitalization task, although the models were significantly more competitive in that space (82.41% AUROC against 80.33% AUROC). Furthermore, we found that demographic features and transfer learning features which are frequently omitted from new models proposed in the EMR modeling space contributed significantly to the success of our model.Discussion: We proposed an original construction of deep learning electronic medical record models which achieved very strong performance. We found that our unique model construction outperformed on several tasks in comparison to a leading literature alternative, even when input data was held constant between them. We obtained further improvements by incorporating several methods that are frequently overlooked in new model proposals, suggesting that it will be useful to explore these options further in the future.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500033,34396057,
J,"Akgun, Kathleen M.; Sigel, Keith; Cheung, Kei-Hoi; Kidwai-Khan, Farah; Bryant, Alex K.; Brandt, Cynthia; Justice, Amy; Crothers, Kristina",,,,"Sigel, Keith Magnus/AAZ-7898-2021","Sigel, Keith Magnus/0000-0002-4051-4861; Akgun, Kathleen/0000-0003-2623-7463",,,Extracting lung function measurements to enhance phenotyping of chronic obstructive pulmonary disease (COPD) in an electronic health record using automated tools,,,,,,,,PLOS ONE,,,,15,1,,,,,e0227730,10.1371/journal.pone.0227730,,,,JAN 16 2020,2020,"BackgroundChronic obstructive pulmonary disease (COPD) is associated with poor quality of life, hospitalization and mortality. COPD phenotype includes using pulmonary function tests to determine airflow obstruction from the forced expiratory volume in one second (FEV1):forced vital capacity. FEV1 is a commonly used value for severity but is difficult to identify in structured electronic health record (EHR) data.Data source and methodsUsing the Microsoft SQL Server's full-text search feature and string functions supporting regular-expression-like operations, we developed an automated tool to extract FEV1 values from progress notes to improve ascertainment of FEV1 in EHR in the Veterans Aging Cohort Study (VACS).ResultsThe automated tool increased quantifiable FEV1 values from 12,425 to 16,274 (24% increase in numeric FEV1). Using chart review as the reference, positive predictive value of the tool was 99% (95% Confidence interval: 98.2-100.0%) for identifying quantifiable FEV1 values and a recall value of 100%, yielding an F-measure of 0.99. The tool correctly identified FEV1 measurements in 95% of cases.ConclusionA SQL-based full text search of clinical notes for quantifiable FEV1 is efficient and improves the number of values available in VA data. Future work will examine how these methods can improve phenotyping of patients with COPD in the VA.",,,,,,,,,6,0,0,0,1,0,6,,,1932-6203,,,WOS:000534370100057,31945115,
J,"Tang, Fengyi; Xiao, Cao; Wang, Fei; Zhou, Jiayu",,,,,,,,Predictive modeling in urgent care: a comparative study of machine learning approaches,,,,,,,,JAMIA OPEN,,,,1,1,,,87,98,,10.1093/jamiaopen/ooy011,,,,JUL 2018,2018,"Objective: The growing availability of rich clinical data such as patients' electronic health records provide great opportunities to address a broad range of real-world questions in medicine. At the same time, artificial intelligence and machine learning (ML)-based approaches have shown great premise on extracting insights from those data and helping with various clinical problems. The goal of this study is to conduct a systematic comparative study of different ML algorithms for several predictive modeling problems in urgent care.Design: We assess the performance of 4 benchmark prediction tasks (eg mortality and prediction, differential diagnostics, and disease marker discovery) using medical histories, physiological time-series, and demographics data from the Medical Information Mart for Intensive Care (MIMIC-III) database.Measurements: For each given task, performance was estimated using standard measures including the area under the receiver operating characteristic (AUC) curve, F-1 score, sensitivity, and specificity. Microaveraged AUC was used for multiclass classification models.Results and Discussion: Our results suggest that recurrent neural networks show the most promise in mortality prediction where temporal patterns in physiologic features alone can capture in-hospital mortality risk (AUC> 0.90). Temporal models did not provide additional benefit compared to deep models in differential diagnostics. When comparing the training-testing behaviors of readmission and mortality models, we illustrate that readmission risk may be independent of patient stability at discharge. We also introduce a multiclass prediction scheme for length of stay which preserves sensitivity and AUC with outliers of increasing duration despite decrease in sample size.",,,,,,,,,12,1,0,0,1,0,13,,,,2574-2531,,WOS:000645416900014,31984321,
J,"Liu, Luchen; Li, Haoran; Hu, Zhiting; Shi, Haoran; Wang, Zichang; Tang, Jian; Zhang, Ming",,,,,,,,Learning Hierarchical Representations of Electronic Health Records for Clinical Outcome Prediction.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,597,606,,,,,,2019,2019,"Clinical outcome prediction based on Electronic Health Record (EHR) helps enable early interventions for high-risk patients, and is thus a central task for smart healthcare. Conventional deep sequential models fail to capture the rich temporal patterns encoded in the long and irregular clinical event sequences in EHR. We make the observation that clinical events at a long time scale exhibit strong temporal patterns, while events within a short time period tend to be disordered co-occurrence. We thus propose differentiated mechanisms to model clinical events at different time scales. Our model learns hierarchical representations of event sequences, to adaptively distinguish between short-range and long-range events, and accurately capture their core temporal dependencies. Experimental results on real clinical data show that our model greatly improves over previous state-of-the-art models, achieving AUC scores of 0.94 and 0.90 for predicting death and ICU admission, respectively. Our model also successfully identifies important events for different clinical outcome prediction tasks.",,,,,,,,,1,0,0,0,1,0,1,,,,1942-597X,,MEDLINE:32308854,32308854,
J,"Liu, Qi; Woo, Myung; Zou, Xue; Champaneria, Avee; Lau, Cecilia; Mubbashar, Mohammad Imtiaz; Schwarz, Charlotte; Gagliardi, Jane P.; Tenenbaum, Jessica D.",,,,,,,,Symptom-based patient stratification in mental illness using clinical notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103274,10.1016/j.jbi.2019.103274,,,,OCT 2019,2019,"Mental illnesses are highly heterogeneous with diagnoses based on symptoms that are generally qualitative, subjective, and documented in free text clinical notes rather than as structured data. Moreover, there exists significant variation in symptoms within diagnostic categories as well as substantial overlap in symptoms between diagnostic categories. These factors pose extra challenges for phenotyping patients with mental illness, a task that has proven challenging even for seemingly well characterized diseases. The ability to identify more homogeneous patient groups could both increase our ability to apply a precision medicine approach to psychiatric disorders and enable elucidation of underlying biological mechanism of pathology. We describe a novel approach to deep phenotyping in mental illness in which contextual term extraction is used to identify constellations of symptoms in a cohort of patients diagnosed with schizophrenia and related disorders. We applied topic modeling and dimensionality reduction to identify similar groups of patients and evaluate the resulting clusters through visualization and interrogation of clinically interpretable weighted features. Our findings show that patients diagnosed with schizophrenia may be meaningfully stratified using symptom-based clustering.",,,,,,,,,2,0,0,0,2,0,2,,,1532-0464,1532-0480,,WOS:000525699600013,31499185,
J,"Rosenthal, Bruce; Skrbin, Janet; Fromkin, Janet; Heineman, Emily; McGinn, Tom; Richichi, Rudolph; Berger, Rachel P.",,,,,,,,Integration of physical abuse clinical decision support at 2 general emergency departments,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,10,,,1020,1029,,10.1093/jamia/ocz069,,,,OCT 2019,2019,"Objective: The study sought to develop and evaluate an electronic health record-based child abuse clinical decision support system in 2 general emergency departments.Materials and Methods: A combination of a child abuse screen, natural language processing, physician orders, and discharge diagnoses were used to identify children <2 years of age with injuries suspicious for physical abuse. Providers received an alert and were referred to a physical abuse order set whenever a child triggered the system. Physician compliance with clinical guidelines was compared before and during the intervention.Results: A total of 242 children triggered the system, 86 during the preintervention and 156 during the intervention. The number of children identified with suspicious injuries increased 4-fold during the intervention (P<.001). Compliance was 70% (7 of 10) in the preintervention period vs 50% (22 of 44) in the intervention, a change that was not statistically different (P = .55). Fifty-two percent of providers said that receiving the alert changed their clinical decision making. There was no relationship between compliance and provider or patient demographics.Conclusions: A multifaceted child abuse clinical decision support system resulted in a marked increase in the number of young children identified as having injuries suspicious for physical abuse in 2 general emergency departments. Compliance with published guidelines did not change; we hypothesize that this is related to the increased number of children identified with suspicious, but less serious injuries. These injuries were likely missed preintervention. Tracking compliance with guidelines over time will be important to assess whether compliance increases as physician comfort with evaluation of suspected physical abuse in young children improves.",,,,,,,,,10,0,0,0,1,0,10,,,1067-5027,1527-974X,,WOS:000515123700016,31197358,
J,"Liao, Shun; Kiros, Jamie; Chen, Jiyang; Zhang, Zhaolei; Chen, Ting",,,,,,,,Improving domain adaptation in de-identification of electronic health records through self-training,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2093,2100,,10.1093/jamia/ocab128,,AUG 2021,,OCT 2021,2021,"Objective: De-identification is a fundamental task in electronic health records to remove protected health information entities. Deep learning models have proven to be promising tools to automate de-identification processes. However, when the target domain (where the model is applied) is different from the source domain (where the model is trained), the model often suffers a significant performance drop, commonly referred to as domain adaptation issue. In de-identification, domain adaptation issues can make the model vulnerable for deployment. In this work, we aim to close the domain gap by leveraging unlabeled data from the target domain.Materials and Methods: We introduce a self-training framework to address the domain adaptation issue by leveraging unlabeled data from the target domain. We validate the effectiveness on 4 standard de-identification datasets. In each experiment, we use a pair of datasets: labeled data from the source domain and unlabeled data from the target domain. We compare the proposed self-training framework with supervised learning that directly deploys the model trained on the source domain.Results: In summary, our proposed framework improves the Fl-score by 5.38 (on average) when compared with direct deployment. For example, using i2b2-2014 as the training dataset and i2b2-2006 as the test, the proposed framework increases the Fl-score from 76.61 to 85.41 (+8.8). The method also increases the Fl-score by 10.86 for mimic-radiologyand mimic-discharge.Conclusion: Our work demonstrates an effective self-training framework to boost the domain adaptation performance for the de-identification task for electronic health records.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000745625700005,34363664,
J,"Visweswaran, Shyam; King, Andrew J.; Tajgardoon, Mohammadamin; Calzoni, Luca; Clermont, Gilles; Hochheiser, Harry; Cooper, Gregory F.",,,,"King, Andrew/AAW-5399-2021","King, Andrew/0000-0002-9809-0563",,,Evaluation of eye tracking for a decision support application,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab059,10.1093/jamiaopen/ooab059,,,,JUL 2021,2021,"Eye tracking is used widely to investigate attention and cognitive processes while performing tasks in electronic medical record (EMR) systems. We explored a novel application of eye tracking to collect training data for a machine learning-based clinical decision support tool that predicts which patient data are likely to be relevant for a clinical task. Specifically, we investigated in a laboratory setting the accuracy of eye tracking compared to manual annotation for inferring which patient data in the EMR are judged to be relevant by physicians. We evaluated several methods for processing gaze points that were recorded using a low-cost eye-tracking device. Our results show that eye tracking achieves accuracy and precision of 69% and 53%, respectively compared to manual annotation and are promising for machine learning. The methods for processing gaze points and scripts that we developed offer a first step in developing novel uses for eye tracking for clinical decision support.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500028,34350394,
J,"Yin, Mingwang; Mou, Chengjie; Xiong, Kaineng; Ren, Jiangtao",,,,,"Ren, Jiangtao/0000-0003-2827-8322",,,Chinese clinical named entity recognition with radical-level feature and self-attention mechanism,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103289,10.1016/j.jbi.2019.103289,,,,OCT 2019,2019,"Named entity recognition is a fundamental and crucial task in medical natural language processing problems. In medical fields, Chinese clinical named entity recognition identifies boundaries and types of medical entities from unstructured text such as electronic medical records. Recently, a composition model of bidirectional Long Short-term Memory Networks (BiLSTMs) and conditional random field (BiLSTM-CRF) based character-level semantics has achieved great success in Chinese clinical named entity recognition tasks. But this method can only capture contextual semantics between characters in sentences. However, Chinese characters are hieroglyphics, and deeper semantic information is hidden inside, the BiLSTM-CRF model failed to get this information. In addition, some of the entities in the sentence are dependent, but the Long Short-term Memory (LSTM) does not capture long-term dependencies perfectly between characters. So we propose a BiLSTM-CRF model based on the radical-level feature and self-attention mechanism to solve these problems. We use the convolutional neural network (CNN) to extract radical-level features, aims to capture the intrinsic and internal relevances of characters. In addition, we use self-attention mechanism to capture the dependency between characters regardless of their distance. Experiments show that our model achieves F1-score 93.00% and 86.34% on CCKS-2017 and TP_CNER dataset respectively.",,,,,,,,,25,1,0,0,8,0,26,,,1532-0464,1532-0480,,WOS:000525699600004,31541715,
J,"Wei, Qiang; Chen, Yukun; Salimi, Mandana; Denny, Joshua C.; Mei, Qiaozhu; Lasko, Thomas A.; Chen, Qingxia; Wu, Stephen; Franklin, Amy; Cohen, Trevor; Xu, Hua",,,,"Denny, Josh/AAL-3359-2021","Denny, Josh/0000-0002-3049-7332; Mei, Qiaozhu/0000-0002-8640-1942",,,Cost-aware active learning for named entity recognition in clinical text,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1314,1322,,10.1093/jamia/ocz102,,,,NOV 2019,2019,"Objective: Active Learning (AL) attempts to reduce annotation cost (ie, time) by selecting the most informative examples for annotation. Most approaches tacitly (and unrealistically) assume that the cost for annotating each sample is identical. This study introduces a cost-aware AL method, which simultaneously models both the annotation cost and the informativeness of the samples and evaluates both via simulation and user studies.Materials and Methods: We designed a novel, cost-aware AL algorithm (Cost-CAUSE) for annotating clinical named entities; we first utilized lexical and syntactic features to estimate annotation cost, then we incorporated this cost measure into an existing AL algorithm. Using the 2010 i2b2/VA data set, we then conducted a simulation study comparing Cost-CAUSE with noncost-aware AL methods, and a user study comparing Cost-CAUSE with passive learning.Results: Our cost model fit empirical annotation data well, and Cost-CAUSE increased the simulation area under the learning curve (ALC) scores by up to 5.6% and 4.9%, compared with random sampling and alternate AL methods. Moreover, in a user annotation task, Cost-CAUSE outperformed passive learning on the ALC score and reduced annotation time by 20.5%-30.2%.Discussion: Although AL has proven effective in simulations, our user study shows that a real-world environment is far more complex. Other factors have a noticeable effect on the AL method, such as the annotation accuracy of users, the tiredness of users, and even the physical and mental condition of users.Conclusion: Cost-CAUSE saves significant annotation cost compared to random sampling.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000498169400020,31294792,
J,"Davoodi, Raheleh; Moradi, Mohammad Hassan",,,,"Moradi, Mohammad Hassan/N-6073-2018","Moradi, Mohammad Hassan/0000-0002-3386-4003",,,Mortality prediction in intensive care units (ICUs) using a deep rule-based fuzzy classifier,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,79,,,,48,59,,10.1016/j.jbi.2018.02.008,,,,MAR 2018,2018,"Electronic health records (EHRs) contain critical information useful for clinical studies. Early assessment of patients' mortality in intensive care units is of great importance. In this paper, a Deep Rule-Based Fuzzy System (DRBFS) was proposed to develop an accurate in-hospital mortality prediction in the intensive care unit (ICU) patients employing a large number of input variables. Our main contribution is proposing a system, which is capable of dealing with big data with heterogeneous mixed categorical and numeric attributes. In DRBFS, the hidden layer in each unit is represented by interpretable fuzzy rules. Benefiting the strength of soft partitioning, a modified supervised fuzzy k-prototype clustering has been employed for fuzzy rule generation. According to the stacked approach, the same input space is kept in every base building unit of DRBFS. The training set in addition to random shifts, obtained from random projections of prediction results of the current base building unit is presented as the input of the next base building unit. A cohort of 10,972 adult admissions was selected from Medical Information Mart for Intensive Care (MIMIC-III) data set, where 9.31% of patients have died in the hospital. A heterogeneous feature set of first 48 h from ICU admissions, were extracted for in-hospital mortality rate. Required preprocessing and appropriate feature extraction were applied. To avoid biased assessments, performance indexes were calculated using holdout validation. We have evaluated our proposed method with several common classifiers including naive Bayes (NB), decision trees (DT), Gradient Boosting (GB), Deep Belief Networks (DBN) and D-TSK-FC. The area under the receiver operating characteristics curve (AUROC) for NB, DT, GB, DBN, D-TSK-FC and our proposed method were 73.51%, 61.81%, 72.98%, 70.07%, 66.74% and 73.90% respectively. Our results have demonstrated that DRBFS outperforms various methods, while maintaining interpretable rule bases. Besides, benefiting from specific clustering methods, DRBFS can be well scaled up for large heterogeneous data sets.",,,,,,,,,29,0,0,0,3,0,29,,,1532-0464,1532-0480,,WOS:000430035100006,29471111,
J,"Liu, Lin; Bustamante, Ranier; Earles, Ashley; Demb, Joshua; Messer, Karen; Gupta, Samir",,,,,,,,A strategy for validation of variables derived from large-scale electronic health record data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,121,,,,,,103879,10.1016/j.jbi.2021.103879,,AUG 2021,,SEP 2021,2021,"Purpose: Standardized approaches for rigorous validation of phenotyping from large-scale electronic health record (EHR) data have not been widely reported. We proposed a methodologically rigorous and efficient approach to guide such validation, including strategies for sampling cases and controls, determining sample sizes, estimating algorithm performance, and terminating the validation process, hereafter referred to as the San Diego Approach to Variable Validation (SDAVV).Methods: We propose sample size formulae which should be used prior to chart review, based on pre-specified critical lower bounds for positive predictive value (PPV) and negative predictive value (NPV). We also propose a stepwise strategy for iterative algorithm development/validation cycles, updating sample sizes for data abstraction until both PPV and NPV achieve target performance.Results: We applied the SDAVV to a Department of Veterans Affairs study in which we created two phenotyping algorithms, one for distinguishing normal colonoscopy cases from abnormal colonoscopy controls and one for identifying aspirin exposure. Estimated PPV and NPV both reached 0.970 with a 95% confidence lower bound of 0.915, estimated sensitivity was 0.963 and specificity was 0.975 for identifying normal colonoscopy cases. The phenotyping algorithm for identifying aspirin exposure reached a PPV of 0.990 (a 95% lower bound of 0.950), an NPV of 0.980 (a 95% lower bound of 0.930), and sensitivity and specificity were 0.960 and 1.000.Conclusions: A structured approach for prospectively developing and validating phenotyping algorithms from large-scale EHR data can be successfully implemented, and should be considered to improve the quality of big data research.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000694715700001,34329789,
J,"Perros, Ioakeim; Papalexakis, Evangelos E.; Vuduc, Richard; Searles, Elizabeth; Sun, Jimeng",,,,,"Papalexakis, Evangelos/0000-0002-3411-8483",,,Temporal phenotyping of medically complex children via PARAFAC2 tensor factorization,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,93,,,,,,103125,10.1016/j.jbi.2019.103125,,,,MAY 2019,2019,"Objective: Our aim is to extract clinically-meaningful phenotypes from longitudinal electronic health records (EHRs) of medically-complex children. This is a fragile set of patients consuming a disproportionate amount of pediatric care resources but who often end up with sub-optimal clinical outcome. The rise in available electronic health records (EHRs) provide a rich data source that can be used to disentangle their complex clinical conditions into concise, clinically-meaningful groups of characteristics. We aim at identifying those phenotypes and their temporal evolution in a scalable, computational manner, which avoids the time-consuming manual chart review.Materials and methods: We analyze longitudinal EHRs from Children's Healthcare of Atlanta including 1045 medically complex patients with a total of 59,948 encounters over 2 years. We apply a tensor factorization method called PARAFAC2 to extract: (a) clinically-meaningful groups of features (b) concise patient representations indicating the presence of a phenotype for each patient, and (c) temporal signatures indicating the evolution of those phenotypes over time for each patient.Results: We identified four medically complex phenotypes, namely gastrointestinal disorders, oncological conditions, blood-related disorders, and neurological system disorders, which have distinct clinical characterizations among patients. We demonstrate the utility of patient representations produced by PARAFAC2, towards identifying groups of patients with significant survival variations. Finally, we showcase representative examples of the temporal phenotypic trends extracted for different patients.Discussion: Unsupervised temporal phenotyping is an important task since it minimizes the burden on behalf of clinical experts, by relegating their involvement in the output phenotypes' validation. PARAFAC2 enjoys several compelling properties towards temporal computational phenotyping: (a) it is able to handle high-dimensional data and variable numbers of encounters across patients, (b) it has an intuitive interpretation and (c) it is free from ad-hoc parameter choices. Computational phenotypes, such as the ones computed by our approach, have multiple applications; we highlight three of them which are particularly useful for medically complex children: (1) integration into clinical decision support systems, (2) interpretable mortality prediction and 3) clinical trial recruitment.Conclusion: PARAFAC2 can be applied to unsupervised temporal phenotyping tasks where precise definitions of different phenotypes are absent, and lengths of patient records are varying.",,,,,,,,,7,0,0,0,4,0,7,,,1532-0464,1532-0480,,WOS:000525690500016,30743070,
J,"Albers, D. J.; Elhadad, N.; Claassen, J.; Perotte, R.; Goldstein, A.; Hripcsak, G.",,,,"Claassen, Jan/AAA-5451-2020","Perotte, Rimma/0000-0002-7686-189X",,,Estimating summary statistics for electronic health record laboratory data for use in high-throughput phenotyping algorithms,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,78,,,,87,101,,10.1016/j.jbi.2018.01.004,,,,FEB 2018,2018,"We study the question of how to represent or summarize raw laboratory data taken from an electronic health record (EHR) using parametric model selection to reduce or cope with biases induced through clinical care. It has been previously demonstrated that the health care process (Hripcsak and Albers, 2012, 2013), as defined by -measurement context (Hripcsak and Albers, 2013; Albers et al., 2012) and measurement patterns (Albers and Hripcsak, 2010, 2012), can influence how EHR data are distributed statistically (Kohane and Weber, 2013; Pivovarov et al., 2014). We construct an algorithm, PopKLD, which is based on information criterion model selection (Burnham and Anderson, 2002; Claeskens and Hjort, 2008), is intended to reduce and cope with health care process biases and to produce an intuitively understandable continuous summary. The PopKLD algorithm can be automated and is designed to be applicable in high-throughput settings; for example, the output of the PopKLD algorithm can be used as input for phenotyping algorithms. Moreover, we develop the PopKLD-CAT algorithm that transforms the continuous PopKLD summary into a categorical summary useful for applications that require categorical data such as topic modeling. We evaluate our methodology in two ways. First, we apply the method to laboratory data collected in two different health care contexts, primary versus intensive care. We show that the PopKLD preserves known physiologic features in the data that are lost when summarizing the data using more common laboratory data summaries such as mean and standard deviation. Second, for three disease laboratory measurement pairs, we perform a phenotyping task: we use the PopKLD and PopKLD-CAT algorithms to define high and low values of the laboratory variable that are used for defining a disease state. We then compare the relationship between the PopKLD-CAT summary disease predictions and the same predictions using empirically estimated mean and standard deviation to a gold standard generated by clinical review of patient records. We find that the PopKLD laboratory data summary is substantially better at predicting disease state. The PopKLD or PopKLD-CAT algorithms are not meant to be used as phenotyping algorithms, but we use the phenotyping task to show what information can be gained when using a more informative laboratory data summary. In the process of evaluation our method we show that the different clinical contexts and laboratory measurements necessitate different statistical summaries. Similarly, leveraging the principle of maximum entropy we argue that while some laboratory data only have sufficient information to estimate a mean and standard deviation, other laboratory data captured in an EHR contain substantially more information than can be captured in higher-parameter models.",,,,,,,,,11,0,0,0,6,0,11,,,1532-0464,1532-0480,,WOS:000430035300009,29369797,
J,"To, Daniel; Joyce, Cara; Kulshrestha, Sujay; Sharma, Brihat; Dligach, Dmitry; Churpek, Matthew; Afshar, Majid",,,,,,,,The Addition of United States Census-Tract Data Does Not Improve the Prediction of Substance Misuse.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,1149,1158,,,,,,2021,2021,"Predictors from the structured data in the electronic health record (EHR) have previously been used for case-identification in substance misuse. We aim to examine the added benefit from census-tract data, a proxy for socioeconomic status, to improve identification. A cohort of 186,611 hospitalizations was derived between 2007 and 2017. Reference labels included alcohol misuse only, opioid misuse only, and both alcohol and opioid misuse. Baseline models were created using 24 EHR variables, and enhanced models were created with the addition of 48 census-tract variables from the United States American Community Survey. The absolute net reclassification index (NRI) was applied to measure the benefit in adding census-tract variables to baseline models. The baseline models already had good calibration and discrimination. Adding census-tract variables provided negligible improvement to sensitivity and specificity and NRI was less than 1% across substance groups. Our results show the census-tract added minimal value to prediction models.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308901,35308901,
J,"Garcelon, Nicolas; Neuraz, Antoine; Salomon, Remi; Faour, Hassan; Benoit, Vincent; Delapalme, Arthur; Munnich, Arnold; Burgun, Anita; Rance, Bastien",,,,"Neuraz, Antoine/ABI-6442-2020; Garcelon, Nicolas/AAB-3080-2022","Neuraz, Antoine/0000-0001-7142-6728; Garcelon, Nicolas/0000-0002-3326-2811; Rance, Bastien/0000-0003-4417-1197",,,A clinician friendly data warehouse oriented toward narrative reports: Dr. Warehouse,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,80,,,,52,63,,10.1016/j.jbi.2018.02.019,,,,APR 2018,2018,"Introduction: Clinical data warehouses are often oriented toward integration and exploration of coded data. However narrative reports are of crucial importance for translational research. This paper describes Dr. Warehouse (R), an open source data warehouse oriented toward clinical narrative reports and designed to support clinicians' day-to-day use.Method: Dr. Warehouse relies on an original database model to focus on documents in addition to facts. Besides classical querying functionalities, the system provides an advanced search engine and Graphical User Interfaces adapted to the exploration of text. Dr. Warehouse is dedicated to translational research with cohort recruitment capabilities, high throughput phenotyping and patient centric views (including similarity metrics among patients). These features leverage Natural Language Processing based on the extraction of UMIS (R) concepts, as well as negation and family history detection.Results: A survey conducted after 6 months of use at the Necker Children's Hospital shows a high rate of satisfaction among the users (96.6%). During this period, 122 users performed 2837 queries, accessed 4,267 patients' records and included 36,632 patients in 131 cohorts.The source code is available at this github linkhttps://github.com/imagine-bdd/DRWH.A demonstration based on PubMed abstracts is available at https://imagine-plateforme-bdd.fr/dwh_pubmed/",,,,,,,,,42,0,0,0,14,0,42,,,1532-0464,1532-0480,,WOS:000430035000006,29501921,
J,"Aaron, Skye; McEvoy, Dustin S.; Ray, Soumi; Hickman, Thu-Trang T.; Wright, Adam",,,,,,,,Cranky comments: detecting clinical decision support malfunctions through free-text override reasons,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,1,,,37,43,,10.1093/jamia/ocy139,,,,JAN 2019,2019,"Background: Rule-base clinical decision support alerts are known to malfunction, but tools for discovering malfunctions are limited. Objective: Investigate whether user override comments can be used to discover malfunctions.Methods: We manually classified all rules in our database with at least 10 override comments into 3 categories based on a sample of override comments: broken, not broken, but could be improved, and not broken. We used 3 methods (frequency of comments, cranky word list heuristic, and a Naive Bayes classifier trained on a sample of comments) to automatically rank rules based on features of their override comments. We evaluated each ranking using the manual classification as truth.Results: Of the rules investigated, 62 were broken, 13 could be improved, and the remaining 45 were not broken. Frequency of comments performed worse than a random ranking, with precision at 20 of 8 and AUC = 0.487. The cranky comments heuristic performed better with precision at 20 of 16 and AUC = 0.723. The Naive Bayes classifier had precision at 20 of 17 and AUC = 0.738.Discussion: Override comments uncovered malfunctions in 26% of all rules active in our system. This is a lower bound on total malfunctions and much higher than expected. Even for low-resource organizations, reviewing comments identified by the cranky word list heuristic may be an effective and feasible way of finding broken alerts.Conclusion: Override comments are a rich data source for finding alerts that are broken or could be improved. If possible, we recommend monitoring all override comments on a regular basis.",,,,,,,,,12,0,0,0,1,0,12,,,1067-5027,1527-974X,,WOS:000461520100006,30590557,
J,"Cronin, Robert M.; Conway, Douglas; Condon, David; Jerome, Rebecca N.; Byrne, Daniel W.; Harris, Paul A.",,,,,"Condon, David/0000-0002-8406-783X",,,Patient and healthcare provider views on a patient-reported outcomes portal,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,11,,,1470,1480,,10.1093/jamia/ocy111,,,,NOV 2018,2018,"Background: Over the past decade, public interest in managing health-related information for personal understanding and self-improvement has rapidly expanded. This study explored aspects of how patient-provided health information could be obtained through an electronic portal and presented to inform and engage patients while also providing information for healthcare providers.Methods: We invited participants using ResearchMatch from 2 cohorts: (1) self-reported healthy volunteers (no medical conditions) and (2) individuals with a self-reported diagnosis of anxiety and/or depression. Participants used a secure web application (dashboard) to complete the PROMIS VR domain survey(s) and then complete a feedback survey. A community engagement studio with 5 healthcare providers assessed perspectives on the feasibility and features of a portal to collect and display patient provided health information. We used bivariate analyses and regression analyses to determine differences between cohorts.Results: A total of 480 participants completed the study (239 healthy, 241 anxiety and/or depression). While participants from the tw2o cohorts had significantly different PROMIS scores (p<. 05), both cohorts welcomed the concept of a patient-centric dashboard, saw value in sharing results with their healthcare provider, and wanted to view results over time. However, factors needing consideration before widespread use included personalization for the patient and their health issues, integration with existing information (eg electronic health records), and integration into clinician workflow.Conclusions: Our findings demonstrated a strong desire among healthy people, patients with chronic diseases, and healthcare providers for a self-assessment portal that can collect patient-reported outcome metrics and deliver personalized feedback.",,,,,,,,,19,0,0,0,2,0,19,,,1067-5027,1527-974X,,WOS:000450392500006,30239733,
J,"Geva, Alon; Abman, Steven H.; Manzi, Shannon F.; Ivy, David Dunbar; Mullen, Mary P.; Griffin, John; Lin, Chen; Savova, Guergana K.; Mandl, Kenneth D.",,,,"Geva, Alon/AAM-6793-2021","Geva, Alon/0000-0002-8574-0133",,,Adverse drug event rates in pediatric pulmonary hypertension: a comparison of real-world data sources,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,294,300,,10.1093/jamia/ocz194,,,,FEB 2020,2020,"Objective: Real-world data (RWD) are increasingly used for pharmacoepidemiology and regulatory innovation. Our objective was to compare adverse drug event (ADE) rates determined from two RWD sources, electronic health records and administrative claims data, among children treated with drugs for pulmonary hypertension.Materials and Methods: Textual mentions of medications and signs/symptoms that may represent ADEs were identified in clinical notes using natural language processing. Diagnostic codes for the same signs/symptoms were identified in our electronic data warehouse for the patients with textual evidence of taking pulmonary hypertension-targeted drugs. We compared rates of ADEs identified in clinical notes to those identified from diagnostic code data. In addition, we compared putative ADE rates from clinical notes to those from a healthcare claims dataset from a large, national insurer.Results: Analysis of clinical notes identified up to 7-fold higher ADE rates than those ascertained from diagnostic codes. However, certain ADEs (eg, hearing loss) were more often identified in diagnostic code data. Similar results were found when ADE rates ascertained from clinical notes and national claims data were compared.Discussion: While administrative claims and clinical notes are both increasingly used for RWD-based pharmacovigilance, ADE rates substantially differ depending on data source.Conclusion: Pharmacovigilance based on RWD may lead to discrepant results depending on the data source analyzed. Further work is needed to confirm the validity of identified ADEs, to distinguish them from disease effects, and to understand tradeoffs in sensitivity and specificity between data sources.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000515121300013,31769835,
J,"Yoo, Tae Keun; Oh, Ein; Kim, Hong Kyu; Ryu, Ik Hee; Lee, In Sik; Kim, Jung Sub; Kim, Jin Kuk",,,,"Yoo, Tae Keun/Q-3620-2019","Yoo, Tae Keun/0000-0003-0890-8614",,,Deep learning-based smart speaker to confirm surgical sites for cataract surgeries: A pilot study,,,,,,,,PLOS ONE,,,,15,4,,,,,e0231322,10.1371/journal.pone.0231322,,,,APR 9 2020,2020,"Wrong-site surgeries can occur due to the absence of an appropriate surgical time-out. However, during a time-out, surgical participants are unable to review the patient's charts due to their aseptic hands. To improve the conditions in surgical time-outs, we introduce a deep learning-based smart speaker to confirm the surgical information prior to cataract surgeries. This pilot study utilized the publicly available audio vocabulary dataset and recorded audio data published by the authors. The audio clips of the target words, such as left, right, cataract, phacoemulsification, and intraocular lens, were selected to determine and confirm surgical information in the time-out speech. A deep convolutional neural network model was trained and implemented in the smart speaker that was developed using a mini development board and commercial speakerphone. To validate our model in the consecutive speeches during time-outs, we generated 200 time-out speeches for cataract surgeries by randomly selecting the surgical statuses of the surgical participants. After the training process, the deep learning model achieved an accuracy of 96.3% for the validation dataset of short-word audio clips. Our deep learning-based smart speaker achieved an accuracy of 93.5% for the 200 time-out speeches. The surgical and procedural accuracy was 100%. Additionally, on validating the deep learning model by using web-generated time-out speeches and video clips for general surgery, the model exhibited a robust and good performance. In this pilot study, the proposed deep learning-based smart speaker was able to successfully confirm the surgical information during the time-out speech. Future studies should focus on collecting real-world time-out data and automatically connecting the device to electronic health records. Adopting smart speaker-assisted time-out phases will improve the patients' safety during cataract surgeries, particularly in relation to wrong-site surgeries.",,,,,,,,,2,1,0,0,1,0,3,,,1932-6203,,,WOS:000535977000073,32271836,
J,"Ko, Michael; Chen, Emma; Agrawal, Ashwin; Rajpurkar, Pranav; Avati, Anand; Ng, Andrew; Basu, Sanjay; Shah, Nigam H.",,,,,"Agrawal, Ashwin/0000-0003-1301-2679; Rajpurkar, Pranav/0000-0002-8030-3727",,,Improving hospital readmission prediction using individualized utility analysis,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,119,,,,,,103826,10.1016/j.jbi.2021.103826,,JUN 2021,,JUL 2021,2021,"Objective: Machine learning (ML) models for allocating readmission-mitigating interventions are typically selected according to their discriminative ability, which may not necessarily translate into utility in allocation of resources. Our objective was to determine whether ML models for allocating readmission-mitigating interventions have different usefulness based on their overall utility and discriminative ability. Materials and methods: We conducted a retrospective utility analysis of ML models using claims data acquired from the Optum Clinformatics Data Mart, including 513,495 commercially-insured inpatients (mean [SD] age 69 [19] years; 294,895 [57%] Female) over the period January 2016 through January 2017 from all 50 states with mean 90 day cost of $11,552. Utility analysis estimates the cost, in dollars, of allocating interventions for lowering readmission risk based on the reduction in the 90-day cost. Results: Allocating readmission-mitigating interventions based on a GBDT model trained to predict readmissions achieved an estimated utility gain of $104 per patient, and an AUC of 0.76 (95% CI 0.76, 0.77); allocating interventions based on a model trained to predict cost as a proxy achieved a higher utility of $175.94 per patient, and an AUC of 0.62 (95% CI 0.61, 0.62). A hybrid model combining both intervention strategies is comparable with the best models on either metric. Estimated utility varies by intervention cost and efficacy, with each model performing the best under different intervention settings. Conclusion: We demonstrate that machine learning models may be ranked differently based on overall utility and discriminative ability. Machine learning models for allocation of limited health resources should consider directly optimizing for utility.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000674512900009,34087428,
J,"Chen, Xiaoyi; Garcelon, Nicolas; Neuraz, Antoine; Billot, Katy; Lelarge, Marc; Bonald, Thomas; Garcia, Hugo; Martin, Yoann; Benoit, Vincent; Vincent, Marc; Faour, Hassan; Douillet, Maxime; Lyonnet, Stanislas; Saunier, Sophie; Burgun, Anita",,,,"Chen, Xiaoyi/L-9112-2019; Neuraz, Antoine/ABI-6442-2020; Garcelon, Nicolas/AAB-3080-2022; Chen, Xiaoyi/AAN-4055-2020; saunier, sophie/G-6044-2015","Neuraz, Antoine/0000-0001-7142-6728; Chen, Xiaoyi/0000-0002-7378-5158; Garcelon, Nicolas/0000-0002-3326-2811; saunier, sophie/0000-0002-1069-0047",,,Phenotypic similarity for rare disease: Ciliopathy diagnoses and subtyping,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103308,10.1016/j.jbi.2019.103308,,,,DEC 2019,2019,"Rare diseases are often hard and long to be diagnosed precisely, and most of them lack approved treatment. For some complex rare diseases, precision medicine approach is further required to stratify patients into homogeneous subgroups based on the clinical, biological or molecular features. In such situation, deep phenotyping of these patients and comparing their profiles based on subjacent similarities are thus essential to help fast and precise diagnoses and better understanding of pathophysiological processes in order to develop therapeutic solutions. In this article, we developed a new pipeline of using deep phenotyping to define patient similarity and applied it to ciliopathies, a group of rare and severe diseases caused by ciliary dysfunction. As a French national reference center for rare and undiagnosed diseases, the Necker-Enfants Malades Hospital (Necker Children's Hospital) hosts the Imagine Institute, a research institute focusing on genetic diseases. The clinical data warehouse contains on one hand EHR data, and on the other hand, clinical research data. The similarity metrics were computed on both data sources, and were evaluated with two tasks: diagnoses with EHRs and subtyping with ciliopathy specific research data. We obtained a precision of 0.767 in the top 30 most similar patients with diagnosed ciliopathies. Subtyping ciliopathy patients with phenotypic similarity showed concordances with expert knowledge. Similarity metrics applied to rare disease offer new perspectives in a translational context that may help to recruit patients for research, reduce the length of the diagnostic journey, and better understand the mechanisms of the disease.",,,,,,,,,5,0,0,0,3,0,5,,,1532-0464,1532-0480,,WOS:000525702900015,31622800,
J,"Wajsburt, Perceval; Sarfati, Arnaud; Tannier, Xavier",,,,,"Tannier, Xavier/0000-0002-2452-8868",,,Medical concept normalization in French using multilingual terminologies and contextual embeddings,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,114,,,,,,103684,10.1016/j.jbi.2021.103684,,JAN 2021,,FEB 2021,2021,"Introduction: Concept normalization is the task of linking terms from textual medical documents to their concept in terminologies such as the UMLS (R). Traditional approaches to this problem depend heavily on the coverage of available resources, which poses a problem for languages other than English.Objective: We present a system for concept normalization in French. We consider textual mentions already extracted and labeled by a named entity recognition system, and we classify these mentions with a UMLS concept unique identifier. We take advantage of the multilingual nature of available terminologies and embedding models to improve concept normalization in French without translation nor direct supervision.Materials and methods: We consider the task as a highly-multiclass classification problem. The terms are encoded with contextualized embeddings and classified via cosine similarity and softmax. A first step uses a subset of the terminology to finetune the embeddings and train the model. A second step adds the entire target terminology, and the model is trained further with hard negative selection and softmax sampling.Results: On two corpora from the Quaero FrenchMed benchmark, we show that our approach can lead to good results even with no labeled data at all; and that it outperforms existing supervised methods with labeled data. Discussion: Training the system with both French and English terms improves by a large margin the performance of the system on a French benchmark, regardless of the way the embeddings were pretrained (French, English, multilingual). Our distantly supervised method can be applied to any kind of documents or medical domain, as it does not require any concept-labeled documents.Conclusion: These experiments pave the way for simpler and more effective multilingual approaches to processing medical texts in languages other than English.",,,,,,,,,1,0,0,0,0,0,1,,,1532-0464,1532-0480,,WOS:000695470600007,33450387,
J,"Miller, David M.; Shalhout, Sophia Z.",,,,,"Shalhout, Sophia/0000-0002-2783-5265; Miller, David/0000-0001-9736-9119",,,GENETEX-a GENomics Report TEXt mining R package and Shiny application designed to capture real-world clinico-genomic data,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab082,10.1093/jamiaopen/ooab082,,,,JUL 2021,2021,"Objectives: Clinico-genomic data (CGD) acquired through routine clinical practice has the potential to improve our understanding of clinical oncology. However, these data often reside in heterogeneous and semistructured data, resulting in prolonged time-to-analyses.Materials and Methods: We created GENETEX: an R package and Shiny application for text mining genomic reports from electronic health record (EHR) and direct import into Research Electronic Data Capture (REDCap).Results: GENETEX facilitates the abstraction of CGD from EHR and streamlines the capture of structured data into REDCap. Its functions include natural language processing of key genomic information, transformation of semistructured data into structured data, and importation into REDCap. When evaluated with manual abstraction, GENETEX had >99% agreement and captured CGD in approximately one-fifth the time.Conclusions: GENETEX is freely available under the Massachusetts Institute of Technology license and can be obtained from GitHub (https://github.com/TheMillerLab/genetex). GENETEX is executed in R and deployed as a Shiny application for non-R users. It produces high-fidelity abstraction of CGD in a fraction of the time.",,,,,,,,,1,0,0,0,0,0,1,,,,2574-2531,,WOS:000731864500050,34595403,
J,"Peterson, Kevin J.; Jiang, Guoqian; Liu, Hongfang",,,,,,,,A corpus-driven standardization framework for encoding clinical problems with HL7 FHIR,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,110,,,,,,103541,10.1016/j.jbi.2020.103541,,,,OCT 2020,2020,"Free-text problem descriptions are brief explanations of patient diagnoses and issues, commonly found in problem lists and other prominent areas of the medical record. These compact representations often express complex and nuanced medical conditions, making their semantics challenging to fully capture and standardize. In this study, we describe a framework for transforming free-text problem descriptions into standardized Health Level 7 (HL7) Fast Healthcare Interoperability Resources (FHIR) models.This approach leverages a combination of domain-specific dependency parsers, Bidirectional Encoder Representations from Transformers (BERT) natural language models, and cui2vec Unified Medical Language System (UMLS) concept vectors to align extracted concepts from free-text problem descriptions into structured FHIR models. A neural network classification model is used to classify thirteen relationship types between concepts, facilitating mapping to the FHIR Condition resource. We use data programming, a weak supervision approach, to eliminate the need for a manually annotated training corpus. Shapley values, a mechanism to quantify contribution, are used to interpret the impact of model features.We found that our methods identified the focus concept, or primary clinical concern of the problem description, with an F-1 score of 0.95. Relationships from the focus to other modifying concepts were extracted with an F-1 score of 0.90. When classifying relationships, our model achieved a 0.89 weighted average F-1 score, enabling accurate mapping of attributes into HL7 FHIR models. We also found that the BERT input representation predominantly contributed to the classifier decision as shown by the Shapley values analysis.",,,,,,,,,5,0,0,0,2,0,5,,,1532-0464,1532-0480,,WOS:000579807600004,32814201,
J,"Dong, Xiao; Li, Jianfu; Soysal, Ekin; Bian, Jiang; DuVall, Scott L.; Hanchrow, Elizabeth; Liu, Hongfang; Lynch, Kristine E.; Matheny, Michael; Natarajan, Karthik; Ohno-Machado, Lucila; Pakhomov, Serguei; Reeves, Ruth Madeleine; Sitapati, Amy M.; Abhyankar, Swapna; Cullen, Theresa; Deckard, Jami; Jiang, Xiaoqian; Murphy, Robert; Xu, Hua",,,,,,,,COVID-19 TestNorm: A tool to normalize COVID-19 testing names to LOINC codes,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1437,1442,,10.1093/jamia/ocaa145,,,,SEP 2020,2020,"Large observational data networks that leverage routine clinical practice data in electronic health records (EHRs) are critical resources for research on coronavirus disease 2019 (COVID-19). Data normalization is a key challenge for the secondary use of EHRs for COVID-19 research across institutions. In this study, we addressed the challenge of automating the normalization of COVID-19 diagnostic tests, which are critical data elements, but for which controlled terminology terms were published after clinical implementation. We developed a simple but effective rule-based tool called COVID-19 TestNorm to automatically normalize local COVID-19 testing names to standard LOINC (Logical Observation Identifiers Names and Codes) codes. COVID-19 TestNorm was developed and evaluated using 568 test names collected from 8 healthcare systems. Our results show that it could achieve an accuracy of 97.4% on an independent test set. COVID-19 TestNorm is available as an opensource package for developers and as an online Web application for end users (https://clamp.uth.edu/covid/loinc.php). We believe that it will be a useful tool to support secondary use of EHRs for research on COVID-19.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000593113300014,32569358,
J,"Talal, Andrew H.; Sofikitou, Elisavet M.; Jaanimagi, Urmo; Zeremski, Marija; Tobin, Jonathan N.; Markatou, Marianthi",,,,"Sofikitou, Elisavet/AAM-4690-2020","Sofikitou, Elisavet/0000-0002-8405-684X; Tobin, Jonathan/0000-0003-4722-539X",,,A framework for patient-centered telemedicine: Application and lessons learned from vulnerable populations,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,112,,,,,,103622,10.1016/j.jbi.2020.103622,,,,DEC 2020,2020,"Virtual technologies can facilitate clinical monitoring, clinician-patient interactions, and enhance patient centered approaches to healthcare delivery. Telemedicine, two-way communication between a healthcare provider and a patient not in the same physical location, emphasizes patient preference and convenience by substituting the transportation of patients with information transfer. We present a framework for implementation of a comprehensive, dynamic, patient-centered telemedicine network deployed in 12 opioid treatment programs (OTP) located throughout New York State (NYS). The program aims to effectively manage hepatitis C virus (HCV) infection via telemedicine with co-administration of HCV and substance use medications. We have found that the Sociotechnical System model with emphasis on patient-centered factors provides a framework for telemedicine deployment and implementation to a vulnerable population. The issue of interoperability between the telemedicine platform and the electronic health record (EHR) system as well as clinical information retrieval for medical decision-making are challenges with implementation of a comprehensive, dynamic telemedicine system. Targeting telemedicine to a vulnerable population requires additional consideration of trust in the security and confidentiality of the telemedicine system. Our contribution is the valuable lessons learned from implementing a comprehensive, dynamic, patient-centered telemedicine system among an OTP network throughout NYS as applied to a vulnerable population that can be generalized to other difficult-to-reach populations.",,,,,,,,,11,0,0,0,1,0,11,,,1532-0464,1532-0480,,WOS:000615718800005,33186707,
J,"Hanson, Gillian; Chitnis, Tanuja; Williams, Mitzi J.; Gan, Ryan William; Julian, Laura; Mace, Kieran; Chia, Jenny; Wormser, David; Martinec, Michael; Astorino, Troy; Leviner, Noga; Maung, Pye; Jan, Asif; Belendiuk, Katherine",,,,,,,,Generating real-world data from health records: design of a patient-centric study in multiple sclerosis using a commercial health records platform,,,,,,,,JAMIA OPEN,,,,5,1,,,,,ooab110,10.1093/jamiaopen/ooab110,,,,JAN 7 2022,2022,"Objective The FlywheelMS study will explore the use of a real-world health record data set generated by PicnicHealth, a patient-centric health records platform, to improve understanding of disease course and patterns of care for patients with multiple sclerosis (MS). Materials and Methods The FlywheelMS study aims to enroll 5000 adults with MS in the United States to create a large, deidentified, longitudinal data set for clinical research. PicnicHealth obtains health records, including paper charts, electronic health records, and radiology imaging files from any healthcare site. Using a large-scale health record processing pipeline, PicnicHealth abstracts standard and condition-specific data elements from structured (eg, laboratory test results) and unstructured (eg, narrative) text and maps these to standardized medical vocabularies. Researchers can use the resulting data set to answer empirical questions and study participants can access and share their harmonized health records using PicnicHealth's web application. Results As of November 24, 2020, more than 4176 participants from 49 of 50 US states have enrolled in the FlywheelMS study. A median of 200 pages of records have been collected from 14 different doctors over 8 years per participant. Abstraction precision, established through inter-abstractor agreement, is as high as 97.8% when identifying and mapping data elements to a standard ontology. Conclusion Using a commercial health records platform, the FlywheelMS study is generating a real-world, multimodal data set that could provide valuable insights about patients with MS. This approach to data collection and abstraction is disease-agnostic and could be used to address other clinical research questions in the future.Lay Summary Health records contain valuable information about patients and the care they receive in routine clinical practice; however, use of this data source in research is hindered by the difficulty of obtaining complete analyzable data sets. In the United States, health records for each patient are stored in paper and electronic formats across multiple healthcare providers. Furthermore, data must be extracted from health records before they can be analyzed, which is technically difficult for images and free text. In the first part of this paper, we describe how PicnicHealth, a commercial health records platform, collects health records on behalf of patients in any format and from all healthcare sites. Facilitated by tailored software tools and task-specific machine-learning models, data are extracted from health records by human experts in an efficient and precise manner. This enables patients to access and manage their health record data via a web application. The second part of this paper describes the design, rationale, and recruitment metrics for the ongoing FlywheelMS study, which is exploring whether an anonymized data set generated by PicnicHealth can improve our understanding of the disease course and patterns of care for patients with multiple sclerosis.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000764262900006,,
J,"Bedoya, Armando D.; Futoma, Joseph; Clement, Meredith E.; Corey, Kristin; Brajer, Nathan; Lin, Anthony; Simons, Morgan G.; Gao, Michael; Nichols, Marshall; Balu, Suresh; Heller, Katherine; Sendak, Mark; O'Brien, Cara",,,,,"Bedoya, Armando/0000-0001-6496-7024; Clement, Meredith/0000-0002-0283-6368",,,Machine learning for early detection of sepsis: an internal and temporal validation study,,,,,,,,JAMIA OPEN,,,,3,2,,,252,260,,10.1093/jamiaopen/ooaa006,,,,JUL 2020,2020,"Objective: Determine if deep learning detects sepsis earlier and more accurately than other models. To evaluate model performance using implementation-oriented metrics that simulate clinical practice.Materials and Methods: We trained internally and temporally validated a deep learning model (multi-output Gaussian process and recurrent neural network [MGP-RNN]) to detect sepsis using encounters from adult hospitalized patients at a large tertiary academic center. Sepsis was defined as the presence of 2 or more systemic inflammatory response syndrome (SIRS) criteria, a blood culture order, and at least one element of end-organ failure. The training dataset included demographics, comorbidities, vital signs, medication administrations, and labs from October 1, 2014 to December 1, 2015, while the temporal validation dataset was from March 1, 2018 to August 31, 2018. Comparisons were made to 3 machine learning methods, random forest (RF), Cox regression (CR), and penalized logistic regression (PLR), and 3 clinical scores used to detect sepsis, SIRS, quick Sequential Organ Failure Assessment (qSOFA), and National Early Warning Score (NEWS). Traditional discrimination statistics such as the C-statistic as well as metrics aligned with operational implementation were assessed.Results: The training set and internal validation included 42 979 encounters, while the temporal validation set included 39 786 encounters. The C-statistic for predicting sepsis within 4 h of onset was 0.88 for the MGP-RNN compared to 0.836 for RF, 0.849 for CR, 0.822 for PLR, 0.756 for SIRS, 0.619 for NEWS, and 0.481 for qSOFA. MGP-RNN detected sepsis a median of 5 h in advance. Temporal validation assessment continued to show the MGP-RNN outperform all 7 clinical risk score and machine learning comparisons.Conclusions: We developed and validated a novel deep learning model to detect sepsis. Using our data elements and feature set, ourmodeling approach outperformed other machine learningmethods and clinical scores.",,,,,,,,,15,0,0,0,1,0,15,,,,2574-2531,,WOS:000645439900018,32734166,
J,"Yin, Zhijun; Sulieman, Lina M.; Malin, Bradley A.",,,,"Yin, Zhijun/AAL-3193-2020","Yin, Zhijun/0000-0002-3075-1337",,,A systematic literature review of machine learning in online personal health data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,6,,,561,576,,10.1093/jamia/ocz009,,,,JUN 2019,2019,"Objective: User-generated content (UGC) in online environments provides opportunities to learn an individual's health status outside of clinical settings. However, the nature of UGC brings challenges in both data collecting and processing. The purpose of this study is to systematically review the effectiveness of applying machine learning (ML) methodologies to UGC for personal health investigations.Materials and Methods: We searched PubMed, Web of Science, IEEE Library, ACM library, AAAI library, and the ACL anthology. We focused on research articles that were published in English and in peer-reviewed journals or conference proceedings between 2010 and 2018. Publications that applied ML to UGC with a focus on personal health were identified for further systematic review.Results: We identified 103 eligible studies which we summarized with respect to 5 research categories, 3 data collection strategies, 3 gold standard dataset creation methods, and 4 types of features applied in ML models. Popular off-the-shelf ML models were logistic regression (n=22), support vector machines (n=18), naive Bayes (n=17), ensemble learning (n=12), and deep learning (n=11). The most investigated problems were mental health (n=39) and cancer (n=15). Common health-related aspects extracted from UGC were treatment experience, sentiments and emotions, coping strategies, and social support.Conclusions: The systematic review indicated that ML can be effectively applied to UGC in facilitating the description and inference of personal health. Future research needs to focus on mitigating bias introduced when building study cohorts, creating features from free text, improving clinical creditability of UGC, and model interpretability.",,,,,,,,,19,0,0,0,1,0,19,,,1067-5027,1527-974X,,WOS:000482416300010,30908576,
J,"Narayanan, Sankaran; Achan, Pradeep; Rangan, P. Venkat; Rajan, Sreeranga P.",,,,,,,,Unified concept and assertion detection using contextual multi-task learning in a clinical decision support system,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,122,,,,,,103898,10.1016/j.jbi.2021.103898,,AUG 2021,,OCT 2021,2021,"Assertions, such as negation and speculation, alter the meaning of clinical findings ('concepts') in Electronic Health Records. Accurate assertion detection is vital to the identification of target findings in clinical decision support systems. Diverse clinical concepts and assertion modifiers embedded within longer sentences add to the challenge of error-free detection. Recent approaches leveraging biomedical contextual embeddings lead to standalone concept and assertion models that do not effectively utilize inter-task knowledge transfer. We propose a novel neural model integrating task-specific fine-tuning and multi-task learning in a coherent framework based on the hierarchical relationship between the tasks. We show that such a unified framework enhances both the tasks using several real-world clinical notes' datasets (n2c2 2010, n2c2 2012, NegEx). Concept task performance enhanced by +1.69 F1 on n2c2 2010 and +2.96 F1 on n2c2 2012 compared to standalone baselines. Assertion recognition improved by +2.89 F1 and +3.77 F1, respectively. Negation detection under low-resource settings increased significantly (+2.4 F1, p-value = 3.11E - 05, McNemar's test), demonstrating the impact of inter-task knowledge transfer. The integrated architecture enhanced the generalization performance of speculation detection (+2.09 F1). To the best of our knowledge, this model is the first demonstration of a contextual multi-task system for unified detection of concepts and assertions in clinical decision support applications.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000697050200001,34455090,
J,"Lacson, Ronilda; Cochon, Laila; Ching, Patrick R.; Odigie, Eseosa; Kapoor, Neena; Gagne, Staci; Hammer, Mark M.; Khorasani, Ramin",,,,"Hammer, Mark/AAR-9625-2020; Ching, Patrick/AAZ-5425-2021","Hammer, Mark/0000-0002-1700-7984; Ching, Patrick/0000-0001-6106-2799",,,Integrity of clinical information in radiology reports documenting pulmonary nodules,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,1,,,80,85,,10.1093/jamia/ocaa209,,,,JAN 2021,2021,"Objective: Quantify the integrity, measured as completeness and concordance with a thoracic radiologist, of documenting pulmonary nodule characteristics in CT reports and assess impact on making follow-up recommendations.Materials and Methods: This Institutional Review Board-approved, retrospective cohort study was performed at an academic medical center. Natural language processing was performed on radiology reports of CT scans of chest, abdomen, or spine completed in 2016 to assess presence of pulmonary nodules, excluding patients with lung cancer, of which 300 reports were randomly sampled to form the study cohort. Documentation of nodule characteristics were manually extracted from reports by 2 authors with 20% overlap. CT images corresponding to 60 randomly selected reports were further reviewed by a thoracic radiologist to record nodule characteristics. Documentation completeness for all characteristics were reported in percentage and compared using chi(2) analysis. Concordance with a thoracic radiologist was reported as percentage agreement; impact on making follow-up recommendations was assessed using kappa.Results: Documentation completeness for pulmonary nodule characteristics differed across variables (range = 2%-90%, P< .001). Concordance with a thoracic radiologist was 75% for documenting nodule laterality and 29% for size. Follow-up recommendations were in agreement in 67% and 49% of reports when there was lack of completeness and concordance in documenting nodule size, respectively.Discussion: Essential pulmonary nodule characteristics were under-reported, potentially impacting recommendations for pulmonary nodule follow-up.Conclusion: Lack of documentation of pulmonary nodule characteristics in radiology reports is common, with potential for compromising patient care and clinical decision support tools.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000648972200010,33094346,
J,"Harerimana, Gaspard; Kim, Jong Wook; Jang, Beakcheol",,,,,,,,A deep attention model to forecast the Length Of Stay and the in-hospital mortality right on admission from ICD codes and demographic data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,118,,,,,,103778,10.1016/j.jbi.2021.103778,,MAY 2021,,JUN 2021,2021,"Leveraging the Electronic Health Records (EHR) longitudinal data to produce actionable clinical insights has always been a critical issue for recent studies. Non-forecasted extended hospitalizations account for a disproportionate amount of resource use, the mediocre quality of inpatient care, and avoidable fatalities. The capability to predict the Length of Stay (LoS) and mortality in the early stages of the admission provides opportunities to improve care and prevent many preventable losses. Forecasting the in-hospital mortality is important in providing clinicians with enough insights to make decisions and hospitals to allocate resources, hence predicting the LoS and mortality within the first day of admission is a difficult but a paramount endeavor. The biggest challenge is that few data are available by this time, thus the prediction has to bring in the previous admissions history and free text diagnosis that are recorded immediately on admission. We propose a model that uses the multi-modal EHR structured medical codes and key demographic information to classify the LoS in 3 classes; Short Los (LoS <= 10 days), Medium LoS (10 LoS <= 30 days) and Long LoS (LoS 30 days) as well as mortality as a binary classification of a patient's death during current admission. The prediction has to use data available only within 24 h of admission. The key predictors include previous ICD9 diagnosis codes, ICD9 procedures, key demographic data, and free text diagnosis of the current admission recorded right on admission. We propose a Hierarchical Attention Network (HAN-LoS and HAN-Mor) model and train it to a dataset of over 45321 admissions recorded in the de-identified MIMIC-III dataset. For improved prediction, our attention mechanisms can focus on the most influential past admissions and most influential codes in these admissions. For fair performance evaluation, we implemented and compared the HAN model with previous approaches. With dataset balancing techniques HAN-LoS achieved an AUROC of over 0.82 and a Micro-F1 score of 0.24 and HAN-Mor achieved AUCROC of 0.87 hence outperforming the existing baselines that use structured medical codes as well as clinical time series for LoS and Mortality forecasting. By predicting mortality and LoS using the same model, we show that with little tuning the proposed model can be used for other clinical predictive tasks like phenotyping, decompensation,re-admission prediction, and survival analysis.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663600500017,33872817,
J,"Serper, Marina; Vujkovic, Marijana; Kaplan, David E.; Carr, Rotonya M.; Lee, Kyung Min; Shao, Qing; Miller, Donald R.; Reaven, Peter D.; Phillips, Lawrence S.; O'Donnell, Christopher J.; Meigs, James B.; Wilson, Peter W. F.; Vickers-Smith, Rachel; Kranzler, Henry R.; Justice, Amy C.; Gaziano, John M.; Muralidhar, Sumitra; Pyarajan, Saiju; DuVall, Scott L.; Assimes, Themistocles L.; Lee, Jennifer S.; Tsao, Philip S.; Rader, Daniel J.; Damrauer, Scott M.; Lynch, Julie A.; Saleheen, Danish; Voight, Benjamin F.; Chang, Kyong-Mi",,VA Million Vet Program,,"Vujković, Marijana/S-9414-2019; Vickers-Smith, Rachel/AAM-1502-2021","Vujković, Marijana/0000-0003-4924-5714; Vickers-Smith, Rachel/0000-0002-7224-8916; Serper, Marina/0000-0003-4899-2160; Kaplan, David/0000-0002-3839-336X",,,"Validating a non-invasive, ALT-based non-alcoholic fatty liver phenotype in the million veteran program",,,,,,,,PLOS ONE,,,,15,8,,,,,e0237430,10.1371/journal.pone.0237430,,,,AUG 25 2020,2020,"Background & aims Given ongoing challenges in non-invasive non-alcoholic liver disease (NAFLD) diagnosis, we sought to validate an ALT-based NAFLD phenotype using measures readily available in electronic health records (EHRs) and population-based studies by leveraging the clinical and genetic data in the Million Veteran Program (MVP), a multi-ethnic mega-biobank of US Veterans. Methods MVP participants with alanine aminotransferases (ALT) >40 units/L for men and >30 units/L for women without other causes of liver disease were compared to controls with normal ALT. Genetic variants spanning eight NAFLD risk or ALT-associated loci (LYPLAL1,GCKR,HSD17B13,TRIB1,PPP1R3B,ERLIN1,TM6SF2,PNPLA3)were tested for NAFLD associations with sensitivity analyses adjusting for metabolic risk factors and alcohol consumption. A manual EHR review assessed performance characteristics of the NAFLD phenotype with imaging and biopsy data as gold standards. Genetic associations with advanced fibrosis were explored using FIB4, NAFLD Fibrosis Score and platelet counts. Results Among 322,259 MVP participants, 19% met non-invasive criteria for NAFLD. Trans-ethnic meta-analysis replicated associations with previously reported genetic variants in all butLYPLAL1andGCKRloci (P<6x10(-3)), without attenuation when adjusted for metabolic risk factors and alcohol consumption. At the previously reportedLYPLAL1locus, the established genetic variant did not appear to be associated with NAFLD, however the regional association plot showed a significant association with NAFLD 279kb downstream. In the EHR validation, the ALT-based NAFLD phenotype yielded a positive predictive value 0.89 and 0.84 for liver biopsy and abdominal imaging, respectively (inter-rater reliability (Cohen's kappa = 0.98)).HSD17B13andPNPLA3loci were associated with advanced fibrosis. Conclusions We validate a simple, non-invasive ALT-based NAFLD phenotype using EHR data by leveraging previously established NAFLD risk-associated genetic polymorphisms.",,,,,,,,,3,0,0,0,1,0,3,,,1932-6203,,,WOS:000565553400029,32841307,
J,"Kocaballi, Ahmet Baki; Coiera, Enrico; Tong, Huong Ly; White, Sarah J.; Quiroz, Juan C.; Rezazadegan, Fahimeh; Willcock, Simon; Laranjo, Liliana",,,,"Kocaballi, Baki/R-3136-2019; Laranjo, Liliana/D-5356-2017; White, Sarah/ABC-2800-2021; Quiroz, Juan/P-6215-2016","Kocaballi, Baki/0000-0002-8328-5317; Laranjo, Liliana/0000-0003-1020-3402; White, Sarah/0000-0001-7458-705X; Quiroz, Juan/0000-0003-0241-5376; Tong, Huong Ly/0000-0002-8462-0105; Rezazadegan, Dana/0000-0002-0097-3801; Coiera, Enrico/0000-0002-6444-6584",,,A network model of activities in primary care consultations,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,10,,,1074,1082,,10.1093/jamia/ocz046,,,,OCT 2019,2019,"Objective: The objective of this study is to characterize the dynamic structure of primary care consultations by identifying typical activities and their inter-relationships to inform the design of automated approaches to clinical documentation using natural language processing and summarization methods.Materials and Methods: This is an observational study in Australian general practice involving 31 consultations with 4 primary care physicians. Consultations were audio-recorded, and computer interactions were recorded using screen capture. Physical interactions in consultation rooms were noted by observers. Brief interviews were conducted after consultations. Conversational transcripts were analyzed to identify different activities and their speech content as well as verbal cues signaling activity transitions. An activity transition analysis was then undertaken to generate a network of activities and transitions.Results: Observed activity classes followed those described in well-known primary care consultation models. Activities were often fragmented across consultations, did not flow necessarily in a defined order, and the flow between activities was nonlinear. Modeling activities as a network revealed that discussing a patient's present complaint was the most central activity and was highly connected to medical history taking, physical examination, and assessment, forming a highly interrelated bundle. Family history, allergy, and investigation discussions were less connected suggesting less dependency on other activities. Clear verbal signs were often identifiable at transitions between activities.Discussion: Primary care consultations do not appear to follow a classic linear model of defined information seeking activities; rather, they are fragmented, highly interdependent, and can be reactively triggered.Conclusion: The nonlinearity of activities has significant implications for the design of automated information capture. Whereas dictation systems generate literal translation of speech into text, speech-based clinical summary systems will need to link disparate information fragments, merge their content, and abstract coherent information summaries.",,,,,,,,,7,0,0,0,0,0,7,,,1067-5027,1527-974X,,WOS:000515123700022,31329875,
J,"Liu, Xiaokang; Chubak, Jessica; Hubbard, Rebecca A.; Chen, Yong",,,,,,,,"SAT: a Surrogate-Assisted Two-wave case boosting sampling method, with application to EHR-based association studies",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocab267,,DEC 2021,,,2021,"Objectives Electronic health records (EHRs) enable investigation of the association between phenotypes and risk factors. However, studies solely relying on potentially error-prone EHR-derived phenotypes (ie, surrogates) are subject to bias. Analyses of low prevalence phenotypes may also suffer from poor efficiency. Existing methods typically focus on one of these issues but seldom address both. This study aims to simultaneously address both issues by developing new sampling methods to select an optimal subsample to collect gold standard phenotypes for improving the accuracy of association estimation. Materials and Methods We develop a surrogate-assisted two-wave (SAT) sampling method, where a surrogate-guided sampling (SGS) procedure and a modified optimal subsampling procedure motivated from A-optimality criterion (OSMAC) are employed sequentially, to select a subsample for outcome validation through manual chart review subject to budget constraints. A model is then fitted based on the subsample with the true phenotypes. Simulation studies and an application to an EHR dataset of breast cancer survivors are conducted to demonstrate the effectiveness of SAT. Results We found that the subsample selected with the proposed method contains informative observations that effectively reduce the mean squared error of the resultant estimator of the association. Conclusions The proposed approach can handle the problem brought by the rarity of cases and misclassification of the surrogate in phenotype-absent EHR-based association studies. With a well-behaved surrogate, SAT successfully boosts the case prevalence in the subsample and improves the efficiency of estimation.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000756764900001,34962283,
J,"Cheung, Jeffrey Lam Shin; Paolucci, Natalie; Price, Courtney; Sykes, Jenna; Gupta, Samir",,Canadian Resp Res Network,,,,,,A system uptake analysis and GUIDES checklist evaluation of the Electronic Asthma Management System: A point-of-care computerized clinical decision support system,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,5,,,726,737,,10.1093/jamia/ocaa019,,,,MAY 2020,2020,"Objective: Computerized clinical decision support systems (CCDSSs) promise improvements in care quality; however, uptake is often suboptimal. We sought to characterize system use, its predictors, and user feedback for the Electronic Asthma Management System (eAMS)-an electronic medical record system-integrated, point-of-care CCDSS for asthma-and applied the GUIDES checklist as a framework to identify areas for improvement.Materials and Methods: The eAMS was tested in a 1-year prospective cohort study across 3 Ontario primary care sites. We recorded system usage by clinicians and patient characteristics through system logs and chart reviews. We created multivariable models to identify predictors of (1) CCDSS opening and (2) creation of a self-management asthma action plan (AAP) (final CCDSS step). Electronic questionnaires captured user feedback.Results: Over 1 year, 490 asthma patients saw 121 clinicians. The CCDSS was opened in 205 of 1033 (19.8%) visits and an AAP created in 121 of 1033 (11.7%) visits. Multivariable predictors of opening the CCDSS and producing an AAP included clinic site, having physician-diagnosed asthma, and presenting with an asthma- or respiratory-related complaint. The system usability scale score was 66.316.5 (maximum 100). Reported usage barriers included time and system accessibility.Discussion: The eAMS was used in a minority of asthma patient visits. Varying workflows and cultures across clinics, physician beliefs regarding asthma diagnosis, and relevance of the clinical complaint influenced uptake.Conclusions: Considering our findings in the context of the GUIDES checklist helped to identify improvements to drive uptake and provides lessons relevant to CCDSS design across diseases.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000537475700008,32274495,
J,"Yu, Gang; Yang, Yiwen; Wang, Xuying; Zhen, Huachun; He, Guoping; Li, Zheming; Zhao, Yonggen; Shu, Qiang; Shu, Liqi",,,,,"Yu, Gang/0000-0001-9935-9969",,,Adversarial active learning for the identification of medical concepts and annotation inconsistency,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103481,10.1016/j.jbi.2020.103481,,,,AUG 2020,2020,"Objective: Named entity recognition (NER) is a principal task in the biomedical field and deep learning-based algorithms have been widely applied to biomedical NER. However, all of these methods that are applied to biomedical corpora use only annotated samples to maximize their performances. Thus, (1) large numbers of unannotated samples are relinquished and their values are overlooked. (2) Compared with other types of active learning (AL) algorithms, generative adversarial learning (GAN)-based AL methods have developed slowly. Furthermore, current diversity-based AL methods only compute similarities between a pair of sentences and cannot evaluate distribution similarities between groups of sentences. Annotation inconsistency is one of the significant challenges in the biomedical annotation field. Most existing methods for addressing this challenge are statistics-based or rule-based methods. (3) They require sufficient expert knowledge and complex designs. To address challenges (1), (2), and (3) simultaneously, we propose innovative algorithms.Methods: GAN is introduced in this paper, and we propose the GAN-bidirectional long short-term memoryconditional random field (GAN-BiLSTM-CRF) and the GAN-bidirectional encoder representations from transformers-conditional random field (GAN-BERT-CRF) models, which can be considered an NER model, an AL model, and a model identifying error labels. BiLSTM-CRF or BERT-CRF is defined as the generator and a convolutional neural network (CNN)-based network is considered the discriminator. (1) The generator employs unannotated samples in addition to annotated samples to maximize NER performance. (2) The outputs of the CRF layer and the discriminator are used to select unlabeled samples for the AL task. (3) The discriminator discriminates the distribution of error labels from that of correct labels, identify error labels, and address the annotation inconsistency challenge.Results: The corpus from the 2010 i2b2/VA NLP challenge and the Chinese CCKS-2017 Task 2 dataset are adopted for experiments. Compared to the baseline BiLSTM-CRF and BERT-CRF, the GAN-BiLSTM-CRF and GAN-BERT-CRF models achieved significant improvements on the precision, recall, and Fl scores in terms of NER performance. Learning curves in AL experiments show the comparative results of the proposed models. Furthermore, the trained discriminator can identify samples with incorrect medical labels in both simulation and real-word experimental environments.Conclusion: The idea of introducing GAN contributes significant results in terms of NER, active learning, and the ability to identify incorrect annotated samples. The benefits of GAN will be further studied.",,,,,,,,,3,0,0,0,0,0,3,,,1532-0464,1532-0480,,WOS:000564595700017,32687985,
J,"MacLean, Matthew T.; Jehangir, Qasim; Vujkovic, Marijana; Ko, Yi-An; Litt, Harold; Borthakur, Arijitt; Sagreiya, Hersh; Rosen, Mark; Mankoff, David A.; Schnall, Mitchell D.; Shou, Haochang; Chirinos, Julio; Damrauer, Scott M.; Torigian, Drew A.; Carr, Rotonya; Rader, Daniel J.; Witschey, Walter R.",,,,"Vujković, Marijana/S-9414-2019","Vujković, Marijana/0000-0003-4924-5714; Jehangir, Qasim/0000-0003-2980-067X",,,Quantification of abdominal fat from computed tomography using deep learning and its association with electronic health records in an academic biobank,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1178,1187,,10.1093/jamia/ocaa342,,FEB 2021,,JUN 2021,2021,"Objective: The objective was to develop a fully automated algorithm for abdominal fat segmentation and to deploy this method at scale in an academic biobank.Materials and Methods: We built a fully automated image curation and labeling technique using deep learning and distributive computing to identify subcutaneous and visceral abdominal fat compartments from 52,844 computed tomography scans in 13,502 patients in the Penn Medicine Biobank (PMBB). A classification network identified the inferior and superior borders of the abdomen, and a segmentation network differentiated visceral and subcutaneous fat. Following technical evaluation of our method, we conducted studies to validate known relationships with visceral and subcutaneous fat.Results: When compared with 100 manually annotated cases, the classification network was on average within one 5-mm slice for both the superior (0.4 +/- 1.1 slice) and inferior (0.4 +/- 0.6 slice) borders. The segmentation network also demonstrated excellent performance with intraclass correlation coefficients of 1.00 (P< 2 x 10(-16)) for subcutaneous and 1.00 (P < 2 x 10(-16)) for visceral fat on 100 testing cases. We performed integrative analyses of abdominal fat with the phenome extracted from the electronic health record and found highly significant associations with diabetes mellitus, hypertension, and renal failure, among other phenotypes.Conclusions: This work presents a fully automated and highly accurate method for the quantification of abdominal fat that can be applied to routine clinical imaging studies to fuel translational scientific discovery.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000671031900014,33576413,
J,"Weisenthal, Samuel J.; Quill, Caroline; Farooq, Samir; Kautz, Henry; Zand, Martin S.",,,,"Kautz, Henry/AAF-5190-2020","Kautz, Henry/0000-0001-5219-2970",,,Predicting acute kidney injury at hospital re-entry using high-dimensional electronic health record data,,,,,,,,PLOS ONE,,,,13,11,,,,,e0204920,10.1371/journal.pone.0204920,,,,NOV 20 2018,2018,"Acute Kidney Injury (AKI), a sudden decline in kidney function, is associated with increased mortality, morbidity, length of stay, and hospital cost. Since AKI is sometimes preventable, there is great interest in prediction. Most existing studies consider all patients and therefore restrict to features available in the first hours of hospitalization. Here, the focus is instead on rehospitalized patients, a cohort in which rich longitudinal features from prior hospitalizations can be analyzed. Our objective is to provide a risk score directly at hospital re-entry. Gradient boosting, penalized logistic regression (with and without stability selection), and a recurrent neural network are trained on two years of adult inpatient EHR data (3,387 attributes for 34,505 patients who generated 90,013 training samples with 5,618 cases and 84,395 controls). Predictions are internally evaluated with 50 iterations of 5-fold grouped cross-validation with special emphasis on calibration, an analysis of which is performed at the patient as well as hospitalization level. Error is assessed with respect to diagnosis, race, age, gender, AKI identification method, and hospital utilization. In an additional experiment, the regularization penalty is severely increased to induce parsimony and interpretability. Predictors identified for rehospitalized patients are also reported with a special analysis of medications that might be modifiable risk factors. Insights from this study might be used to construct a predictive tool for AKI in rehospitalized patients. An accurate estimate of AKI risk at hospital entry might serve as a prior for an admitting provider or another predictive algorithm.",,,,,,,,,2,0,0,0,0,0,2,,,1932-6203,,,WOS:000450775300005,30458044,
J,"Wang, Tengyang; Liu, Guanghua; Lin, Hongye",,,,"Wang, TengYang/AAT-3173-2021","Wang, Tengyang/0000-0002-4541-4456",,,A machine learning approach to predict intravenous immunoglobulin resistance in Kawasaki disease patients: A study based on a Southeast China population,,,,,,,,PLOS ONE,,,,15,8,,,,,e0237321,10.1371/journal.pone.0237321,,,,AUG 27 2020,2020,"Kawasaki disease is the leading cause of pediatric acquired heart disease. Coronary artery abnormalities are the main complication of Kawasaki disease. Kawasaki disease patients with intravenous immunoglobulin resistance are at a greater risk of developing coronary artery abnormalities. Several scoring models have been established to predict resistance to intravenous immunoglobulin, but clinicians usually do not apply those models in patients because of their poor performance. To find a better model, we retrospectively collected data including 753 observations and 82 variables. A total of 644 observations were included in the analysis, and 124 of the patients observed were intravenous immunoglobulin resistant (19.25%). We considered 7 different linear and nonlinear machine learning algorithms, including logistic regression (L1 and L1 regularized), decision tree, random forest, AdaBoost, gradient boosting machine (GBM), and lightGBM, to predict the class of intravenous immunoglobulin resistance (binary classification). Data from patients who were discharged before Sep 2018 were included in the training set (n = 497), while all the data collected after 9/1/2018 were included in the test set (n = 147). We used the area under the ROC curve, accuracy, sensitivity, and specificity to evaluate the performances of each model. The gradient GBM had the best performance (area under the ROC curve 0.7423, accuracy 0.8844, sensitivity 0.3043, specificity 0.9919). Additionally, the feature importance was evaluated with SHapley Additive exPlanation (SHAP) values, and the clinical utility was assessed with decision curve analysis. We also compared our model with the Kobayashi score, Egami score, Formosa score and Kawamura score. Our machine learning model outperformed all of the aforementioned four scoring models. Our study demonstrates a novel and robust machine learning method to predict intravenous immunoglobulin resistance in Kawasaki disease patients. We believe this approach could be implemented in an electronic health record system as a form of clinical decision support in the near future.",,,,,,,,,4,0,0,0,4,0,4,,,1932-6203,,,WOS:000566948800061,32853226,
J,"Zhan, Chen; Roughead, Elizabeth; Liu, Lin; Pratt, Nicole; Li, Jiuyong",,,,"Liu, Lin/ABD-1224-2020; Li, Jiuyong/AAY-2706-2020; Roughead, Elizabeth E/G-4431-2010; Pratt, Nicole/A-1348-2011","Liu, Lin/0000-0003-2843-5738; Li, Jiuyong/0000-0002-9023-1878; Roughead, Elizabeth E/0000-0002-6811-8991; Pratt, Nicole/0000-0001-8730-8910; Zhan, Chen/0000-0002-4794-8339",,,A data-driven method to detect adverse drug events from prescription data,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,85,,,,10,20,,10.1016/j.jbi.2018.07.013,,,,SEP 2018,2018,"Drug safety issues such as Adverse Drug Events (ADEs) can cause serious consequences for the public. The clinical trials that are undertaken to assess medicine efficacy and safety prior to marketing, generally, may provide sufficient samples for discovering common ADEs. However, more samples are needed to detect infrequent and rare events. Additionally, clinical trials may not include all subgroups of patients. For these reasons, post-marketing surveillance of medicines is necessary for identifying drug safety issues. Most regulatory agencies use the Spontaneous Reporting Systems to identify associations between medicines and suspected ADEs. Data mining with effective analytical frameworks and large-scale medical data is potentially an alternative method to discover and monitor ADEs. In the present paper, we aim to detect potential ADEs from prescription data by discovering ADE associated prescription sequences. In an ADE associated prescription sequence (D-p -> D-s) the prior medicine D-p leads to an ADE for which the succeeding medicine D-s is dispensed to treat. We propose a data driven method which integrates (1) a constrained sequential pattern mining to uncover prescription sequences as potential signals of ADEs, (2) domain constraints to eliminate interference signals and (3) an adapted Self Controlled Case Series model to evaluate the potential signals of ADEs. Despite ample prior works using Electronic Health Records (EHRs), our method utilises pure prescription data which does not contain additional information, e.g. symptoms or diagnoses as included in EHRs. To assess the performance of the proposed method, we apply it to a real-world dataset from the Pharmaceutical Benefits Scheme of Australia. The dataset contains over 50 million records covering approximately 2 million patients. The results demonstrate the effectiveness of our method in identifying both known ADEs and unknown yet suspicious ADEs with limited detection of false positive signals. Comparing to a recognised gold standard, our method successfully detects 67.4% of the positive adverse events while only 8.78% false positives exist.",,,,,,,,,3,1,0,0,2,0,4,,,1532-0464,1532-0480,,WOS:000460600100002,30016721,
J,"He, Wenjun; Kirchoff, Katie G.; Sampson, Royce R.; McGhee, Kimberly K.; Cates, Andrew M.; Obeid, Jihad S.; Lenert, Leslie A.",,,,"; Obeid, Jihad/P-9793-2016","McGhee, Kimberly/0000-0003-0163-7225; Obeid, Jihad/0000-0002-7193-7779; He, Wenjun/0000-0003-2043-1329",,,Research Integrated Network of Systems (RINS): a virtual data warehouse for the acceleration of translational research,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,7,,,1440,1450,,10.1093/jamia/ocab023,,MAR 2021,,JUL 2021,2021,"Objective: Integrated, real-time data are crucial to evaluate translational efforts to accelerate innovation into care. Too often, however, needed data are fragmented in disparate systems. The South Carolina Clinical & Translational Research Institute at the Medical University of South Carolina (MUSC) developed and implemented a universal study identifier-the Research Master Identifier (RMID)-for tracking research studies across disparate systems and a data warehouse-inspired model-the Research Integrated Network of Systems (RINS)-for integrating data from those systems.Materials and Methods: In 2017, MUSC began requiring the use of RMIDs in informatics systems that support human subject studies. We developed a web-based tool to create RMIDs and application programming interfaces to synchronize research records and visualize linkages to protocols across systems. Selected data from these disparate systems were extracted and merged nightly into an enterprise data mart, and performance dashboards were created to monitor key translational processes.Results: Within 4 years, 5513 RMIDs were created. Among these were 726 (13%) bridged systems needed to evaluate research study performance, and 982 (18%) linked to the electronic health records, enabling patientlevel reporting.Discussion: Barriers posed by data fragmentation to assessment of program impact have largely been eliminated at MUSC through the requirement for an RMID, its distribution via RINS to disparate systems, and mapping of system-level data to a single integrated data mart.Conclusion: By applying data warehousing principles to federate data at the study level, the RINS project reduced data fragmentation and promoted research systems integration.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000685209200010,33729486,
J,"Baron, Jason M.; Paranjape, Ketan; Love, Tara; Sharma, Vishakha; Heaney, Denise; Prime, Matthew",,,,,,,,"Development of a meta-model to address missing data, predict patient-specific cancer survival and provide a foundation for clinical decision support",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,605,615,,10.1093/jamia/ocaa254,,,,MAR 2021,2021,"Objective: Like most real-world data, electronic health record (EHR)-derived data from oncology patients typically exhibits wide interpatient variability in terms of available data elements. This interpatient variability leads to missing data and can present critical challenges in developing and implementing predictive models to underlie clinical decision support for patient-specific oncology care. Here, we sought to develop a novel ensemble approach to addressing missing data that we term the meta-model and apply the meta-model to patient-specific cancer prognosis.Materials and Methods: Using real-world data, we developed a suite of individual random survival forest models to predict survival in patients with advanced lung cancer, colorectal cancer, and breast cancer. Individual models varied by the predictor data used. We combined models for each cancer type into a meta-model that predicted survival for each patient using a weighted mean of the individual models for which the patient had all requisite predictors.Results: The meta-model significantly outperformed many of the individual models and performed similarly to the best performing individual models. Comparisons of the meta-model to a more traditional imputation-based method of addressing missing data supported the meta-model's utility.Conclusions: We developed a novel machine learning-based strategy to underlie clinical decision support and predict survival in cancer patients, despite missing data. The meta-model may more generally provide a tool for addressing missing data across a variety of clinical prediction problems. Moreover, the meta-model may address other challenges in clinical predictive modeling including model extensibility and integration of predictive algorithms trained across different institutions and datasets.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000637314400020,33260202,
J,"Wang, Liqin; Blackley, Suzanne V.; Blumenthal, Kimberly G.; Yerneni, Sharmitha; Goss, Foster R.; Lo, Ying-Chih; Shah, Sonam N.; Ortega, Carlos A.; Korach, Zfania Tom; Seger, Diane L.; Zhou, Li",,,,"Blumenthal, Kimberly G./AAG-8290-2019","Ortega, Carlos/0000-0002-2394-8975; Shah, Sonam/0000-0002-2222-895X",,,A dynamic reaction picklist for improving allergy reaction documentation in the electronic health record,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,6,,,917,923,,10.1093/jamia/ocaa042,,,,JUN 2020,2020,"Objective: Incomplete and static reaction picklists in the allergy module led to free-text and missing entries that inhibit the clinical decision support intended to prevent adverse drug reactions. We developed a novel, data-driven, dynamic reaction picklist to improve allergy documentation in the electronic health record (EHR).Materials and Methods: We split 3 decades of allergy entries in the EHR of a large Massachusetts healthcare system into development and validation datasets. We consolidated duplicate allergens and those with the same ingredients or allergen groups. We created a reaction value set via expert review of a previously developed value set and then applied natural language processing to reconcile reactions from structured and free-text entries. Three association rule-mining measures were used to develop a comprehensive reaction picklist dynamically ranked by allergen. The dynamic picklist was assessed using recall at top k suggested reactions, comparing performance to the static picklist.Results: The modified reaction value set contained 490 reaction concepts. Among 4 234 327 allergy entries collected, 7463 unique consolidated allergens and 469 unique reactions were identified. Of the 3 dynamic reaction picklists developed, the 1 with the optimal ranking achieved recalls of 0.632, 0.763, and 0.822 at the top 5, 10, and 15, respectively, significantly outperforming the static reaction picklist ranked by reaction frequency.Conclusion: The dynamic reaction picklist developed using EHR data and a statistical measure was superior to the static picklist and suggested proper reactions for allergy documentation. Further studies might evaluate the usability and impact on allergy documentation in the EHR.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000542064800011,32417930,
J,"Liu, Vincent X.; Bates, David W.; Wiens, Jenna; Shah, Nigam",,,,,,,,The number needed to benefit: estimating the value of predictive analytics in healthcare,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1655,1659,,10.1093/jamia/ocz088,,,,DEC 2019,2019,"Predictive analytics in health care has generated increasing enthusiasm recently, as reflected in a rapidly growing body of predictive models reported in literature and in real-time embedded models using electronic health record data. However, estimating the benefit of applying any single model to a specific clinical problem remains challenging today. Developing a shared framework for estimating model value is therefore critical to facilitate the effective, safe, and sustainable use of predictive tools into the future. We highlight key concepts within the prediction-action dyad that together are expected to impact model benefit. These include factors relevant to model prediction (including the number needed to screen) as well as those relevant to the subsequent action (number needed to treat). In the simplest terms, a number needed to benefit contextualizes the numbers needed to screen and treat, offering an opportunity to estimate the value of a clinical predictive model in action.",,,,,,,,,14,0,0,0,2,0,14,,,1067-5027,1527-974X,,WOS:000515125300028,31192367,
J,"Baldwin, Tyler; Guo, Yufan; Mukherjee, Vandana V; Syeda-Mahmood, Tanveer",,,,,,,,Generalized Extraction and Classification of Span-Level Clinical Phrases.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,205,214,,,,,,2018,2018,"Much of the critical information in a patient's electronic health record (EHR) is hidden in unstructured text. As such, there is an increasing role for automated text extraction and summarization to make this information available in a way that can be quickly and easily understood. While many clinical note text extraction techniques have been examined, most existing techniques are either narrowly targeted or focus primarily on concept-level extraction, potentially missing important contextual information. In contrast, in this work we examine the extraction of several clinical categories at the phrase level, attempting to provide the necessary context while still keeping the extracted elements concise. To do so, we employ a three-stage pipeline which extracts categorized phrases of interest using clinical concepts as anchor points. Results suggest the proposed method achieves performance comparable to that of individual human annotators.",,,,,,,,,2,0,0,0,2,0,2,,,,1942-597X,,MEDLINE:30815058,30815058,
J,"Thompson, Hale M.; Sharma, Brihat; Bhalla, Sameer; Boley, Randy; McCluskey, Connor; Dligach, Dmitriy; Churpek, Matthew M.; Karnik, Niranjan S.; Afshar, Majid",,,,"Karnik, Niranjan/N-4103-2019","Karnik, Niranjan/0000-0001-7650-3008; Thompson, Hale/0000-0002-9704-934X",,,Bias and fairness assessment of a natural language processing opioid misuse classifier: detection and mitigation of electronic health record data disadvantages across racial subgroups,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2393,2403,,10.1093/jamia/ocab148,,AUG 2021,,NOV 2021,2021,"Objectives: To assess fairness and bias of a previously validated machine learning opioid misuse classifier.Materials & Methods: Two experiments were conducted with the classifier's original (n = 1000) and external validation (n = 53 974) datasets from 2 health systems. Bias was assessed via testing for differences in type II error rates across racial/ethnic subgroups (Black, Hispanic/Latinx, White, Other) using bootstrapped 95% confidence intervals. A local surrogate model was estimated to interpret the classifier's predictions by race and averaged globally from the datasets. Subgroup analyses and post-hoc recalibrations were conducted to attempt to mitigate biased metrics.Results: We identified bias in the false negative rate (FNR = 0.32) of the Black subgroup compared to the FNR (0.17) of the White subgroup. Top features included heroin and substance abuse across subgroups. Posthoc recalibrations eliminated bias in FNR with minimal changes in other subgroup error metrics. The Black FNR subgroup had higher risk scores for readmission and mortality than the White FNR subgroup, and a higher mortality risk score than the Black true positive subgroup (P< .05).Discussion: The Black FNR subgroup had the greatest severity of disease and risk for poor outcomes. Similar features were present between subgroups for predicting opioid misuse, but inequities were present. Post-hoc mitigation techniques mitigated bias in type II error rate without creating substantial type I error rates. From model design through deployment, bias and data disadvantages should be systematically addressed.Conclusion: Standardized, transparent bias assessments are needed to improve trustworthiness in clinical machine learning models.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000711702400010,34383925,
J,"Hanson, Gillian; Chitnis, Tanuja; Williams, Mitzi J; Gan, Ryan William; Julian, Laura; Mace, Kieran; Chia, Jenny; Wormser, David; Martinec, Michael; Astorino, Troy; Leviner, Noga; Maung, Pye; Jan, Asif; Belendiuk, Katherine",,,,,,,,Generating real-world data from health records: design of a patient-centric study in multiple sclerosis using a commercial health records platform.,,,,,,,,JAMIA open,,,,5,1,,,ooab110,ooab110,,10.1093/jamiaopen/ooab110,,,,2022-Apr,2022,"Objective: The FlywheelMS study will explore the use of a real-world health record data set generated by PicnicHealth, a patient-centric health records platform, to improve understanding of disease course and patterns of care for patients with multiple sclerosis (MS).Materials and Methods: The FlywheelMS study aims to enroll 5000 adults with MS in the United States to create a large, deidentified, longitudinal data set for clinical research. PicnicHealth obtains health records, including paper charts, electronic health records, and radiology imaging files from any healthcare site. Using a large-scale health record processing pipeline, PicnicHealth abstracts standard and condition-specific data elements from structured (eg, laboratory test results) and unstructured (eg, narrative) text and maps these to standardized medical vocabularies. Researchers can use the resulting data set to answer empirical questions and study participants can access and share their harmonized health records using PicnicHealth's web application.Results: As of November 24, 2020, more than 4176 participants from 49 of 50 US states have enrolled in the FlywheelMS study. A median of 200 pages of records have been collected from 14 different doctors over 8 years per participant. Abstraction precision, established through inter-abstractor agreement, is as high as 97.8% when identifying and mapping data elements to a standard ontology.Conclusion: Using a commercial health records platform, the FlywheelMS study is generating a real-world, multimodal data set that could provide valuable insights about patients with MS. This approach to data collection and abstraction is disease-agnostic and could be used to address other clinical research questions in the future.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,MEDLINE:35155999,35155999,
J,"Hanson, Gillian; Chitnis, Tanuja; Williams, Mitzi J.; Gan, Ryan William; Julian, Laura; Mace, Kieran; Chia, Jenny; Wormser, David; Martinec, Michael; Astorino, Troy; Leviner, Noga; Maung, Pye; Jan, Asif; Belendiuk, Katherine",,,,,,,,Generating real-world data from health records: design of a patient-centric study in multiple sclerosis using a commercial health records platform,,,,,,,,JAMIA OPEN,,,,5,1,,,,,ooab110,10.1093/jamiaopen/ooab110,,,,APR 2022,2022,"Objective: The FlywheelMS study will explore the use of a real-world health record data set generated by PicnicHealth, a patient-centric health records platform, to improve understanding of disease course and patterns of care for patients with multiple sclerosis (MS).Materials and Methods: The FlywheelMS study aims to enroll 5000 adults with MS in the United States to create a large, deidentified, longitudinal data set for clinical research. PicnicHealth obtains health records, including paper charts, electronic health records, and radiology imaging files from any healthcare site. Using a large-scale health record processing pipeline, PicnicHealth abstracts standard and condition-specific data elements from structured (eg, laboratory test results) and unstructured (eg, narrative) text and maps these to standardized medical vocabularies. Researchers can use the resulting data set to answer empirical questions and study participants can access and share their harmonized health records using PicnicHealth's web application.Results: As of November 24, 2020, more than 4176 participants from 49 of 50 US states have enrolled in the FlywheelMS study. A median of 200 pages of records have been collected from 14 different doctors over 8 years per participant. Abstraction precision, established through inter-abstractor agreement, is as high as 97.8% when identifying and mapping data elements to a standard ontology.Conclusion: Using a commercial health records platform, the FlywheelMS study is generating a real-world, mu Itimodal data set that could provide valuable insights about patients with MS. This approach to data collection and abstraction is disease-agnostic and could be used to address other clinical research questions in the future.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000744381100009,,
J,"Alonso, Alvaro; Alam, Aniqa B; Kamel, Hooman; Subbian, Vignesh; Qian, Jun; Boerwinkle, Eric; Cicek, Mine; Clark, Cheryl R; Cohn, Elizabeth G; Gebo, Kelly A; Loperena-Cortes, Roxana; Mayo, Kelsey R; Mockrin, Stephen; Ohno-Machado, Lucila; Schully, Sheri D; Ramirez, Andrea H; Greenland, Philip",,,,"Alonso, Alvaro/A-4917-2010","Alonso, Alvaro/0000-0002-2225-8323",,,Epidemiology of atrial fibrillation in the All of Us Research Program.,,,,,,,,PloS one,,,,17,3,,,e0265498,e0265498,,10.1371/journal.pone.0265498,,,,2022,2022,"BACKGROUND: The prevalence, incidence and risk factors of atrial fibrillation (AF) in a large, geographically and ethnically diverse cohort in the United States have not been fully described.METHODS: We analyzed data from 173,099 participants of the All of Us Research Program recruited in the period 2017-2019, with 92,318 of them having electronic health records (EHR) data available, and 35,483 having completed a medical history survey. Presence of AF at baseline was identified from self-report and EHR records. Incident AF was obtained from EHR. Demographic, anthropometric and clinical risk factors were obtained from questionnaires, baseline physical measurements and EHR.RESULTS: At enrollment, mean age was 52 years old (range 18-89). Females and males accounted for 61% and 39% respectively. Non-Hispanic Whites accounted for 67% of participants, with non-Hispanic Blacks, non-Hispanic Asians and Hispanics accounting for 26%, 4% and 3% of participants, respectively. Among 92,318 participants with available EHR data, 3,885 (4.2%) had AF at the time of study enrollment, while the corresponding figure among 35,483 with medical history data was 2,084 (5.9%). During a median follow-up of 16 months, 354 new cases of AF were identified among 88,433 eligible participants. Individuals who were older, male, non-Hispanic white, had higher body mass index, or a prior history of heart failure or coronary heart disease had higher prevalence and incidence of AF.CONCLUSION: The epidemiology of AF in the All of Us Research Program is similar to that reported in smaller studies with careful phenotyping, highlighting the value of this new resource for the study of AF and, potentially, other cardiovascular diseases.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35294480,35294480,
J,"Christopoulou, Fenia; Thy Thy Tran; Sahu, Sunil Kumar; Miwa, Makoto; Ananiadou, Sophia",,,,"Miwa, Makoto/M-5596-2018","Miwa, Makoto/0000-0002-2330-6972; Tran, Thy/0000-0002-0627-9706",,,Adverse drug events and medication relation extraction in electronic health records with ensemble deep learning methods,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,39,46,,10.1093/jamia/ocz101,,,,JAN 2020,2020,"Objective: Identification of drugs, associated medication entities, and interactions among them are crucial to prevent unwanted effects of drug therapy, known as adverse drug events. This article describes our participation to the n2c2 shared-task in extracting relations between medication-related entities in electronic health records.Materials and Methods: We proposed an ensemble approach for relation extraction and classification between drugs and medication-related entities. We incorporated state-of-the-art named-entity recognition (NER) models based on bidirectional long short-term memory (BiLSTM) networks and conditional random fields (CRF) for end-to-end extraction. We additionally developed separate models for intra- and inter-sentence relation extraction and combined them using an ensemble method. The intra-sentence models rely on bidirectional long short-term memory networks and attention mechanisms and are able to capture dependencies between multiple related pairs in the same sentence. For the inter-sentence relations, we adopted a neural architecture that utilizes the Transformer network to improve performance in longer sequences.Results: Our team ranked third with a micro-averaged F1 score of 94.72% and 87.65% for relation and end-toend relation extraction, respectively (Tracks 2 and 3). Our ensemble effectively takes advantages from our proposed models. Analysis of the reported results indicated that our proposed approach is more generalizable than the top-performing system, which employs additional training data- and corpus-driven processing techniques.Conclusions: We proposed a relation extraction system to identify relations between drugs and medicationrelated entities. The proposed approach is independent of external syntactic tools. Analysis showed that by using latent Drug-Drug interactions we were able to significantly improve the performance of non-Drug-Drug pairs in EHRs.",,,,,,,,,22,4,0,0,5,0,26,,,1067-5027,1527-974X,,WOS:000548300200006,31390003,
J,"Yang, Xi; Gong, Yan; Waheed, Nida; March, Keith; Bian, Jiang; Hogan, William R; Wu, Yonghui",,,,,,,,Identifying Cancer Patients at Risk for Heart Failure Using Machine Learning Methods.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,933,941,,,,,,2019,2019,"Cardiotoxicity related to cancer therapies has become a serious issue, diminishing cancer treatment outcomes and quality of life. Early detection of cancer patients at risk for cardiotoxicity before cardiotoxic treatments and providing preventive measures are potential solutions to improve cancer patients' quality of life. This study focuses on predicting the development of heart failure in cancer patients after cancer diagnoses using historical electronic health record (EHR) data. We examined four machine learning algorithms using 143,199 cancer patients from the University of Florida Health (UF Health) Integrated Data Repository (IDR). We identified a total number of 1,958 qualified cases and matched them to 15,488 controls by gender, age, race, and major cancer type. Two feature encoding strategies were compared to encode variables as machine learning features. The gradient boosting (GB) based model achieved the best AUC score of 0.9077 (with a sensitivity of 0.8520 and a specificity of 0.8138), outperforming other machine learning methods. We also looked into the subgroup of cancer patients with exposure to chemotherapy drugs and observed a lower specificity score (0.7089). The experimental results show that machine learning methods are able to capture clinical factors that are known to be associated with heart failure and that it is feasible to use machine learning methods to identify cancer patients at risk for cancer therapy-related heart failure.",,,,,,,,,4,0,0,0,1,0,4,,,,1942-597X,,MEDLINE:32308890,32308890,
J,"Guo, Yi; He, Xing; Lyu, Tianchen; Zhang, Hansi; Wu, Yonghui; Yang, Xi; Chen, Zhaoyi; Markham, Merry Jennifer; Modave, Francois; Xie, Mengjun; Hogan, William; Harle, Christopher A; Shenkman, Elizabeth A; Bian, Jiang",,,,,"He, Xing/0000-0003-0290-8058; Xie, Mengjun/0000-0001-5089-9614",,,Developing and Validating a Computable Phenotype for the Identification of Transgender and Gender Nonconforming Individuals and Subgroups.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,514,523,,,,,,2020,2020,"Transgender and gender nonconforming (TGNC) individuals face significant marginalization, stigma, and discrimination. Under-reporting of TGNC individuals is common since they are often unwilling to self-identify. Meanwhile, the rapid adoption of electronic health record (EHR) systems has made large-scale, longitudinal real-world clinical data available to research and provided a unique opportunity to identify TGNC individuals using their EHRs, contributing to a promising routine health surveillance approach. Built upon existing work, we developed and validated a computable phenotype (CP) algorithm for identifying TGNC individuals and their natal sex (i.e., male-to-female or female-to-male) using both structured EHR data and unstructured clinical notes. Our CP algorithm achieved a 0.955 F1-score on the training data and a perfect F1-score on the independent testing data. Consistent with the literature, we observed an increasing percentage of TGNC individuals and a disproportionate burden of adverse health outcomes, especially sexually transmitted infections and mental health distress, in this population.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:33936425,33936425,
J,"Jeong, Eugene; Park, Namgi; Choi, Young; Park, Rae Woong; Yoon, Dukyong",,,,,"Choi, Young/0000-0002-8314-6130; Yoon, Dukyong/0000-0003-1635-8376",,,Machine learning model combining features from algorithms with different analytical methodologies to detect laboratory-event- related adverse drug reaction signals,,,,,,,,PLOS ONE,,,,13,11,,,,,e0207749,10.1371/journal.pone.0207749,,,,NOV 21 2018,2018,"BackgroundThe importance of identifying and evaluating adverse drug reactions (ADRs) has been widely recognized. Many studies have developed algorithms for ADR signal detection using electronic health record (EHR) data. In this study, we propose a machine learning (ML) model that enables accurate ADR signal detection by integrating features from existing algorithms based on inpatient EHR laboratory results.Materials and methodsTo construct an ADR reference dataset, we extracted known drug-laboratory event pairs represented by a laboratory test from the EU-SPC and SIDER databases. All possible drug-laboratory event pairs, except known ones, are considered unknown. To detect a known drug-laboratory event pair, three existing algorithms-CERT, CLEAR, and PACE- were applied to 21-year inpatient EHR data. We also constructed ML models (based on random forest, L1 regularized logistic regression, support vector machine, and a neural network) that use the intermediate products of the CERT, CLEAR, and PACE algorithms as inputs and determine whether a drug-laboratory event pair is associated. For performance comparison, we evaluated the sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), Fl-measure, and area under receiver operating characteristic (AUROC).ResultsAll measures of ML models outperformed those of existing algorithms with sensitivity of 0.593-0.793, specificity of 0.619-0.796, NPV of 0.645-0.727, PPV of 0.680-0.777, F1-measure of 0.629-0.709, and AUROC of 0.737-0.816. Features related to change or distribution of shape were considered important for detecting ADR signals. Conclusions Improved performance of ML models indicated that applying our model to EHR data is feasible and promising for detecting more accurate and comprehensive ADR signals.ConclusionsImproved performance of ML models indicated that applying our model to EHR data is feasible and promising for detecting more accurate and comprehensive ADR signals.",,,,,,,,,9,0,0,0,4,0,9,,,1932-6203,,,WOS:000451054800080,30462745,
J,"Agmon, Shunit; Gillis, Plia; Horvitz, Eric; Radinsky, Kira",,,,,,,,Gender-sensitive word embeddings for healthcare,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,415,423,,10.1093/jamia/ocab279,,,,JAN 29 2022,2022,"Objective To analyze gender bias in clinical trials, to design an algorithm that mitigates the effects of biases of gender representation on natural-language (NLP) systems trained on text drawn from clinical trials, and to evaluate its performance. Materials and Methods We analyze gender bias in clinical trials described by 16 772 PubMed abstracts (2008-2018). We present a method to augment word embeddings, the core building block of NLP-centric representations, by weighting abstracts by the number of women participants in the trial. We evaluate the resulting gender-sensitive embeddings performance on several clinical prediction tasks: comorbidity classification, hospital length of stay prediction, and intensive care unit (ICU) readmission prediction. Results For female patients, the gender-sensitive model area under the receiver-operator characteristic (AUROC) is 0.86 versus the baseline of 0.81 for comorbidity classification, mean absolute error 4.59 versus the baseline of 4.66 for length of stay prediction, and AUROC 0.69 versus 0.67 for ICU readmission. All results are statistically significant. Discussion Women have been underrepresented in clinical trials. Thus, using the broad clinical trials literature as training data for statistical language models could result in biased models, with deficits in knowledge about women. The method presented enables gender-sensitive use of publications as training data for word embeddings. In experiments, the gender-sensitive embeddings show better performance than baseline embeddings for the clinical tasks studied. The results highlight opportunities for recognizing and addressing gender and other representational biases in the clinical trials literature. Conclusion Addressing representational biases in data for training NLP embeddings can lead to better results on downstream tasks for underrepresented populations.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000761451900002,34918101,
J,"Lustgarten, Jonathan L.; Zehnder, Ashley; Shipman, Wayde; Gancher, Elizabeth; Webb, Tracy L.",,,,,"Shipman, Loyd/0000-0003-3520-9261",,,"Veterinary informatics: forging the future between veterinary medicine, human medicine, and One Health initiatives-a joint paper by the Association for Veterinary Informatics (AVI) and the CTSA One Health Alliance (COHA)",,,,,,,,JAMIA OPEN,,,,3,2,,,306,317,,10.1093/jamiaopen/ooaa005,,,,JUL 2020,2020,"Objectives: This manuscript reviews the current state of veterinary medical electronic health records and the ability to aggregate and analyze large datasets from multiple organizations and clinics. We also review analytical techniques as well as research efforts into veterinary informatics with a focus on applications relevant to human and animal medicine. Our goal is to provide references and context for these resources so that researchers can identify resources of interest and translational opportunities to advance the field.Methods and Results: This review covers various methods of veterinary informatics including natural language processing and machine learning techniques in brief and various ongoing and future projects. After detailing techniques and sources of data, we describe some of the challenges and opportunities within veterinary informatics as well as providing reviews of common One Health techniques and specific applications that affect both humans and animals.Discussion: Current limitations in the field of veterinary informatics include limited sources of training data for developing machine learning and artificial intelligence algorithms, siloed data between academic institutions, corporate institutions, and many small private practices, and inconsistent data formats that make many integration problems difficult. Despite those limitations, there have been significant advancements in the field in the last few years and continued development of a few, key, large data resources that are available for interested clinicians and researchers. These real-world use cases and applications show current and significant future potential as veterinary informatics grows in importance. Veterinary informatics can forge new possibilities within veterinary medicine and between veterinary medicine, human medicine, and One Health initiatives.",,,,,,,,,7,0,0,0,1,0,7,,,,2574-2531,,WOS:000645439900024,32734172,
J,"Somani, Sulaiman; Yoffie, Stephen; Teng, Shelly; Havaldar, Shreyas; Nadkarni, Girish N.; Zhao, Shan; Glicksberg, Benjamin S.",,,,,"Somani, Sulaiman/0000-0003-0913-8674",,,Development and validation of techniques for phenotyping ST-elevation myocardial infarction encounters from electronic health records,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab068,10.1093/jamiaopen/ooab068,,,,JUL 2021,2021,"Objectives: Classifying hospital admissions into various acute myocardial infarction phenotypes in electronic health records (EHRs) is a challenging task with strong research implications that remains unsolved. To our knowledge, this study is the first study to design and validate phenotyping algorithms using cardiac catheterizations to identify not only patients with a ST-elevation myocardial infarction (STEMI), but the specific encounter when it occurred.Materials and Methods: We design and validate multi-modal algorithms to phenotype STEMI on a multicenter EHR containing 5.1 million patients and 115 million patient encounters by using discharge summaries, diagnosis codes, electrocardiography readings, and the presence of cardiac catheterizations on the encounter.Results: We demonstrate that robustly phenotyping STEMIs by selecting discharge summaries containing STEM has the potential to capture the most number of STEMIs (positive predictive value [PPV] = 0.36, N = 2110), but that addition of a STEMI-related International Classification of Disease (ICD) code and cardiac catheterizations to these summaries yields the highest precision (PPV = 0.94, N = 952).Discussion and Conclusion: In this study, we demonstrate that the incorporation of percutaneous coronary intervention increases the PPV for detecting STEMI-related patient encounters from the EHR.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500037,34423260,
J,"Xiong, Ying; Shi, Xue; Chen, Shuai; Jiang, Dehuan; Tang, Buzhou; Wang, Xiaolong; Chen, Qingcai; Yan, Jun",,,,,"Tang, Buzhou/0000-0003-0271-8246",,,Cohort selection for clinical trials using hierarchical neural network,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1203,1208,,10.1093/jamia/ocz099,,,,NOV 2019,2019,"Objective: Cohort selection for clinical trials is a key step for clinical research. We proposed a hierarchical neural network to determine whether a patient satisfied selection criteria or not.Materials and Methods: We designed a hierarchical neural network (denoted as CNN-Highway-LSTM or LSTM-Highway-LSTM) for the track 1 of the national natural language processing (NLP) clinical challenge (n2c2) on cohort selection for clinical trials in 2018. The neural network is composed of 5 components: (1) sentence representation using convolutional neural network (CNN) or long short-term memory (LSTM) network; (2) a highway network to adjust information flow; (3) a self-attention neural network to reweight sentences; (4) document representation using LSTM, which takes sentence representations in chronological order as input; (5) a fully connected neural network to determine whether each criterion is met or not. We compared the proposed method with its variants, including the methods only using the first component to represent documents directly and the fully connected neural network for classification (denoted as CNN-only or LSTM-only) and the methods without using the highway network (denoted as CNN-LSTM or LSTM-LSTM). The performance of all methods was measured by micro-averaged precision, recall, and F1 score.Results: The micro-averaged F1 scores of CNN-only, LSTM-only, CNN-LSTM, LSTM-LSTM, CNN-Highway-LSTM, and LSTM-Highway-LSTM were 85.24%, 84.25%, 87.27%, 88.68%, 88.48%, and 90.21%, respectively. The highest micro-averaged F1 score is higher than our submitted 1 of 88.55%, which is 1 of the top-ranked results in the challenge. The results indicate that the proposed method is effective for cohort selection for clinical trials.Discussion: Although the proposed method achieved promising results, some mistakes were caused by word ambiguity, negation, number analysis and incomplete dictionary. Moreover, imbalanced data was another challenge that needs to be tackled in the future.Conclusion: In this article, we proposed a hierarchical neural network for cohort selection. Experimental results show that this method is good at selecting cohort.",,,,,,,,,11,0,0,0,4,0,11,,,1067-5027,1527-974X,,WOS:000498169400007,31305921,
J,"Gu, Yifan; Yang, Xuebing; Tian, Lei; Yang, Hongyu; Lv, Jicheng; Yang, Chao; Wang, Jinwei; Xi, Jianing; Kong, Guilan; Zhang, Wensheng",,,,,,,,Structure-aware siamese graph neural networks for encounter-level patient similarity learning,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,104027,10.1016/j.jbi.2022.104027,,,,MAR 2022,2022,"Patient similarity learning has attracted great research interest in biomedical informatics. Correctly identifying the similarity between a given patient and patient records in the database could contribute to clinical references for diagnosis and medication. The sparsity of underlying relationships between patients poses difficulties for similarity learning, which becomes more challenging when considering real-world Electronic Health Records (EHRs) with a large number of missing values. In the paper, we organize EHRs as a graph and propose a novel deep learning framework, Structure-aware Siamese Graph neural Networks (SSGNet), to perform robust encounter-level patient similarity learning while capturing the intrinsic graph structure and mitigating the influence from missing values. The proposed SSGNet regards each patient encounter as a node, and learns the node embeddings and the similarity between nodes simultaneously via Graph Neural Networks (GNNs) with siamese architecture. Further, SSGNet employs a low-rank and contrastive objective to optimize the structure of the patient graph and enhance model capacity. The extensive experiments were conducted on two publicly available datasets and a real-world dataset regarding IgA nephropathy from Peking University First Hospital, in comparison with multiple baseline and state-of-the-art methods. The significant improvement in Accuracy, Precision, Recall and F1 score on the patient encounter pairwise similarity classification task demonstrates the superiority of SSGNet. The mean average precision (mAP) of SSGNet on the similar encounter retrieval task is also better than other competitors. Furthermore, SSGNet's stable similarity classification accuracies at different missing rates of data validate the effectiveness and robustness of our proposal.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000017,35181493,
J,"Wu, Danny T Y; Meganathan, Karthikeyan; Newcomb, Matthew; Ni, Yizhao; Dexheimer, Judith W; Kirkendall, Eric S; Spooner, S Andrew",,,,,"Ni, Yizhao/0000-0001-8599-454X; Wu, Tzu-Yu/0000-0002-7658-3754",,,A Comparison of Existing Methods to Detect Weight Data Errors in a Pediatric Academic Medical Center.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1103,1109,,,,,,2018,2018,"Dosing errors due to erroneous body weight entry can be mitigated through algorithms designed to detect anomalies in weight patterns. To prepare for the development of a new algorithm for weight-entry error detection, we compared methods for detecting weight anomalies to human annotation, including a regression-based method employed in a real-time web service. Using a random sample of 4,000 growth charts, annotators identified clinically important anomalies with good inter-rater reliability. Performance of the three detection algorithms was variable, with the best performance from the algorithm that takes into account weights collected after the anomaly was recorded. All methods were highly specific, but positive predictive value ranged from < 5% to over 82%. There were 203 records of missed errors, but all of these were either due to no prior data points or errors too small to be clinically significant. This analysis illustrates the need for better weight-entry error detection algorithms.",,,,,,,,,2,0,0,0,1,0,2,,,,1942-597X,,MEDLINE:30815152,30815152,
J,"Flamholz, Zachary N.; Crane-Droesch, Andrew; Ungar, Lyle H.; Weissman, Gary E.",,,,,"Flamholz, Zachary/0000-0002-0129-8836",,,"Word embeddings trained on published case reports are lightweight, effective for clinical tasks, and free of protected health information",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,125,,,,,,103971,10.1016/j.jbi.2021.103971,,DEC 2021,,JAN 2022,2022,"Objective: Quantify tradeoffs in performance, reproducibility, and resource demands across several strategies for developing clinically relevant word embeddings. Materials and methods: We trained separate embeddings on all full-text manuscripts in the Pubmed Central (PMC) Open Access subset, case reports therein, the English Wikipedia corpus, the Medical Information Mart for Intensive Care (MIMIC) III dataset, and all notes in the University of Pennsylvania Health System (UPHS) electronic health record. We tested embeddings in six clinically relevant tasks including mortality prediction and de-identification, and assessed performance using the scaled Brier score (SBS) and the proportion of notes successfully de-identified, respectively. Results: Embeddings from UPHS notes best predicted mortality (SBS 0.30, 95% CI 0.15 to 0.45) while Wikipedia embeddings performed worst (SBS 0.12, 95% CI -0.05 to 0.28). Wikipedia embeddings most consistently (78% of notes) and the full PMC corpus embeddings least consistently (48%) de-identified notes. Across all six tasks, the full PMC corpus demonstrated the most consistent performance, and the Wikipedia corpus the least. Corpus size ranged from 49 million tokens (PMC case reports) to 10 billion (UPHS). Discussion: Embeddings trained on published case reports performed as least as well as embeddings trained on other corpora in most tasks, and clinical corpora consistently outperformed non-clinical corpora. No single corpus produced a strictly dominant set of embeddings across all tasks and so the optimal training corpus depends on intended use. Conclusion: Embeddings trained on published case reports performed comparably on most clinical tasks to embeddings trained on larger corpora. Open access corpora allow training of clinically relevant, effective, and reproducible embeddings.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000735446400001,34920127,
J,"Abdalla, Mohamed; Abdalla, Moustafa; Rudzicz, Frank; Hirst, Graeme",,,,,,,,Using word embeddings to improve the privacy of clinical notes,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,6,,,901,907,,10.1093/jamia/ocaa038,,,,JUN 2020,2020,"Objective: In this work, we introduce a privacy technique for anonymizing clinical notes that guarantees all private health information is secured (including sensitive data, such as family history, that are not adequately covered by current techniques).Materials and Methods: We employ a new random replacement paradigm (replacing each token in clinical notes with neighboring word vectors from the embedding space) to achieve 100% recall on the removal of sensitive information, unachievable with current search-and-secure paradigms. We demonstrate the utility of this paradigm on multiple corpora in a diverse set of classification tasks.Results: We empirically evaluate the effect of our anonymization technique both on upstream and downstream natural language processing tasks to show that our perturbations, while increasing security (ie, achieving 100% recall on any dataset), do not greatly impact the results of end-to-end machine learning approaches.Discussion: As long as current approaches utilize precision and recall to evaluate deidentification algorithms, there will remain a risk of overlooking sensitive information. Inspired by differential privacy, we sought to make it statistically infeasible to recreate the original data, although at the cost of readability. We hope that the work will serve as a catalyst to further research into alternative deidentification methods that can address current weaknesses.Conclusion: Our proposed technique can secure clinical texts at a low cost and extremely high recall with a readability trade-off while remaining useful for natural language processing classification tasks. We hope that our work can be used by risk-averse data holders to release clinical texts to researchers.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000542064800009,32388549,
J,"Parikh, Ravi B.; Linn, Kristin A.; Yan, Jiali; Maciejewski, Matthew L.; Rosland, Ann-Marie; Volpp, Kevin G.; Groeneveld, Peter W.; Navathe, Amol S.",,,,,"Navathe, Amol/0000-0001-7182-4988; Parikh, Ravi/0000-0003-2692-6306; Groeneveld, Peter/0000-0002-7374-4292",,,A machine learning approach to identify distinct subgroups of veterans at risk for hospitalization or death using administrative and electronic health record data,,,,,,,,PLOS ONE,,,,16,2,,,,,e0247203,10.1371/journal.pone.0247203,,,,FEB 19 2021,2021,"BackgroundIdentifying individuals at risk for future hospitalization or death has been a major priority of population health management strategies. High-risk individuals are a heterogeneous group, and existing studies describing heterogeneity in high-risk individuals have been limited by data focused on clinical comorbidities and not socioeconomic or behavioral factors. We used machine learning clustering methods and linked comorbidity-based, sociodemographic, and psychobehavioral data to identify subgroups of high-risk Veterans and study long-term outcomes, hypothesizing that factors other than comorbidities would characterize several subgroups.Methods and findingsIn this cross-sectional study, we used data from the VA Corporate Data Warehouse, a national repository of VA administrative claims and electronic health data. To identify high-risk Veterans, we used the Care Assessment Needs (CAN) score, a routinely-used VA model that predicts a patient's percentile risk of hospitalization or death at one year. Our study population consisted of 110,000 Veterans who were randomly sampled from 1,920,436 Veterans with a CAN score >= 75(th) percentile in 2014. We categorized patient-level data into 119 independent variables based on demographics, comorbidities, pharmacy, vital signs, laboratories, and prior utilization. We used a previously validated density-based clustering algorithm to identify 30 subgroups of high-risk Veterans ranging in size from 50 to 2,446 patients. Mean CAN score ranged from 72.4 to 90.3 among subgroups. Two-year mortality ranged from 0.9% to 45.6% and was highest in the home-based care and metastatic cancer subgroups. Mean inpatient days ranged from 1.4 to 30.5 and were highest in the post-surgery and blood loss anemia subgroups. Mean emergency room visits ranged from 1.0 to 4.3 and were highest in the chronic sedative use and polysubstance use with amphetamine predominance subgroups. Five subgroups were distinguished by psychobehavioral factors and four subgroups were distinguished by sociodemographic factors.ConclusionsHigh-risk Veterans are a heterogeneous population consisting of multiple distinct subgroups-many of which are not defined by clinical comorbidities-with distinct utilization and outcome patterns. To our knowledge, this represents the largest application of ML clustering methods to subgroup a high-risk population. Further study is needed to determine whether distinct subgroups may benefit from individualized interventions.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000620629200048,33606819,
J,"Yin, Ziyan; Tong, Jiayi; Chen, Yong; Hubbard, Rebecca A.; Tang, Cheng Yong",,,,,,,,A cost-effective chart review sampling design to account for phenotyping error in electronic health records (EHR) data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,1,,,52,61,,10.1093/jamia/ocab222,,OCT 2021,,JAN 2021,2021,"Objectives: Electronic health records (EHR) are commonly used for the identification of novel risk factors for disease, often referred to as an association study. A major challenge to EHR-based association studies is phenotyping error in EHR-derived outcomes. A manual chart review of phenotypes is necessary for unbiased evaluation of risk factor associations. However, this process is time-consuming and expensive. The objective of this paper is to develop an outcome-dependent sampling approach for designing manual chart review, where EHR-derived phenotypes can be used to guide the selection of charts to be reviewed in order to maximize statistical efficiency in the subsequent estimation of risk factor associations.Materials and Methods: After applying outcome-dependent sampling, an augmented estimator can be constructed by optimally combining the chart-reviewed phenotypes from the selected patients with the error-prone EHR-derived phenotype. We conducted simulation studies to evaluate the proposed method and applied our method to data on colon cancer recurrence in a cohort of patients treated for a primary colon cancer in the Kaiser Permanente Washington (KPW) healthcare system.Results: Simulations verify the coverage probability of the proposed method and show that, when disease prevalence is less than 30%, the proposed method has smaller variance than an existing method where the validation set for chart review is uniformly sampled. In addition, from design perspective, the proposed method is able to achieve the same statistical power with 50% fewer charts to be validated than the uniform sampling method, thus, leading to a substantial efficiency gain in chart review. These findings were also confirmed by the application of the competing methods to the KPW colon cancer data. Discussion: Our simulation studies and analysis of data from KPW demonstrate that, compared to an existing uniform sampling method, the proposed outcome-dependent method can lead to a more efficient chart review sampling design and unbiased association estimates with higher statistical efficiency.Conclusion: The proposed method not only optimally combines phenotypes from chart review with EHR-derived phenotypes but also suggests an efficient design for conducting chart review, with the goal of improving the efficiency of estimated risk factor associations using EHR data.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000740719600007,34718618,
J,"Rodriguez, Victor Alfonso; Bhave, Shreyas; Chen, Ruijun; Pang, Chao; Hripcsak, George; Sengupta, Soumitra; Elhadad, Noemie; Green, Robert; Adelman, Jason; Metitiri, Katherine Schlosser; Elias, Pierre; Groves, Holden; Mohan, Sumit; Natarajan, Karthik; Perotte, Adler",,,,"Mohan, Sumit/I-5625-2019","Mohan, Sumit/0000-0002-5305-9685; Chen, RuiJun/0000-0001-5281-4143",,,"Development and validation of prediction models for mechanical ventilation, renal replacement therapy, and readmission in COVID-19 patients",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,7,,,1480,1488,,10.1093/jamia/ocab029,,MAR 2021,,JUL 2021,2021,"Objective: Coronavirus disease 2019 (COVID-19) patients are at risk for resource-intensive outcomes including mechanical ventilation (MV), renal replacement therapy (RRT), and readmission. Accurate outcome prognostication could facilitate hospital resource allocation. We develop and validate predictive models for each outcome using retrospective electronic health record data for COVID-19 patients treated between March 2 and May 6,2020.Materials and Methods: For each outcome, we trained 3 classes of prediction models using clinical data for a cohort of SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2)-positive patients (n = 2256). Cross-validation was used to select the best-performing models per the areas under the receiver-operating characteristic and precision-recall curves. Models were validated using a held-out cohort (n =855). We measured each model's calibration and evaluated feature importances to interpret model output.Results: The predictive performance for our selected models on the held-out cohort was as follows: area under the receiver-operating characteristic curve-MV 0.743 (95% CI, 0.682-0.812), RRT 0.847 (95% CI, 0.772-0.936), readmission 0.871 (95% CI, 0.830-0.917); area under the precision-recall curve-MV 0.137 (95% CI, 0.047-0.175), RRT 0.325 (95% CI, 0.117-0.497), readmission 0.504 (95% CI, 0.388-0.604). Predictions were well calibrated, and the most important features within each model were consistent with clinical intuition.Discussion: Our models produce performant, well-calibrated, and interpretable predictions for COVID-19 patients at risk for the target outcomes. They demonstrate the potential to accurately estimate outcome prognosis in resource-constrained care sites managing COVID-19 patients.Conclusions: We develop and validate prognostic models targeting MV, RRT, and readmission for hospitalized COVID-19 patients which produce accurate, interpretable predictions. Additional external validation studies are needed to further verify the generalizability of our results.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000685209200014,33706377,
J,"Ostropolets, Anna; Reich, Christian; Ryan, Patrick; Shang, Ning; Hripcsak, George; Weng, Chunhua",,,,,"Weng, Chunhua/0000-0002-9624-0214; Ostropolets, Anna/0000-0002-0847-6682; Shang, Ning/0000-0001-7040-5204",,,Adapting electronic health records-derived phenotypes to claims data: Lessons learned in using limited clinical data for phenotyping,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,102,,,,,,103363,10.1016/j.jbi.2019.103363,,,,FEB 2020,2020,"Algorithms for identifying patients of interest from observational data must address missing and inaccurate data and are desired to achieve comparable performance on both administrative claims and electronic health records data. However, administrative claims data do not contain the necessary information to develop accurate algorithms for disorders that require laboratory results, and this omission can result in insensitive diagnostic code-based algorithms. In this paper, we tested our assertion that the performance of a diagnosis code-based algorithm for chronic kidney disorder (CKD) can be improved by adding other codes indirectly related to CKD (e.g., codes for dialysis, kidney transplant, suspicious kidney disorders). Following the best practices from Observational Health Data Sciences and Informatics (OHDSI), we adapted an electronic health record-based gold standard algorithm for CKD and then created algorithms that can be executed on administrative claims data and account for related data quality issues. We externally validated our algorithms on four electronic health record datasets in the OHDSI network. Compared to the algorithm that uses CKD diagnostic codes only, positive predictive value of the algorithms that use additional codes was slightly increased (47.4% vs. 47.9-48.5% respectively). The algorithms adapted from the gold standard algorithm can be used to infer chronic kidney disorder based on administrative claims data. We succeeded in improving the generalizability and consistency of the CKD phenotypes by using data and vocabulary standardized across the OHDSI network, although performance variability across datasets remains. We showed that identifying and addressing coding and data heterogeneity can improve the performance of the algorithms.",,,,,,,,,4,0,0,0,2,0,4,,,1532-0464,1532-0480,,WOS:000525735200001,31866433,
J,"Yuan, Chi; Ryan, Patrick B.; Ta, Casey; Guo, Yixuan; Li, Ziran; Hardin, Jill; Makadia, Rupa; Jin, Peng; Shang, Ning; Kang, Tian; Weng, Chunhua",,,,"Kang, Tian/AAU-1423-2021","Shang, Ning/0000-0001-7040-5204",,,Criteria2Query: a natural language interface to clinical databases for cohort definition,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,4,,,294,305,,10.1093/jamia/ocy178,,,,APR 2019,2019,"Objective Cohort definition is a bottleneck for conducting clinical research and depends on subjective decisions by domain experts. Data-driven cohort definition is appealing but requires substantial knowledge of terminologies and clinical data models. Criteria2Query is a natural language interface that facilitates human-computer collaboration for cohort definition and execution using clinical databases.Materials and Methods Criteria2Query uses a hybrid information extraction pipeline combining machine learning and rule-based methods to systematically parse eligibility criteria text, transforms it first into a structured criteria representation and next into sharable and executable clinical data queries represented as SQL queries conforming to the OMOP Common Data Model. Users can interactively review, refine, and execute queries in the ATLAS web application. To test effectiveness, we evaluated 125 criteria across different disease domains from ClinicalTrials.gov and 52 user-entered criteria. We evaluated F1 score and accuracy against 2 domain experts and calculated the average computation time for fully automated query formulation. We conducted an anonymous survey evaluating usability.Results Criteria2Query achieved 0.795 and 0.805 F1 score for entity recognition and relation extraction, respectively. Accuracies for negation detection, logic detection, entity normalization, and attribute normalization were 0.984, 0.864, 0.514 and 0.793, respectively. Fully automatic query formulation took 1.22 seconds/criterion. More than 80% (11+ of 13) of users would use Criteria2Query in their future cohort definition tasks.Conclusions We contribute a novel natural language interface to clinical databases. It is open source and supports fully automated and interactive modes for autonomous data-driven cohort definition by researchers with minimal human effort. We demonstrate its promising user friendliness and usability.",,,,,,,,,30,1,0,0,8,0,31,,,1067-5027,1527-974X,,WOS:000461148100004,30753493,
J,"Carrell, David S.; Malin, Bradley A.; Cronkite, David J.; Aberdeen, John S.; Clark, Cheryl; Li, Muqun (Rachel); Bastakoty, Dikshya; Nyemba, Steve; Hirschman, Lynette",,,,,"Carrell, David S./0000-0002-8471-0928",,,Resilience of clinical text de-identified with hiding in plain sight to hostile reidentification attacks by human readers,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1374,1382,,10.1093/jamia/ocaa095,,,,SEP 2020,2020,"Objective: Effective, scalable de-identification of personally identifying information (PII) for information-rich clinical text is critical to support secondary use, but no method is 100% effective. The hiding-in-plain-sight (HIPS) approach attempts to solve this residual PII problem. HIPS replaces PII tagged by a de-identification system with realistic but fictitious (resynthesized) content, making it harder to detect remaining unredacted PII.Materials and Methods: Using 2000 representative clinical documents from 2 healthcare settings (4000 total), we used a novel method to generate 2 de-identified 100-document corpora (200 documents total) in which PII tagged by a typical automated machine-learned tagger was replaced by HIPS-resynthesized content. Four readers conducted aggressive reidentification attacks to isolate leaked PII: 2 readers from within the originating institution and 2 external readers.Results: Overall, mean recall of leaked PII was 26.8% and mean precision was 37.2%. Mean recall was 9% (mean precision = 37%) for patient ages, 32% (mean precision = 26%) for dates, 25% (mean precision = 37%) for doctor names, 45% (mean precision = 55%) for organization names, and 23% (mean precision = 57%) for patient names. Recall was 32% (precision = 40%) for internal and 22% (precision =33%) for external readers.Discussion and Conclusions: Approximately 70% of leaked PII hiding in a corpus de-identified with HIPS resynthesis is resilient to detection by human readers in a realistic, aggressive reidentification attack scenariomore than double the rate reported in previous studies but less than the rate reported for an attack assisted by machine learning methods.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000593113300006,32930712,
J,"Parikh, Rishi V.; Tan, Thida C.; Fan, Dongjie; Law, David; Salyer, Anne S.; Yankulin, Leonid; Wojcicki, Janet M.; Zheng, Sijie; Ordonez, Juan D.; Chertow, Glenn M.; Khoshniat-Rad, Farzien; Yang, Jingrong; Go, Alan S.",,,,,"Chertow, Glenn/0000-0002-7599-0534",,,Population-based identification and temporal trend of children with primary nephrotic syndrome: The Kaiser Permanente nephrotic syndrome study,,,,,,,,PLOS ONE,,,,16,10,,,,,e0257674,10.1371/journal.pone.0257674,,,,2021,2021,"Introduction Limited population-based data exist about children with primary nephrotic syndrome (NS). Methods We identified a cohort of children with primary NS receiving care in Kaiser Permanente Northern California, an integrated healthcare delivery system caring for >750,000 children. We identified all children <18 years between 1996 and 2012 who had nephrotic range proteinuria (urine ACR>3500 mg/g, urine PCR>3.5 mg/mg, 24-hour urine protein>3500 mg or urine dipstick>300 mg/dL) in laboratory databases or a diagnosis of NS in electronic health records. Nephrologists reviewed health records for clinical presentation and laboratory and biopsy results to confirm primary NS. Results Among 365 cases of confirmed NS, 179 had confirmed primary NS attributed to presumed minimal change disease (MCD) (72%), focal segmental glomerulosclerosis (FSGS) (23%) or membranous nephropathy (MN) (5%). The overall incidence of primary NS was 1.47 (95% Confidence Interval:1.27-1.70) per 100,000 person-years. Biopsy data were available in 40% of cases. Median age for patients with primary NS was 6.9 (interquartile range:3.7 to 12.9) years, 43% were female and 26% were white, 13% black, 17% Asian/Pacific Islander, and 32% Hispanic. Conclusion This population-based identification of children with primary NS leveraging electronic health records can provide a unique approach and platform for describing the natural history of NS and identifying determinants of outcomes in children with primary NS.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000729172300011,34648518,
J,"Fu, Li-Heng; Schwartz, Jessica; Moy, Amanda; Knaplund, Chris; Kang, Min-Jeoung; Schnock, Kumiko O.; Garcia, Jose P.; Jia, Haomiao; Dykes, Patricia C.; Cato, Kenrick; Albers, David; Rossetti, Sarah Collins",,,,,"Fu, Li-heng/0000-0001-5662-8321",,,Development and validation of early warning score system: A systematic literature review,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,105,,,,,,103410,10.1016/j.jbi.2020.103410,,,,MAY 2020,2020,"Objectives: This review aims to: 1) evaluate the quality of model reporting, 2) provide an overview of methodology for developing and validating Early Warning Score Systems (EWSs) for adult patients in acute care settings, and 3) highlight the strengths and limitations of the methodologies, as well as identify future directions for EWS derivation and validation studies.Methodology: A systematic search was conducted in PubMed, Cochrane Library, and CINAHL. Only peer reviewed articles and clinical guidelines regarding developing and validating EWSs for adult patients in acute care settings were included. 615 articles were extracted and reviewed by five of the authors. Selected studies were evaluated based on the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) checklist. The studies were analyzed according to their study design, predictor selection, outcome measurement, methodology of modeling, and validation strategy.Results: A total of 29 articles were included in the final analysis. Twenty-six articles reported on the development and validation of a new EWS, while three reported on validation and model modification. Only eight studies met more than 75% of the items in the TRIPOD checklist. Three major techniques were utilized among the studies to inform their predictive algorithms: 1) clinical-consensus models (n = 6), 2) regression models (n = 15), and 3) tree models (n = 5). The number of predictors included in the EWSs varied from 3 to 72 with a median of seven. Twenty-eight models included vital signs, while 11 included lab data. Pulse oximetry, mental status, and other variables extracted from electronic health records (EHRs) were among other frequently used predictors. Inhospital mortality, unplanned transfer to the intensive care unit (ICU), and cardiac arrest were commonly used clinical outcomes. Twenty-eight studies conducted a form of model validation either within the study or against other widely-used EWSs. Only three studies validated their model using an external database separate from the derived database.Conclusion: This literature review demonstrates that the characteristics of the cohort, predictors, and outcome selection, as well as the metrics for model validation, vary greatly across EWS studies. There is no consensus on the optimal strategy for developing such algorithms since data-driven models with acceptable predictive accuracy are often site-specific. A standardized checklist for clinical prediction model reporting exists, but few studies have included reporting aligned with it in their publications. Data-driven models are subjected to biases in the use of EHR data, thus it is particularly important to provide detailed study protocols and acknowledge, leverage, or reduce potential biases of the data used for EWS development to improve transparency and generalizability.",,,,,,,,,13,0,0,0,2,0,13,,,1532-0464,1532-0480,,WOS:000535653800004,32278089,
J,"Abulaish, Muhammad; Parwez, Md Aslam; Jahiruddin",,,,"Parwez, Aslam/AAR-3119-2021; Abulaish, Muhammad/L-7397-2014; uddin, Jahir/AAQ-8811-2021","Abulaish, Muhammad/0000-0003-3387-4743; uddin, Jahir/0000-0003-3909-9821; PARWEZ, MD ASLAM/0000-0003-0087-7171",,,DiseaSE: A biomedical text analytics system for disease symptom extraction and characterization,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103324,10.1016/j.jbi.2019.103324,,,,DEC 2019,2019,"Due to increasing volume and unstructured nature of the scientific literatures in biomedical domain, most of the information embedded within them remain untapped. This paper presents a biomedical text analytics system, DiseaSE (Disease Symptom Extraction), to identify and extract disease symptoms and their associations from biomedical text documents retrieved from the PubMed database. It implements various NLP and information extraction techniques to convert text documents into record-size information components that are represented as semantic triples and processed using TextRank and other ranking techniques to identify feasible disease symptoms. Eight different diseases, including dengue, malaria, cholera, diarrhoea, influenza, meningitis, leishmaniasis, and kala-azar are considered for experimental evaluation of the proposed DiseaSE system. On analysis, we found that the DiseaSE system is able to identify new symptoms that are even not catalogued on standard websites such as Center for Disease Control (CDC), World Health Organization (WHO), and National Health Survey (NHS). The proposed DiseaSE system also aims to compile generic associations between a disease and its symptoms, and presents a graph-theoretic analysis and visualization scheme to characterize disease at different levels of granularity. The identified disease symptoms and their associations could be useful to generate a biomedical knowledgebase (e.g., a disease ontology) for the development of e-health and disease surveillance systems.",,,,,,,,,3,1,0,0,0,0,4,,,1532-0464,1532-0480,,WOS:000525702900010,31678590,
J,"Obeid, Jihad S.; Davis, Matthew; Turner, Matthew; Meystre, Stephane M.; Heider, Paul M.; O'Bryan, Edward C.; Lenert, Leslie A.",,,,"; Obeid, Jihad/P-9793-2016","Davis, Matthew/0000-0001-9111-4932; Heider, Paul/0000-0002-1589-4567; Obeid, Jihad/0000-0002-7193-7779",,,An artificial intelligence approach to COVID-19 infection risk assessment in virtual visits: A case report,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,8,,,1321,1325,,10.1093/jamia/ocaa105,,,,AUG 2020,2020,"Objective: In an effort to improve the efficiency of computer algorithms applied to screening for coronavirus disease 2019 (COVID-19) testing, we used natural language processing and artificial intelligence-based methods with unstructured patient data collected through telehealth visits.Materials and Methods: After segmenting and parsing documents, we conducted analysis of overrepresented words in patient symptoms. We then developed a word embedding-based convolutional neural network for predicting COVID-19 test results based on patients' self-reported symptoms.Results: Text analytics revealed that concepts such as smell and taste were more prevalent than expected in patients testing positive. As a result, screening algorithms were adapted to include these symptoms. The deep learning model yielded an area under the receiver-operating characteristic curve of 0.729 for predicting positive results and was subsequently applied to prioritize testing appointment scheduling.Conclusions: Informatics tools such as natural language processing and artificial intelligence methods can have significant clinical impacts when applied to data streams early in the development of clinical systems for outbreak response.",,,,,,,,,17,0,0,0,2,0,17,,,1067-5027,1527-974X,,WOS:000584507600019,32449766,
J,"Mao, Chengsheng; Yao, Liang; Luo, Yuan",,,,,,,,MedGCN: Medication recommendation and lab test imputation via graph convolutional networks,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,127,,,,,,104000,10.1016/j.jbi.2022.104000,,,,MAR 2022,2022,"Laboratory testing and medication prescription are two of the most important routines in daily clinical practice. Developing an artificial intelligence system that can automatically make lab test imputations and medication recommendations can save costs on potentially redundant lab tests and inform physicians of a more effective prescription. We present an intelligent medical system (named MedGCN) that can automatically recommend the patients' medications based on their incomplete lab tests, and can even accurately estimate the lab values that have not been taken. In our system, we integrate the complex relations between multiple types of medical entities with their inherent features in a heterogeneous graph. Then we model the graph to learn a distributed representation for each entity in the graph based on graph convolutional networks (GCN). By the propagation of graph convolutional networks, the entity representations can incorporate multiple types of medical information that can benefit multiple medical tasks. Moreover, we introduce a cross regularization strategy to reduce overfitting for multi-task training by the interaction between the multiple tasks. In this study, we construct a graph to associate 4 types of medical entities, i.e., patients, encounters, lab tests, and medications, and applied a graph neural network to learn node embeddings for medication recommendation and lab test imputation. we validate our MedGCN model on two real-world datasets: NMEDW and MIMIC-III. The experimental results on both datasets demonstrate that our model can outperform the state-of-the-art in both tasks. We believe that our innovative system can provide a promising and reliable way to assist physicians to make medication prescriptions and to save costs on potentially redundant lab tests.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000772252000003,35104644,
J,"Salvatore, Maxwell; Beesley, Lauren J.; Fritsche, Lars G.; Hanauer, David; Shi, Xu; Mondul, Alison M.; Pearce, Celeste Leigh; Mukherjee, Bhramar",,,,"Fritsche, Lars G/AAF-9387-2019","Fritsche, Lars G/0000-0002-2110-1690",,,Phenotype risk scores (PheRS) for pancreatic cancer using time-stamped electronic health record data: Discovery and validation in two large biobanks,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,113,,,,,,103652,10.1016/j.jbi.2020.103652,,,,JAN 2021,2021,"Background: Traditional methods for disease risk prediction and assessment, such as diagnostic tests using serum, urine, blood, saliva or imaging biomarkers, have been important for identifying high-risk individuals for many diseases, leading to early detection and improved survival. For pancreatic cancer, traditional methods for screening have been largely unsuccessful in identifying high-risk individuals in advance of disease progression leading to high mortality and poor survival. Electronic health records (EHR) linked to genetic profiles provide an opportunity to integrate multiple sources of patient information for risk prediction and stratification. We leverage a constellation of temporally associated diagnoses available in the EHR to construct a summary risk score, called a phenotype risk score (PheRS), for identifying individuals at high-risk for having pancreatic cancer. The proposed PheRS approach incorporates the time with respect to disease onset into the prediction framework. We combine and contrast the PheRS with more well-known measures of inherited susceptibility, namely, the polygenic risk scores (PRS) for prediction of pancreatic cancer.Methodology: We first calculated pairwise, unadjusted associations between pancreatic cancer diagnosis and all possible other diagnoses across the medical phenome. We call these pairwise associations co-occurrences. After accounting for cross-phenotype correlations, the multivariable association estimates from a subset of relatively independent diagnoses were used to create a weighted sum PheRS. We constructed time-restricted risk scores using data from 38,359 participants in the Michigan Genomics Initiative (MGI) based on the diagnoses contained in the EHR at 0, 1, 2, and 5 years prior to the target pancreatic cancer diagnosis. The PheRS was assessed for predictability in the UK Biobank (UKB). We tested the relative contribution of PheRS when added to a model containing a summary measure of inherited genetic susceptibility (PRS) plus other covariates like age, sex, smoking status, drinking status, and body mass index (BMI).Results: Our exploration of co-occurrence patterns identified expected associations while also revealing unexpected relationships that may warrant closer attention. Solely using the pancreatic cancer PheRS at 5 years before the target diagnoses yielded an AUC of 0.60 (95% CI = [0.58, 0.62]) in UKB. A larger predictive model including PheRS, PRS, and the covariates at the 5-year threshold achieved an AUC of 0.74 (95% CI = [0.72, 0.76]) in UKB. We note that PheRS does contribute independently in the joint model. Finally, scores at the top percentiles of the PheRS distribution demonstrated promise in terms of risk stratification. Scores in the top 2% were 10.20 (95% CI = [9.34, 12.99]) times more likely to identify cases than those in the bottom 98% in UKB at the 5-year threshold prior to pancreatic cancer diagnosis.Conclusions: We developed a framework for creating a time-restricted PheRS from EHR data for pancreatic cancer using the rich information content of a medical phenome. In addition to identifying hypothesis-generating associations for future research, this PheRS demonstrates a potentially important contribution in identifying high risk individuals, even after adjusting for PRS for pancreatic cancer and other traditional epidemiologic covariates. The methods are generalizable to other phenotypic traits.",,,,,,,,,4,0,1,0,3,0,5,,,1532-0464,1532-0480,,WOS:000615920400004,33279681,
J,"Rogers, James R.; Hripcsak, George; Cheung, Ying Kuen; Weng, Chunhua",,,,,"Weng, Chunhua/0000-0002-9624-0214",,,Clinical comparison between trial participants and potentially eligible patients using electronic health record data: A generalizability assessment method,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,119,,,,,,103822,10.1016/j.jbi.2021.103822,,JUN 2021,,JUL 2021,2021,"Objective: To present a generalizability assessment method that compares baseline clinical characteristics of trial participants (TP) to potentially eligible (PE) patients as presented in their electronic health record (EHR) data while controlling for clinical setting and recruitment period.Methods: For each clinical trial, a clinical event was defined to identify patients of interest using available EHR data from one clinical setting during the trial's recruitment timeframe. The trial's eligibility criteria were then applied and patients were separated into two mutually exclusive groups: (1) TP, which were patients that participated in the trial per trial enrollment data; (2) PE, the remaining patients. The primary outcome was standardized differences in clinical characteristics between TP and PE per trial. A standardized difference was considered prominent if its absolute value was greater than or equal to 0.1. The secondary outcome was the difference in mean propensity scores (PS) between TP and PE per trial, in which the PS represented prediction for a patient to be in the trial. Three diverse trials were selected for illustration: one focused on hepatitis C virus (HCV) patients receiving a liver transplantation; one focused on leukemia patients and lymphoma patients; and one focused on appendicitis patients.Results: For the HCV trial, 43 TP and 83 PE were found, with 61 characteristics evaluated. Prominent differences were found among 69% of characteristics, with a mean PS difference of 0.13. For the leukemia/lymphoma trial, 23 TP and 23 PE were found, with 39 characteristics evaluated. Prominent differences were found among 82% of characteristics, with a mean PS difference of 0.76. For the appendicitis trial, 123 TP and 242 PE were found, with 52 characteristics evaluated. Prominent differences were found among 52% of characteristics, with a mean PS difference of 0.15.Conclusions: Differences in clinical characteristics were observed between TP and PE among all three trials. In two of the three trials, not all of the differences necessarily compromised trial generalizability and subsets of PE could be considered similar to their corresponding TP. In the remaining trial, lack of generalizability appeared present, but may be a result of other factors such as small sample size or site recruitment strategy. These inconsistent findings suggest eligibility criteria alone are sometimes insufficient in defining a target group to generalize to. With caveats in limited scalability, EHR data quality, and lack of patient perspective on trial participation, this generalizability assessment method that incorporates control for temporality and clinical setting promise to better pinpoint clinical patterns and trial considerations.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000674512900003,34044156,
J,"Vajravelu, Ravy K.; Scott, Frank I.; Mamtani, Ronac; Li, Hongzhe; Moore, Jason H.; Lewis, James D.",,,,"Moore, Jason H./AAV-9645-2021; Scott, Frank I/Q-3875-2019","Moore, Jason H./0000-0002-5015-1099; Scott, Frank I/0000-0002-6021-0419",,,Medication class enrichment analysis: a novel algorithm to analyze multiple pharmacologic exposures simultaneously using electronic health record data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,7,,,780,789,,10.1093/jamia/ocx162,,,,JUL 2018,2018,"Objective: Observational studies analyzing multiple exposures simultaneously have been limited by difficulty distinguishing relevant results from chance associations due to poor specificity. Set-based methods have been successfully used in genomics to improve signal-to-noise ratio. We present and demonstrate medication class enrichment analysis (MCEA), a signal-to-noise enhancement algorithm for observational data inspired by set-based methods.Materials and Methods: We used The Health Improvement Network database to study medications associated with Clostridium difficile infection (CDI). We performed case-control studies for each medication in The Health Improvement Network to obtain odds ratios (ORs) for association with CDI. We then calculated the association of each pharmacologic class with CDI using logistic regression and MCEA. We also performed simulation studies in which we assessed the sensitivity and specificity of logistic regression compared to MCEA for ORs 0.1-2.0.Results: When analyzing pharmacologic classes using logistic regression, 47 of 110 pharmacologic classes were identified as associated with CDI. When analyzing pharmacologic classes using MCEA, only fluoroquinolones, a class of antibiotics with biologically confirmed causation, and heparin products were associated with CDI. In simulation, MCEA had superior specificity compared to logistic regression across all tested effect sizes and equal or better sensitivity for all effect sizes besides those close to null.Discussion: Although these results demonstrate the promise of MCEA, additional studies that include inpatient administered medications are necessary for validation of the algorithm.Conclusions: In clinical and simulation studies, MCEA demonstrated superior sensitivity and specificity for identifying pharmacologic classes associated with CDI compared to logistic regression.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000440954800003,29378062,
J,"Dai, Hong-Jie; Su, Chu-Hsien; Wu, Chi-Shin",,,,,,,,Adverse drug event and medication extraction in electronic health records via a cascading architecture with different sequence labeling models and word embeddings,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,47,55,,10.1093/jamia/ocz120,,,,JAN 2020,2020,"Objective: An adverse drug event (ADE) refers to an injury resulting from medical intervention related to a drug including harm caused by drugs or from the usage of drugs. Extracting ADEs from clinical records can help physicians associate adverse events to targeted drugs.Materials and Methods: We proposed a cascading architecture to recognize medical concepts including ADEs, drug names, and entities related to drugs. The architecture includes a preprocessing method and an ensemble of conditional random fields (CRFs) and neural network-based models to respectively address the challenges of surrogate string and overlapping annotation boundaries observed in the employed ADEs and medication extraction (ADME) corpus. The effectiveness of applying different pretrained and postprocessed word embeddings for the ADME task was also studied.Results: The empirical results showed that both CRFs and neural network-based models provide promising solution for the ADME task. The neural network-based models particularly outperformed CRFs in concept types involving narrative descriptions. Our best run achieved an overall micro F-score of 0.919 on the employed corpus. Our results also suggested that the Global Vectors for word representation embedding in general domain provides a very strong baseline, which can be further improved by applying the principal component analysis to generate more isotropic vectors.Conclusions: We have demonstrated that the proposed cascading architecture can handle the problem of overlapped annotations and further improve the overall recall and F-scores because the architecture enables the developed models to exploit more context information and forms an ensemble for creating a stronger recognizer.",,,,,,,,,10,0,0,0,1,0,10,,,1067-5027,1527-974X,,WOS:000548300200007,31334805,
J,"Cheung, Dora; Cumbler, Ethan; Hale, Gary; Pell, Jonathan",,,,,,,,Reining in the QTc: reducing the risk of Torsades de Pointes across a major health system,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,9,,,1202,1205,,10.1093/jamia/ocy081,,,,SEP 2018,2018,"Hospitalized patients have a high prevalence of prolonged QTc and are a high-risk population for Torsades de Pointes (TdP). One modifiable risk factor for TdP is the use of QT prolonging drugs. Electronically alerting providers who are ordering QT prolonging drugs in at-risk patients may help to achieve safer prescribing practices. Our previous study decreased inappropriate prescription of IV haloperidol by 36% using a targeted smart electronic alert. We wanted to assess an approach to expanding this type of electronic alert to commonly used QT prolonging medications and evaluate how this would affect prescribing practice. This retrospective cohort study evaluated the impact of these alerts for 12 frequently prescribed high-risk medications across a major health system. Between October 2016 and June 2017, a total of 6453 alerts fired and resulted in 3020 (46.8%) orders being cancelled by the provider. Our focused electronic alert significantly decreased prescribing of QT prolonging medications in high-risk patients.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000443542400013,29961858,
J,"Parr, Sharidan K.; Shotwell, Matthew S.; Jeffery, Alvin D.; Lasko, Thomas A.; Matheny, Michael E.",,,,"Matheny, Michael E/B-3541-2008; Jeffery, Alvin D/B-1551-2014","Matheny, Michael E/0000-0003-3217-4147; Parr, Sharidan/0000-0002-4596-3818",,,Automated mapping of laboratory tests to LOINC codes using noisy labels in a national electronic health record system database,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,10,,,1292,1300,,10.1093/jamia/ocy110,,,,OCT 2018,2018,"Objective: Standards such as the Logical Observation Identifiers Names and Codes (LOINC VR) are critical for interoperability and integrating data into common data models, but are inconsistently used. Without consistent mapping to standards, clinical data cannot be harmonized, shared, or interpreted in a meaningful context. We sought to develop an automated machine learning pipeline that leverages noisy labels to map laboratory data to LOINC codes.Materials and Methods: Across 130 sites in the Department of Veterans Affairs Corporate Data Warehouse, we selected the 150 most commonly used laboratory tests with numeric results per site from 2000 through 2016. Using source data text and numeric fields, we developed a machine learning model and manually validated random samples from both labeled and unlabeled datasets.Results: The raw laboratory data consisted of >6.5 billion test results, with 2215 distinct LOINC codes. The model predicted the correct LOINC code in 85% of the unlabeled data and 96% of the labeled data by test frequency. In the subset of labeled data where the original and model-predicted LOINC codes disagreed, the model-predicted LOINC code was correct in 83% of the data by test frequency.Conclusion: Using a completely automated process, we are able to assign LOINC codes to unlabeled data with high accuracy. When the model-predicted LOINC code differed from the original LOINC code, the model prediction was correct in the vast majority of cases. This scalable, automated algorithm may improve data quality and interoperability, while substantially reducing the manual effort currently needed to accurately map laboratory data.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000448166200004,30137378,
J,"Shang, Ning; Liu, Cong; Rasmussen, Luke, V; Ta, Casey N.; Caroll, Robert J.; Benoit, Barbara; Lingren, Todd; Dikilitas, Ozan; Mentch, Frank D.; Carrell, David S.; Wei, Wei-Qi; Luo, Yuan; Gainer, Vivian S.; Kullo, Iftikhar J.; Pacheco, Jennifer A.; Hakonarson, Hakon; Walunas, Theresa L.; Denny, Joshua C.; Wiley, Ken; Murphy, Shawn N.; Hripcsak, George; Weng, Chunhua",,,,"Denny, Josh/AAL-3359-2021; Luo, Yuan/K-5563-2016","Denny, Josh/0000-0002-3049-7332; Luo, Yuan/0000-0003-0195-7456; Lingren, Todd/0000-0003-0311-7100; Rasmussen, Luke/0000-0002-4497-8049; Walunas, Theresa/0000-0002-7653-3650; Shang, Ning/0000-0001-7040-5204",,,Making work visible for electronic phenotype implementation: Lessons learned from the eMERGE network,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103293,10.1016/j.jbi.2019.103293,,,,NOV 2019,2019,"Background: Implementation of phenotype algorithms requires phenotype engineers to interpret human-readable algorithms and translate the description (text and flowcharts) into computable phenotypes - a process that can be labor intensive and error prone. To address the critical need for reducing the implementation efforts, it is important to develop portable algorithms.Methods: We conducted a retrospective analysis of phenotype algorithms developed in the Electronic Medical Records and Genomics (eMERGE) network and identified common customization tasks required for implementation. A novel scoring system was developed to quantify portability from three aspects: Knowledge conversion, clause Interpretation, and Programming (KIP). Tasks were grouped into twenty representative categories. Experienced phenotype engineers were asked to estimate the average time spent on each category and evaluate time saving enabled by a common data model (CDM), specifically the Observational Medical Outcomes Partnership (OMOP) model, for each category.Results: A total of 485 distinct clauses (phenotype criteria) were identified from 55 phenotype algorithms, corresponding to 1153 customization tasks. In addition to 25 non-phenotype-specific tasks, 46 tasks are related to interpretation, 613 tasks are related to knowledge conversion, and 469 tasks are related to programming. A score between 0 and 2 (0 for easy, 1 for moderate, and 2 for difficult portability) is assigned for each aspect, yielding a total KIP score range of 0 to 6. The average clause-wise KIP score to reflect portability is 1.37 +/- 1.38. Specifically, the average knowledge (K) score is 0.64 +/- 0.66, interpretation (I) score is 0.33 +/- 0.55, and programming (P) score is 0.40 +/- 0.64. 5% of the categories can be completed within one hour (median). 70% of the categories take from days to months to complete. The OMOP model can assist with vocabulary mapping tasks.Conclusion: This study presents firsthand knowledge of the substantial implementation efforts in phenotyping and introduces a novel metric (KIP) to measure portability of phenotype algorithms for quantifying such efforts across the eMERGE Network. Phenotype developers are encouraged to analyze and optimize the portability in regards to knowledge, interpretation and programming. CDMs can be used to improve the portability for some 'knowledge-oriented' tasks.",,,,,,,,,11,0,0,0,4,0,11,,,1532-0464,1532-0480,,WOS:000525701400006,31542521,
J,"Gong, Jue; Simon, Gregory E.; Liu, Shan",,,,,,,,Machine learning discovery of longitudinal patterns of depression and suicidal ideation,,,,,,,,PLOS ONE,,,,14,9,,,,,e0222665,10.1371/journal.pone.0222665,,,,SEP 20 2019,2019,"Background and aimDepression is often accompanied by thoughts of self-harm, which are a strong predictor of subsequent suicide attempt and suicide death. Few empirical data are available regarding the temporal correlation between depression symptoms and suicidal ideation. We investigated the anecdotal concern that suicidal ideation may increase during a period of depression improvement.DataLongitudinal Patient Health Questionnaire (PHQ)-9 is a questionnaire of 9 multiple-choice questions to assess the frequency of depressive symptoms within the previous two weeks. We analyzed a chronic depression treatment population's electronic health record (EHR) data, containing 610 patients' longitudinal PHQ-9 scores (62% age 45 and older; 68% female) within 40 weeks.MethodsThe irregular and sparse EHR data were transformed into continuous trajectories using Gaussian process regression. We first estimated the correlations between the symptoms (total score of the first 8 questions; PHQ-8) and suicide ideation (9th question score; Item 9) using the cross-correlation function. We then used an artificial neural network (ANN) to discover subtypes of depression patterns from the fitted depression trajectories. In addition, we conducted a separate analysis using the unfitted raw PHQ scores to examine PHQ-8's and Item 9's pattern changes.ResultsResults showed that the majority of patients' PHQ-8 and Item 9 scores displayed strong temporal correlations. We found five patterns in the PHQ-8 and the Item 9 trajectories. We also found 8% - 13% of the patients have experienced an increase in suicidal ideation during the improvement of their PHQ-8. Using a trajectory-based method for subtype pattern detection in depression progression, we provided a better understanding of temporal correlations between depression symptoms over time.",,,,,,,,,4,0,0,0,2,0,4,,,1932-6203,,,WOS:000532297900023,31539408,
J,"Song, Xing; Waitman, Lemuel R.; Hu, Yong; Yu, Alan S. L.; Robins, David; Liu, Mei",,,,,,,,Robust clinical marker identification for diabetic kidney disease with ensemble feature selection,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,3,,,242,253,,10.1093/jamia/ocy165,,,,MAR 2019,2019,"Objective: Diabetic kidney disease (DKD) is one of the most frequent complications in diabetes associated with substantial morbidity and mortality. To accelerate DKD risk factor discovery, we present an ensemble feature selection approach to identify a robust set of discriminant factors using electronic medical records (EMRs).Material and Methods: We identified a retrospective cohort of 15 645 adult patients with type 2 diabetes, excluding those with pre-existing kidney disease, and utilized all available clinical data types in modeling. We compared 3 machine-learning-based embedded feature selection methods in conjunction with 6 feature ensemble techniques for selecting top-ranked features in terms of robustness to data perturbations and predictability for DKD onset.Results: The gradient boosting machine (GBM) with weighted mean rank feature ensemble technique achieved the best performance with an AUC of 0.82 [95%-CI, 0.81-0.83] on internal validation and 0.71 [95%-CI, 0.68-0.73] on external temporal validation. The ensemble model identified a set of 440 features from 84 872 unique clinical features that are both predicative of DKD onset and robust against data perturbations, including 191 labs, 51 visit details (mainly vital signs), 39 medications, 34 orders, 30 diagnoses, and 95 other clinical features.Discussion: Many of the top-ranked features have not been included in the state-of-art DKD prediction models, but their relationships with kidney function have been suggested in existing literature.Conclusion: Our ensemble feature selection framework provides an option for identifying a robust and parsimonious feature set unbiasedly from EMR data, which effectively aids in knowledge discovery for DKD risk factors.",,,,,,,,,21,0,0,0,6,0,21,,,1067-5027,1527-974X,,WOS:000461520800007,30602020,
J,"Seol, Hee Yun; Shrestha, Pragya; Muth, Joy Fladager; Wi, Chung-Il; Sohn, Sunghwan; Ryu, Euijung; Park, Miguel; Ihrke, Kathy; Moon, Sungrim; King, Katherine; Wheeler, Philip; Borah, Bijan; Moriarty, James; Rosedahl, Jordan; Liu, Hongfang; McWilliams, Deborah B.; Juhn, Young J.",,,,,,,,Artificial intelligence-assisted clinical decision support for childhood asthma management: A randomized clinical trial,,,,,,,,PLOS ONE,,,,16,8,,,,,e0255261,10.1371/journal.pone.0255261,,,,2021,2021,"Rationale Clinical decision support (CDS) tools leveraging electronic health records (EHRs) have been an approach for addressing challenges in asthma care but remain under-studied through clinical trials. Objectives To assess the effectiveness and efficiency of Asthma-Guidance and Prediction System (A-GPS), an Artificial Intelligence (AI)-assisted CDS tool, in optimizing asthma management through a randomized clinical trial (RCT). Methods This was a single-center pragmatic RCT with a stratified randomization design conducted for one year in the primary care pediatric practice of the Mayo Clinic, MN. Children (<18 years) diagnosed with asthma receiving care at the study site were enrolled along with their 42 primary care providers. Study subjects were stratified into three strata (based on asthma severity, asthma care status, and asthma diagnosis) and were blinded to the assigned groups. Measurements Intervention was a quarterly A-GPS report to clinicians including relevant clinical information for asthma management from EHRs and machine learning-based prediction for risk of asthma exacerbation (AE). Primary endpoint was the occurrence of AE within 1 year and secondary outcomes included time required for clinicians to review EHRs for asthma management. Main results Out of 555 participants invited to the study, 184 consented for the study and were randomized (90 in intervention and 94 in control group). Median age of 184 participants was 8.5 years. While the proportion of children with AE in both groups decreased from the baseline (P = 0.042), there was no difference in AE frequency between the two groups (12% for the intervention group vs. 15% for the control group, Odds Ratio: 0.82; 95%CI 0.374-1.96; P = 0.626) during the study period. For the secondary end points, A-GPS intervention, however, significantly reduced time for reviewing EHRs for asthma management of each participant (median: 3.5 min, IQR: 2-5), compared to usual care without A-GPS (median: 11.3 min, IQR: 6.3-15); p<0.001). Mean health care costs with 95%CI of children during the trial (compared to before the trial) in the intervention group were lower than those in the control group (-$1,036 [-$2177, $44] for the intervention group vs. +$80 [-$841, $1000] for the control group), though there was no significant difference (p = 0.12). Among those who experienced the first AE during the study period (n = 25), those in the intervention group had timelier follow up by the clinical care team compared to those in the control group but no significant difference was found (HR = 1.93; 95% CI: 0.82-1.45, P = 0.10). There was no difference in the proportion of duration when patients had well-controlled asthma during the study period between the intervention and the control groups. Conclusions While A-GPS-based intervention showed similar reduction in AE events to usual care, it might reduce clinicians' burden for EHRs review resulting in efficient asthma management. A larger RCT is needed for further studying the findings.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000680243400047,34339438,
J,"Duan, Rui; Boland, Mary Regina; Liu, Zixuan; Liu, Yue; Chang, Howard H.; Xu, Hua; Chu, Haitao; Schmid, Christopher H.; Forrest, Christopher B.; Holmes, John H.; Schuemie, Martijn J.; Berlin, Jesse A.; Moore, Jason H.; Chen, Yong",,,,"Schmid, Christopher H./J-2398-2014; Moore, Jason H./AAV-9645-2021","Schmid, Christopher H./0000-0002-0855-5313; Moore, Jason H./0000-0002-5015-1099; Boland, Mary Regina/0000-0001-8576-6408",,,Learning from electronic health records across multiple sites: A communication-efficient and privacy-preserving distributed algorithm,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,3,,,376,385,,10.1093/jamia/ocz199,,,,MAR 2020,2020,"Objectives: We propose a one-shot, privacy-preserving distributed algorithm to perform logistic regression (ODAL) across multiple clinical sites.Materials and Methods: ODAL effectively utilizes the information from the local site (where the patient-level data are accessible) and incorporates the first-order (ODAL1) and second-order (ODAL2) gradients of the likelihood function from other sites to construct an estimator without requiring iterative communication across sites or transferring patient-level data. We evaluated ODAL via extensive simulation studies and an application to a dataset from the University of Pennsylvania Health System. The estimation accuracy was evaluated by comparing it with the estimator based on the combined individual participant data or pooled data (ie, gold standard).Results: Our simulation studies revealed that the relative estimation bias of ODAL1 compared with the pooled estimates was < 3%, and the ratio of standard errors was <1.25 for all scenarios. ODAL2 achieved higher accuracy (with relative bias <0.1% and ratio of standard errors <1.05). In real data analysis, we investigated the associations of 100 medications with fetal loss during pregnancy. We found that ODAL1 provided estimates with relative bias <10% for 85% of medications, and ODAL2 has relative bias <10% for 99% of medications. For communication cost, ODAL1 requires transferring p numbers from each site to the local site and ODAL2 requires transferring (p x p + p) numbers from each site to the local site, where p is the number of parameters in the regression model.Conclusions: This study demonstrates that ODAL is privacy-preserving and communication-efficient with small bias and high statistical efficiency.",,,,,,,,,18,0,0,0,5,0,18,,,1067-5027,1527-974X,,WOS:000548302800005,31816040,
J,"Macieira, Tamara G. R.; Yao, Yingwei; Keenan, Gail M.",,,,,"Goncalves Rezende Macieira, Tamara/0000-0003-1100-3760",,,Use of machine learning to transform complex standardized nursing care plan data into meaningful research variables: a palliative care exemplar,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,12,,,2695,2701,,10.1093/jamia/ocab205,,SEP 2021,,DEC 2021,2021,"The aim of this article was to describe a novel methodology for transforming complex nursing care plan data into meaningful variables to assess the impact of nursing care. We extracted standardized care plan data for older adults from the electronic health records of 4 hospitals. We created a palliative care framework with 8 categories. A subset of the data was manually classified under the framework, which was then used to train random forest machine learning algorithms that performed automated classification. Two expert raters achieved a 78% agreement rate. Random forest classifiers trained using the expert consensus achieved accuracy (agreement with consensus) between 77% and 89%. The best classifier was utilized for the automated classification of the remaining data. Utilizing machine learning reduces the cost of transforming raw data into representative constructs that can be used in research and practice to understand the essence of nursing specialty care, such as palliative care.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000728261700017,34569603,
J,"Prenovost, Katherine M.; Fihn, Stephan D.; Maciejewski, Matthew L.; Nelson, Karin; Vijan, Sandeep; Rosland, Ann-Marie",,,,"Fihn, Stephan/ABA-1040-2020","Prenovost, Katherine/0000-0002-5837-3905",,,Using item response theory with health system data to identify latent groups of patients with multiple health conditions,,,,,,,,PLOS ONE,,,,13,11,,,,,e0206915,10.1371/journal.pone.0206915,,,,NOV 26 2018,2018,"A critical step toward tailoring effective interventions for heterogeneous and medically complex patients is to identify clinically meaningful subgroups on the basis of their comorbid conditions. We applied Item Response Theory (IRT), a potentially useful tool to identify clinically meaningful subgroups, to characterize phenotypes within a cohort of high-risk patients. This was a retrospective cohort study using 68,400 high-risk Veteran's Health Administration (VHA) patients. Thirty-one physical and mental health diagnosis indicators based on ICD-9 codes from patients' inpatient, outpatient VHA and VA-paid community care claims. Results revealed 6 distinct subgroups of high-risk patients were identified: substance use, complex mental health, complex diabetes, liver disease, cancer with cardiovascular disease, and cancer with mental health. Multinomial analyses showed that subgroups significantly differed on demographic and utilization variables which underscored the uniqueness of the groups. Using IRT models with clinical diagnoses from electronic health records permitted identification of diagnostic constellations among otherwise undifferentiated high-risk patients. Recognizing distinct patient profiles provides a framework from which insights into medical complexity of high-risk patients can be explored and effective interventions can be tailored.",,,,,,,,,7,0,0,0,1,0,7,,,1932-6203,,,WOS:000451325700014,30475823,
J,"Tang, Paul C.; Miller, Sarah; Stavropoulos, Harry; Kartoun, Uri; Zambrano, John; Ng, Kenney",,,,,,,,Precision population analytics: population management at the point-of-care,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,3,,,588,595,,10.1093/jamia/ocaa247,,,,MAR 2021,2021,"Objective: To present clinicians at the point-of-care with real-world data on the effectiveness of various treatment options in a precision cohort of patients closely matched to the index patient.Materials and Methods: We developed disease-specific, machine-learning, patient-similarity models for hypertension (HTN), type II diabetes mellitus (T2DM), and hyperlipidemia (HL) using data on approximately 2.5 million patients in a large medical group practice. For each identified decision point, an encounter during which the patient's condition was not controlled, we compared the actual outcome of the treatment decision administered to that of the best-achieved outcome for similar patients in similar clinical situations.Results: For the majority of decision points (66.8%, 59.0%, and 83.5% for HTN, T2DM, and HL, respectively), there were alternative treatment options administered to patients in the precision cohort that resulted in a significantly increased proportion of patients under control than the treatment option chosen for the index patient. The expected percentage of patients whose condition would have been controlled if the best-practice treatment option had been chosen would have been better than the actual percentage by: 36% (65.1% vs 48.0%, HTN), 68% (37.7% vs 22.5%, T2DM), and 138% (75.3% vs 31.7%, HL).Conclusion: Clinical guidelines are primarily based on the results of randomized controlled trials, which apply to a homogeneous subject population. Providing the effectiveness of various treatment options used in a precision cohort of patients similar to the index patient can provide complementary information to tailor guideline recommendations for individual patients and potentially improve outcomes.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000637314400018,33180897,
J,"Wei, Qiang; Franklin, Amy; Cohen, Trevor; Xu, Hua",,,,,,,,Clinical text annotation - what factors are associated with the cost of time?,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1552,1560,,,,,,2018,2018,"Building high-quality annotated clinical corpora is necessary for developing statistical Natural Language Processing (NLP) models to unlock information embedded in clinical text, but it is also time consuming and expensive. Consequently, it important to identify factors that may affect annotation time, such as syntactic complexity of the text- to-be-annotated and the vagaries of individual user behavior. However, limited work has been done to understand annotation of clinical text. In this study, we aimed to investigate how factors inherent to the text affect annotation time for a named entity recognition (NER) task. We recruited 9 users to annotate a clinical corpus and recorded annotation time for each sample. Then we defined a set of factors that we hypothesized might affect annotation time, and fitted them into a linear regression model to predict annotation time. The linear regression model achieved an R2 of 0.611, and revealed eight time-associated factors, including characteristics of sentences, individual users, and annotation order with implications for the practice of annotation, and the development of cost models for active learning research.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:30815201,30815201,
J,"Inaguma, Daijo; Kitagawa, Akimitsu; Yanagiya, Ryosuke; Koseki, Akira; Iwamori, Toshiya; Kudo, Michiharu; Yuzawa, Yukio",,,,,,,,Increasing tendency of urine protein is a risk factor for rapid eGFR decline in patients with CKD: A machine learning-based prediction model by using a big database,,,,,,,,PLOS ONE,,,,15,9,,,,,e0239262,10.1371/journal.pone.0239262,,,,SEP 17 2020,2020,"Artificial intelligence is increasingly being adopted in medical fields to predict various outcomes. In particular, chronic kidney disease (CKD) is problematic because it often progresses to end-stage kidney disease. However, the trajectories of kidney function depend on individual patients. In this study, we propose a machine learning-based model to predict the rapid decline in kidney function among CKD patients by using a big hospital database constructed from the information of 118,584 patients derived from the electronic medical records system. The database included the estimated glomerular filtration rate (eGFR) of each patient, recorded at least twice over a period of 90 days. The data of 19,894 patients (16.8%) were observed to satisfy the CKD criteria. We characterized the rapid decline of kidney function by a decline of 30% or more in the eGFR within a period of two years and classified the available patients into two groups-those exhibiting rapid eGFR decline and those exhibiting non-rapid eGFR decline. Following this, we constructed predictive models based on two machine learning algorithms. Longitudinal laboratory data including urine protein, blood pressure, and hemoglobin were used as covariates. We used longitudinal statistics with a baseline corresponding to 90-, 180-, and 360-day windows prior to the baseline point. The longitudinal statistics included the exponentially smoothed average (ESA), where the weight was defined to be 0.9*(t/b), where t denotes the number of days prior to the baseline point and b denotes the decay parameter. In this study, b was taken to be 7 (7-day ESA). We used logistic regression (LR) and random forest (RF) algorithms based on Python code with scikit-learn library () for model creation. The areas under the curve for LR and RF were 0.71 and 0.73, respectively. The 7-day ESA of urine protein ranked within the first two places in terms of importance according to both models. Further, other features related to urine protein were likely to rank higher than the rest. The LR and RF models revealed that the degree of urine protein, especially if it exhibited an increasing tendency, served as a prominent risk factor associated with rapid eGFR decline.",,,,,,,,,1,0,0,0,1,0,1,,,1932-6203,,,WOS:000573848800035,32941535,
J,"Hassanzadeh, Hamed; Nguyen, Anthony; Verspoor, Karin",,,,"Nguyen, Anthony/AFQ-7018-2022; Nguyen, Anthony/B-5913-2009; Verspoor, Karin/G-6034-2016; Hassanzadeh, Hamed/O-2719-2019","Nguyen, Anthony/0000-0002-6215-6954; Nguyen, Anthony/0000-0002-6215-6954; Verspoor, Karin/0000-0002-8661-1544; Hassanzadeh, Hamed/0000-0003-2315-1963",,,Quantifying semantic similarity of clinical evidence in the biomedical literature to facilitate related evidence synthesis,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103321,10.1016/j.jbi.2019.103321,,,,DEC 2019,2019,"Objective: Published clinical trials and high quality peer reviewed medical publications are considered as the main sources of evidence used for synthesizing systematic reviews or practicing Evidence Based Medicine (EBM). Finding all relevant published evidence for a particular medical case is a time and labour intensive task, given the breadth of the biomedical literature. Automatic quantification of conceptual relationships between key clinical evidence within and across publications, despite variations in the expression of clinically-relevant concepts, can help to facilitate synthesis of evidence. In this study, we aim to provide an approach towards expediting evidence synthesis by quantifying semantic similarity of key evidence as expressed in the form of individual sentences. Such semantic textual similarity can be applied as a key approach for supporting selection of related studies.Material and methods: We propose a generalisable approach for quantifying semantic similarity of clinical evidence in the biomedical literature, specifically considering the similarity of sentences corresponding to a given type of evidence, such as clinical interventions, population information, clinical findings, etc. We develop three sets of generic, ontology-based, and vector-space models of similarity measures that make use of a variety of lexical, conceptual, and contextual information to quantify the similarity of full sentences containing clinical evidence. To understand the impact of different similarity measures on the overall evidence semantic similarity quantification, we provide a comparative analysis of these measures when used as input to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing.Results: The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity.Conclusion: Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.",,,,,,,,,5,0,0,0,2,0,5,,,1532-0464,1532-0480,,WOS:000525702900016,31676460,
J,"Viani, Natalia; Miller, Timothy A.; Napolitano, Carlo; Priori, Silvia G.; Savova, Guergana K.; Bellazzi, Riccardo; Sacchi, Lucia",,,,"Napolitano, Carlo/K-4760-2016; Priori, Silvia G/ABH-6894-2020; SACCHI, LUCIA/AAC-5074-2022; napolitano, carlo/ABI-4608-2020; Bellazzi, Riccardo/J-6432-2018","Napolitano, Carlo/0000-0002-7643-4628; Priori, Silvia G/0000-0001-6877-0288; SACCHI, LUCIA/0000-0002-1390-9825; napolitano, carlo/0000-0002-7643-4628; Bellazzi, Riccardo/0000-0002-6974-9808; Miller, Timothy/0000-0003-4513-403X",,,Supervised methods to extract clinical events from cardiology reports in Italian,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,95,,,,,,103219,10.1016/j.jbi.2019.103219,,,,JUL 2019,2019,"Clinical narratives are a valuable source of information for both patient care and biomedical research. Given the unstructured nature of medical reports, specific automatic techniques are required to extract relevant entities from such texts. In the natural language processing (NLP) community, this task is often addressed by using supervised methods. To develop such methods, both reliably-annotated corpora and elaborately designed features are needed. Despite the recent advances on corpora collection and annotation, research on multiple domains and languages is still limited. In addition, to compute the features required for supervised classification, suitable language- and domain-specific tools are needed.In this work, we propose a novel application of recurrent neural networks (RNNs) for event extraction from medical reports written in Italian. To train and evaluate the proposed approach, we annotated a corpus of 75 cardiology reports for a total of 4365 mentions of relevant events and their attributes (e.g., the polarity). For the annotation task, we developed specific annotation guidelines, which are provided together with this paper.The RNN-based classifier was trained on a training set including 3335 events (60 documents). The resulting model was integrated into an NLP pipeline that uses a dictionary lookup approach to search for relevant concepts inside the text. A test set of 1030 events (15 documents) was used to evaluate and compare different pipeline configurations. As a main result, using the RNN-based classifier instead of the dictionary lookup approach allowed increasing recall from 52.4% to 88.9%, and precision from 81.1% to 88.2%. Further, using the two methods in combination, we obtained final recall, precision, and Fl score of 91.7%, 88.6%, and 90.1%, respectively. These experiments indicate that integrating a well-performing RNN-based classifier with a standard knowledge-based approach can be a good strategy to extract information from clinical text in non-English languages.",,,,,,,,,6,0,0,0,2,0,6,,,1532-0464,1532-0480,,WOS:000525695600017,31150777,
J,"Sarker, Abeed; DeRoos, Annika; Perrone, Jeanmarie",,,,"Sarker, Abeed/W-1044-2019","Sarker, Abeed/0000-0001-7358-544X",,,Mining social media for prescription medication abuse monitoring: a review and proposal for a data-centric framework,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,315,329,,10.1093/jamia/ocz162,,,,FEB 2020,2020,"Objective: Prescription medication (PM) misuse and abuse is a major health problem globally, and a number of recent studies have focused on exploring social media as a resource for monitoring nonmedical PM use. Our objectives are to present a methodological review of social media-based PM abuse or misuse monitoring studies, and to propose a potential generalizable, data-centric processing pipeline for the curation of data from this resource.Materials and Methods: We identified studies involving social media, PMs, and misuse or abuse (inclusion criteria) from Medline, Embase, Scopus, Web of Science, and Google Scholar. We categorized studies based on multiple characteristics including but not limited to data size; social media source(s); medications studied; and primary objectives, methods, and findings.Results: A total of 39 studies met our inclusion criteria, with 31 (similar to 79.5%) published since 2015. Twitter has been the most popular resource, with Reddit and Instagram gaining popularity recently. Early studies focused mostly on manual, qualitative analyses, with a growing trend toward the use of data-centric methods involving natural language processing and machine learning.Discussion: There is a paucity of standardized, data-centric frameworks for curating social media data for task-specific analyses and near real-time surveillance of nonmedical PM use. Many existing studies do not quantify human agreements for manual annotation tasks or take into account the presence of noise in data.Conclusion: The development of reproducible and standardized data-centric frameworks that build on the current state-of-the-art methods in data and text mining may enable effective utilization of social media data for understanding and monitoring nonmedical PM use.",,,,,,,,,8,0,0,0,4,0,9,,,1067-5027,1527-974X,,WOS:000515121300016,31584645,
J,"Ljubic, Branimir; Hai, Ameen Abdel; Stanojevic, Marija; Diaz, Wilson; Polimac, Daniel; Pavlovski, Martin; Obradovic, Zoran",,,,,"Abdel Hai, Ameen/0000-0001-5173-5291; Ljubic, Branimir/0000-0002-3287-3741; Obradovic, Zoran/0000-0002-2051-0142",,,Predicting complications of diabetes mellitus using advanced machine learning algorithms,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1343,1351,,10.1093/jamia/ocaa120,,,,SEP 2020,2020,"Objective: We sought to predict if patients with type 2 diabetes mellitus (DM2) would develop 10 selected complications. Accurate prediction of complications could help with more targeted measures that would prevent or slow down their development.Materials and Methods: Experiments were conducted on the Healthcare Cost and Utilization Project State Inpatient Databases of California for the period of 2003 to 2011. Recurrent neural network (RNN) long short-term memory (LSTM) and RNN gated recurrent unit (GRU) deep learning methods were designed and compared with random forest and multilayer perceptron traditional models. Prediction accuracy of selected complications were compared on 3 settings corresponding to minimum number of hospitalizations between diabetes diagnosis and the diagnosis of complications.Results: The diagnosis domain was used for experiments. The best results were achieved with RNN GRU model, followed by RNN LSTM model. The prediction accuracy achieved with RNN GRU model was between 73% (myocardial infarction) and 83% (chronic ischemic heart disease), while accuracy of traditional models was between 66% - 76%.Discussion: The number of hospitalizations was an important factor for the prediction accuracy. Experiments with 4 hospitalizations achieved significantly better accuracy than with 2 hospitalizations. To achieve improved accuracy deep learning models required training on at least 1000 patients and accuracy significantly dropped if training datasets contained 500 patients. The prediction accuracy of complications decreases over time period. Considering individual complications, the best accuracy was achieved on depressive disorder and chronic ischemic heart disease.Conclusions: The RNN GRU model was the best choice for electronic medical record type of data, based on the achieved results.",,,,,,,,,4,0,0,0,3,0,4,,,1067-5027,1527-974X,,WOS:000593113300002,32869093,
J,"Murphree, Dennis H.; Wilson, Patrick M.; Asai, Shusaku W.; Quest, Daniel J.; Lin, Yaxiong; Mukherjee, Piyush; Chhugani, Nirmal; Strand, Jacob J.; Demuth, Gabriel; Mead, David; Wright, Brian; Harrison, Andrew; Soleimani, Jalal; Herasevich, Vitaly; Pickering, Brian W.; Storlie, Curtis B.",,,,"Harrison, Andrew M./I-3708-2013","Harrison, Andrew M./0000-0003-0063-9421",,,Improving the delivery of palliative care through predictive modeling and healthcare informatics,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1065,1073,,10.1093/jamia/ocaa211,,FEB 2021,,JUN 2021,2021,"Objective: Access to palliative care (PC) is important for many patients with uncontrolled symptom burden from serious or complex illness. However, many patients who could benefit from PC do not receive it early enough or at all. We sought to address this problem by building a predictive model into a comprehensive clinical framework with the aims to (i) identify in-hospital patients likely to benefit from a PC consult, and (ii) intervene on such patients by contacting their care team.Materials and Methods: Electronic health record data for 68 349 inpatient encounters in 2017 at a large hospital were used to train a model to predict the need for PC consult. This model was published as a web service, connected to institutional data pipelines, and consumed by a downstream display application monitored by the PC team. For those patients that the PC team deems appropriate, a team member then contacts the patient's corresponding care team.Results: Training performance AUC based on a 20% holdout validation set was 0.90. The most influential variables were previous palliative care, hospital unit, Albumin, Troponin, and metastatic cancer. The model has been successfully integrated into the clinical workflow making real-time predictions on hundreds of patients per day. The model had an in-production AUC of 0.91. A clinical trial is currently underway to assess the effect on clinical outcomes.Conclusions: A machine learning model can effectively predict the need for an inpatient PC consult and has been successfully integrated into practice to refer new patients to PC.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000671031900002,33611523,
J,"Visweswaran, Shyam; Samayamuthu, Malarkodi J.; Morris, Michele; Weber, Griffin M.; MacFadden, Douglas; Trevvett, Philip; Klann, Jeffrey G.; Gainer, Vivian S.; Benoit, Barbara; Murphy, Shawn N.; Patel, Lav; Mirkovic, Nebojsa; Borovskiy, Yuliya; Johnson, Robert D.; Wyatt, Matthew C.; Wang, Amy Y.; Follett, Robert W.; Chau, Ngan; Zhu, Wenhong; Abajian, Mark; Chuang, Amy; Bahroos, Neil; Reeder, Phillip; Xie, Donglu; Cai, Jennifer; Sendro, Elaina R.; Toto, Robert D.; Firestein, Gary S.; Nadler, Lee M.; Reis, Steven E.",,,,"Samayamuthu, Malarkodi Jebathilagam/AAU-6232-2021","Samayamuthu, Malarkodi Jebathilagam/0000-0003-0061-8196; Patel, Lav/0000-0002-8626-137X",,,Development of a Coronavirus Disease 2019 (COVID-19) Application Ontology for the Accrual to Clinical Trials (ACT) network,,,,,,,,JAMIA OPEN,,,,4,2,,,,,ooab036,10.1093/jamiaopen/ooab036,,APR 2021,,APR 2021,2021,"Clinical data networks that leverage large volumes of data in electronic health records (EHRs) are significant resources for research on coronavirus disease 2019 (COVID-19). Data harmonization is a key challenge in seamless use of multisite EHRs for COVID-19 research. We developed a COVID-19 application ontology in the national Accrual to Clinical Trials (ACT) network that enables harmonization of data elements that are critical to COVID-19 research. The ontology contains over 50 000 concepts in the domains of diagnosis, procedures, medications, and laboratory tests. In particular, it has computational phenotypes to characterize the course of illness and outcomes, derived terms, and harmonized value sets for severe acute respiratory syndrome coronavirus 2 laboratory tests. The ontology was deployed and validated on the ACT COVID-19 network that consists of 9 academic health centers with data on 14.5M patients. This ontology, which is freely available to the entire research community on GitHub at https://github.com/shyamvis/ACT-COVID-Ontology, will be useful for harmonizing EHRs for COVID-19 research beyond the ACT network.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731861400015,34113801,
J,"Kreuger, Aukje L.; Middelburg, Rutger A.; Beckers, Erik A. M.; de Vooght, Karen M. K.; Zwaginga, Jaap Jan; Kerkhoffs, Jean-Louis H.; van der Bom, Johanna G.",,,,"Middelburg, Rutger/N-9134-2017","Middelburg, Rutger/0000-0002-6545-7277; Kreuger, Aukje/0000-0002-1658-9257",,,The identification of cases of major hemorrhage during hospitalization in patients with acute leukemia using routinely recorded healthcare data,,,,,,,,PLOS ONE,,,,13,8,,,,,e0200655,10.1371/journal.pone.0200655,,,,AUG 15 2018,2018,"IntroductionElectronic health care data offers the opportunity to study rare events, although detecting these events in large datasets remains difficult. We aimed to develop a model to identify leukemia patients with major hemorrhages within routinely recorded health records.MethodsThe model was developed using routinely recorded health records of a cohort of leukemia patients admitted to an academic hospital in the Netherlands between June 2011 and December 2015. Major hemorrhage was assessed by chart review. The model comprised CT-brain, hemoglobin drop, and transfusion need within 24 hours for which the best discriminating cut off values were taken. External validation was performed within a cohort of two other academic hospitals.ResultsThe derivation cohort consisted of 255 patients, 10,638 hospitalization days, of which chart review was performed for 353 days. The incidence of major hemorrhage was 0.22 per 100 days in hospital. The model consisted of CT-brain (yes/no), hemoglobin drop of >= 0.8 g/dl and transfusion of >= 6 units. The C-statistic was 0.988 (CI 0.981-0.995). In the external validation cohort of 436 patients (19,188 days), the incidence of major hemorrhage was 0.46 per 100 hospitalization days and the C-statistic was 0.975 (CI 0.970-0.980). Presence of at least one indicator had a sensitivity of 100% (CI 95.8-100) and a specificity of 90.7% (CI 90.2-91.1). The number of days to screen to find one case decreased from 217.4 to 23.6.InterpretationA model based on information on CT-brain, hemoglobin drop and need of transfusions can accurately identify cases of major hemorrhage within routinely recorded health records.",,,,,,,,,4,0,0,0,2,0,4,,,1932-6203,,,WOS:000441738000004,30110326,
J,"Zhu, Jie; Gallego, Blanca",,,,,"Zhu, Jie/0000-0002-1863-9262",,,Targeted estimation of heterogeneous treatment effect in observational survival analysis,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,107,,,,,,103474,10.1016/j.jbi.2020.103474,,,,JUL 2020,2020,"The aim of clinical effectiveness research using repositories of electronic health records is to identify what health interventions 'work best' in real-world settings. Since there are several reasons why the net benefit of intervention may differ across patients, current comparative effectiveness literature focuses on investigating heterogeneous treatment effect and predicting whether an individual might benefit from an intervention. The on majority of this literature has concentrated on the estimation of the effect of treatment on binary outcomes. However, many medical interventions are evaluated in terms of their effect on future events, which are subject to loss to follow-up. In this study, we describe a framework for the estimation of heterogeneous treatment effect in terms of differences in time-to-event (survival) probabilities. We divide the problem into three phases: (1) estimation of treatment effect conditioned on unique sets of the covariate vector; (2) identification of features important for heterogeneity using non-parametric variable importance methods; and (3) estimation of treatment effect on the reference classes defined by the previously selected features, using one-step Targeted Maximum Likelihood Estimation. We conducted a series of simulation studies and found that this method performs well when either sample size or event rate is high enough and the number of covariates contributing to the effect heterogeneity is moderate. An application of this method to a clinical case study was conducted by estimating the effect of oral anticoagulants on newly diagnosed non-valvular atrial fibrillation patients using data from the UK Clinical Practice Research Datalink.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000551649200022,32562899,
J,"Oetjens, Matthew T.; Luo, Jonathan Z.; Chang, Alexander; Leader, Joseph B.; Hartzel, Dustin N.; Moore, Bryn S.; Strande, Natasha T.; Kirchner, H. Lester; Ledbetter, David H.; Justice, Anne E.; Carey, David J.; Mirshahi, Tooraj",,,,,"Justice, Anne/0000-0002-8903-8712; Strande, Natasha/0000-0001-5148-9772",,,Electronic health record analysis identifies kidney disease as the leading risk factor for hospitalization in confirmed COVID-19 patients,,,,,,,,PLOS ONE,,,,15,11,,,,,e0242182,10.1371/journal.pone.0242182,,,,NOV 12 2020,2020,"BackgroundEmpirical data on conditions that increase risk of coronavirus disease 2019 (COVID-19) progression are needed to identify high risk individuals. We performed a comprehensive quantitative assessment of pre-existing clinical phenotypes associated with COVID-19-related hospitalization.MethodsPhenome-wide association study (PheWAS) of SARS-CoV-2-positive patients from an integrated health system (Geisinger) with system-level outpatient/inpatient COVID-19 testing capacity and retrospective electronic health record (EHR) data to assess pre-COVID-19 pandemic clinical phenotypes associated with hospital admission (hospitalization).ResultsOf 12,971 individuals tested for SARS-CoV-2 with sufficient pre-COVID-19 pandemic EHR data at Geisinger, 1604 were SARS-CoV-2 positive and 354 required hospitalization. We identified 21 clinical phenotypes in 5 disease categories meeting phenome-wide significance (P<1.60x10(-4)), including: six kidney phenotypes, e.g. end stage renal disease or stage 5 CKD (OR = 11.07, p = 1.96x10(-8)), six cardiovascular phenotypes, e.g. congestive heart failure (OR = 3.8, p = 3.24x10(-5)), five respiratory phenotypes, e.g. chronic airway obstruction (OR = 2.54, p = 3.71x10(-5)), and three metabolic phenotypes, e.g. type 2 diabetes (OR = 1.80, p = 7.51x10(-5)). Additional analyses defining CKD based on estimated glomerular filtration rate, confirmed high risk of hospitalization associated with pre-existing stage 4 CKD (OR 2.90, 95% CI: 1.47, 5.74), stage 5 CKD/dialysis (OR 8.83, 95% CI: 2.76, 28.27), and kidney transplant (OR 14.98, 95% CI: 2.77, 80.8) but not stage 3 CKD (OR 1.03, 95% CI: 0.71, 1.48).ConclusionsThis study provides quantitative estimates of the contribution of pre-existing clinical phenotypes to COVID-19 hospitalization and highlights kidney disorders as the strongest factors associated with hospitalization in an integrated US healthcare system.",,,,,,,,,13,0,0,0,4,0,13,,,1932-6203,,,WOS:000593948000016,33180868,
J,"Zhou, Sicheng; Wang, Nan; Wang, Liwei; Liu, Hongfang; Zhang, Rui",,,,,,,,CancerBERT: a cancer domain-specific language model for extracting breast cancer phenotypes from electronic health records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac040,,MAR 2022,,,2022,"Objective Accurate extraction of breast cancer patients' phenotypes is important for clinical decision support and clinical research. This study developed and evaluated cancer domain pretrained CancerBERT models for extracting breast cancer phenotypes from clinical texts. We also investigated the effect of customized cancer-related vocabulary on the performance of CancerBERT models. Materials and Methods A cancer-related corpus of breast cancer patients was extracted from the electronic health records of a local hospital. We annotated named entities in 200 pathology reports and 50 clinical notes for 8 cancer phenotypes for fine-tuning and evaluation. We kept pretraining the BlueBERT model on the cancer corpus with expanded vocabularies (using both term frequency-based and manually reviewed methods) to obtain CancerBERT models. The CancerBERT models were evaluated and compared with other baseline models on the cancer phenotype extraction task. Results All CancerBERT models outperformed all other models on the cancer phenotyping NER task. Both CancerBERT models with customized vocabularies outperformed the CancerBERT with the original BERT vocabulary. The CancerBERT model with manually reviewed customized vocabulary achieved the best performance with macro F1 scores equal to 0.876 (95% CI, 0.873-0.879) and 0.904 (95% CI, 0.902-0.906) for exact match and lenient match, respectively. Conclusions The CancerBERT models were developed to extract the cancer phenotypes in clinical notes and pathology reports. The results validated that using customized vocabulary may further improve the performances of domain specific BERT models in clinical NLP tasks. The CancerBERT models developed in the study would further help clinical decision support.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000773047600001,35333345,
J,"Mate, Sebastian; Buerkle, Thomas; Kapsner, Lorenz A.; Toddenroth, Dennis; Kampf, Marvin O.; Sedlmayr, Martin; Castellanos, Ixchel; Prokosch, Hans-Ulrich; Kraus, Stefan",,,,,"Burkle, Thomas/0000-0002-2936-5375; Mate, Sebastian/0000-0002-1389-3384; Kapsner, Lorenz A./0000-0003-1866-860X; Kampf, Marvin/0000-0002-9108-0469; Kraus, Stefan/0000-0001-8465-7103",,,A method for the graphical modeling of relative temporal constraints,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,100,,,,,,103314,10.1016/j.jbi.2019.103314,,,,DEC 2019,2019,"Searching for patient cohorts in electronic patient data often requires the definition of temporal constraints between the selection criteria. However, beyond a certain degree of temporal complexity, the non-graphical, form-based approaches implemented in current translational research platforms may be limited when modeling such constraints. In our opinion, there is a need for an easily accessible and implementable, fully graphical method for creating temporal queries. We aim to respond to this challenge with a new graphical notation. Based on Allen's time interval algebra, it allows for modeling temporal queries by arranging simple horizontal bars depicting symbolic time intervals. To make our approach applicable to complex temporal patterns, we apply two extensions: with duration intervals, we enable the inference about relative temporal distances between patient events, and with time interval modifiers, we support counting and excluding patient events, as well as constraining numeric values. We describe how to generate database queries from this notation. We provide a prototypical implementation, consisting of a temporal query modeling frontend and an experimental backend that connects to an i2b2 system. We evaluate our modeling approach on the MIMIC-III database to demonstrate that it can be used for modeling typical temporal phenotyping queries.",,,,,,,,,4,0,0,0,2,0,4,,,1532-0464,1532-0480,,WOS:000525702900002,31629921,
J,"Walker, Lorne W.; Nowalk, Andrew J.; Visweswaran, Shyam",,,,,"Walker, Lorne/0000-0002-2500-0504",,,Predicting outcomes in central venous catheter salvage in pediatric central line-associated bloodstream infection,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,4,,,862,867,,10.1093/jamia/ocaa328,,JAN 2021,,APR 2021,2021,"Objective: Central line-associated bloodstream infections (CLABSIs) are a common, costly, and hazardous healthcare-associated infection in children. In children in whom continued access is critical, salvage of infected central venous catheters (CVCs) with antimicrobial lock therapy is an alternative to removal and replacement of the CVC. However, the success of CVC salvage is uncertain, and when it fails the catheter has to be removed and replaced. We describe a machine learning approach to predict individual outcomes in CVC salvage that can aid the clinician in the decision to attempt salvage.Materials and Methods: Over a 14-year period, 969 pediatric CLABSIs were identified in electronic health records. We used 164 potential predictors to derive 4 types of machine learning models to predict 2 failed salvage outcomes, infection recurrence and CVC removal, at 10 time points between 7 days and 1 year from infection onset.Results: The area under the receiver-operating characteristic curve varied from 0.56 to 0.83, and key predictors varied over time. The infection recurrence model performed better than the CVC removal model did.Conclusions: Machine learning-based outcome prediction can inform clinical decision making for children. We developed and evaluated several models to predict clinically relevant outcomes in the context of CVC salvage in pediatric CLABSI and illustrate the variability of predictors over time.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000648977500023,33463685,
J,"Hung, Chen-Ying; Lin, Ching-Heng; Lan, Tsuo-Hung; Peng, Giia-Sheun; Lee, Chi-Chun",,,,"Peng, Giia-Sheun/AAE-4778-2022","Lan, Tsuo-Hung/0000-0002-2796-1026",,,Development of an intelligent decision support system for ischemic stroke risk assessment in a population-based electronic health record database,,,,,,,,PLOS ONE,,,,14,3,,,,,e0213007,10.1371/journal.pone.0213007,,,,MAR 13 2019,2019,"BackgroundIntelligent decision support systems (IDSS) have been applied to tasks of disease management. Deep neural networks (DNNs) are artificial intelligent techniques to achieve high modeling power. The application of DNNs to large-scale data for estimating stroke risk needs to be assessed and validated. This study aims to apply a DNN for deriving a stroke predictive model using a big electronic health record database.Methods and results The Taiwan National Health Insurance Research Database was used to conduct a retrospective population-based study. The database was divided into one development dataset for model training (similar to 70% of total patients for training and similar to 10% for parameter tuning) and two testing datasets (each similar to 10%). A total of 11,192,916 claim records from 840,487 patients were used. The primary outcome was defined as any ischemic stroke in inpatient records within 3 years after study enrollment. The DNN was evaluated using the area under the receiver operating characteristic curve (AUC or c-statistic). The development dataset included 672,214 patients (a total of 8,952,000 records) of whom 2,060 patients had stroke events. The mean age of the population was 35.5 +/- 20.2 years, with 48.5% men. The model achieved AUC values of 0.920 (95% confidence interval [CI], 0.908-0.932) in testing dataset 1 and 0.925 (95% CI, 0.914-0.937) in testing dataset 2. Under a high sensitivity operating point, the sensitivity and specificity were 92.5% and 79.8% for testing dataset 1; 91.8% and 79.9% for testing dataset 2. Under a high specificity operating point, the sensitivity and specificity were 80.3% and 87.5% for testing dataset 1; 83.7% and 87.5% for testing dataset 2. The DNN model maintained high predictability 5 years after being developed. The model achieved similar performance to other clinical risk assessment scores.ConclusionsUsing a DNN algorithm on this large electronic health record database is capable of obtaining a high performing model for assessment of ischemic stroke risk. Further research is needed to determine whether such a DNN-based IDSS could lead to an improvement in clinical practice.",,,,,,,,,7,0,0,0,0,0,7,,,1932-6203,,,WOS:000461048900054,30865675,
J,"Kim, Youngjun; Heider, Paul M; Meystre, Stephane M",,,,,,,,Comparative Study of Various Approaches for Ensemble-based De-identification of Electronic Health Record Narratives.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,648,657,,,,,,2020,2020,"De-identification of electric health record narratives is a fundamental task applying natural language processing to better protect patient information privacy. We explore different types of ensemble learning methods to improve clinical text de-identification. We present two ensemble-based approaches for combining multiple predictive models. The first method selects an optimal subset of de-identification models by greedy exclusion. This ensemble pruning allows one to save computational time or physical resources while achieving similar or better performance than the ensemble of all members. The second method uses a sequence of words to train a sequential model. For this sequence labelling-based stacked ensemble, we employ search-based structured prediction and bidirectional long short-term memory algorithms. We create ensembles consisting of de-identification models trained on two clinical text corpora. Experimental results show that our ensemble systems can effectively integrate predictions from individual models and offer better generalization across two different corpora.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936439,33936439,
J,"Glynn, Earl F.; Hoffman, Mark A.",,,,,,,,Heterogeneity introduced by EHR system implementation in a de-identified data resource from 100 non-affiliated organizations,,,,,,,,JAMIA OPEN,,,,2,4,,,554,561,,10.1093/jamiaopen/ooz035,,,,DEC 2019,2019,"Objectives: Electronic health record (EHR) data aggregated from multiple, non-affiliated, sources provide an important resource for biomedical research, including digital phenotyping. Unlike work with EHR data from a single organization, aggregate EHR data introduces a number of analysis challenges.Materials and Methods: We used the Cerner Health Facts data, a de-identified aggregate EHR data resource populated by data from 100 independent health systems, to investigate the impact of EHR implementation factors on the aggregate data. These included use of ancillary modules, data continuity, International Classification of Disease (ICD) version and prompts for clinical documentation.Results and Discussion: Health Facts includes six categories of data from ancillary modules. We found of the 664 facilities in Health Facts, 49 use all six categories while 88 facilities were not using any. We evaluated data contribution over time and found considerable variation at the health system and facility levels. We analyzed the transition from ICD-9 to ICD-10 and found that some organizations completed the shift in 2014 while others remained on ICD-9 in 2017, well after the 2015 deadline. We investigated the utilization of discharge disposition to document death and found inconsistent use of this field. We evaluated clinical events used to document travel status implemented in response to Ebola, height and smoking history. Smoking history documentation increased dramatically after Meaningful Use, but dropped in some organizations. These observations highlight the need for any research involving aggregate EHR data to consider implementation factors that contribute to variability in the data before attributing gaps to missing data.",,,,,,,,,14,0,0,0,1,0,14,,,,2574-2531,,WOS:000645419800024,32025653,
J,"Goldstein, Benjamin A.; Phelan, Matthew; Pagidipati, Neha J.; Holman, Rury R.; Pencina, Michael J.; Stuart, Elizabeth A.",,,,,"Stuart, Elizabeth/0000-0002-9042-8611",,,An outcome model approach to transporting a randomized controlled trial results to a target population,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,5,,,429,437,,10.1093/jamia/ocy188,,,,MAY 2019,2019,"Objective: Participants enrolled into randomized controlled trials (RCTs) often do not reflect real-world populations. Previous research in how best to transport RCT results to target populations has focused on weighting RCT data to look like the target data. Simulation work, however, has suggested that an outcome model approach may be preferable. Here, we describe such an approach using source data from the 2 x 2 factorial NAVIGATOR (Nateglinide And Valsartan in Impaired Glucose Tolerance Outcomes Research) trial, which evaluated the impact of valsartan and nateglinide on cardiovascular outcomes and new-onset diabetes in a prediabetic population.Materials and Methods: Our target data consisted of people with prediabetes serviced at the Duke University Health System. We used random survival forests to develop separate outcome models for each of the 4 treatments, estimating the 5-year risk difference for progression to diabetes, and estimated the treatment effect in our local patient populations, as well as subpopulations, and compared the results with the traditional weighting approach.Results: Our models suggested that the treatment effect for valsartan in our patient population was the same as in the trial, whereas for nateglinide treatment effect was stronger than observed in the original trial. Our effect estimates were more efficient than the weighting approach and we effectively estimated subgroup differences.Conclusions: The described method represents a straightforward approach to efficiently transporting an RCT result to any target population.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000465119800007,30869798,
J,"Carrell, David S.; Cronkite, David J.; Li, Muqun (Rachel); Nyemba, Steve; Malin, Bradley A.; Aberdeen, John S.; Hirschman, Lynette",,,,,"Carrell, David S./0000-0002-8471-0928; Aberdeen, John/0000-0002-0112-1037",,,The machine giveth and the machine taketh away: a parrot attack on clinical text deidentified with hiding in plain sight,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1536,1544,,10.1093/jamia/ocz114,,,,DEC 2019,2019,"Objective: Clinical corpora can be deidentified using a combination of machine-learned automated taggers and hiding in plain sight (HIPS) resynthesis. The latter replaces detected personally identifiable information (PII) with random surrogates, allowing leaked PII to blend in or hide in plain sight. We evaluated the extent to which a malicious attacker could expose leaked PII in such a corpus.Materials and Methods: We modeled a scenario where an institution (the defender) externally shared an 800-note corpus of actual outpatient clinical encounter notes from a large, integrated health care delivery system in Washington State. These notes were deidentified by a machine-learned PII tagger and HIPS resynthesis. A malicious attacker obtained and performed a parrot attack intending to expose leaked PII in this corpus. Specifically, the attacker mimicked the defender's process by manually annotating all PII-like content in half of the released corpus, training a PII tagger on these data, and using the trained model to tag the remaining encounter notes. The attacker hypothesized that untagged identifiers would be leaked PII, discoverable by manual review. We evaluated the attacker's success using measures of leak-detection rate and accuracy.Results: The attacker correctly hypothesized that 211 (68%) of 310 actual PII leaks in the corpus were leaks, and wrongly hypothesized that 191 resynthesized PII instances were also leaks. One-third of actual leaks remained undetected.Discussion and Conclusion: A malicious parrot attack to reveal leaked PII in clinical text deidentified by machine-learned HIPS resynthesis can attenuate but not eliminate the protective effect of HIPS deidentification.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000515125300013,31390016,
J,"McCoy, Thomas H., Jr.; Pellegrini, Amelia M.; Perlis, Roy H.",,,,,"McCoy, Thomas/0000-0002-5624-0439",,,Differences among Research Domain Criteria score trajectories by Diagnostic and Statistical Manual categorical diagnosis during inpatient hospitalization,,,,,,,,PLOS ONE,,,,15,8,,,,,e0237698,10.1371/journal.pone.0237698,,,,AUG 25 2020,2020,"With brief psychiatric hospitalizations, the extent to which symptoms change is rarely characterized. We sought to understand symptomatic changes across Research Domain Criteria (RDoC) dimensions, and the extent to which such improvement might be associated with risk for readmission. We identified 3,634 individuals with 4,713 hospital admissions to the psychiatric inpatient unit of a large academic medical center between 2010 and 2015. We applied a natural language processing tool to extract estimates of the five RDoC domains to the admission note and discharge summary and calculated the change in each domain. We examined the extent to which symptom domains changed during admission, and their relationship to baseline clinical and sociodemographic features, using linear regression. Symptomatic worsening was rare in the negative valence (0.4%) and positive valence (5.1%) domains, but more common in cognition (25.8%). Most diagnoses exhibited improvement in negative valence, which was associated with significant reduction in readmission risk. Despite generally brief hospital stays, we detected reduction across multiple symptom domains, with greatest improvement in negative symptoms, and greatest probability of worsening in cognitive symptoms. This approach should facilitate investigations of other features or interventions which may influence pace of clinical improvement.",,,,,,,,,4,0,0,0,2,0,4,,,1932-6203,,,WOS:000565553400052,32842139,
J,"Callahan, Alison; Polony, Vladimir; Posada, Jose D.; Banda, Juan M.; Gombar, Saurabh; Shah, Nigam H.",,,,"Posada, Jose/AAB-5284-2022","Posada, Jose/0000-0003-3864-0241; Banda, Juan/0000-0001-8499-824X",,,ACE: the Advanced Cohort Engine for searching longitudinal patient records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,7,,,1468,1479,,10.1093/jamia/ocab027,,MAR 2021,,JUL 2021,2021,"Objective: To propose a paradigm for a scalable time-aware clinical data search, and to describe the design, implementation and use of a search engine realizing this paradigm.Materials and Methods: The Advanced Cohort Engine (ACE) uses a temporal query language and in-memory datastore of patient objects to provide a fast, scalable, and expressive time-aware search. ACE accepts data in the Observational Medicine Outcomes Partnership Common Data Model, and is configurable to balance performance with compute cost. ACE's temporal query language supports automatic query expansion using clinical knowledge graphs. The ACE API can be used with R, Python, Java, HTTP, and a Web UI.Results: ACE offers an expressive query language for complex temporal search across many clinical data types with multiple output options. ACE enables electronic phenotyping and cohort-building with subsecond response times in searching the data of millions of patients for a variety of use cases.Discussion: ACE enables fast, time-aware search using a patient object-centric datastore, thereby overcoming many technical and design shortcomings of relational algebra-based querying. Integrating electronic phenotype development with cohort-building enables a variety of high-value uses for a learning health system. Tradeoffs include the need to learn a new query language and the technical setup burden.Conclusion: ACE is a tool that combines a unique query language for time-aware search of longitudinal patient records with a patient object datastore for rapid electronic phenotyping, cohort extraction, and exploratory data analyses.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000685209200013,33712854,
J,"Li, Ruowang; Duan, Rui; Kember, Rachel L.; Rader, Daniel J.; Damrauer, Scott M.; Moore, Jason H.; Chen, Yong",,Regeneron Genetics Ctr,,"Moore, Jason H./AAV-9645-2021","Moore, Jason H./0000-0002-5015-1099; Li, Ruowang/0000-0002-7910-4253",,,A regression framework to uncover pleiotropy in large-scale electronic health record data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,10,,,1083,1090,,10.1093/jamia/ocz084,,,,OCT 2019,2019,"Objective: Pleiotropy, where 1 genetic locus affects multiple phenotypes, can offer significant insights in understanding the complex genotype-phenotype relationship. Although individual genotype-phenotype associations have been thoroughly explored, seemingly unrelated phenotypes can be connected genetically through common pleiotropic loci or genes. However, current analyses of pleiotropy have been challenged by both methodologic limitations and a lack of available suitable data sources.Materials and Methods: In this study, we propose to utilize a new regression framework, reduced rank regression, to simultaneously analyze multiple phenotypes and genotypes to detect pleiotropic effects. We used a large-scale biobank linked electronic health record data from the Penn Medicine BioBank to select 5 cardiovascular diseases (hypertension, cardiac dysrhythmias, ischemic heart disease, congestive heart failure, and heart valve disorders) and 5 mental disorders (mood disorders; anxiety, phobic and dissociative disorders; alcohol-related disorders; neurological disorders; and delirium dementia) to validate our framework.Results: Compared with existing methods, reduced rank regression showed a higher power to distinguish known associated single-nucleotide polymorphisms from random single-nucleotide polymorphisms. In addition, genome-wide gene-based investigation of pleiotropy showed that reduced rank regression was able to identify candidate genetic variants with novel pleiotropic effects compared to existing methods.Conclusion: The proposed regression framework offers a new approach to account for the phenotype and genotype correlations when identifying pleiotropic effects. By jointly modeling multiple phenotypes and genotypes together, the method has the potential to distinguish confounding from causal genotype and phenotype associations.",,,,,,,,,3,0,0,0,1,0,3,,,1067-5027,1527-974X,,WOS:000515123700023,31529123,
J,"Xie, Fagen; Chen, Qiaoling; Zhou, Yichen; Chen, Wansu; Bautista, Jemianne; Nguyen, Emilie T.; Parker, Rex A.; Wu, Bechien U.",,,,,,,,Characterization of patients with advanced chronic pancreatitis using natural language processing of radiology reports,,,,,,,,PLOS ONE,,,,15,8,,,,,e0236817,10.1371/journal.pone.0236817,,,,AUG 19 2020,2020,"Study aim To develop and apply a natural language processing algorithm for characterization of patients diagnosed with chronic pancreatitis in a diverse integrated U.S. healthcare system. Methods Retrospective cohort study including patients initially diagnosed with chronic pancreatitis (CP) within a regional integrated healthcare system between January 1, 2006 and December 31, 2015. Imaging reports from these patients were extracted from the electronic medical record system and split into training, validation and implementation datasets. A natural language processing (NLP) algorithm was first developed through the training dataset to identify specific features (atrophy, calcification, pseudocyst, cyst and main duct dilatation) from free-text radiology reports. The validation dataset was applied to validate the performance by comparing against the manual chart review. The developed algorithm was then applied to the implementation dataset. We classified patients with calcification(s) or >= 2 radiographic features as advanced CP. We compared etiology, comorbid conditions, treatment parameters as well as survival between advanced CP and others diagnosed during the study period. Results 6,346 patients were diagnosed with CP during the study period with 58,085 radiology studies performed. For individual features, NLP yielded sensitivity from 88.7% to 95.3%, specificity from 98.2% to 100.0%. A total of 3,672 patients met cohort inclusion criteria: 1,330 (36.2%) had evidence of advanced CP. Patients with advanced CP had increased frequency of smoking (57.8% vs. 43.0%), diabetes (47.6% vs. 35.9%) and underweight body mass index (6.6% vs. 3.6%), all p<0.001. Mortality from pancreatic cancer was higher in advanced CP (15.3/1,000 person-year vs. 2.8/1,000, p<0.001). Underweight BMI (HR 1.6, 95% CL 1.2, 2.1), smoking (HR 1.4, 95% CL 1.1, 1.7) and diabetes (HR 1.4, 95% CL 1.2, 1.6) were independent risk factors for mortality. Conclusion Patients with advanced CP experienced increased disease-related complications and pancreatic cancer-related mortality. Excess all-cause mortality was driven primarily by potentially modifiable risk factors including malnutrition, smoking and diabetes.",,,,,,,,,1,0,0,0,1,0,1,,,1932-6203,,,WOS:000563929200006,32813684,
J,"Rethmeier, Nils; Serbetci, Necip Oguz; Moller, Sebastian; Roller, Roland",,,,,,,,EffiCare: Better Prognostic Models via Resource-Efficient Health Embeddings.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1060,1069,,,,,,2020,2020,"Recent medical prognostic models adapted from high data-resource fields like language processing have quickly grown in complexity and size. However, since medical data typically constitute low data-resource settings, performances on tasks like clinical prediction did not improve expectedly. Instead of following this trend of using complex neural models in combination with small, pre-selected feature sets, we propose EffiCare, which focuses on minimizing hospital resource requirements for assistive clinical prediction models. First, by embedding medical events, we eliminate manual domain feature-engineering and increase the amount oflearning data. Second, we use small, but data-efficient models, that compute faster and are easier to interpret. We evaluate our approach on four clinical prediction tasks and achieve substantial performance improvements over highly resource-demanding state-of-the-art methods. Finally, to evaluate our model beyond score improvements, we apply explainability and interpretability methods to analyze the decisions of our model and whether it uses data sources and parameters efficiently.1.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936482,33936482,
J,"Zhang, Hansi; He, Zhe; He, Xing; Guo, Yi; Nelson, David R; Modave, Francois; Wu, Yonghui; Hogan, William; Prosperi, Mattia; Bian, Jiang",,,,"; He, Zhe/J-2336-2014","He, Xing/0000-0003-0290-8058; He, Zhe/0000-0003-3608-0244; Wu, Yonghui/0000-0002-6780-6135",,,Computable Eligibility Criteria through Ontology-driven Data Access: A Case Study of Hepatitis C Virus Trials.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1601,1610,,,,,,2018,2018,"The increasing adoption of electronic health record (EHR) systems and proliferation of clinical data offer unprecedented opportunities for cohort identification to accelerate patient recruitment. However, the effort required to translate trial eligibility criteria to the correct cohort identification queries for clinical investigators is substantial, at least in part due to the lack of clear definitions in both the free-text eligibility criteria and the data models used to structure the available data elements in target patient databases. We propose to adopt an ontology-driven data access approach that generates formal representations of the connections between the entities in eligibility criteria and the available data elements to (1) narrow the semantic gap between researchers' cohort identification needs and the underlying database nuances, and (2) render the eligibility criteria computable. We implemented our approach based on an analysis of the eligibility criteria from 77 Hepatitis C trials. We found that 4 major types of data manipulation queries and 4 temporal patterns covered all eligibility criteria that were computable. We built a prototype system that helps researchers write computable eligibility criteria and execute them against clinical data in real-time to find potential trial cohorts.",,,,,,,,,7,0,0,0,1,0,7,,,,1942-597X,,MEDLINE:30815206,30815206,
J,"Watson, Joshua; Hutyra, Carolyn A.; Clancy, Shayna M.; Chandiramani, Anisha; Bedoya, Armando; Ilangovan, Kumar; Nderitu, Nancy; Poon, Eric G.",,,,,"Bedoya, Armando/0000-0001-6496-7024; Poon, Eric/0000-0002-7251-5842",,,Overcoming barriers to the adoption and implementation of predictive modeling and machine learning in clinical care: what can we learn from US academic medical centers?,,,,,,,,JAMIA OPEN,,,,3,2,,,167,172,,10.1093/jamiaopen/ooz046,,,,JUL 2020,2020,"There is little known about how academic medical centers (AMCs) in the US develop, implement, and maintain predictive modeling and machine learning (PM and ML) models. We conducted semi-structured interviews with leaders from AMCs to assess their use of PM and ML in clinical care, understand associated challenges, and determine recommended best practices. Each transcribed interview was iteratively coded and reconciled by a minimum of 2 investigators to identify key barriers to and facilitators of PM and ML adoption and implementation in clinical care. Interviews were conducted with 33 individuals from 19 AMCs nationally. AMCs varied greatly in the use of PM and ML within clinical care, from some just beginning to explore their utility to others with multiple models integrated into clinical care. Informants identified 5 key barriers to the adoption and implementation of PM and ML in clinical care: (1) culture and personnel, (2) clinical utility of the PM and ML tool, (3) financing, (4) technology, and (5) data. Recommendation to the informatics community to overcome these barriers included: (1) development of robust evaluation methodologies, (2) partnership with vendors, and (3) development and dissemination of best practices. For institutions developing clinical PM and ML applications, they are advised to: (1) develop appropriate governance, (2) strengthen data access, integrity, and provenance, and (3) adhere to the 5 rights of clinical decision support. This article highlights key challenges of implementing PM and ML in clinical care at AMCs and suggests best practices for development, implementation, and maintenance at these institutions.",,,,,,,,,7,0,0,0,0,0,7,,,,2574-2531,,WOS:000645439900007,32734155,
J,"Hobensack, Mollie; Ojo, Marietta; Barron, Yolanda; Bowles, Kathryn H.; Cato, Kenrick; Chae, Sena; Kennedy, Erin; McDonald, Margaret, V; Rossetti, Sarah Collins; Song, Jiyoun; Sridharan, Sridevi; Topaz, Maxim",,,,,"Song, Jiyoun/0000-0003-0362-0670",,,Documentation of hospitalization risk factors in electronic health records (EHRs): a qualitative study with home healthcare clinicians,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac023,,FEB 2022,,,2022,"Objective To identify the risk factors home healthcare (HHC) clinicians associate with patient deterioration and understand how clinicians respond to and document these risk factors. Methods We interviewed multidisciplinary HHC clinicians from January to March of 2021. Risk factors were mapped to standardized terminologies (eg, Omaha System). We used directed content analysis to identify risk factors for deterioration. We used inductive thematic analysis to understand HHC clinicians' response to risk factors and documentation of risk factors. Results Fifteen HHC clinicians identified a total of 79 risk factors that were mapped to standardized terminologies. HHC clinicians most frequently responded to risk factors by communicating with the prescribing provider (86.7% of clinicians) or following up with patients and caregivers (86.7%). HHC clinicians stated that a majority of risk factors can be found in clinical notes (ie, care coordination (53.3%) or visit (46.7%)). Discussion Clinicians acknowledged that social factors play a role in deterioration risk; but these factors are infrequently studied in HHC. While a majority of risk factors were represented in the Omaha System, additional terminologies are needed to comprehensively capture risk. Since most risk factors are documented in clinical notes, methods such as natural language processing are needed to extract them. Conclusion This study engaged clinicians to understand risk for deterioration during HHC. The results of our study support the development of an early warning system by providing a comprehensive list of risk factors grounded in clinician expertize and mapped to standardized terminologies.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000759756700001,35196369,
J,"Rodriguez, Victor A; Tony, Sun; Thangaraj, Phyllis; Pang, Chao; Kalluri, Krishna S; Jiang, Xinzhuo; Ostropolets, Anna; RuiJun, Chen; Karthik, Natarajan; Ryan, Patrick",,,,,"Ostropolets, Anna/0000-0002-0847-6682",,,Phenotype Concept Set Construction from Concept Pair Likelihoods.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1080,1089,,,,,,2020,2020,"Phenotyping algorithms are essential tools for conducting clinical research on observational data. Manually devel- oped phenotyping algorithms, such as those curated within the eMERGE (electronic Medical Records and Genomics) Network, represent the gold standard but are time consuming to create. In this work, we propose a framework for learning from the structure of eMERGE phenotype concept sets to assist construction of novel phenotype definitions. We use eMERGE phenotypes as a source of reference concept sets and engineer rich features characterizing the con- cept pairs within each set. We treat these pairwise relationships as edges in a concept graph, train models to perform edge prediction, and identify candidate phenotype concept sets as highly connected subgraphs. Candidate concept sets may then be interrogated and composed to construct novel phenotype definitions.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936484,33936484,
J,"Johnson, Alistair E. W.; Stone, David J.; Celi, Leo A.; Pollard, Tom J.",,,,,"Pollard, Tom/0000-0002-5676-7898",,,The MIMIC Code Repository: enabling reproducibility in critical care research,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,1,,,32,39,,10.1093/jamia/ocx084,,,,JAN 2018,2018,"Lack of reproducibility in medical studies is a barrier to the generation of a robust knowledge base to support clinical decision-making. In this paper we outline the Medical Information Mart for Intensive Care (MIMIC) Code Repository, a centralized code base for generating reproducible studies on an openly available critical care dataset.Code is provided to load the data into a relational structure, create extractions of the data, and reproduce entire analysis plans including research studies.Concepts extracted include severity of illness scores, comorbid status, administrative definitions of sepsis, physiologic criteria for sepsis, organ failure scores, treatment administration, and more. Executable documents are used for tutorials and reproduce published studies end-to-end, providing a template for future researchers to replicate. The repository's issue tracker enables community discussion about the data and concepts, allowing users to collaboratively improve the resource.The centralized repository provides a platform for users of the data to interact directly with the data generators, facilitating greater understanding of the data. It also provides a location for the community to collaborate on necessary concepts for research progress and share them with a larger audience. Consistent application of the same code for underlying concepts is a key step in ensuring that research studies on the MIMIC database are comparable and reproducible.By providing open source code alongside the freely accessible MIMIC-III database, we enable end-to-end reproducible analysis of electronic health records.",,,,,,,,,96,5,0,0,35,0,100,,,1067-5027,1527-974X,,WOS:000419605800007,29036464,
J,"Wang, Feng; Wang, Yu; Tian, Yu; Zhang, Ping; Chen, Jianghua; Li, Jingsong",,,,,"Wang, Feng/0000-0001-9499-8606",,,Pattern recognition and prognostic analysis of longitudinal blood pressure records in hemodialysis treatment based on a convolutional neural network,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,98,,,,,,103271,10.1016/j.jbi.2019.103271,,,,OCT 2019,2019,"Objective: The aim of this study is to analyze and visualize blood pressure (BP) patterns during continuous hemodialysis (HD) sessions, referred to as multiple-session patterns (MSPs), and explore whether deep learning models with MSPs have better performance.Material and methods: Data from 3.79 million hemodialysis BP records collected from July 30, 2007, to August 25, 2016, were obtained from the health system's electronic health records. We analyzed BP patterns during 36 continuous HD sessions (approximately 3 months) and selected 1311 (survival: 1246; death: 65) end-stage renal disease patients to classify 1-year outcomes (survival or death). Convolution kernels of different sizes were used to construct convolutional neural networks to recognize MSPs and BP patterns during a single HD session, referred to as single-session patterns (SSPs). BP patterns corresponded to convolution kernels and were represented and visualized as the input patches that activate the feature maps most. We used global average pooling (GAP) to measure the overall response of the inputs to each convolution kernel (pattern). The weights of the fully connected layers after GAP can measure the correlations between the convolution kernels (patterns) and the classification results. We solved the problem of data imbalance with a two-phase training strategy.Results: The F1_score was 0.782 +/- 0.058 (95% CI) in the models with SSPs and was approximately 19.5% higher (0.977 +/- 0.014, 95% CI) in the models with MSPs.Conclusions: The results indicated that consistent with previous studies, patients with lower BPs and longer HD sessions have better prognoses. BP patterns during continuous HD sessions can represent patients' 1-year mortality risk better than BP patterns during a single HD session and therefore improve the performance of prediction models.",,,,,,,,,4,0,0,0,2,0,4,,,1532-0464,1532-0480,,WOS:000525699600012,31454648,
J,"Carmichael, Harris; Coquet, Jean; Sun, Ran; Sang, Shengtian; Groat, Danielle; Asch, Steven M.; Bledsoe, Joseph; Peltan, Ithan D.; Jacobs, Jason R.; Hernandez-Boussard, Tina",,,,"Peltan, Ithan/J-1853-2019; Coquet, Jean/AAI-5591-2020","Peltan, Ithan/0000-0003-1730-234X; Coquet, Jean/0000-0002-7008-6925; Hernandez-Boussard, Tina/0000-0001-6553-3455; Jacobs, Jason/0000-0002-3406-0410; Groat, Danielle/0000-0002-1180-4448; Sang, Shengtian/0000-0003-0851-9520",,,Learning from past respiratory failure patients to triage COVID-19 patient ventilator needs: A multi-institutional study,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,119,,,,,,103802,10.1016/j.jbi.2021.103802,,MAY 2021,,JUL 2021,2021,"Background: Unlike well-established diseases that base clinical care on randomized trials, past experiences, and training, prognosis in COVID19 relies on a weaker foundation. Knowledge from other respiratory failure diseases may inform clinical decisions in this novel disease. The objective was to predict 48-hour invasive mechanical ventilation (IMV) within 48 h in patients hospitalized with COVID-19 using COVID-like diseases (CLD). Methods: This retrospective multicenter study trained machine learning (ML) models on patients hospitalized with CLD to predict IMV within 48 h in COVID-19 patients. CLD patients were identified using diagnosis codes for bacterial pneumonia, viral pneumonia, influenza, unspecified pneumonia and acute respiratory distress syndrome (ARDS), 2008-2019. A total of 16 cohorts were constructed, including any combinations of the four diseases plus an exploratory ARDS cohort, to determine the most appropriate cohort to use. Candidate predictors included demographic and clinical parameters that were previously associated with poor COVID-19 outcomes. Model development included the implementation of logistic regression and three ensemble tree-based algorithms: decision tree, AdaBoost, and XGBoost. Models were validated in hospitalized COVID-19 patients at two healthcare systems, March 2020-July 2020. ML models were trained on CLD patients at Stanford Hospital Alliance (SHA). Models were validated on hospitalized COVID-19 patients at both SHA and Intermountain Healthcare. Results: CLD training data were obtained from SHA (n = 14,030), and validation data included 444 adult COVID19 hospitalized patients from SHA (n = 185) and Intermountain (n = 259). XGBoost was the top-performing ML model, and among the 16 CLD training cohorts, the best model achieved an area under curve (AUC) of 0.883 in the validation set. In COVID-19 patients, the prediction models exhibited moderate discrimination performance, with the best models achieving an AUC of 0.77 at SHA and 0.65 at Intermountain. The model trained on all pneumonia and influenza cohorts had the best overall performance (SHA: positive predictive value (PPV) 0.29, negative predictive value (NPV) 0.97, positive likelihood ratio (PLR) 10.7; Intermountain: PPV, 0.23, NPV 0.97, PLR 10.3). We identified important factors associated with IMV that are not traditionally considered for respiratory diseases. Conclusions: The performance of prediction models derived from CLD for 48-hour IMV in patients hospitalized with COVID-19 demonstrate high specificity and can be used as a triage tool at point of care. Novel predictors of IMV identified in COVID-19 are often overlooked in clinical practice. Lessons learned from our approach may assist other research institutes seeking to build artificial intelligence technologies for novel or rare diseases with limited data for training and validation.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000674512900015,33965640,
J,"Xu, Wanwan; Su, Chang; Li, Yan; Rogers, Steven; Wang, Fei; Chen, Kun; Aseltine, Robert",,,,,"Su, Chang/0000-0003-4019-6389",,,Improving suicide risk prediction via targeted data fusion: proof of concept using medical claims data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,3,,,500,511,,10.1093/jamia/ocab209,,,,JAN 29 2022,2022,"Objective Reducing suicidal behavior among patients in the healthcare system requires accurate and explainable predictive models of suicide risk across diverse healthcare settings. Materials and Methods We proposed a general targeted fusion learning framework that can be used to build a tailored risk prediction model for any specific healthcare setting, drawing on information fusion from a separate more comprehensive dataset with indirect sample linkage through patient similarities. As a proof of concept, we predicted suicide-related hospitalizations for pediatric patients in a limited statewide Hospital Inpatient Discharge Dataset (HIDD) fused with a more comprehensive medical All-Payer Claims Database (APCD) from Connecticut. Results We built a suicide risk prediction model for the source data (APCD) and calculated patient risk scores. Patient similarity scores between patients in the source and target (HIDD) datasets using their demographic characteristics and diagnosis codes were assessed. A fused risk score was generated for each patient in the target dataset using our proposed targeted fusion framework. With this model, the averaged sensitivities at 90% and 95% specificity improved by 67% and 171%, and the positive predictive values for the combined fusion model improved 64% and 135% compared to the conventional model. Discussion and Conclusions We proposed a general targeted fusion learning framework that can be used to build a tailored predictive model for any specific healthcare setting. Results from this study suggest we can improve the performance of predictive models in specific target settings without complete integration of the raw records from external data sources.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000761451900011,34850890,
J,"Denaxas, Spiros; Liu, Ge; Feng, Qiping; Fatemifar, Ghazaleh; Bastarache, Lisa; Kerchberger, Eric V; Hingorani, Aroon D; Lumbers, Tom; Peterson, Josh F; Wei, Wei-Qi; Hemingway, Harry",,,,"Hemingway, Harry/C-1219-2009","Hemingway, Harry/0000-0003-2279-0624",,,Mapping the Read2/CTV3 controlled clinical terminologies to Phecodes in UK Biobank primary care electronic health records: implementation and evaluation.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,362,371,,,,,,2021,2021,"Objective: To establish and validate mappings between primary care clinical terminologies (Read Version 2, Clinical Terms Version 3) and Phecodes. Methods: We processed 123,662,421 primary care events from 230,096 UK Biobank (UKB) participants. We assessed the validity of the primary care-derived Phecodes by conducting PheWAS analyses for seven pre-selected SNPs in the UKB and compared with estimates from BioVU. Results: We mapped 92% of Read2 (n=10,834) and 91% of CTV3 (n=21,988) to 1,449 and 1,490 Phecodes. UKB PheWAS using Phecodes from primary care EHR and hospitalizations replicated all (n=22) previously-reported genotype-phenotype associations. When limiting Phecodes to primary care EHR, replication was 81% (n=18). Conclusion: We introduced a first version of mappings from Read2/CTV3 to Phecodes. The reference list of diseases provided by Phecodes can be extended, enabling researchers to leverage primary care EHR for high-throughput discovery research.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308936,35308936,
J,"Jauk, Stefanie; Kramer, Diether; Grossauer, Birgit; Rienmueller, Susanne; Avian, Alexander; Berghold, Andrea; Leodolter, Werner; Schulz, Stefan",,,,,"Jauk, Stefanie/0000-0003-1287-594X",,,Risk prediction of delirium in hospitalized patients using machine learning: An implementation and prospective evaluation study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,9,,,1383,1392,,10.1093/jamia/ocaa113,,,,SEP 2020,2020,"Objective: Machine learning models trained on electronic health records have achieved high prognostic accuracy in test datasets, but little is known about their embedding into clinical workflows. We implemented a random forest-based algorithm to identify hospitalized patients at high risk for delirium, and evaluated its performance in a clinical setting.Materials and Methods: Delirium was predicted at admission and recalculated on the evening of admission. The defined prediction outcome was a delirium coded for the recent hospital stay. During 7 months of prospective evaluation, 5530 predictions were analyzed. In addition, 119 predictions for internal medicine patients were compared with ratings of clinical experts in a blinded and nonblinded setting.Results: During clinical application, the algorithm achieved a sensitivity of 74.1% and a specificity of 82.2%. Discrimination on prospective data (area under the receiver-operating characteristic curve = 0.86) was as good as in the test dataset, but calibration was poor. The predictions correlated strongly with delirium risk perceived by experts in the blinded (r = 0.81) and nonblinded ( r = 0.62) settings. A major advantage of our setting was the timely prediction without additional data entry.Discussion: The implemented machine learning algorithm achieved a stable performance predicting delirium in high agreement with expert ratings, but improvement of calibration is needed. Future research should evaluate the acceptance of implemented machine learning algorithms by health professionals.Conclusions: Our study provides new insights into the implementation process of a machine learning algorithm into a clinical workflow and demonstrates its predictive power for delirium.",,,,,,,,,10,0,0,0,2,0,10,,,1067-5027,1527-974X,,WOS:000593113300007,32968811,
J,"Lee, Shin-Jye; Xu, Zhaozhao; Li, Tong; Yang, Yun",,,,,"Yang, Yun/0000-0002-9893-3436",,,A novel bagging C4.5 algorithm based on wrapper feature selection for supporting wise clinical decision making,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,78,,,,144,155,,10.1016/j.jbi.2017.11.005,,,,FEB 2018,2018,"From the perspective of clinical decision-making in a Medical IoT-based healthcare system, achieving effective and efficient analysis of long-term health data for supporting wise clinical decision-making is an extremely important objective, but determining how to effectively deal with the multi-dimensionality and high volume of generated data obtained from Medical IoT-based healthcare systems is an issue of increasing importance in IoT healthcare data exploration and management. A novel classifier or predicator equipped with a good feature selection function contributes effectively to classification and prediction performance. This paper proposes a novel bagging C4.5 algorithm based on wrapper feature selection, for the purpose of supporting wise clinical decision-making in the medical and healthcare fields. In particular, the new proposed sampling method, S-C4.5 SMOTE, is not only able to overcome the problem of data distortion, but also improves overall system performance because its mechanism aims at effectively reducing the data size without distortion, by keeping datasets balanced and technically smooth. This achievement directly supports the Wrapper method of effective feature selection without the need to consider the problem of huge amounts of data; this is a novel innovation in this work.",,,,,,,,,30,5,0,0,4,0,35,,,1532-0464,1532-0480,,WOS:000430035300013,29137965,
J,"Deng, Yi; Jiang, Xiaoqian; Long, Qi",,,,,,,,Privacy-Preserving Methods for Vertically Partitioned Incomplete Data.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,348,357,,,,,,2020,2020,"Distributed health data networks that use information from multiple sources have drawn substantial interest in recent years. However, missing data are prevalent in such networks and present significant analytical challenges. The current state-of-the-art methods for handling missing data require pooling data into a central repository before analysis, which may not be possible in a distributed health data network. In this paper, we propose a privacy- preserving distributed analysis framework for handling missing data when data are vertically partitioned. In this framework, each institution with a particular data source utilizes the local private data to calculate necessary intermediate aggregated statistics, which are then shared to build a global model for handling missing data. To evaluate our proposed methods, we conduct simulation studies that clearly demonstrate that the proposed privacy- preserving methods perform as well as the methods using the pooled data and outperform several naive methods. We further illustrate the proposed methods through the analysis of a real dataset. The proposed framework for handling vertically partitioned incomplete data is substantially more privacy-preserving than methods that require pooling of the data, since no individual-level data are shared, which can lower hurdles for collaboration across multiple institutions and build stronger public trust.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936407,33936407,
J,"Percha, Bethany; Zhang, Yuhao; Bozkurt, Selen; Rubin, Daniel; Altman, Russ B.; Langlotz, Curtis P.",,,,,"Altman, Russ/0000-0003-3859-2905",,,Expanding a radiology lexicon using contextual patterns in radiology reports,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,6,,,679,685,,10.1093/jamia/ocx152,,,,JUN 2018,2018,"Objective: Distributional semantics algorithms, which learn vector space representations of words and phrases from large corpora, identify related terms based on contextual usage patterns. We hypothesize that distributional semantics can speed up lexicon expansion in a clinical domain, radiology, by unearthing synonyms from the corpus.Materials and Methods: We apply word2vec, a distributional semantics software package, to the text of radiology notes to identify synonyms for RadLex, a structured lexicon of radiology terms. We stratify performance by term category, term frequency, number of tokens in the term, vector magnitude, and the context window used in vector building.Results: Ranking candidates based on distributional similarity to a target term results in high curation efficiency: on a ranked list of 775 249 terms, >50% of synonyms occurred within the first 25 terms. Synonyms are easier to find if the target term is a phrase rather than a single word, if it occurs at least 100x in the corpus, and if its vector magnitude is between 4 and 5. Some RadLex categories, such as anatomical substances, are easier to identify synonyms for than others.Discussion: The unstructured text of clinical notes contains a wealth of information about human diseases and treatment patterns. However, searching and retrieving information from clinical notes often suffer due to variations in how similar concepts are described in the text. Biomedical lexicons address this challenge, but are expensive to produce and maintain. Distributional semantics algorithms can assist lexicon curation, saving researchers time and money.",,,,,,,,,12,0,0,0,4,0,12,,,1067-5027,1527-974X,,WOS:000434113600009,29329435,
J,"Blaisure, Jonathan C; Ceusters, Werner M",,,,,,,,Enhancing the Representational Power of i2b2 through Referent Tracking.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,262,271,,,,,,2018,2018,"The Informatics for Integrating Biology and the Bedside (i2b2) software platform has proven successful in leveraging clinical enterprise data for the identification of cohorts of patients satisfying certain demographic, phenotypic and genetic criteria in support of further studies. An unanswered question thus far is whether i2b2 search criteria could include characteristics of assertions themselves, e.g. diagnoses, rather than what the assertions (observations) are about, e.g. diseases. This would allow, for instance, to find cohorts of patients for which different providers have been in disagreement about what condition the patient is suffering from. Previous research has shown that this requires more explicit detail about, and unique identification of, two sorts of entities: those that directly or indirectly contribute to the coming into existence of such observations and those that are either explicitly mentioned or merely implied in the assertions. Our research here demonstrates that i2b2's modifier system can be used to represent the relationships between observations and their explicit or implied referents on the one hand, and between relevant referents themselves on the other hand, both in combination with the storage of explicit unique instance identifiers for these observations and referents in i2b2's fact table. While this approach adheres to i2b2's base functionality and implementation specifications, it makes explicit ambiguities and confusions that would otherwise remain undetected.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:30815064,30815064,
J,"Fu, Li-Heng; Knaplund, Chris; Cato, Kenrick; Perotte, Adler; Kang, Min-Jeoung; Dykes, Patricia C.; Albers, David; Rossetti, Sarah Collins",,,,,"Albers, David/0000-0002-5369-526X; Rossetti, Sarah/0000-0003-2632-8867",,,Utilizing timestamps of longitudinal electronic health record data to classify clinical deterioration events,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,9,,,1955,1963,,10.1093/jamia/ocab111,,JUL 2021,,SEP 2021,2021,"Objective: To propose an algorithm that utilizes only timestamps of longitudinal electronic health record data to classify clinical deterioration events.Materials and methods: This retrospective study explores the efficacy of machine learning algorithms in classifying clinical deterioration events among patients in intensive care units using sequences of timestamps of vital sign measurements, flowsheets comments, order entries, and nursing notes. We design a data pipeline to partition events into discrete, regular time bins that we refer to as timesteps. Logistic regressions, random forest classifiers, and recurrent neural networks are trained on datasets of different length of timesteps, respectively, against a composite outcome of death, cardiac arrest, and Rapid Response Team calls. Then these models are validated on a holdout dataset.Results: A total of 6720 intensive care unit encounters meet the criteria and the final dataset includes 830 578 timestamps. The gated recurrent unit model utilizes timestamps of vital signs, order entries, flowsheet comments, and nursing notes to achieve the best performance on the time-to-outcome dataset, with an area under the precision-recall curve of 0.101 (0.06, 0.137), a sensitivity of 0.443, and a positive predictive value of 0. 092 at the threshold of 0.6.Discussion and Conclusion: This study demonstrates that our recurrent neural network models using only timestamps of longitudinal electronic health record data that reflect healthcare processes achieve well-performing discriminative power.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000692577000018,34270710,
J,"Papez, Vaclav; Moinat, Maxim; Payralbe, Stefan; Asselbergs, Folkert W.; Lumbers, R. Thomas; Hemingway, Harry; Dobson, Richard; Denaxas, Spiros",,,,"Asselbergs, Folkert W./ABD-6752-2021; Hemingway, Harry/C-1219-2009; dobson, richard/C-9269-2011","Asselbergs, Folkert W./0000-0002-1692-8669; Hemingway, Harry/0000-0003-2279-0624; Papez, Vaclav/0000-0002-2123-7993; Denaxas, Spiros/0000-0001-9612-7791; dobson, richard/0000-0003-4224-9245",,,Transforming and evaluating electronic health record disease phenotyping algorithms using the OMOP common data model: a case study in heart failure,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab001,10.1093/jamiaopen/ooab001,,,,JUL 2021,2021,"Objective: The aim of the study was to transform a resource of linked electronic health records (EHR) to the OMOP common data model (CDM) and evaluate the process in terms of syntactic and semantic consistency and quality when implementing disease and risk factor phenotyping algorithms.Materials and Methods: Using heart failure (HF) as an exemplar, we represented three national EHR sources (Clinical Practice Research Datalink, Hospital Episode Statistics Admitted Patient Care, Office for National Statistics) into the OMOP CDM 5.2. We compared the original and CDM HF patient population by calculating and presenting descriptive statistics of demographics, related comorbidities, and relevant clinical biomarkers.Results: We identified a cohort of 502 536 patients with the incident and prevalent HF and converted 1 099 195 384 rows of data from 216 581 914 encounters across three EHR sources to the OMOP CDM. The largest percentage (65%) of unmapped events was related to medication prescriptions in primary care. The average coverage of source vocabularies was >98% with the exception of laboratory tests recorded in primary care. The raw and transformed data were similar in terms of demographics and comorbidities with the largest difference observed being 3.78% in the prevalence of chronic obstructive pulmonary disease (COPD).Conclusion: Our study demonstrated that the OMOP CDM can successfully be applied to convert EHR linked across multiple healthcare settings and represent phenotyping algorithms spanning multiple sources. Similar to previous research, challenges mapping primary care prescriptions and laboratory measurements still persist and require further work. The use of OMOP CDM in national UK EHR is a valuable research tool that can enable large-scale reproducible observational research.",,,,,,,,,2,0,0,0,1,0,2,,,,2574-2531,,WOS:000731864500010,34514354,
J,"Jang, Giup; Lee, Taekeon; Hwang, Soyoun; Park, Chihyun; Ahn, Jaegyoon; Seo, Sukyung; Hwang, Youhyeon; Yoon, Youngmi",,,,,"Park, Chihyun/0000-0003-4995-2312",,,PISTON: Predicting drug indications and side effects using topic modeling and natural language processing,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,87,,,,96,107,,10.1016/j.jbi.2018.09.015,,,,NOV 2018,2018,"The process of discovering novel drugs to treat diseases requires a long time and high cost. It is important to understand side effects of drugs as well as their therapeutic effects, because these can seriously damage the patients due to unexpected actions of the derived candidate drugs. In order to overcome these limitations, computational methods for predicting the therapeutic effects and side effects have been proposed. In particular, text mining is a widely used technique in the field of systems biology, because it can discover hidden relationships between drugs, genes and diseases from a large amount of literature data. Compared with in vivo/in vitro experiments, text mining derives meaningful results with less time and cost.In this study, we propose an algorithm for predicting novel drug-phenotype associations and drug-side effect associations using topic modeling and natural language processing (NLP). We extract sentences in which drugs and genes co-occur from the abstracts of the literature and identify words that describe the relationship between them using NLP. Considering the characteristics of the identified words, we determine if the drug has an up regulation effect or a down-regulation effect on the gene. Based on genes that affect drugs and their regulatory relationships, we group the frequently occurring genes and regulatory relationships into topics, and build a drug topic probability matrix by calculating the score that the drug will have a topic using topic modeling. Using the matrix, a classifier is constructed for predicting the novel indications and side effects of drugs considering the characteristics of known drug-phenotype associations or drug-side effect associations.The proposed method predicts both indications and side effects with a single algorithm, and it can exclude drugs with serious side effects or side effects that patients do not want to experience from among the candidate drugs provided for the treatment of the phenotype. Furthermore, lists of novel candidate drugs for phenotypes and side effects can be continuously updated with our algorithm every time a document is added. More than a thousand documents are produced per day, and it is possible for our algorithm to efficiently derive candidate drugs because it requires less cost than the existing drug repositioning methods. The resource of PISTON is available at databio.gachon.ac.kr/tools/PISTON.",,,,,,,,,7,0,0,0,2,0,7,,,1532-0464,1532-0480,,WOS:000460600700010,30268842,
J,"Rundo, Leonardo; Pirrone, Roberto; Vitabile, Salvatore; Sala, Evis; Gambino, Orazio",,,,"Rundo, Leonardo/AAF-3999-2019; Vitabile, Salvatore/F-6323-2013","Rundo, Leonardo/0000-0003-3341-5483; Vitabile, Salvatore/0000-0002-2673-8551; Gambino, Orazio/0000-0003-4642-7133",,,Recent advances of HCI in decision-making tasks for optimized clinical workflows and precision medicine,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103479,10.1016/j.jbi.2020.103479,,,,AUG 2020,2020,"The ever-increasing amount of biomedical data is enabling new large-scale studies, even though ad hoc computational solutions are required. The most recent Machine Learning (ML) and Artificial Intelligence (AI) techniques have been achieving outstanding performance and an important impact in clinical research, aiming at precision medicine, as well as improving healthcare workflows. However, the inherent heterogeneity and uncertainty in the healthcare information sources pose new compelling challenges for clinicians in their decision-making tasks. Only the proper combination of AI and human intelligence capabilities, by explicitly taking into account effective and safe interaction paradigms, can permit the delivery of care that outperforms what either can do separately. Therefore, Human-Computer Interaction (HCI) plays a crucial role in the design of software oriented to decision-making in medicine. In this work, we systematically review and discuss several research fields strictly linked to HCI and clinical decision-making, by subdividing the articles into six themes, namely: Interfaces, Visualization, Electronic Health Records, Devices, Usability, and Clinical Decision Support Systems. However, these articles typically present overlaps among the themes, revealing that HCI inter-connects multiple topics. With the goal of focusing on HCI and design aspects, the articles under consideration were grouped into four clusters. The advances in AI can effectively support the physicians' cognitive processes, which certainly play a central role in decision-making tasks because the human mental behavior cannot be completely emulated and captured; the human mind might solve a complex problem even without a statistically significant amount of data by relying upon domain knowledge. For this reason, technology must focus on interactive solutions for supporting the physicians effectively in their daily activities, by exploiting their unique knowledge and evidence-based reasoning, as well as improving the various aspects highlighted in this review.",,,,,,,,,16,0,0,0,2,0,16,,,1532-0464,1532-0480,,WOS:000564595700003,32561444,
J,"Kumar, Akshat; Goodrum, Heath; Kim, Ashley; Stender, Carly; Roberts, Kirk; Bernstam, Elmer, V",,,,,"Kim, Ashley/0000-0002-5931-9476",,,Closing the loop: automatically identifying abnormal imaging results in scanned documents,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac007,,FEB 2022,,,2022,"Objectives Scanned documents (SDs), while common in electronic health records and potentially rich in clinically relevant information, rarely fit well with clinician workflow. Here, we identify scanned imaging reports requiring follow-up with high recall and practically useful precision. Materials and methods We focused on identifying imaging findings for 3 common causes of malpractice claims: (1) potentially malignant breast (mammography) and (2) lung (chest computed tomography [CT]) lesions and (3) long-bone fracture (X-ray) reports. We train our ClinicalBERT-based pipeline on existing typed/dictated reports classified manually or using ICD-10 codes, evaluate using a test set of manually classified SDs, and compare against string-matching (baseline approach). Results A total of 393 mammograms, 305 chest CT, and 683 bone X-ray reports were manually reviewed. The string-matching approach had an F1 of 0.667. For mammograms, chest CTs, and bone X-rays, respectively: models trained on manually classified training data and optimized for F1 reached an F1 of 0.900, 0.905, and 0.817, while separate models optimized for recall achieved a recall of 1.000 with precisions of 0.727, 0.518, and 0.275. Models trained on ICD-10-labelled data and optimized for F1 achieved F1 scores of 0.647, 0.830, and 0.643, while those optimized for recall achieved a recall of 1.0 with precisions of 0.407, 0.683, and 0.358. Discussion Our pipeline can identify abnormal reports with potentially useful performance and so decrease the manual effort required to screen for abnormal findings that require follow-up. Conclusion It is possible to automatically identify clinically significant abnormalities in SDs with high recall and practically useful precision in a generalizable and minimally laborious way.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000763816400001,35146510,
J,"Meaney, Christopher; Escobar, Michael; Moineddin, Rahim; Stukel, Therese A.; Kalia, Sumeet; Aliarzadeh, Babak; Chen, Tao; O'Neill, Braden; Greiver, Michelle",,,,,,,,"Non-negative matrix factorization temporal topic models and clinical text data identify COVID-19 pandemic effects on primary healthcare and community health in Toronto, Canada",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,128,,,,,,104034,10.1016/j.jbi.2022.104034,,,,APR 2022,2022,"Objective: To demonstrate how non-negative matrix factorization can be used to learn a temporal topic model over a large collection of primary care clinical notes, characterizing diverse COVID-19 pandemic effects on the physical/mental/social health of residents of Toronto, Canada. Materials and Methods: The study employs a retrospective open cohort design, consisting of 382,666 primary care progress notes from 44,828 patients, 54 physicians, and 12 clinics collected 01/01/2017 through 31/12/2020. Non-negative matrix factorization uncovers a meaningful latent topical structure permeating the corpus of primary care notes. The learned latent topical basis is transformed into a multivariate time series data structure. Time series methods and plots showcase the evolution/dynamics of learned topics over the study period and allow the identification of COVID-19 pandemic effects. We perform several post-hoc checks of model robustness to increase trust that descriptive/unsupervised inferences are stable over hyper-parameter configurations and/or data perturbations. Results: Temporal topic modelling uncovers a myriad of pandemic-related effects from the expressive clinical text data. In terms of direct effects on patient-health, topics encoding respiratory disease symptoms display altered dynamics during the pandemic year. Further, the pandemic was associated with a multitude of indirect patient level effects on topical domains representing mental health, sleep, social and familial dynamics, measurement of vitals/labs, uptake of prevention/screening maneuvers, and referrals to medical specialists. Finally, topic models capture changes in primary care practice patterns resulting from the pandemic, including changes in EMR documentation strategies and the uptake of telemedicine. Conclusion: Temporal topic modelling applied to a large corpus of rich primary care clinical text data, can identify a meaningful topical/thematic summarization which can provide policymakers and public health stakeholders a passive, cost-effective, technology for understanding holistic impacts of the COVID-19 pandemic on the primary healthcare system and community/public-health.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000767877600001,35202844,
J,"Reale, Carrie; Novak, Laurie L; Robinson, Katelyn; Simpson, Christopher L; Ribeiro, Jessica D; Franklin, Joseph C; Ripperger, Michael; Walsh, Colin G",,,,,,,,User-Centered Design of a Machine Learning Intervention for Suicide Risk Prediction in a Military Setting.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1050,1058,,,,,,2020,2020,"Primary care represents a major opportunity for suicide prevention in the military. Significant advances have been made in using electronic health record data to predict suicide attempts in patient populations. With a user-centered design approach, we are developing an intervention that uses predictive analytics to inform care teams about their patients' risk of suicide attempt. We present our experience working with clinicians and staff in a military primary care setting to create preliminary designs and a context-specific usability testing plan for the deployment of the suicide risk indicator.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:33936481,33936481,
J,"Mauer, Elizabeth; Lee, Jihui; Choi, Justin; Zhang, Hongzhe; Hoffman, Katherine L.; Easthausen, Imaani J.; Rajan, Mangala; Weiner, Mark G.; Kaushal, Rainu; Safford, Monika M.; Steel, Peter A. D.; Banerjee, Samprit",,,,,,,,A predictive model of clinical deterioration among hospitalized COVID-19 patients by harnessing hospital course trajectories,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,118,,,,,,103794,10.1016/j.jbi.2021.103794,,MAY 2021,,JUN 2021,2021,"From early March through mid-May 2020, the COVID-19 pandemic overwhelmed hospitals in New York City. In anticipation of ventilator shortages and limited ICU bed capacity, hospital operations prioritized the development of prognostic tools to predict clinical deterioration. However, early experience from frontline physicians observed that some patients developed unanticipated deterioration after having relatively stable periods, attesting to the uncertainty of clinical trajectories among hospitalized patients with COVID-19. Prediction tools that incorporate clinical variables at one time-point, usually on hospital presentation, are suboptimal for patients with dynamic changes and evolving clinical trajectories. Therefore, our study team developed a machinelearning algorithm to predict clinical deterioration among hospitalized COVID-19 patients by extracting clinically meaningful features from complex longitudinal laboratory and vital sign values during the early period of hospitalization with an emphasis on informative missing-ness. To incorporate the evolution of the disease and clinical practice over the course of the pandemic, we utilized a time-dependent cross-validation strategy for model development. Finally, we validated our prediction model on an external validation cohort of COVID-19 patients served in a demographically distinct population from the training cohort. The main finding of our study is the identification of risk profiles of early, late and no clinical deterioration during the course of hospitalization. While risk prediction models that include simple predictors at ED presentation and clinical judgement are able to identify any deterioration vs. no deterioration, our methodology is able to isolate a particular risk group that remain stable initially but deteriorate at a later stage of the course of hospitalization. We demonstrate the superior predictive performance with the utilization of laboratory and vital sign data during the early period of hospitalization compared to the utilization of data at presentation alone. Our results will allow efficient hospital resource allocation and will motivate research in understanding the late deterioration risk group.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663600500009,33933654,
J,"Kelly, Jonathan; Wang, Chen; Zhang, Jianyi; Das, Spandan; Ren, Anna; Warnekar, Pradnya",,,,,,,,Automated Mapping of Real-world Oncology Laboratory Data to LOINC.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,611,620,,,,,,2021,2021,"In this study we seek to determine the efficacy of using automated mapping methods to reduce the manual mapping burden of laboratory data to LOINC(r) on a nationwide electronic health record derived oncology specific dataset. We developed novel encoding methodologies to vectorize free text lab data, and evaluated logistic regression, random forest, and knn machine learning classifiers. All machine learning models did significantly better than deterministic baseline algorithms. The best classifiers were random forest and were able to predict the correct LOINC code 94.5% of the time. Ensemble classifiers further increased accuracy, with the best ensemble classifier predicting the same code 80.5% of the time with an accuracy of 99%. We conclude that by using an automated laboratory mapping model we can both reduce manual mapping time, and increase quality of mappings, suggesting automated mapping is a viable tool in a real-world oncology dataset.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308998,35308998,
J,"Zheutlin, Amanda B.; Vieira, Luciana; Shewcraft, Ryan A.; Li, Shilong; Wang, Zichen; Schadt, Emilio; Gross, Susan; Dolan, Siobhan M.; Stone, Joanne; Schadt, Eric; Li, Li",,,,,"Vieira, Luciana/0000-0002-6397-4692; Zheutlin, Amanda/0000-0001-6987-1435",,,Improving postpartum hemorrhage risk prediction using longitudinal electronic medical records,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,2,,,296,305,,10.1093/jamia/ocab161,,AUG 2021,,FEB 2021,2021,"Objective: Postpartum hemorrhage (PPH) remains a leading cause of preventable maternal mortality in the United States. We sought to develop a novel risk assessment tool and compare its accuracy to tools used in current practice.Materials and Methods: We used a PPH digital phenotype that we developed and validated previously to identify 6639 PPH deliveries from our delivery cohort (N=70948). Using a vast array of known and potential risk factors extracted from electronic medical records available prior to delivery, we trained a gradient boosting model in a subset of our cohort. In a held-out test sample, we compared performance of our model with 3 clinical risk-assessment tools and 1 previously published model.Results: Our 24-feature model achieved an area under the receiver-operating characteristic curve (AUROC) of 0.71 (95% confidence interval [CI], 0.69-0.72), higher than all other tools (research-based AUROC, 0.67 [95% CI, 0.66-0.69]; clinical AUROCs, 0.55 [95% CI, 0.54-0.56] to 0.61 [95% CI, 0.59-0.62]). Five features were novel, including red blood cell indices and infection markers measured upon admission. Additionally, we identified inflection points for vital signs and labs where risk rose substantially. Most notably, patients with median intrapartum systolic blood pressure above 132mm Hg had an 11% (95% CI, 8%-13%) median increase in relative risk for PPH.Conclusions: We developed a novel approach for predicting PPH and identified clinical feature thresholds that can guide intrapartum monitoring for PPH risk. These results suggest that our model is an excellent candidate for prospective evaluation and could ultimately reduce PPH morbidity and mortality through early detection and prevention.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000749569600008,34405866,
J,"Reese, Thomas; Segall, Noa; Nesbitt, Paige; Del Fiol, Guilherme; Waller, Rosalie; Macpherson, Brekk C.; Tonna, Joseph E.; Wright, Melanie C.",,,,"Wright, Melanie C/AAL-6759-2020; Tonna, Joseph Edward/H-7632-2019","Wright, Melanie C/0000-0001-7121-504X; Tonna, Joseph Edward/0000-0001-8879-2628; Reese, Thomas/0000-0002-1081-1670; Del Fiol, Guilherme/0000-0001-9954-6799",,,Patient information organization in the intensive care setting: expert knowledge elicitation with card sorting methods,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,8,,,1026,1035,,10.1093/jamia/ocy045,,,,AUG 2018,2018,"Introduction: Many electronic health records fail to support information uptake because they impose low-level information organization tasks on users. Clinical concept-oriented views have shown information processing improvements, but the specifics of this organization for critical care are unclear.Objective: To determine high-level cognitive processes and patient information organization schema in critical care.Methods: We conducted an open card sort of 29 patient data elements and a modified Delphi card sort of 65 patient data elements. Study participants were 39 clinicians with varied critical care training and experience. We analyzed the open sort with a hierarchical cluster analysis (HCA) and factor analysis (FA). The Delphi sort was split into three initiating groups that resulted in three unique solutions. We compared results between open sort analyses (HCA and FA), between card sorting exercises (open and Delphi), and across the Delphi solutions.Results: Between the HCA and FA, we observed common constructs including cardiovascular and hemodynamics, infectious disease, medications, neurology, patient overview, respiratory, and vital signs. The more comprehensive Delphi sort solutions also included gastrointestinal, renal, and imaging constructs.Conclusions: We identified primarily system-based groupings (e.g., cardiovascular, respiratory). Source-based (e.g., medications, laboratory) groups became apparent when participants were asked to sort a longer list of concepts. These results suggest a hybrid approach to information organization, which may combine systems, source, or problem-based groupings, best supports clinicians' mental models. These results can contribute to the design of information displays to better support clinicians' access and interpretation of information for critical care decisions.",,,,,,,,,5,0,0,0,0,0,5,,,1067-5027,1527-974X,,WOS:000440955200013,30060091,
J,"Sottile, Peter D.; Albers, David; DeWitt, Peter E.; Russell, Seth; Stroh, J. N.; Kao, David P.; Adrian, Bonnie; Levine, Matthew E.; Mooney, Ryan; Larchick, Lenny; Kutner, Jean S.; Wynia, Matthew K.; Glasheen, Jeffrey J.; Bennett, Tellen D.",,,,"Kao, David P/K-3288-2013","Kao, David P/0000-0002-2832-9348; stroh, j.n./0000-0003-4844-1983",,,Real-time electronic health record mortality prediction during the COVID-19 pandemic: a prospective cohort study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2354,2365,,10.1093/jamia/ocab100,,SEP 2021,,NOV 2021,2021,"Objective: To rapidly develop, validate, and implement a novel real-time mortality score for the COVID-19 pandemic that improves upon sequential organ failure assessment (SOFA) for decision support for a Crisis Standards of Care team.Materials and Methods: We developed, verified, and deployed a stacked generalization model to predict mortality using data available in the electronic health record (EHR) by combining 5 previously validated scores and additional novel variables reported to be associated with COVID-19-specific mortality. We verified the model with prospectively collected data from 12 hospitals in Colorado between March 2020 and July 2020. We compared the area under the receiver operator curve (AUROC) for the new model to the SOFA score and the Charlson Comorbidity Index.Results: The prospective cohort included 27 296 encounters, of which 1358 (5.0%) were positive for SARS-CoV-2, 4494 (16.5%) required intensive care unit care, 1480 (5.4%) required mechanical ventilation, and 717 (2.6%) ended in death. The Charlson Comorbidity Index and SOFA scores predicted mortality with an AUROC of 0.72 and 0.90, respectively. Our novel score predicted mortality with AUROC 0.94. In the subset of patients with COVID-19, the stacked model predicted mortality with AUROC 0.90, whereas SOFA had AUROC of 0.85.Discussion: Stacked regression allows a flexible, updatable, live-implementable, ethically defensible predictive analytics tool for decision support that begins with validated models and includes only novel information that improves prediction.Conclusion: We developed and validated an accurate in-hospital mortality prediction score in a live EHR for automatic and continuous calculation using a novel model that improved upon SOFA.",,,,,,,,,4,0,0,0,2,0,4,,,1067-5027,1527-974X,,WOS:000711702400006,33973011,
J,"Li, Yifu; Jin, Ran; Luo, Yuan",,,,"Luo, Yuan/K-5563-2016","Luo, Yuan/0000-0003-0195-7456",,,Classifying relations in clinical narratives using segment graph convolutional and recurrent neural networks (Seg-GCRNs),,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,3,,,262,268,,10.1093/jamia/ocy157,,,,MAR 2019,2019,"We propose to use segment graph convolutional and recurrent neural networks (Seg-GCRNs), which use only word embedding and sentence syntactic dependencies, to classify relations from clinical notes without manual feature engineering. In this study, the relations between 2 medical concepts are classified by simultaneously learning representations of text segments in the context of sentence syntactic dependency: preceding, concept(1), middle, concept(2), and succeeding segments. Seg-GCRN was systematically evaluated on the i2b2/VA relation classification challenge datasets. Experiments show that Seg-GCRN attains state-of-the-art micro-averaged F-measure for all 3 relation categories: 0.692 for classifying medical treatment-problem relations, 0.827 for medical test-problem relations, and 0.741 for medical problem-medical problem relations. Comparison with the previous state-of-the-art segment convolutional neural network (Seg-CNN) suggests that adding syntactic dependency information helps refine medical word embedding and improves concept relation classification without manual feature engineering. Seg-GCRN can be trained efficiently for the i2b2/VA dataset on a GPU platform.",,,,,,,,,24,2,0,0,1,0,26,,,1067-5027,1527-974X,,WOS:000461520800009,30590613,
J,"Liu, Dianbo; Sahu, Ricky; Ignatov, Vlad; Gottlieb, Dan; Mandl, Kenneth D",,,,,,,,High Performance Computing on Flat FHIR Files Created with the New SMART/HL7 Bulk Data Access Standard.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,592,596,,,,,,2019,2019,"The FHIR Bulk Data API is designed to create a uniform capability for population-level exports from clinical systems, into a file format often referred to as Flat-FHIR. Leveraging the SMART backend services authentication and authorization profile, the approach enables healthcare providers and organizations to define and access cohorts from electronic health records and payor claims data with push button simplicity--a substantial advance over the current state, where each site of care needs highly skilled extraction transform and load (ETL) efforts.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:32308853,32308853,
J,"O'Neill, Braden; Kalia, Sumeet; Aliarzadeh, Babak; Moineddin, Rahim; Fung, Wai Lun Alan; Sullivan, Frank; Maloul, Asmaa; Bernard, Steven; Greiver, Michelle",,,,"Sullivan, Frank/L-8286-2019","Sullivan, Frank/0000-0002-6623-4964",,,"Agreement between primary care and hospital diagnosis of schizophrenia and bipolar disorder: A cross-sectional, observational study using record linkage",,,,,,,,PLOS ONE,,,,14,1,,,,,e0210214,10.1371/journal.pone.0210214,,,,JAN 7 2019,2019,"People with serious mental illness die 10-25 years sooner than people without these conditions. Multiple challenges to accessing and benefitting from healthcare have been identified amongst this population, including a lack of coordination between mental health services and general health services. It has been identified in other conditions such as diabetes that accurate documentation of diagnosis in the primary care chart is associated with better quality of care. It is suspected that if a patient admitted to the hospital with serious mental illness is then discharged without adequate identification of their diagnosis in the primary care setting, follow up (such as medication management and care coordination) may be more difficult. We identified cohorts of patients with schizophrenia and bipolar disorder who accessed care through the North York Family Health Team (a group of 77 family physicians in Toronto, Canada) and North York General Hospital (a large community hospital) between January 1, 2012 and December 31, 2014. We identified whether labeling for these conditions was concordant between the two settings and explored predictors of concordant labeling. This was a retrospective cross-sectional study using de-identified data from the Health Databank Collaborative, a linked primary care-hospital database. We identified 168 patients with schizophrenia and 370 patients with bipolar disorder. Overall diagnostic concordance between primary care and hospital records was 23.2% for schizophrenia and 15.7% for bipolar disorder. Concordance was higher for those with multiple (2+) inpatient visits (for schizophrenia: OR 2.42; 95% CI 0.64-9.20 and for bipolar disorder: OR 8.38; 95% CI 3.16-22.22). Capture-recapture modeling estimated that 37.4% of patients with schizophrenia (95% CI 20.7-54.1) and 39.6% with bipolar disorder (95% CI 25.7-53.6) had missing labels in both settings when adjusting for patients' age, sex, income quintiles and co-morbidities. In this sample of patients accessing care at a large family health team and community hospital, concordance of diagnostic information about serious mental illness was low. Interventions should be developed to improve diagnosis and continuity of care across multiple settings.",,,,,,,,,4,0,0,0,2,0,4,,,1932-6203,,,WOS:000455045900053,30615653,
J,"Zhang, Jianqiu; Drawz, Paul E; Zhu, Ying; Hultman, Gretchen; Simon, Gyorgy; Melton, Genevieve B",,,,,,,,Validation of Administrative Coding and Clinical Notes for Hospital-Acquired Acute Kidney Injury in Adults.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,1234,1243,,,,,,2021,2021,"Acute kidney injury (AKI) is potentially catastrophic and commonly seen among inpatients. In the United States, the quality of administrative coding data for capturing AKI accurately is questionable and needs to be updated. This retrospective study validated the quality of administrative coding for hospital-acquired AKI and explored the opportunities to improve the phenotyping performance by utilizing additional data sources from the electronic health record (EHR). A total of34570 patients were included, and overall prevalence of AKI based on the KDIGO reference standard was 10.13%, We obtained significantly different quality measures (sensitivity.-0.486, specificity:0.947, PPV.0.509, NPV:0.942 in the full cohort) of administrative coding from the previously reported ones in the U.S. Additional use of clinical notes by incorporating automatic NLP data extraction has been found to increase the AUC in phenotyping AKI, and AKI was better recognized in patients with heart failure, indicating disparities in the coding and management of AKI.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308921,35308921,
J,"Ben-Assuli, Ofir; Jacobi, Arie; Goldman, Orit; Shenhar-Tsarfaty, Shani; Rogowski, Ori; Zeltser, David; Shapira, Itzhak; Berliner, Shlomo; Zelber-Sagi, Shira",,,,,,,,Stratifying individuals into non-alcoholic fatty liver disease risk levels using time series machine learning models,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,126,,,,,,103986,10.1016/j.jbi.2022.103986,,,,FEB 2022,2022,"Non-alcoholic fatty liver disease (NAFLD) affects 25% of the population worldwide, and its prevalence is anticipated to increase globally. While most NAFLD patients are asymptomatic, NAFLD may progress to fibrosis, cirrhosis, cardiovascular disease, and diabetes. Research reports, with daunting results, show the challenge that NAFLD's burden causes to global population health. The current process for identifying fibrosis risk levels is inefficient, expensive, does not cover all potential populations, and does not identify the risk in time. Instead of invasive liver biopsies, we implemented a non-invasive fibrosis assessment process calculated from clinical data (accessed via EMRs/EHRs). We stratified patients' risks for fibrosis from 2007 to 2017 by modeling the risk in 5579 individuals. The process involved time-series machine learning models (Hidden Markov Models and Group Based Trajectory Models) profiled fibrosis risk by modeling patients' latent medical status resulted in three groups. The high-risk group had abnormal lab test values and a higher prevalence of chronic conditions. This study can help overcome the inefficient, traditional process of detecting fibrosis via biopsies (that are also medically unfeasible due to their invasive nature, the medical resources involved, and costs) at early stages. Thus longitudinal risk assessment may be used to make population-specific medical recommendations targeting early detection of high risk patients, to avoid the development of fibrosis disease and its complications as well as decrease healthcare costs.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000767887400002,35007752,
J,"Pattisapu, Nikhil; Anand, Vivek; Patil, Sangameshwar; Palshikar, Girish; Varma, Vasudeva",,,,,,,,Distant supervision for medical concept normalization,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,109,,,,,,103522,10.1016/j.jbi.2020.103522,,,,SEP 2020,2020,"We consider the task of Medical Concept Normalization (MCN) which aims to map informal medical phrases such as loosing weight to formal medical concepts, such as weight loss. Deep learning models have shown high performance across various MCN datasets containing small number of target concepts along with adequate number of training examples per concept. However, scaling these models to millions of medical concepts entails the creation of much larger datasets which is cost and effort intensive. Recent works have shown that training MCN models using automatically labeled examples extracted from medical knowledge bases partially alleviates this problem. We extend this idea by computationally creating a distant dataset from patient discussion forums. We extract informal medical phrases and medical concepts from these forums using a synthetically trained classifier and an off-the-shelf medical entity linker respectively. We use pretrained sentence encoding models to find the k-nearest phrases corresponding to each medical concept. These mappings are used in combination with the examples obtained from medical knowledge bases to train an MCN model. Our approach outperforms the previous state-of-the-art by 15.9% and 17.1% classification accuracy across two datasets while avoiding manual labeling.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000575072400007,32783923,
J,"Rasmussen, Luke V; Brandt, Pascal S; Jiang, Guoqian; Kiefer, Richard C; Pacheco, Jennifer A; Adekkanattu, Prakash; Ancker, Jessica S; Wang, Fei; Xu, Zhenxing; Pathak, Jyotishman; Luo, Yuan",,,,"Luo, Yuan/K-5563-2016","Luo, Yuan/0000-0003-0195-7456",,,Considerations for Improving the Portability of Electronic Health Record-Based Phenotype Algorithms.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,755,764,,,,,,2019,2019,"With the increased adoption of electronic health records, data collected for routine clinical care is used for health outcomes and population sciences research, including the identification of phenotypes. In recent years, research networks, such as eMERGE, OHDSI and PCORnet, have been able to increase statistical power and population diversity by combining patient cohorts. These networks share phenotype algorithms that are executed at each participating site. Here we observe experiences with phenotype algorithm portability across seven research networks and propose a generalizable framework for phenotype algorithm portability. Several strategies exist to increase the portability of phenotype algorithms, reducing the implementation effort needed by each site. These include using a common data model, standardized representation of the phenotype algorithm logic, and technical solutions to facilitate federated execution of queries. Portability is achieved by tradeoffs across three domains: Data, Authoring and Implementation, and multiple approaches were observed in representing portable phenotype algorithms. Our proposed framework will help guide future research in operationalizing phenotype algorithm portability at scale.",,,,,,,,,2,0,0,0,0,0,2,,,,1942-597X,,MEDLINE:32308871,32308871,
J,"Mu, Emily; Jabbour, Sarah; Dalca, Adrian V; Guttag, John; Wiens, Jenna; Sjoding, Michael W",,,,,,,,Augmenting existing deterioration indices with chest radiographs to predict clinical deterioration.,,,,,,,,PloS one,,,,17,2,,,e0263922,e0263922,,10.1371/journal.pone.0263922,,,,2022,2022,"IMPORTANCE: When hospitals are at capacity, accurate deterioration indices could help identify low-risk patients as potential candidates for home care programs and alleviate hospital strain. To date, many existing deterioration indices are based entirely on structured data from the electronic health record (EHR) and ignore potentially useful information from other sources.OBJECTIVE: To improve the accuracy of existing deterioration indices by incorporating unstructured imaging data from chest radiographs.DESIGN, SETTING, AND PARTICIPANTS: Machine learning models were trained to predict deterioration of patients hospitalized with acute dyspnea using existing deterioration index scores and chest radiographs. Models were trained on hospitalized patients without coronavirus disease 2019 (COVID-19) and then subsequently tested on patients with COVID-19 between January 2020 and December 2020 at a single tertiary care center who had at least one radiograph taken within 48 hours of hospital admission.MAIN OUTCOMES AND MEASURES: Patient deterioration was defined as the need for invasive or non-invasive mechanical ventilation, heated high flow nasal cannula, IV vasopressor administration or in-hospital mortality at any time following admission. The EPIC deterioration index was augmented with unstructured data from chest radiographs to predict risk of deterioration. We compared discriminative performance of the models with and without incorporating chest radiographs using area under the receiver operating curve (AUROC), focusing on comparing the fraction and total patients identified as low risk at different negative predictive values (NPV).RESULTS: Data from 6278 hospitalizations were analyzed, including 5562 hospitalizations without COVID-19 (training cohort) and 716 with COVID-19 (216 in validation, 500 in held-out test cohort). At a NPV of 0.95, the best-performing image-augmented deterioration index identified 49 more (9.8%) individuals as low-risk compared to the deterioration index based on clinical data alone in the first 48 hours of admission. At a NPV of 0.9, the EPIC image-augmented deterioration index identified 26 more individuals (5.2%) as low-risk compared to the deterioration index based on clinical data alone in the first 48 hours of admission.CONCLUSION AND RELEVANCE: Augmenting existing deterioration indices with chest radiographs results in better identification of low-risk patients. The model augmentation strategy could be used in the future to incorporate other forms of unstructured data into existing disease models.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35167608,35167608,
J,"Malhotra, Ananya; Rachet, Bernard; Bonaventure, Audrey; Pereira, Stephen P.; Woods, Laura M.",,,,"Malhotra, Ananya/AAZ-6801-2020; Pereira, Stephen/C-5639-2009; Woods, Laura M/Q-1714-2017","Malhotra, Ananya/0000-0002-0691-0705; Bonaventure, Audrey/0000-0001-6665-8145; Pereira, Stephen/0000-0003-0821-1809; Woods, Laura M/0000-0002-2178-1577",,,Can we screen for pancreatic cancer? Identifying a sub-population of patients at high risk of subsequent diagnosis using machine learning techniques applied to primary care data,,,,,,,,PLOS ONE,,,,16,6,,,,,e0251876,10.1371/journal.pone.0251876,,,,JUN 2 2021,2021,"Background Pancreatic cancer (PC) represents a substantial public health burden. Pancreatic cancer patients have very low survival due to the difficulty of identifying cancers early when the tumour is localised to the site of origin and treatable. Recent progress has been made in identifying biomarkers for PC in the blood and urine, but these cannot be used for population-based screening as this would be prohibitively expensive and potentially harmful.Methods We conducted a case-control study using prospectively-collected electronic health records from primary care individually-linked to cancer registrations. Our cases were comprised of 1,139 patients, aged 15-99 years, diagnosed with pancreatic cancer between January 1, 2005 and June 30, 2009. Each case was age-, sex- and diagnosis time-matched to four non-pancreatic (cancer patient) controls. Disease and prescription codes for the 24 months prior to diagnosis were used to identify 57 individual symptoms. Using a machine learning approach, we trained a logistic regression model on 75% of the data to predict patients who later developed PC and tested the model's performance on the remaining 25%.Results We were able to identify 41.3% of patients < = 60 years at 'high risk' of developing pancreatic cancer up to 20 months prior to diagnosis with 72.5% sensitivity, 59% specificity and, 66% AUC. 43.2% of patients >60 years were similarly identified at 17 months, with 65% sensitivity, 57% specificity and, 61% AUC. We estimate that combining our algorithm with currently available biomarker tests could result in 30 older and 400 younger patients per cancer being identified as 'potential patients', and the earlier diagnosis of around 60% of tumours.Conclusion After further work this approach could be applied in the primary care setting and has the potential to be used alongside a non-invasive biomarker test to increase earlier diagnosis. This would result in a greater number of patients surviving this devastating disease.",,,,,,,,,3,0,0,0,1,0,3,,,1932-6203,,,WOS:000664638500019,34077433,
J,"Ghosh, Shantanu; Bian, Jiang; Guo, Yi; Prosperi, Mattia",,,,,"Bian, Jiang/0000-0002-2238-5429",,,Deep propensity network using a sparse autoencoder for estimation of treatment effects,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1197,1206,,10.1093/jamia/ocaa346,,FEB 2021,,JUN 2021,2021,"Objective: Drawing causal estimates from observational data is problematic, because datasets often contain underlying bias (eg, discrimination in treatment assignment). To examine causal effects, it is important to evaluate what-if scenarios-the so-called counterfactuals. We propose a novel deep learning architecture for propensity score matching and counterfactual prediction-the deep propensity network using a sparse autoencoder (DPN-SA)-to tackle the problems of high dimensionality, nonlinear/nonparallel treatment assignment, and residual confounding when estimating treatment effects.Materials and Methods: We used 2 randomized prospective datasets, a semisynthetic one with nonlinear/nonparallel treatment selection bias and simulated counterfactual outcomes from the Infant Health and Development Program and a real-world dataset from the LaLonde's employment training program. We compared different configurations of the DPN-SA against logistic regression and LASSO as well as deep counterfactual networks with propensity dropout (DCN-PD). Models' performances were assessed in terms of average treatment effects, mean squared error in precision on effect's heterogeneity, and average treatment effect on the treated, over multiple training/test runs.Results: The DPN-SA outperformed logistic regression and LASSO by 36%-63%, and DCN-PD by 6%-10% across all datasets. All deep learning architectures yielded average treatment effects close to the true ones with low variance. Results were also robust to noise-injection and addition of correlated variables. Code is publicly available at https://github.com/Shantanu48114860/DPN-SAz.Discussion and Conclusion: Deep sparse autoencoders are particularly suited for treatment effect estimation studies using electronic health records because they can handle high-dimensional covariate sets, large sample sizes, and complex heterogeneity in treatment assignments.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000671031900016,33594415,
J,"Cykert, Samuel; DeWalt, Darren A.; Weiner, Bryan J.; Pignone, Michael; Fine, Jason; Kim, Jung In",,,,,"Weiner, Bryan/0000-0002-6996-9480",,,A population approach using cholesterol imputation to identify adults with high cardiovascular risk: a report from AHRQ's EvidenceNow initiative,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,2,,,155,158,,10.1093/jamia/ocy151,,,,FEB 2019,2019,"Objective Large practice networks have access to EHR data that can be used to drive important improvements in population health. However, missing data often limit improvement efforts. Our goal was to determine the proportion of patients in a cohort of small primary care practices who lacked cholesterol data to calculate ASCVD risk scores and then gauge the extent that imputation can accurately identify individuals already at high risk. 219 practices enrolled. Patients between the ages of 40 and 79 years qualified for risk calculation. For patients who lacked cholesterol data, we measured the effect of employing a conservative estimation strategy using a total cholesterol of 170 mg/dl and HDL-cholesterol of 50 mg/dl in the ASCVD risk equation to identify patients with 10%, 10-year ASCVD risk who were eligible for risk reduction interventions then compared this to a rigorous formal imputation methodology. 345 440 patients, average age 58 years, qualified for risk scores. 108 515 patients were missing cholesterol information. Using the good value estimation methodology, 40 565 had risk scores 10% compared to 43 205 using formal imputation. However, the latter strategy yielded a lower specificity and higher false positive rate. Estimates using either strategy achieved ASCVD risk stratification quickly and accurately identified high risk patients who could benefit from intervention.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000460629800009,30496426,
J,"Ding, Xiruo; Mower, Justin; Subramanian, Devika; Cohen, Trevor",,,,,,,,Augmenting aer2vec: Enriching distributed representations of adverse event report data with orthographic and lexical information,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,119,,,,,,103833,10.1016/j.jbi.2021.103833,,JUN 2021,,JUL 2021,2021,"Adverse Drug Events (ADEs) are prevalent, costly, and sometimes preventable. Post-marketing drug surveillance aims to monitor ADEs that occur after a drug is released to market. Reports of such ADEs are aggregated by reporting systems, such as the Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS). In this paper, we consider the topic of how best to represent data derived from reports in FAERS for the purpose of detecting post-marketing surveillance signals, in order to inform regulatory decision making. In our previous work, we developed aer2vec, a method for deriving distributed representations (concept embeddings) of drugs and side effects from ADE reports, establishing the utility of distributional information for pharmacovigilance signal detection. In this paper, we advance this line of research further by evaluating the utility of encoding orthographic and lexical information. We do so by adapting two Natural Language Processing methods, subword embedding and vector retrofitting, which were developed to encode such information into word embeddings. Models were compared for their ability to distinguish between positive and negative examples in a set of manually curated drug/ADE relationships, with both aer2vec enhancements offering advantages in performances over baseline models, and best performance obtained when retrofitting and subword embeddings were applied in concert. In addition, this work demonstrates that models leveraging distributed representations do not require extensive manual preprocessing to perform well on this pharmacovigilance signal detection task, and may even benefit from information that would otherwise be lost during the normalization and standardization process.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000674512900008,34111555,
J,"Wang, Zhe; Wang, Bolu; Zhou, Yangming; Li, Dongdong; Yin, Yichao",,,,,"Zhou, Yangming/0000-0002-4254-6517",,,Weight-based multiple empirical kernel learning with neighbor discriminant constraint for heart failure mortality prediction,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,101,,,,,,103340,10.1016/j.jbi.2019.103340,,,,JAN 2020,2020,"Heart Failure (HF) is one of the most common causes of hospitalization and is burdened by short-term (inhospital) and long-term (6-12 month) mortality. Accurate prediction of HF mortality plays a critical role in evaluating early treatment effects. However, due to the lack of a simple and effective prediction model, mortality prediction of HF is difficult, resulting in a low rate of control. To handle this issue, we propose a Weight-based Multiple Empirical Kernel Learning with Neighbor Discriminant Constraint (WMEKL-NDC) method for HF mortality prediction. In our method, feature selection by calculating the F-value of each feature is first performed to identify the crucial clinical features. Then, different weights are assigned to each empirical kernel space according to the centered kernel alignment criterion. To make use of the discriminant information of samples, neighbor discriminant constraint is finally integrated into multiple empirical kernel learning framework. Extensive experiments were performed on a real clinical dataset containing 10, 198 in-patients records collected from Shanghai Shuguang Hospital in March 2009 and April 2016. Experimental results demonstrate that our proposed WMEKL-NDC method achieves a highly competitive performance for HF mortality prediction of inhospital, 30-day and 1-year. Compared with the state-of-the-art multiple kernel learning and baseline algorithms, our proposed WMEKL-NDC is more accurate on mortality prediction Moreover, top 10 crucial clinical features are identified together with their meanings, which are very useful to assist clinicians in the treatment of HF disease.",,,,,,,,,5,0,0,0,1,0,5,,,1532-0464,1532-0480,,WOS:000525735000012,31756495,
J,"Duan, Rui; Luo, Chongliang; Schuemie, Martijn J.; Tong, Jiayi; Liang, C. Jason; Chang, Howard H.; Boland, Mary Regina; Bian, Jiang; Xu, Hua; Holmes, John H.; Forrest, Christopher B.; Morton, Sally C.; Berlin, Jesse A.; Moore, Jason H.; Mahoney, Kevin B.; Chen, Yong",,,,"Moore, Jason H./AAV-9645-2021","Moore, Jason H./0000-0002-5015-1099; Schuemie, Martijn/0000-0002-0817-5361; Luo, Chongliang/0000-0003-3682-9454",,,Learning from local to global: An efficient distributed algorithm for modeling time-to-event data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,7,,,1028,1036,,10.1093/jamia/ocaa044,,,,JUL 2020,2020,"Objective: We developed and evaluated a privacy-preserving One-shot Distributed Algorithm to fit a multicenter Cox proportional hazards model (ODAC) without sharing patient-level information across sites.Materials and Methods: Using patient-level data from a single site combined with only aggregated information from other sites, we constructed a surrogate likelihood function, approximating the Cox partial likelihood function obtained using patient-level data from all sites. By maximizing the surrogate likelihood function, each site obtained a local estimate of the model parameter, and the ODAC estimator was constructed as a weighted average of all the local estimates. We evaluated the performance of ODAC with (1) a simulation study and (2) a real-world use case study using 4 datasets from the Observational Health Data Sciences and Informatics network.Results: On the one hand, our simulation study showed that ODAC provided estimates nearly the same as the estimator obtained by analyzing, in a single dataset, the combined patient-level data from all sites (ie, the pooled estimator). The relative bias was <0.1% across all scenarios. The accuracy of ODAC remained high across different sample sizes and event rates. On the other hand, the meta-analysis estimator, which was obtained by the inverse variance weighted average of the site-specific estimates, had substantial bias when the event rate is <5%, with the relative bias reaching 20% when the event rate is 1%. In the Observational Health Data Sciences and Informatics network application, the ODAC estimates have a relative bias <5% for 15 out of 16 log hazard ratios, whereas the meta-analysis estimates had substantially higher bias than ODAC.Conclusions: ODAC is a privacy-preserving and noniterative method for implementing time-to-event analyses across multiple sites. It provides estimates on par with the pooled estimator and substantially outperforms the meta-analysis estimator when the event is uncommon, making it extremely suitable for studying rare events and diseases in a distributed manner.",,,,,,,,,10,0,0,0,3,0,10,,,1067-5027,1527-974X,,WOS:000612220200007,32626900,
J,"Savoy, April; Militello, Laura G.; Patel, Himalaya; Flanagan, Mindy E.; Russ, Alissa L.; Daggy, Joanne K.; Weiner, Michael; Saleem, Jason J.",,,,"Weiner, Michael/M-5185-2013; Weiner, Michael/H-5342-2019; Savoy, April/AAM-6728-2021","Weiner, Michael/0000-0002-0877-4583; Weiner, Michael/0000-0002-0877-4583; Daggy, Joanne/0000-0003-0815-1746; Savoy, April/0000-0001-9002-9234",,,A cognitive systems engineering design approach to improve the usability of electronic order forms for medical consultation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,85,,,,138,148,,10.1016/j.jbi.2018.07.021,,,,SEP 2018,2018,"Background: During medical referrals, communication barriers between referring and consulting outpatient clinics delay patients' access to health care. One notable opportunity for reducing these barriers is improved usefulness and usability of electronic medical consultation order forms. The cognitive systems engineering (CSE) design approach focuses on supporting humans in managing cognitive complexity in sociotechnical systems. Cognitive complexity includes communication, decision-making, problem solving, and planning.Objective: The objective of this research was to implement a CSE design approach to develop a template that supports the cognitive needs of referring clinicians and improves referral communication.Methods: We conducted interviews and observations with primary care providers and specialists at two major tertiary, urban medical facilities. Using qualitative analysis, we identified cognitive requirements and design guidelines. Next, we designed user interface (UI) prototypes and compared their usability with that of a currently implemented UI at a major Midwestern medical facility.Results: Physicians' cognitive challenges were summarized in four cognitive requirements and 13 design guidelines. As a result, two UI prototypes were developed to support order template search and completion. To compare UIs, 30 clinicians (referrers) participated in a consultation ordering simulation complemented with the think-aloud elicitation method. Oral comments about the UIs were coded for both content and valence (i.e., positive, neutral, or negative). Across 619 comments, the odds ratio for the UI prototype to elicit higher-valenced comments than the implemented UI was 13.5 (95% CI = [9.2, 19.8]), p < .001.Conclusion: This study reinforced the significance of applying a CSE design approach to inform the design of health information technology. In addition, knowledge elicitation methods enabled identification of physicians' cognitive requirements and challenges when completing electronic medical consultation orders. The resultant knowledge was used to derive design guidelines and UI prototypes that were more useful and usable for referring physicians. Our results support the implementation of a CSE design approach for electronic medical consultation orders.",,,,,,,,,9,0,0,0,3,0,9,,,1532-0464,1532-0480,,WOS:000460600100015,30071316,
J,"Kim, Yejin; Lhatoo, Samden; Zhang, Guo-Qiang; Chen, Luyao; Jiang, Xiaoqian",,,,,"Jiang, Xiaoqian/0000-0001-9933-2205; Kim, Yejin/0000-0001-7815-6310",,,Temporal phenotyping for transitional disease progress: An application to epilepsy and Alzheimer's disease,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,107,,,,,,103462,10.1016/j.jbi.2020.103462,,,,JUL 2020,2020,"Complicated multifactorial diseases deteriorate from one disease to other diseases. For example, existing studies consider Alzheimer's disease (AD) a comorbidity of epilepsy, but also recognize epilepsy to occur more frequently in patients with AD than those without. It is important to understand the progress of disease that deteriorates to severe diseases. To this end, we develop a transitional phenotyping method based on both longitudinal and cross-sectional relationships between diseases and/or medications. For a cross-sectional approach, we utilized a skip-gram model to represent co-occurred disease or medication. For a longitudinal approach, we represented each patient as a transition probability between medical events and used supervised tensor factorization to decompose into groups of medical events that develop together. Then we harmonized both information to derive high-risk transitional patterns. We applied our method to disease progress from epilepsy to AD. An epilepsy-AD cohort of 600,000 patients were extracted from Cerner Health Facts data. Our experimental results suggested a causal relationship between epilepsy and later onset of AD, and also identified five epilepsy subgroups with distinct phenotypic patterns leading to AD. While such findings are preliminary, the proposed method combining representation learning with tensor factorization seems to be an effective approach for risk factor analysis.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000551649200017,32562896,
J,"Rizvi, Rubina F.; Vasilakes, Jake; Adam, Terrence J.; Melton, Genevieve B.; Bishop, Jeffrey R.; Bian, Jiang; Tao, Cui; Zhang, Rui",,,,,"Tao, Cui/0000-0002-4267-1924",,,iDISK: the integrated DIetary Supplements Knowledge base,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,4,,,539,548,,10.1093/jamia/ocz216,,,,APR 2020,2020,"Objective: To build a knowledge base of dietary supplement (DS) information, called the integrated DIetary Supplement Knowledge base (iDISK), which integrates and standardizes DS-related information from 4 existing resources.Materials and Methods: iDISK was built through an iterative process comprising 3 phases: 1) establishment of the content scope, 2) development of the data model, and 3) integration of existing resources. Four well-regarded DS resources were integrated into iDISK: The Natural Medicines Comprehensive Database, the About Herbs page on the Memorial Sloan Kettering Cancer Center website, the Dietary Supplement Label Database, and the Natural Health Products Database. We evaluated the iDISK build process by manually checking that the data elements associated with 50 randomly selected ingredients were correctly extracted and integrated from their respective sources.Results: iDISK encompasses a terminology of 4208 DS ingredient concepts, which are linked via 6 relationship types to 495 drugs, 776 diseases, 985 symptoms, 605 therapeutic classes, 17 system organ classes, and 137 568 DS products. iDISK also contains 7 concept attribute types and 3 relationship attribute types. Evaluation of the data extraction and integration process showed average errors of 0.3%, 2.6%, and 0.4% for concepts, relationships and attributes, respectively.Conclusion: We developed iDISK, a publicly available standardized DS knowledge base that can facilitate more efficient and meaningful dissemination of DS knowledge.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000548306200006,32068839,
J,"Kumar, Sayantan; Oh, Inez; Schindler, Suzanne; Lai, Albert M.; Payne, Philip R. O.; Gupta, Aditi",,,,"Kumar, Sayantan/AFL-5937-2022; Kumar, Sayantan/AAG-5678-2022","Kumar, Sayantan/0000-0001-7213-0734; Kumar, Sayantan/0000-0001-7213-0734; Oh, Inez/0000-0002-0780-8710",,,Machine learning for modeling the progression of Alzheimer disease dementia using clinical data: a systematic literature review,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab052,10.1093/jamiaopen/ooab052,,,,JUL 2021,2021,"Objective: Alzheimer disease (AD) is the most common cause of dementia, a syndrome characterized by cognitive impairment severe enough to interfere with activities of daily life. We aimed to conduct a systematic literature review (SLR) of studies that applied machine learning (ML) methods to clinical data derived from electronic health records in order to model risk for progression of AD dementia.Materials and Methods: We searched for articles published between January 1, 2010, and May 31, 2020, in PubMed, Scopus, ScienceDirect, IEEE Explore Digital Library, Association for Computing Machinery Digital Library, and arXiv. We used predefined criteria to select relevant articles and summarized them according to key components of ML analysis such as data characteristics, computational algorithms, and research focus.Results: There has been a considerable rise over the past 5 years in the number of research papers using MLbased analysis for AD dementia modeling. We reviewed 64 relevant articles in our SLR. The results suggest that majority of existing research has focused on predicting progression of AD dementia using publicly available datasets containing both neuroimaging and clinical data (neurobehavioral status exam scores, patient demographics, neuroimaging data, and laboratory test values).Discussion: Identifying individuals at risk for progression of AD dementia could potentially help to personalize disease management to plan future care. Clinical data consisting of both structured data tables and clinical notes can be effectively used in ML-based approaches to model risk for AD dementia progression. Data sharing and reproducibility of results can enhance the impact, adaptation, and generalizability of this research.",,,,,,,,,4,0,0,0,2,0,4,,,,2574-2531,,WOS:000731864500021,34350389,
J,"Zimbelman, Eloise G.; Keefe, Robert F.",,,,,,,,Development and validation of smartwatch-based activity recognition models for rigging crew workers on cable logging operations,,,,,,,,PLOS ONE,,,,16,5,,,,,e0250624,10.1371/journal.pone.0250624,,,,MAY 12 2021,2021,"Analysis of high-resolution inertial sensor and global navigation satellite system (GNSS) data collected by mobile and wearable devices is a relatively new methodology in forestry and safety research that provides opportunities for modeling work activities in greater detail than traditional time study analysis. The objective of this study was to evaluate whether smartwatch-based activity recognition models could quantify the activities of rigging crew workers setting and disconnecting log chokers on cable logging operations. Four productive cycle elements (travel to log, set choker, travel away, clear) were timed for choker setters and four productive cycle elements (travel to log, unhook, travel away, clear) were timed for chasers working at five logging sites in North Idaho. Each worker wore a smartwatch that recorded accelerometer data at 25 Hz. Random forest machine learning was used to develop predictive models that classified the different cycle elements based on features extracted from the smartwatch acceleration data using 15 sliding window sizes (1 to 15 s) and five window overlap levels (0%, 25%, 50%, 75%, and 90%). Models were compared using multiclass area under the Receiver Operating Characteristic (ROC) curve, or AUC. The best choker setter model was created using a 3-s window with 90% overlap and had sensitivity values ranging from 76.95% to 83.59% and precision values ranging from 41.42% to 97.08%. The best chaser model was created using a 1-s window with 90% overlap and had sensitivity values ranging from 71.95% to 82.75% and precision values ranging from 14.74% to 99.16%. These results have demonstrated the feasibility of quantifying forestry work activities using smartwatch-based activity recognition models, a basic step needed to develop real-time safety notifications associated with high-risk job functions and to advance subsequent, comparative analysis of health and safety metrics across stand, site, and work conditions.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000664627300023,33979355,
J,"Effland, Thomas; Lawson, Anna; Balter, Sharon; Devinney, Katelynn; Reddy, Vasudha; Waechter, HaeNa; Gravano, Luis; Hsu, Daniel",,,,,"Hsu, Daniel/0000-0002-3495-7113",,,Discovering foodborne illness in online restaurant reviews,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,12,,,1586,1592,,10.1093/jamia/ocx093,,,,DEC 2018,2018,"Objective: We developed a system for the discovery of foodborne illness mentioned in online Yelp restaurant reviews using text classification. The system is used by the New York City Department of Health and Mental Hygiene (DOHMH) to monitor Yelp for foodborne illness complaints.Materials and Methods: We built classifiers for 2 tasks: (1) determining if a review indicated a person experiencing foodborne illness and (2) determining if a review indicated multiple people experiencing foodborne illness. We first developed a prototype classifier in 2012 for both tasks using a small labeled dataset. Over years of system deployment, DOHMH epidemiologists labeled 13 526 reviews selected by this classifier. We used these biased data and a sample of complementary reviews in a principled bias-adjusted training scheme to develop significantly improved classifiers. Finally, we performed an error analysis of the best resulting classifiers.Results: We found that logistic regression trained with bias-adjusted augmented data performed best for both classification tasks, with F1-scores of 87% and 66% for tasks 1 and 2, respectively.Discussion: Our error analysis revealed that the inability of our models to account for long phrases caused the most errors. Our bias-adjusted training scheme illustrates how to improve a classification system iteratively by exploiting available biased labeled data.Conclusions: Our system has been instrumental in the identification of 10 outbreaks and 8523 complaints of foodborne illness associated with New York City restaurants since July 2012. Our evaluation has identified strong classifiers for both tasks, whose deployment will allow DOHMH epidemiologists to more effectively monitor Yelp for foodborne illness investigations.",,,,,,,,,21,1,0,0,5,0,22,,,1067-5027,1527-974X,,WOS:000457590600003,29329402,
J,"Na, Jie; Zong, Nansu; Wang, Chen; Midthun, David E.; Luo, Yuan; Yang, Ping; Jiang, Guoqian",,,,,,,,Characterizing phenotypic abnormalities associated with high-risk individuals developing lung cancer using electronic health records from the All of Us researcher workbench,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2313,2324,,10.1093/jamia/ocab174,,SEP 2021,,NOV 2021,2021,"Objective: The study sought to test the feasibility of conducting a phenome-wide association study to characterize phenotypic abnormalities associated with individuals at high risk for lung cancer using electronic health records.Materials and Methods: We used the beta release of the All of Us Researcher Workbench with clinical and survey data from a population of 225 000 subjects. We identified 3 cohorts of individuals at high risk to develop lung cancer based on (1) the 2013 U.S. Preventive Services Task Force criteria, (2) the long-term quitters of cigarette smoking criteria, and (3) the younger age of onset criteria. We applied the logistic regression analysis to identify the significant associations between individuals' phenotypes and their risk categories. We validated our findings against a lung cancer cohort from the same population and conducted an expert review to understand whether these associations are known or potentially novel.Results: We found a total of 214 statistically significant associations (P< .05 with a Bonferroni correction and odds ratio > 1.5) enriched in the high-risk individuals from 3 cohorts, and 15 enriched in the low-risk individuals. Forty significant associations enriched in the high-risk individuals and 13 enriched in the low-risk individuals were validated in the cancer cohort. Expert review identified 15 potentially new associations enriched in the high-risk individuals.Conclusions: It is feasible to conduct a phenome-wide association study to characterize phenotypic abnormalities associated in high-risk individuals developing lung cancer using electronic health records. The All of Us Research Workbench is a promising resource for the research studies to evaluate and optimize lung cancer screening criteria.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000711702400002,34505903,
J,"Castro, Victor M.; Gainer, Vivian; Wattanasin, Nich; Benoit, Barbara; Cagan, Andrew; Ghosh, Bhaswati; Goryachev, Sergey; Metta, Reeta; Park, Heekyong; Wang, David; Mendis, Michael; Rees, Martin; Herrick, Christopher; Murphy, Shawn N.",,,,,"Park, Heekyong/0000-0001-9481-3288",,,The Mass General Brigham Biobank Portal: an i2b2-based data repository linking disparate and high-dimensional patient data to support multimodal analytics,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,4,,,643,651,,10.1093/jamia/ocab264,,,,MAR 15 2022,2022,"Objective Integrating and harmonizing disparate patient data sources into one consolidated data portal enables researchers to conduct analysis efficiently and effectively. Materials and Methods We describe an implementation of Informatics for Integrating Biology and the Bedside (i2b2) to create the Mass General Brigham (MGB) Biobank Portal data repository. The repository integrates data from primary and curated data sources and is updated weekly. The data are made readily available to investigators in a data portal where they can easily construct and export customized datasets for analysis. Results As of July 2021, there are 125 645 consented patients enrolled in the MGB Biobank. 88 527 (70.5%) have a biospecimen, 55 121 (43.9%) have completed the health information survey, 43 552 (34.7%) have genomic data and 124 760 (99.3%) have EHR data. Twenty machine learning computed phenotypes are calculated on a weekly basis. There are currently 1220 active investigators who have run 58 793 patient queries and exported 10 257 analysis files. Discussion The Biobank Portal allows noninformatics researchers to conduct study feasibility by querying across many data sources and then extract data that are most useful to them for clinical studies. While institutions require substantial informatics resources to establish and maintain integrated data repositories, they yield significant research value to a wide range of investigators. Conclusion The Biobank Portal and other patient data portals that integrate complex and simple datasets enable diverse research use cases. i2b2 tools to implement these registries and make the data interoperable are open source and freely available.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000769066500009,34849976,
J,"Luo, Yuan; Szolovits, Peter; Dighe, Anand S.; Baron, Jason M.",,,,"Dighe, Anand/AAP-9640-2020; Luo, Yuan/K-5563-2016","Dighe, Anand/0000-0003-4130-0758; Luo, Yuan/0000-0003-0195-7456",,,3D-MICE: integration of cross-sectional and longitudinal imputation for multi-analyte longitudinal clinical data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,6,,,645,653,,10.1093/jamia/ocx133,,,,JUN 2018,2018,"Objective: A key challenge in clinical data mining is that most clinical datasets contain missing data. Since many commonly used machine learning algorithms require complete datasets (no missing data), clinical analytic approaches often entail an imputation procedure to fill in missing data. However, although most clinical datasets contain a temporal component, most commonly used imputation methods do not adequately accommodate longitudinal time-based data. We sought to develop a new imputation algorithm, 3-dimensional multiple imputation with chained equations (3D-MICE), that can perform accurate imputation of missing clinical time series data.Methods: We extracted clinical laboratory test results for 13 commonly measured analytes (clinical laboratory tests). We imputed missing test results for the 13 analytes using 3 imputation methods: multiple imputation with chained equations (MICE), Gaussian process (GP), and 3D-MICE. 3D-MICE utilizes both MICE and GP imputation to integrate cross-sectional and longitudinal information. To evaluate imputation method performance, we randomly masked selected test results and imputed these masked results alongside results missing from our original data. We compared predicted results to measured results for masked data points.Results: 3D-MICE performed significantly better than MICE and GP-based imputation in a composite of all 13 analytes, predicting missing results with a normalized root-mean-square error of 0.342, compared to 0.373 for MICE alone and 0.358 for GP alone.Conclusions: 3D-MICE offers a novel and practical approach to imputing clinical laboratory time series data. 3D-MICE may provide an additional tool for use as a foundation in clinical predictive analytics and intelligent clinical decision support.",,,,,,,,,30,1,0,0,6,0,31,,,1067-5027,1527-974X,,WOS:000434113600005,29202205,
J,"Blackley, Suzanne V.; Huynh, Jessica; Wang, Liqin; Korach, Zfania; Zhou, Li",,,,,,,,Speech recognition for clinical documentation from 1990 to 2018: a systematic review,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,4,,,324,338,,10.1093/jamia/ocy179,,,,APR 2019,2019,"Objective The study sought to review recent literature regarding use of speech recognition (SR) technology for clinical documentation and to understand the impact of SR on document accuracy, provider efficiency, institutional cost, and more.Materials and Methods We searched 10 scientific and medical literature databases to find articles about clinician use of SR for documentation published between January 1, 1990, and October 15, 2018. We annotated included articles with their research topic(s), medical domain(s), and SR system(s) evaluated and analyzed the results.Results One hundred twenty-two articles were included. Forty-eight (39.3%) involved the radiology department exclusively and 10 (8.2%) involved emergency medicine; 10 (8.2%) mentioned multiple departments. Forty-eight (39.3%) articles studied productivity; 20 (16.4%) studied the effect of SR on documentation time, with mixed findings. Decreased turnaround time was reported in all 19 (15.6%) studies in which it was evaluated. Twenty-nine (23.8%) studies conducted error analyses, though various evaluation metrics were used. Reported percentage of documents with errors ranged from 4.8% to 71%; reported word error rates ranged from 7.4% to 38.7%. Seven (5.7%) studies assessed documentation-associated costs; 5 reported decreases and 2 reported increases. Many studies (44.3%) used products by Nuance Communications. Other vendors included IBM (9.0%) and Philips (6.6%); 7 (5.7%) used self-developed systems.Conclusion Despite widespread use of SR for clinical documentation, research on this topic remains largely heterogeneous, often using different evaluation metrics with mixed findings. Further, that SR-assisted documentation has become increasingly common in clinical settings beyond radiology warrants further investigation of its use and effectiveness in these settings.",,,,,,,,,19,1,0,0,5,0,20,,,1067-5027,1527-974X,,WOS:000461148100008,30753666,
J,"Docherty, Matt; Regnier, Stephane A.; Capkun, Gorana; Balp, Maria-Magdalena; Ye, Qin; Janssens, Nico; Tietz, Andreas; Loeffler, Juergen; Cai, Jennifer; Pedrosa, Marcos C.; Schattenberg, Jorn M.",,,,"Schattenberg, Jörn M./C-1301-2013","Schattenberg, Jörn M./0000-0002-4224-4703",,,Development of a novel machine learning model to predict presence of nonalcoholic steatohepatitis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1235,1241,,10.1093/jamia/ocab003,,MAR 2021,,JUN 2021,2021,"Objective: To develop a computer model to predict patients with nonalcoholic steatohepatitis (NASH) using machine learning (ML).Materials and Methods: This retrospective study utilized two databases: a) the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) nonalcoholic fatty liver disease (NAFLD) adult database (20042009), and b) the Optum (R) de-identified Electronic Health Record dataset (2007-2018), a real-world dataset representative of common electronic health records in the United States. We developed an ML model to predict NASH, using confirmed NASH and non-NASH based on liver histology results in the NIDDK dataset to train the model.Results: Models were trained and tested on NIDDK NAFLD data (704 patients) and the best-performing models evaluated on Optum data (similar to 3,000,000 patients). An eXtreme Gradient Boosting model (XGBoost) consisting of 14 features exhibited high performance as measured by area under the curve (0.82), sensitivity (81%), and precision (81%) in predicting NASH. Slightly reduced performance was observed with an abbreviated feature set of 5 variables (0.79, 80%, 80%, respectively). The full model demonstrated good performance (AUC 0.76) to predict NASH in Optum data.Discussion: The proposed model, named NASHmap, is the first ML model developed with confirmed NASH and non-NASH cases as determined through liver biopsy and validated on a large, real-world patient dataset. Both the 14 and 5-feature versions exhibit high performance.Conclusion: The NASHmap model is a convenient and high performing tool that could be used to identify patients likely to have NASH in clinical settings, allowing better patient management and optimal allocation of clinical resources.",,,,,,,,,5,0,0,0,0,0,5,,,1067-5027,1527-974X,,WOS:000671031900020,33684933,
J,"Boland, Mary Regina; Parhi, Pradipta; Li, Li; Miotto, Riccardo; Carroll, Robert; Iqbal, Usman; Phung-Anh (Alex) Nguyen; Schuemie, Martijn; You, Seng Chan; Smith, Donahue; Mooney, Sean; Ryan, Patrick; Li, Yu-Chuan (Jack); Park, Rae Woong; Denny, Josh; Dudley, Joel T.; Hripcsak, George; Gentine, Pierre; Tatonetti, Nicholas P.",,,,"Gentine, Pierre/C-1495-2013; Denny, Josh/AAL-3359-2021","Gentine, Pierre/0000-0002-0845-8345; Denny, Josh/0000-0002-3049-7332; MOONEY, SEAN D/0000-0003-2654-0833; Boland, Mary Regina/0000-0001-8576-6408; Li, Li/0000-0001-6746-4297; Miotto, Riccardo/0000-0002-7815-6000",,,Uncovering exposures responsible for birth season - disease effects: a global study,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,3,,,275,288,,10.1093/jamia/ocx105,,,,MAR 2018,2018,"Objective: Birth month and climate impact lifetime disease risk, while the underlying exposures remain largely elusive. We seek to uncover distal risk factors underlying these relationships by probing the relationship between global exposure variance and disease risk variance by birth season.Material and Methods: This study utilizes electronic health record data from 6 sites representing 10.5 million individuals in 3 countries (United States, South Korea, and Taiwan). We obtained birth month-disease risk curves from each site in a case-control manner. Next, we correlated each birth month-disease risk curve with each exposure. A meta-analysis was then performed of correlations across sites. This allowed us to identify the most significant birth month-exposure relationships supported by all 6 sites while adjusting for multiplicity. We also successfully distinguish relative age effects (a cultural effect) from environmental exposures.Results: Attention deficit hyperactivity disorder was the only identified relative age association. Our methods identified several culprit exposures that correspond well with the literature in the field. These include a link between first-trimester exposure to carbon monoxide and increased risk of depressive disorder (R = 0.725, confidence interval [95% CI], 0.529-0.847), first-trimester exposure to fine air particulates and increased risk of atrial fibrillation (R = 0.564, 95% CI, 0.363-0.715), and decreased exposure to sunlight during the third trimester and increased risk of type 2 diabetes mellitus (R = -0.816, 95% CI, -0.5767, -0.929).Conclusion: A global study of birth month-disease relationships reveals distal risk factors involved in causal biological pathways that underlie them.",,,,,,,,,21,0,0,0,8,0,21,,,1067-5027,1527-974X,,WOS:000426850500008,29036387,
J,"Cheah, Seong L.; Scarf, Vanessa L.; Rossiter, Chris; Thornton, Charlene; Homer, Caroline S. E.",,,,,"Scarf, Vanessa/0000-0003-3503-9610",,,Creating the first national linked dataset on perinatal and maternal outcomes in Australia: Methods and challenges,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,93,,,,,,103152,10.1016/j.jbi.2019.103152,,,,MAY 2019,2019,"Background: Data linkage offers a powerful mechanism for examining healthcare outcomes across populations and can generate substantial robust datasets using routinely collected electronic data. However, it presents methodological challenges, especially in Australia where eight separate states and territories maintain health datasets. This study used linked data to investigate perinatal and maternal outcomes in relation to place of birth. It examined data from all eight jurisdictions regarding births planned in hospitals, birth centres and at home. Data linkage enabled the first Australia-wide dataset on birth outcomes. However, jurisdictional differences in data collection created challenges in obtaining comparable cohorts of women with similar low-risk pregnancies in all birth settings. The objective of this paper is to describe the techniques for managing previously linked data, and specifically for ensuring the resulting dataset contained only low-risk pregnancies.Methods: This paper indicates the procedures for preparing and merging linked perinatal, inpatient and mortality data from different sources, providing technical guidance to address challenges arising in linked data study designs.Results: We combined data from eight jurisdictions linking four collections of administrative healthcare and civil registration data. The merging process ensured that variables were consistent, compatible and relevant to study aims. To generate comparable cohorts for all three birth settings, we developed increasingly complex strategies to ensure that the dataset eliminated women with pregnancies at risk of complications during labour and birth. It was then possible to compare birth outcomes for comparable samples, enabling specific examination of the impact of birth setting on maternal and infant safety across Australia.Conclusions: Data linkage is a valuable resource to enhance knowledge about birth outcomes from different settings, notwithstanding methodological challenges. Researchers can develop and share practical techniques to address these challenges. Study findings suggest that jurisdictions develop more consistent data collections to facilitate future data linkage.",,,,,,,,,4,0,0,0,1,0,4,,,1532-0464,1532-0480,,WOS:000525690500006,30890464,
J,"Wang, QuanQiu; Xu, Rong",,,,,,,,CoMNRank: An integrated approach to extract and prioritize human microbial metabolites from MEDLINE records,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,109,,,,,,103524,10.1016/j.jbi.2020.103524,,,,SEP 2020,2020,"Motivation: Trillions of bacteria in human body (human microbiota) affect human health and diseases by controlling host functions through small molecule metabolites.An accurate and comprehensive catalog of the metabolic output from human microbiota is critical for our deep understanding of how microbial metabolism contributes to human health.The large number of published biomedical research articles is a rich resource of microbiome studies.However, automatically extracting microbial metabolites from free-text documents and differentiating them from other human metabolites is a challenging task.Here we developed an integrated approach called Co-occurrence Metabolite Network Ranking (CoMNRank) by combining named entity extraction, network construction and topic sensitive network-based prioritization to extract and prioritize microbial metabolites from biomedical articles.Methods: The text data included 28,851,232 MEDLINE records.CoMNRank consists of three steps: (1) extraction of human metabolites from MEDLINE records; (2) construction of a weighted co-occurrence metabolite network (CoMN); (3) prioritization and differentiation of microbial metabolites from other human metabolites.Results: For the first step of CoMNRank, we extracted 11,846 human metabolites from MEDLINE articles, with a baseline performance of precision of 0.014, recall of 0.959 and Fl of 0.028.We then constructed a weighted CoMN of 6,996 nodes and 986,186 edges.CoMNRank effectively prioritized microbial metabolites: the precision of top ranked metabolites is 0.45, a 31-fold enrichment as compared to the overall precision of 0.014.Manual curation of top 100 metabolites showed a true precision of 0.67, among which 48% true positives are not captured by existing databases.Conclusion: Our study sets the foundation for future tasks of microbial entity and relationship extractions as well as data-driven studies of how microbial metabolism contributes to human health and diseases.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000575072400018,32791237,
J,"Kuo, Tsung-Ting; Gabriel, Rodney A.; Cidambi, Krishna R.; Ohno-Machado, Lucila",,,,,"Kuo, Tsung-Ting/0000-0002-8728-4477",,,EXpectation Propagation LOgistic REgRession on permissioned blockCHAIN (ExplorerChain): decentralized online healthcare/genomics predictive model learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,5,,,747,756,,10.1093/jamia/ocaa023,,,,MAY 2020,2020,"Objective: Predicting patient outcomes using healthcare/genomics data is an increasingly popular/important area. However, some diseases are rare and require data from multiple institutions to construct generalizable models. To address institutional data protection policies, many distributed methods keep the data locally but rely on a central server for coordination, which introduces risks such as a single point of failure. We focus on providing an alternative based on a decentralized approach. We introduce the idea using blockchain technology for this purpose, with a brief description of its own potential advantages/disadvantages.Materials and Methods: We explain how our proposed EXpectation Propagation LOgistic REgRession on Permissioned blockCHAIN (ExplorerChain) can achieve the same results when compared to a distributed model that uses a central server on 3 healthcare/genomic datasets, and what trade-offs need to be considered when using centralized/decentralized methods. We explain how the use of blockchain technology can help decrease some of the problems encountered in decentralized methods.Results: We showed that the discrimination power of ExplorerChain can be statistically similar to its counterpart central server-based algorithm. While ExplorerChain inherited some benefits of blockchain, it had a small increased running time.Discussion: ExplorerChain has the same prerequisites as a distributed model with a centralized server for coordination. In a manner similar to secure multi-party computation strategies, it assumes that participating institutions are honest, but curious.Conclusion: When evaluated on relatively small datasets, results suggest that ExplorerChain, which combines artificial intelligence and blockchain technologies, performs as well as a central server-based method, and may avoid some risks at the cost of efficiency.",,,,,,,,,15,0,0,0,6,0,16,,,1067-5027,1527-974X,,WOS:000537475700010,32364235,
J,"Kim, Jungyeon; Yun, Brian J.; Aaronson, Emily L.; Kaafarani, Haytham M. A.; Linov, Pamela; Rao, Sandhya K.; Weilburg, Jeffery B.; Lee, Jarone",,,,"Kim, Jungyeon/M-2125-2019","Kim, Jungyeon/0000-0002-6261-6084; Yun, Brian/0000-0002-3842-420X",,,The next step to reducing emergency department (ED) crowding: Engaging specialist physicians,,,,,,,,PLOS ONE,,,,13,8,,,,,e0201393,10.1371/journal.pone.0201393,,,,AUG 20 2018,2018,"BackgroundMuch work on reducing ED utilization has focused on primary care practices, but few studies have examined ED visits from patients followed by specialists, especially when the ED visit is related to the specialist's clinical practice.ObjectiveTo determine the proportion and characteristics of patients that utilized the ED for specialtyrelated diagnosis.MethodsRetrospective, population-based, cohort study was conducted using information from electronic health records and billing database between January 2016 and December 2016. Patients who had seen a specialist during the last five years from the index ED visit date were included. The identification of ED visits attributable to specialists was based on the primary diagnosis of ED visits and the frequency of visit with specialists within a given timeframe.ResultsApproximately 28% of ED visits analyzed were attributable to specialists. ED visits attributed specialists were represented by older patients and occurred more during working hours and early days of week. The most common diagnoses related to ED visits attributed to specialists were Circulatory, Musculoskeletal, Skin, Breast and Mental. Multiple departments, subdivisions and specialists were involved with each ED visit. The number of specialists following the patients who visited the ED ranged from one to six and the number of departments/subdivisions ranged from one to four. Patients that used the ED often were more likely to belong to departments (OR = 1.53) and specialists (OR = 1.18) associated with high ED utilization patterns.ConclusionPatients coming to the ED with specialty-related complaints are unique and require full engagement of the specialist and the specialty group. This study offers a new view of connections patients have with their specialists and engaging specialists both at department level and individual specialist level may be an important factor to reduce ED overcrowding.",,,,,,,,,6,0,0,0,1,0,6,,,1932-6203,,,WOS:000442202100008,30125284,
J,"Moen, Hans; Hakala, Kai; Peltonen, Laura-Maria; Suhonen, Henry; Ginter, Filip; Salakoski, Tapio; Salantera, Sanna",,,,,"Moen, Hans/0000-0003-1418-7892; Salantera, Sanna/0000-0003-2529-6699; Peltonen, Laura-Maria/0000-0001-5740-6480",,,Supporting the use of standardized nursing terminologies with automatic subject heading prediction: a comparison of sentence-level text classification methods,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,81,88,,10.1093/jamia/ocz150,,,,JAN 2020,2020,"Objective: This study focuses on the task of automatically assigning standardized (topical) subject headings to free-text sentences in clinical nursing notes. The underlying motivation is to support nurses when they document patient care by developing a computer system that can assist in incorporating suitable subject headings that reflect the documented topics. Central in this study is performance evaluation of several text classification methods to assess the feasibility of developing such a system.Materials and Methods: Seven text classification methods are evaluated using a corpus of approximately 0.5 million nursing notes (5.5 million sentences) with 676 unique headings extracted from a Finnish university hospital. Several of these methods are based on artificial neural networks. Evaluation is first done in an automatic manner for all methods, then a manual error analysis is done on a sample.Results: We find that a method based on a bidirectional long short-term memory network performs best with an average recall of 0.5435 when allowed to suggest 1 subject heading per sentence and 0.8954 when allowed to suggest 10 subject headings per sentence. However, other methods achieve comparable results. The manual analysis indicates that the predictions are better than what the automatic evaluation suggests.Conclusions: The results indicate that several of the tested methods perform well in suggesting the most appropriate subject headings on sentence level. Thus, we find it feasible to develop a text classification system that can support the use of standardized terminologies and save nurses time and effort on care documentation.",,,,,,,,,4,0,0,0,1,1,5,,,1067-5027,1527-974X,,WOS:000548300200011,31605490,
J,"Guo, Aixia; Drake, Bettina F.; Khan, Yosef M.; Langabeer, James R., II; Foraker, Randi E.",,,,,"Foraker, Randi/0000-0001-9255-9394; Drake, Bettina/0000-0001-9340-5848",,,"Time-series cardiovascular risk factors and receipt of screening for breast, cervical, and colon cancer: The Guideline Advantage",,,,,,,,PLOS ONE,,,,15,8,,,,,e0236836,10.1371/journal.pone.0236836,,,,AUG 13 2020,2020,"Background Cancer is the second leading cause of death in the United States. Cancer screenings can detect precancerous cells and allow for earlier diagnosis and treatment. Our purpose was to better understand risk factors for cancer screenings and assess the effect of cancer screenings on changes of Cardiovascular health (CVH) measures before and after cancer screenings among patients. Methods We used The Guideline Advantage (TGA)-American Heart Association ambulatory quality clinical data registry of electronic health record data (n = 362,533 patients) to investigate associations between time-series CVH measures and receipt of breast, cervical, and colon cancer screenings. Long short-term memory (LSTM) neural networks was employed to predict receipt of cancer screenings. We also compared the distributions of CVH factors between patients who received cancer screenings and those who did not. Finally, we examined and quantified changes in CVH measures among the screened and non-screened groups. Results Model performance was evaluated by the area under the receiver operator curve (AUROC): the average AUROC of 10 curves was 0.63 for breast, 0.70 for cervical, and 0.61 for colon cancer screening. Distribution comparison found that screened patients had a higher prevalence of poor CVH categories. CVH submetrics were improved for patients after cancer screenings. Conclusion Deep learning algorithm could be used to investigate the associations between time-series CVH measures and cancer screenings in an ambulatory population. Patients with more adverse CVH profiles tend to be screened for cancers, and cancer screening may also prompt favorable changes in CVH. Cancer screenings may increase patient CVH health, thus potentially decreasing burden of disease and costs for the health system (e.g., cardiovascular diseases and cancers).",,,,,,,,,2,0,0,0,0,0,2,,,1932-6203,,,WOS:000562668300031,32790674,
J,"Matsuo, Ryosuke; Yamazaki, Tomoyoshi; Suzuki, Muneou; Toyama, Hinako; Araki, Kenji",,,,,"Matsuo, Ryosuke/0000-0001-8432-7796",,,A random forest algorithm-based approach to capture latent decision variables and their cutoff values,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,110,,,,,,103548,10.1016/j.jbi.2020.103548,,,,OCT 2020,2020,"Although reference intervals (RIs) and clinical decision limits (CDLs) are vital laboratory information for supporting the interpretation of numerical clinical pathology results, there is evidence that RIs and CDLs vary in certain contexts as well as other evidence that RIs and CDLs are flawed. We propose a random forest algorithm-based exploration methodology by using phenotype transformation of independent variables in relation to dependent variables to capture latent decision variables and their cutoff values. We denote certain CDLs within the RIs estimated by an indirect method that affect some diagnostics or outcomes in the context of specific patients' conditions as latent CDLs. We then apply the proposed methodology to clinical laboratory data regarding bodily fluids, such as blood, urine at the admission of patients for the exploration of latent CDLs of hospital length of stay (HLOS) for each patients' condition identified by diseases of patients who undergoing surgeries. From the exploration results, we found that free Thyroxine (T4) above five unique cutoff values: 1.16 ng/dL, 1.19 ng/dL, 1.2 ng/dL, 1.23 ng/dL and 1.25 ng/dL for tachyarrhythmia predicted longer HLOS, though these cutoff values fall within the estimated RIs as well as the hospital-determined RIs. In addition to the evidence that higher free Thyroxine (T4) levels within the RIs have an association with the corresponding disease, on the whole, the cutoff values except 1.16 ng/dL tended to affect long HLOS with the significant differences. The cutoff values could be taken up for discussion among clinical experts whether it is meaningful to alert the risk of patients' conditions and the long HLOS at the admission of patients. If clinical experts appreciate its meaningfulness in clinical practice, the alerts could be embedded in electronic medical records for handling those risks at the admission of patients.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000579807600010,32866626,
J,"Dong, Hang; Suarez-Paniagua, Victor; Whiteley, William; Wu, Honghan",,,,"Dong, Hang/AAV-4658-2021","Whiteley, William/0000-0002-4816-8991",,,Explainable automated coding of clinical notes using hierarchical label-wise attention networks and label embedding initialisation,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,116,,,,,,103728,10.1016/j.jbi.2021.103728,,MAR 2021,,APR 2021,2021,"Background: Diagnostic or procedural coding of clinical notes aims to derive a coded summary of disease-related information about patients. Such coding is usually done manually in hospitals but could potentially be automated to improve the efficiency and accuracy of medical coding. Recent studies on deep learning for automated medical coding achieved promising performances. However, the explainability of these models is usually poor, preventing them to be used confidently in supporting clinical practice. Another limitation is that these models mostly assume independence among labels, ignoring the complex correlations among medical codes which can potentially be exploited to improve the performance.Methods: To address the issues of model explainability and label correlations, we propose a Hierarchical Labelwise Attention Network (HLAN), which aimed to interpret the model by quantifying importance (as attention weights) of words and sentences related to each of the labels. Secondly, we propose to enhance the major deep learning models with a label embedding (LE) initialisation approach, which learns a dense, continuous vector representation and then injects the representation into the final layers and the label-wise attention layers in the models. We evaluated the methods using three settings on the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS (National Health Service) COVID-19 (Coronavirus disease 2019) shielding codes. Experiments were conducted to compare the HLAN model and label embedding initialisation to the state-of-the-art neural network based methods, including variants of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).Results: HLAN achieved the best Micro-level AUC and F1 on the top-50 code prediction, 91.9% and 64.1%, respectively; and comparable results on the NHS COVID-19 shielding code prediction to other models: around 97% Micro-level AUC. More importantly, in the analysis of model explanations, by highlighting the most salient words and sentences for each label, HLAN showed more meaningful and comprehensive model interpretation compared to the CNN-based models and its downgraded baselines, HAN and HA-GRU. Label embedding (LE) initialisation significantly boosted the previous state-of-the-art model, CNN with attention mechanisms, on the full code prediction to 52.5% Micro-level F1. The analysis of the layers initialised with label embeddings further explains the effect of this initialisation approach. The source code of the implementation and the results are openly available at https://github.com/acadTags/Explainable-Automated-Medical-Coding.Conclusion: We draw the conclusion from the evaluation results and analyses. First, with hierarchical label-wise attention mechanisms, HLAN can provide better or comparable results for automated coding to the state-of-theart, CNN-based models. Second, HLAN can provide more comprehensive explanations for each label by highlighting key words and sentences in the discharge summaries, compared to the n-grams in the CNN-based models and the downgraded baselines, HAN and HA-GRU. Third, the performance of deep learning based multi-label classification for automated coding can be consistently boosted by initialising label embeddings that captures the correlations among labels. We further discuss the advantages and drawbacks of the overall method regarding its potential to be deployed to a hospital and suggest areas for future studies.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000640446800009,33711543,
J,"Carmen, Raisa; Yom-Tov, Galit B.; Van Nieuwenhuyse, Inneke; Foubert, Bram; Ofran, Yishai",,,,"Van Nieuwenhuyse, Inneke/AAD-4356-2020","Carmen, Raisa/0000-0003-1025-8702; Ofran, Yishai/0000-0002-5521-1337; Yom-Tov, Galit/0000-0003-0295-7968; Van Nieuwenhuyse, Inneke/0000-0003-2759-3726",,,The role of specialized hospital units in infection and mortality risk reduction among patients with hematological cancers,,,,,,,,PLOS ONE,,,,14,3,,,,,e0211694,10.1371/journal.pone.0211694,,,,MAR 20 2019,2019,"MotivationPatients with hematological malignancies are susceptible to life-threatening infections after chemotherapy. The current study aimed to evaluate whether management of such patients in dedicated inpatient and emergency wards could provide superior infection prevention and outcome.MethodsWe have developed an approach allowing to retrieve infection-related information from unstructured electronic medical records of a tertiary center. Data on 2,330 adults receiving 13,529 chemotherapy treatments for hematological malignancies were identified and assessed. Infection and mortality hazard rates were calculated with multivariate models. Patients were randomly divided into 80: 20 training and validation cohorts. To develop patient-tailored risk-prediction models, several machine-learning methods were compared using area under the curve (AUC).ResultsOf the tested algorithms, the probit model was found to most accurately predict the evaluated hazards and was implemented in an online calculator. The infection-prediction model identified risk factors for infection based on patient characteristics, treatment and history. Observation of patients with a high predicted infection risk in general wards appeared to increase their infection hazard (p = 0.009) compared to similar patients observed in hematology units. The mortality-risk model demonstrated that for infection events starting at home, admission through hematology services was associated with a lower mortality hazard compared to admission through the general emergency department (p = 0.007). Both models show that dedicated hematological facilities and emergency services improve patient outcome post-chemotherapy. The calculated numbers needed to treat were 30.27 and 31.08 for the dedicated emergency and observation facilities, respectively. Infection hazard risks were found to be non-monotonic in time.ConclusionsThe accuracy of the proposed mortality and infection risk-prediction models was high, with the AUC of 0.74 and 0.83, respectively. Our results demonstrate that temporal assessment of patient risks is feasible. This may enable physicians to move from one-point decision-making to a continuous dynamic observation, allowing a more flexible and patient-tailored admission policy.",,,,,,,,,1,0,0,0,0,0,1,,,1932-6203,,,WOS:000461765900008,30893320,
J,"Brandt, Pascal S.; Pacheco, Jennifer A.; Rasmussen, Luke, V",,,,,"Rasmussen, Luke/0000-0002-4497-8049",,,Development of a repository of computable phenotype definitions using the clinical quality language,,,,,,,,JAMIA OPEN,,,,4,4,,,,,ooab094,10.1093/jamiaopen/ooab094,,,,OCT 2021,2021,"Objective: The objective of this study is to create a repository of computable, technology-agnostic phenotype definitions for the purposes of analysis and automatic cohort identification.Materials and Methods: We selected phenotype definitions from PheKB and excluded definitions that did not use structured data or were not used in published research. We translated these definitions into the Clinical Quality Language (CQL) and Fast Healthcare Interoperability Resources (FHIR) and validated them using code review and automated tests.Results: A total of 33 phenotype definitions met our inclusion criteria. We developed 40 CQL libraries, 231 value sets, and 347 test cases. To support these test cases, a total of 1624 FHIR resources were created as test data. Discussion andConclusion: Although a number of challenges were encountered while translating the phenotypes into structured form, such as requiring specialized knowledge, or imprecise, ambiguous, and conflicting language, we have created a repository and a development environment that can be used for future research on computable phenotypes.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864600009,34926996,
J,"Ju, Meizhi; Nguyen, Nhung T. H.; Miwa, Makoto; Ananiadou, Sophia",,,,"Miwa, Makoto/M-5596-2018","Miwa, Makoto/0000-0002-2330-6972; Nguyen, Nhung/0000-0001-5935-9235",,,An ensemble of neural models for nested adverse drug events and medication extraction with subwords,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,22,30,,10.1093/jamia/ocz075,,,,JAN 2020,2020,"Objective: This article describes an ensembling system to automatically extract adverse drug events and drug related entities from clinical narratives, which was developed for the 2018 n2c2 Shared Task Track 2.Materials and Methods: We designed a neural model to tackle both nested (entities embedded in other entities) and polysemous entities (entities annotated with multiple semantic types) based on MIMIC III discharge summaries. To better represent rare and unknown words in entities, we further tokenized the MIMIC III data set by splitting the words into finer-grained subwords. We finally combined all the models to boost the performance. Additionally, we implemented a featured-based conditional random field model and created an ensemble to combine its predictions with those of the neural model.Results: Our method achieved 92.78% lenient micro F1-score, with 95.99% lenient precision, and 89.79% lenient recall, respectively. Experimental results showed that combining the predictions of either multiple models, or of a single model with different settings can improve performance.Discussion: Analysis of the development set showed that our neural models can detect more informative text regions than feature-based conditional random field models. Furthermore, most entity types significantly benefit from subword representation, which also allows us to extract sparse entities, especially nested entities.Conclusion: The overall results have demonstrated that the ensemble method can accurately recognize entities, including nested and polysemous entities. Additionally, our method can recognize sparse entities by reconsidering the clinical narratives at a finer-grained subword level, rather than at the word level.",,,,,,,,,12,0,0,0,3,0,12,,,1067-5027,1527-974X,,WOS:000548300200004,31197355,
J,"Eisman, Aaron S; Shah, Nishant R; Eickhoff, Carsten; Zerveas, George; Chen, Elizabeth S; Wu, Wen-Chih; Sarkar, Indra Neil",,,,,"Eisman, Aaron/0000-0001-7609-1488",,,Extracting Angina Symptoms from Clinical Notes Using Pre-Trained Transformer Architectures.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,412,421,,,,,,2020,2020,"Anginal symptoms can connote increased cardiac risk and a need for change in cardiovascular management. In this study, a pre-trained transformer architecture was used to automatically detect and characterize anginal symptoms from within the history of present illness sections of 459 primary care physician notes. Consecutive patients referred for cardiac testing were included. Notes were annotated for positive and negative mentions of chest pain and shortness of breath characterization. The results demonstrate high sensitivity and specificity for the detection of chest pain or discomfort, substernal chest pain, shortness of breath, and dyspnea on exertion. Model performance extracting factors related to provocation and palliation of chest pain were limited by small sample size. Overall, this study shows that pre-trained transformer architectures have promise in automating the extraction of anginal symptoms from clinical texts.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936414,33936414,
J,"Davazdahemami, Behrooz; Delen, Dursun",,,,"Delen, Dursun/AAA-2566-2020; Davazdahemami, Behrooz/AAS-7496-2020; Delen, Dursun/O-6938-2015","Delen, Dursun/0000-0001-8857-5148; Davazdahemami, Behrooz/0000-0003-2885-6014; Delen, Dursun/0000-0001-8857-5148",,,A chronological pharmacovigilance network analytics approach for predicting adverse drug events,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,10,,,1311,1321,,10.1093/jamia/ocy097,,,,OCT 2018,2018,"Objectives: This study extends prior research by combining a chronological pharmacovigilance network approach with machine-learning (ML) techniques to predict adverse drug events (ADEs) based on the drugs' similarities in terms of the proteins they target in the human body. The focus of this research, though, is particularly centered on predicting the drug-ADE associations for a set of 8 common and high-risk ADEs.Materials and methods: large collection of annotated MEDLINE biomedical articles was used to construct a drug-ADE network, and the network was further equipped with information about drugs' target proteins. Several network metrics were extracted and used as predictors in ML algorithms to predict the existence of network edges (ie, associations or relationships).Results: Gradient boosted trees (GBTs) as an ensemble ML algorithm outperformed other prediction methods in identifying the drug-ADE associations with an overall accuracy of 92.8% on the validation sample. The prediction model was able to predict drug-ADE associations, on average, 3.84 years earlier than they were actually mentioned in the biomedical literature.Conclusion: While network analysis and ML techniques were used in separation in prior ADE studies, our results showed that they, in combination with each other, can boost the power of one another and predict better. Moreover, our results highlight the superior capability of ensemble-type ML methods in capturing drugADE patterns compared to the regular (ie, singular), ML algorithms.",,,,,,,,,15,0,0,0,8,0,15,,,1067-5027,1527-974X,,WOS:000448166200006,30085102,
J,"Amith, Muhammad; He, Zhe; Bian, Jiang; Lossio-Ventura, Juan Antonio; Tao, Cui",,,,"He, Zhe/M-2593-2018","He, Zhe/0000-0003-3608-0244; Lossio-Ventura, Juan Antonio/0000-0003-0996-2356; Bian, Jiang/0000-0002-2238-5429; Tao, Cui/0000-0002-4267-1924; Amith, Muhammad/0000-0003-4333-1857",,,Assessing the practice of biomedical ontology evaluation: Gaps and opportunities,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,80,,,,1,13,,10.1016/j.jbi.2018.02.010,,,,APR 2018,2018,"With the proliferation of heterogeneous health care data in the last three decades, biomedical ontologies and controlled biomedical terminologies play a more and more important role in knowledge representation and management, data integration, natural language processing, as well as decision support for health information systems and biomedical research. Biomedical ontologies and controlled terminologies are intended to assure interoperability. Nevertheless, the quality of biomedical ontologies has hindered their applicability and subsequent adoption in real-world applications. Ontology evaluation is an integral part of ontology development and maintenance. In the biomedicine domain, ontology evaluation is often conducted by third parties as a quality assurance (or auditing) effort that focuses on identifying modeling errors and inconsistencies. In this work, we first organized four categorical schemes of ontology evaluation methods in the existing literature to create an integrated taxonomy. Further, to understand the ontology evaluation practice in the biomedicine domain, we reviewed a sample of 200 ontologies from the National Center for Biomedical Ontology (NCBO) BioPortal the largest repository for biomedical ontologies and observed that only 15 of these ontologies have documented evaluation in their corresponding inception papers. We then surveyed the recent quality assurance approaches for biomedical ontologies and their use. We also mapped these quality assurance approaches to the ontology evaluation criteria. It is our anticipation that ontology evaluation and quality assurance approaches will be more widely adopted in the development life cycle of biomedical ontologies.",,,,,,,,,23,0,0,0,6,0,23,,,1532-0464,1532-0480,,WOS:000430035000001,29462669,
J,"Hripcsak, George; Levine, Matthew E.; Shang, Ning; Ryan, Patrick B.",,,,,"Levine, Matthew/0000-0002-5627-3169; Shang, Ning/0000-0001-7040-5204",,,Effect of vocabulary mapping for conditions on phenotype cohorts,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,12,,,1618,1625,,10.1093/jamia/ocy124,,,,DEC 2018,2018,"Objective: To study the effect on patient cohorts of mapping condition (diagnosis) codes from source billing vocabularies to a clinical vocabulary.Materials and Methods: Nine International Classification of Diseases, Ninth Revision, Clinical Modification (ICD9-CM) concept sets were extracted from eMERGE network phenotypes, translated to Systematized Nomenclature of Medicine - Clinical Terms concept sets, and applied to patient data that were mapped from source ICD9-CM and ICD10-CM codes to Systematized Nomenclature of Medicine - Clinical Terms codes using Observational Health Data Sciences and Informatics (OHDSI) Observational Medical Outcomes Partnership (OMOP) vocabulary mappings. The original ICD9-CM concept set and a concept set extended to ICD10-CM were used to create patient cohorts that served as gold standards.Results: Four phenotype concept sets were able to be translated to Systematized Nomenclature of Medicine - Clinical Terms without ambiguities and were able to perform perfectly with respect to the gold standards. The other 5 lost performance when 2 or more ICD9-CM or ICD10-CM codes mapped to the same Systematized Nomenclature of Medicine - Clinical Terms code. The patient cohorts had a total error (false positive and false negative) of up to 0.15% compared to querying ICD9-CM source data and up to 0.26% compared to querying ICD9-CM and ICD10-CM data. Knowledge engineering was required to produce that performance; simple automated methods to generate concept sets had errors up to 10% (one outlier at 250%).Discussion: The translation of data from source vocabularies to Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) resulted in very small error rates that were an order of magnitude smaller than other error sources.Conclusion: It appears possible to map diagnoses from disparate vocabularies to a single clinical vocabulary and carry out research using a single set of definitions, thus improving efficiency and transportability of research.",,,,,,,,,21,0,0,0,9,0,20,,,1067-5027,1527-974X,,WOS:000457590600007,30395248,
J,"James, Glen; Reisberg, Sulev; Lepik, Kaido; Galwey, Nicholas; Avillach, Paul; Kolberg, Liis; Magi, Reedik; Esko, Tonu; Alexander, Myriam; Waterworth, Dawn; Loomis, A. Katrina; Vilo, Jaak",,,,"Mägi, Reedik/AAJ-9679-2021; Vilo, Jaak/A-7183-2008; Vilo, Jaak/AAK-2228-2020","Vilo, Jaak/0000-0001-5604-4107; Vilo, Jaak/0000-0001-5604-4107; Lepik, Kaido/0000-0001-9884-3265",,,An exploratory phenome wide association study linking asthma and liver disease genetic variants to electronic health records from the Estonian Biobank,,,,,,,,PLOS ONE,,,,14,4,,,,,e0215026,10.1371/journal.pone.0215026,,,,APR 12 2019,2019,"The Estonian Biobank, governed by the Institute of Genomics at the University of Tartu (Biobank), has stored genetic material/DNA and continuously collected data since 2002 on a total of 52,274 individuals representing similar to 5% of the Estonian adult population and is increasing. To explore the utility of data available in the Biobank, we conducted a phenome-wide association study (PheWAS) in two areas of interest to healthcare researchers; asthma and liver disease. We used 11 asthma and 13 liver disease-associated single nucleotide polymorphisms (SNPs), identified from published genome-wide association studies, to test our ability to detect established associations. We confirmed 2 asthma and 5 liver disease associated variants at nominal significance and directionally consistent with published results. We found 2 associations that were opposite to what was published before (rs4374383: AA increases risk of NASH/NAFLD, rs11597086 increases ALT level). Three SNP-diagnosis pairs passed the phenome-wide significance threshold: rs9273349 and E06 (thyroiditis, p = 5.50x10(-8)); rs9273349 and E10 (type-1 diabetes, p = 2.60x10(-7)); and rs2281135 and K76 (non-alcoholic liver diseases, including NAFLD, p = 4.10x10(-7)). We have validated our approach and confirmed the quality of the data for these conditions. Importantly, we demonstrate that the extensive amount of genetic and medical information from the Estonian Biobank can be successfully utilized for scientific research.",,,,,,,,,6,0,0,0,3,0,6,,,1932-6203,,,WOS:000464349000030,30978214,
J,"Azadani, Mozhgan Nasr; Ghadiri, Nasser; Davoodijam, Ensieh",,,,"Ghadiri, Nasser/AAB-1624-2021","Ghadiri, Nasser/0000-0002-6519-6548",,,Graph-based biomedical text summarization: An itemset mining and sentence clustering approach,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,84,,,,42,58,,10.1016/j.jbi.2018.06.005,,,,AUG 2018,2018,"Objective: Automatic text summarization offers an efficient solution to access the ever-growing amounts of both scientific and clinical literature in the biomedical domain by summarizing the source documents while maintaining their most informative contents. In this paper, we propose a novel graph-based summarization method that takes advantage of the domain-specific knowledge and a well-established data mining technique called frequent itemset mining.Methods: Our summarizer exploits the Unified Medical Language System (UMLS) to construct a concept-based model of the source document and mapping the document to the concepts. Then, it discovers frequent itemsets to take the correlations among multiple concepts into account. The method uses these correlations to propose a similarity function based on which a represented graph is constructed. The summarizer then employs a minimum spanning tree based clustering algorithm to discover various subthemes of the document. Eventually, it generates the final summary by selecting the most informative and relative sentences from all subthemes within the text. Results: We perform an automatic evaluation over a large number of summaries using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics. The results demonstrate that the proposed summarization system outperforms various baselines and benchmark approaches.Conclusion: The carried out research suggests that the incorporation of domain-specific knowledge and frequent itemset mining equips the summarization system in a better way to address the informativeness measurement of the sentences. Moreover, clustering the graph nodes (sentences) can enable the summarizer to target different main subthemes of a source document efficiently. The evaluation results show that the proposed approach can significantly improve the performance of the summarization systems in the biomedical domain.",,,,,,,,,18,0,0,0,2,0,18,,,1532-0464,1532-0480,,WOS:000445054800005,29906584,
J,"Payne, Thomas H.; Alonso, W. David; Markiel, J. Andrew; Lybarger, Kevin; Lordon, Ross; Yetisgen, Meliha; Zech, Jennifer M.; White, Andrew A.",,,,"White, Andrew A/AAW-2681-2021","White, Andrew A/0000-0002-9859-0947",,,"Using voice to create inpatient progress notes: effects on note timeliness, quality, and physician satisfaction",,,,,,,,JAMIA OPEN,,,,1,2,,,218,226,,10.1093/jamiaopen/ooy036,,,,OCT 2018,2018,"Objectives: We describe the evaluation of a system to create hospital progress notes using voice and electronic health record integration to determine if note timeliness, quality, and physician satisfaction are improved.Materials and methods: We conducted a randomized controlled trial to measure effects of this new method of writing inpatient progress notes, which evolved over time, on important outcomes.Results: Intervention subjects created 709 notes and control subjects created 1143 notes. When adjusting for clustering by provider and secular trends, there was no significant difference between the intervention and control groups in the time between when patients were seen on rounds and when progress notes were viewable by others (95% confidence interval -106.9 to 12.2 min). There were no significant differences in physician satisfaction or note quality between intervention and control.Discussion: Though we did not find support for the superiority of this system (Voice-Generated Enhanced Electronic Note System [VGEENS]) for our 3 primary outcomes, if notes are created using voice during or soon after rounds they are available within 10 min. Shortcomings that likely influenced subject satisfaction include the early state of our VGEENS and the short interval for system development before the randomized trial began.Conclusion: VGEENS permits voice dictation on rounds to create progress notes and can reduce delay in note availability and may reduce dependence on copy/paste within notes. Timing of dictation determines when notes are available. Capturing notes in near-real-time has potential to apply NLP and decision support sooner than when notes are typed later in the day, and to improve note accuracy.",,,,,,,,,8,0,0,0,1,0,8,,,,2574-2531,,WOS:000645417100015,31984334,
J,"Dalton-Locke, Christian; Thygesen, Johan H.; Werbeloff, Nomi; Osborn, David; Killaspy, Helen",,,,"; Osborn, David/B-8165-2009","Dalton-Locke, Christian/0000-0002-1876-4741; Osborn, David/0000-0003-2519-1539",,,Using de-identified electronic health records to research mental health supported housing services: A feasibility study,,,,,,,,PLOS ONE,,,,15,8,,,,,e0237664,10.1371/journal.pone.0237664,,,,AUG 20 2020,2020,"Background Mental health supported housing services are a key component in the rehabilitation of people with severe and complex needs. They are implemented widely in the UK and other deinstitutionalised countries but there have been few empirical studies of their effectiveness due to the logistic challenges and costs of standard research methods. The Clinical Record Interactive Search (CRIS) tool, developed to de-identify and interrogate routinely recorded electronic health records, may provide an alternative to evaluate supported housing services. Methods The feasibility of using the Camden and Islington NHS Foundation Trust CRIS database to identify a sample of users of mental health supported accommodation services. Two approaches to data interrogation and case identification were compared; using structured fields indicating individual's accommodation status, and iterative development of free text searches of clinical notes referencing supported housing. The data used were recorded over a 10-year-period (01-January-2008 to 31-December-2017). Results Both approaches were carried out by one full-time researcher over four weeks (150 hours). Two structured fields indicating accommodation status were found, 2,140 individuals had a value in at least one of the fields representative of supported accommodation. The free text search of clinical notes returned 21,103 records pertaining to 1,105 individuals. A manual review of 10% of the notes indicated an estimated 733 of these individuals had used a supported housing service, a positive predictive value of 66.4%. Over two-thirds of the individuals returned in the free text search (768/1,105, 69.5%) were identified via the structured fields approach. Although the estimated positive predictive value was relatively high, a substantial proportion of the individuals appearing only in the free text search (337/1,105, 30.5%) are likely to be false positives. Conclusions It is feasible and requires minimal resources to use de-identified electronic health record search tools to identify large samples of users of mental health supported housing using structured and free text fields. Further work is needed to establish the availability and completion of variables relevant to specific clinical research questions in order to fully assess the utility of electronic health records in evaluating the effectiveness of these services.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000564315600007,32817624,
J,"Kumar, Praveen; Nestsiarovich, Anastasiya; Nelson, Stuart J.; Kerner, Berit; Perkins, Douglas J.; Lambert, Christophe G.",,,,"Lambert, Christophe/AAH-4448-2021","Lambert, Christophe/0000-0003-1994-2893; Nelson, Stuart/0000-0002-8756-0179",,,Imputation and characterization of uncoded self-harm in major mental illness using machine learning,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,1,,,136,146,,10.1093/jamia/ocz173,,,,JAN 2020,2020,"Objective: We aimed to impute uncoded self-harm in administrative claims data of individuals with major mental illness (MMI), characterize self-harm incidence, and identify factors associated with coding bias.Materials and Methods: The IBM MarketScan database (2003-2016) was used to analyze visit-level self-harm in 10 120 030 patients with >= 2 MMI codes. Five machine learning (ML) classifiers were tested on a balanced data subset, with XGBoost selected for the full dataset. Classification performance was validated via random data mislabeling and comparison with a clinician-derived gold standard. The incidence of coded and imputed self-harm was characterized by year, patient age, sex, U.S. state, and MMI diagnosis.Results: Imputation identified 1 592 703 self-harm events vs 83 113 coded events, with areas under the curve >0.99 for the balanced and full datasets, and 83.5% agreement with the gold standard. The overall coded and imputed self-harm incidence were 0.28% and 5.34%, respectively, varied considerably by age and sex, and was highest in individuals with multiple MMI diagnoses. Self-harm undercoding was higher in male than in female individuals and increased with age. Substance abuse, injuries, poisoning, asphyxiation, brain disorders, harmful thoughts, and psychotherapy were the main features used by ML to classify visits.Discussion: Only 1 of 19 self-harm events was coded for individuals with MMI. ML demonstrated excellent performance in recovering self-harm visits. Male individuals and seniors with MMI are particularly vulnerable to self-harm undercoding and may be at risk of not getting appropriate psychiatric care.Conclusions: ML can effectively recover unrecorded self-harm in claims data and inform psychiatric epidemiological and observational studies.",,,,,,,,,3,0,0,0,0,0,3,,,1067-5027,1527-974X,,WOS:000548300200017,31651956,
J,"Kim, Grace Y E; Noshad, Morteza; Stehr, Henning; Rojansky, Rebecca; Gratzinger, Dita; Oak, Jean; Brar, Rondeep; Iberri, David; Kong, Christina; Zehnder, James; Chen, Jonathan H",,,,,"Gratzinger, Dita/0000-0002-9182-8123",,,Machine Learning Predictability of Clinical Next Generation Sequencing for Hematologic Malignancies to Guide High-Value Precision Medicine.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2021,,,,641,650,,,,,,2021,2021,"Advancing diagnostic testing capabilities such as clinical next generation sequencing methods offer the potential to diagnose, risk stratify, and guide specialized treatment, but must be balanced against the escalating costs of healthcare to identify patient cases most likely to benefit from them. Heme-STAMP (Stanford Actionable Mutation Panel for Hematopoietic and Lymphoid Malignancies) is one such next generation sequencing test. Our objective is to assess how well Heme-STAMP pathological variants can be predicted given electronic health records data available at the time of test ordering. The model demonstrated AUROC 0.74 (95% CI: [0.72, 0.76]) with 99% negative predictive value at 6% specificity. A benchmark for comparison is the prevalence of positive results in the dataset at 58.7%. Identifying patients with very low or very high predicted probabilities of finding actionable mutations (positive result) could guide more precise high-value selection of patient cases to test.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:35308914,35308914,
J,"Agiro, Abiy; Chen, Xiaoxue; Eshete, Biruk; Sutphen, Rebecca; Clark, Elizabeth Bourquardez; Burroughs, Cristina M.; Nowell, W. Benjamin; Curtis, Jeffrey R.; Loud, Sara; McBurney, Robert; Merkel, Peter A.; Sreih, Antoine G.; Young, Kalen; Haynes, Kevin",,,,"CHEN, XIAOXUE/AAS-6758-2021","Chen, Xiaoxue/0000-0002-2077-6020; Nowell, William/0000-0002-4951-6476",,,Data linkages between patient-powered research networks and health plans: a foundation for collaborative research,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,7,,,594,602,,10.1093/jamia/ocz012,,,,JUL 2019,2019,"Objective: Patient-powered research networks (PPRNs) are a valuable source of patient-generated information. Diagnosis code-based algorithms developed by PPRNs can be used to query health plans' claims data to identify patients for research opportunities. Our objective was to implement privacy-preserving record linkage processes between PPRN members' and health plan enrollees' data, compare linked and nonlinked members, and measure disease-specific confirmation rates for specific health conditions.Materials and Methods: This descriptive study identified overlapping members from 4 PPRN registries and 14 health plans. Our methods for the anonymous linkage of overlapping members used secure Health Insurance Portability and Accountability Act-compliant, 1-way, cryptographic hash functions. Self-reported diagnoses by PPRN members were compared with claims-based computable phenotypes to calculate confirmation rates across varying durations of health plan coverage.Results: Data for 21 616 PPRN members were hashed. Of these, 4487 (21%) members were linked, regardless of any expected overlap with the health plans. Linked members were more likely to be female and younger than nonlinked members were. Irrespective of duration of enrollment, the confirmation rates for the breast or ovarian cancer, rheumatoid or psoriatic arthritis or psoriasis, multiple sclerosis, or vasculitis PPRNs were 72%, 50%, 75%, and 67%, increasing to 91%, 67%, 93%, and 80%, respectively, for members with >= 5 years of continuous health plan enrollment.Conclusions: This study demonstrated that PPRN membership and health plan data can be successfully linked using privacy-preserving record linkage methodology, and used to confirm self-reported diagnosis. Identifying and confirming self-reported diagnosis of members can expedite patient selection for research opportunities, shorten study recruitment timelines, and optimize costs.",,,,,,,,,10,0,0,0,2,0,10,,,1067-5027,1527-974X,,WOS:000474273800004,30938759,
J,"Gupta, Aakansha; Katarya, Rahul",,,,,"Gupta, Aakansha/0000-0001-7100-0014; Katarya, Prof. Rahul/0000-0001-7763-291X",,,Social media based surveillance systems for healthcare using machine learning: A systematic review,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103500,10.1016/j.jbi.2020.103500,,,,AUG 2020,2020,"Background: Real-time surveillance in the field of health informatics has emerged as a growing domain of interest among worldwide researchers. Evolution in this field has helped in the introduction of various initiatives related to public health informatics. Surveillance systems in the area of health informatics utilizing social media information have been developed for early prediction of disease outbreaks and to monitor diseases. In the past few years, the availability of social media data, particularly Twitter data, enabled real-time syndromic surveillance that provides immediate analysis and instant feedback to those who are charged with follow-ups and investigation of potential outbreaks. In this paper, we review the recent work, trends, and machine learning(ML) text classification approaches used by surveillance systems seeking social media data in the healthcare domain. We also highlight the limitations and challenges followed by possible future directions that can be taken further in this domain.Methods: To study the landscape of research in health informatics performing surveillance of the various health-related data posted on social media or web-based platforms, we present a bibliometric analysis of the 1240 publications indexed in multiple scientific databases (IEEE, ACM Digital Library, ScienceDirect, PubMed) from the year 2010-2018. The papers were further reviewed based on the various machine learning algorithms used for analyzing health-related text posted on social media platforms.Findings:: Based on the corpus of 148 selected articles, the study finds the types of social media or web-based platforms used for surveillance in the healthcare domain, along with the health topic(s) studied by them. In the corpus of selected articles, we found 26 articles were using machine learning technique. These articles were studied to find commonly used ML techniques. The majority of studies (24%) focused on the surveillance of flu or influenza-like illness (ILI). Twitter (64%) is the most popular data source to perform surveillance research using social media text data, and Support Vector Machine (SVM) (33%) being the most used ML algorithm for text classification.Conclusions: The inclusion of online data in surveillance systems has improved the disease prediction ability over traditional syndromic surveillance systems. However, social media based surveillance systems have many limitations and challenges, including noise, demographic bias, privacy issues, etc. Our paper mentions future directions, which can be useful for researchers working in the area. Researchers can use this paper as a library for social media based surveillance systems in the healthcare domain and can expand such systems by incorporating the future works discussed in our paper.",,,,,,,,,26,0,0,0,6,0,26,,,1532-0464,1532-0480,,WOS:000564594600007,32622833,
J,"Lybarger, Kevin; Yetisgen, Meliha; Ostendorf, Mari",,,,,,,,Using Neural Multi-task Learning to Extract Substance Abuse Information from Clinical Notes.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,1395,1404,,,,,,2018,2018,"Substance abuse carries many negative health consequences. Detailed information about patients' substance abuse history is usually captured in free-text clinical notes. Automatic extraction of substance abuse information is vital to assess patients' risk for developing certain diseases and adverse outcomes. We introduce a novel neural architecture to automatically extract substance abuse information. The model, which uses multi-task learning, outperformed previous work and several baselines created using discrete models. The classifier obtained 0.88-0.95 F1 for detecting substance abuse status (current, none, past, unknown) on a withheld test set. Other substance abuse entities (amount, frequency, exposure history, quit history, and type) were also extracted with high-performance. Our results demonstrate the feasibility of extracting substance abuse information with little annotated data. Additionally, we used the neural multi-task model to automatically annotate 59.7K notes from a different source. Manual review of a subset of these notes resulted 0.84-0.89 precision for substance abuse status.",,,,,,,,,1,0,0,0,1,0,1,,,,1942-597X,,MEDLINE:30815184,30815184,
J,"de Melo, Andreia C.; Thuler, Luiz C. S.; da Silva, Jesse L.; de Albuquerque, Lucas Z.; Pecego, Ana C.; Rodrigues, Luciana de O. R.; da Conceicao, Magda S.; Garrido, Marianne M.; Quintella Mendes, Gelcio L.; Mendes Pereira, Ana Cristina P.; Soares, Marcelo A.; Viola, Joao P. B.",,Brazilian Natl Canc Inst COVID-19,,"Soares, Marcelo A/G-5662-2010; de Melo, Andreia/C-8133-2019; Gomes, Renan/ABF-6345-2021","de Melo, Andreia/0000-0002-1201-4333; Gomes, Renan/0000-0002-0897-469X; Viola, Joao/0000-0002-0698-3146; da Silva, Jesse Lopes/0000-0002-0790-9917",,,Cancer inpatients with COVID-19: A report from the Brazilian National Cancer Institute,,,,,,,,PLOS ONE,,,,15,10,,,,,e0241261,10.1371/journal.pone.0241261,,,,OCT 26 2020,2020,"ObjectiveThis study aimed to describe the demographic and clinical characteristics of cancer inpatients with COVID-19 exploring clinical outcomes.MethodsA retrospective search in the electronic medical records of cancer inpatients admitted to the Brazilian National Cancer Institute from April 30, 2020 to May 26, 2020 granted identification of 181 patients with COVID-19 confirmed by RT-PCR.ResultsThe mean age was 55.3 years (SD +/- 21.1). Comorbidities were present in 110 (60.8%) cases. The most prevalent solid tumors were breast (40 [22.1%]), gastrointestinal (24 [13.3%]), and gynecological (22 [12.2%]). Among hematological malignancies, lymphoma (20 [11%]) and leukemia (10 [5.5%]) predominated. Metastatic disease accounted for 90 (49.7%) cases. In total, 63 (34.8%) had recently received cytotoxic chemotherapy. The most common complications were respiratory failure (70 [38.7%]), septic shock (40 [22.1%]) and acute kidney injury (33 [18.2%]). A total of 60 (33.1%) patients died due to COVID-19 complications. For solid tumors, the COVID-19-specific mortality rate was 37.7% (52 out of 138 patients) and for hematological malignancies, 23.5% (8 out of 34). According to the univariate analysis COVID-19-specific mortality was significantly associated with age over 75 years (P = .002), metastatic cancer (p <0.001), two or more sites of metastases (P < .001), the presence of lung (P < .001) or bone metastases (P = .001), non-curative treatment or best supportive care intent (P < .001), higher C-reactive protein levels (P = .002), admission due to COVID-19 (P = .009), and antibiotics use (P = .02). After multivariate analysis, cases with admission due to symptoms of COVID-19 (P = .027) and with two or more metastatic sites (P < .001) showed a higher risk of COVID-19-specific death.ConclusionThis is the first Brazilian cohort of cancer patients with COVID-19. The rates of complications and COVID-19-specific death were significantly high.",,,,,,,,,20,0,0,0,6,1,20,,,1932-6203,,,WOS:000588370000038,33104715,
J,"Shao, Lizhen; Xu, Yadong; Fu, Dongmei",,,,,,,,Classification of ADHD with bi-objective optimization,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,84,,,,164,170,,10.1016/j.jbi.2018.07.011,,,,AUG 2018,2018,"Attention Deficit Hyperactive Disorder (ADHD) is one of the most common diseases in school aged children. In this paper, we consider using fMRI data with classification techniques to aid the diagnosis of ADHD and propose a bi-objective ADHD classification scheme based on L-1-norm support vector machine (SVM). In our classification model, two objectives, namely, the margin of separation and the empirical error are considered at the same time. Then the normal boundary intersection (NBI) method of Das and Dennis is used to solve the bi-objective optimization problem. A representative nondominated set which reflects the entire trade-off information between the two objectives is obtained. Each representative nondominated point in the set corresponds to an efficient classifier. Finally a decision maker can choose a final efficient classifier from the set according to the performance of each classifier. Our scheme avoids the trial and error process for regularization hyper-parameter selection. Experimental results show that our bi-objective optimization classification scheme for ADHD diagnosis performs considerably better than some traditional classification methods.",,,,,,,,,11,1,0,0,2,0,12,,,1532-0464,1532-0480,,WOS:000445054800016,30009990,
J,"Segal, G.; Segev, A.; Brom, A.; Lifshitz, Y.; Wasserstrum, Y.; Zimlichman, E.",,,,,"Wasserstrum, Yishay/0000-0001-8063-2806; Segal, Gad/0000-0002-3851-3245; Segev, Amitai/0000-0002-6653-7543",,,"Reducing drug prescription errors and adverse drug events by application of a probabilistic, machine-learning based clinical decision support system in an inpatient setting",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,12,,,1560,1565,,10.1093/jamia/ocz135,,,,DEC 2019,2019,"Background: Drug prescription errors are made, worldwide, on a daily basis, resulting in a high burden of morbidity and mortality. Existing rule-based systems for prevention of such errors are unsuccessful and associated with substantial burden of false alerts.Objective: In this prospective study, we evaluated the accuracy, validity, and clinical usefulness of medication error alerts generated by a novel system using outlier detection screening algorithms, used on top of a legacy standard system, in a real-life inpatient setting.Materials and Methods: We integrated a novel outlier system into an existing electronic medical record system, in a single medical ward in a tertiary medical center. The system monitored all drug prescriptions written during 16 months. The department's staff assessed all alerts for accuracy, clinical validity, and usefulness. We recorded all physician's real-time responses to alerts generated.Results: The alert burden generated by the system was low, with alerts generated for 0.4% of all medication orders. Sixty percent of the alerts were flagged after the medication was already dispensed following changes in patients' status which necessitated medication changes (eg, changes in vital signs). Eighty-five percent of the alerts were confirmed clinically valid, and 80% were considered clinically useful. Forty-three percent of the alerts caused changes in subsequent medical orders.Conclusion: A clinical decision support system that used a probabilistic, machine-learning approach based on statistically derived outliers to detect medication errors generated clinically useful alerts. The system had high accuracy, low alert burden and low false-positive rate, and led to changes in subsequent orders.",,,,,,,,,13,1,0,0,2,0,14,,,1067-5027,1527-974X,,WOS:000515125300015,31390471,
J,"Hashir, Mohammad; Sawhney (Rupy), Rapinder",,,,,"Hashir, Mohammad/0000-0001-8135-190X",,,Towards unstructured mortality prediction with free-text clinical notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,108,,,,,,103489,10.1016/j.jbi.2020.103489,,,,AUG 2020,2020,"Healthcare data continues to flourish yet a relatively small portion, mostly structured, is being utilized effectively for predicting clinical outcomes. The rich subjective information available in unstructured clinical notes can possibly facilitate higher discrimination but tends to be under-utilized in mortality prediction. This work attempts to assess the gain in performance when multiple notes that have been minimally preprocessed are used as an input for prediction. A hierarchical architecture consisting of both convolutional and recurrent layers is used to concurrently model the different notes compiled in an individual hospital stay. This approach is evaluated on predicting in-hospital mortality on the MIMIC-III dataset. On comparison to approaches utilizing structured data, it achieved higher metrics despite requiring less cleaning and preprocessing. This demonstrates the potential of unstructured data in enhancing mortality prediction and signifies the need to incorporate more raw unstructured data into current clinical prediction methods.",,,,,,,,,2,0,0,0,0,0,2,,,1532-0464,1532-0480,,WOS:000564595700009,32592755,
J,"Luo, Yen-Fu; Sun, Weiyi; Rumshisky, Anna",,,,"Rumshisky, Anna/AAR-6732-2020","Rumshisky, Anna/0000-0002-8029-0823",,,MCN: A comprehensive corpus for medical concept normalization,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,92,,,,,,103132,10.1016/j.jbi.2019.103132,,,,APR 2019,2019,"Normalization of clinical text involves linking different ways of talking about the same clinical concept to the same term in the standardized vocabulary. To date, very few annotated corpora for normalization have been available, and existing corpora so far have been limited in scope and only dealt with the normalization of diseases and disorders. In this paper, we describe the annotation methodology we developed in order to create a new manually annotated wide-coverage corpus for clinical concept normalization, the Medical Concept Normalization (MCN) corpus.In order to ensure wider coverage, we applied normalization to the text spans corresponding to the medical problems, treatments, and tests in the named entity corpus released for the fourth i2b2/VA shared task. In contrast to previous annotation efforts, we do not assign multiple concept labels to the named entities that do not map to a unique concept in the controlled vocabulary. Nor do we leave that named entity without a concept label. Instead, our normalization method that splits such named entities, resolving some of the core ambiguity issues. Lastly, we supply a sieve-based normalization baseline for MCN which combines MetaMap with multiple exact match components. The resulting corpus consists of 100 discharge summaries and provides normalization for the total of 10,919 concept mentions, using 3792 unique concepts from two controlled vocabularies. Our inter-annotator agreement is 67.69% pre-adjudication and 74.20% post-adjudication. Our sieve-based normalization baseline for MCN achieves 77% accuracy in cross-validation. We also detail the challenges of creating a normalization corpus, including the limitations deriving from both the mention span selection and the ambiguity and inconsistency within the current standardized terminologies. In order to facilitate the development of improved concept normalization methods, the MCN corpus will be publicly released to the research community in a shared task in 2019.",,,,,,,,,13,0,0,0,3,0,13,,,1532-0464,1532-0480,,WOS:000525688900007,30802545,
J,"Kashyap, Sehj; Morse, Keith E.; Patel, Birju; Shah, Nigam H.",,,,,"Kashyap, Sehj/0000-0003-0276-2183; Morse, Keith/0000-0002-8307-1642",,,A survey of extant organizational and computational setups for deploying predictive models in health systems,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2445,2450,,10.1093/jamia/ocab154,,AUG 2021,,NOV 2021,2021,"Objective: Artificial intelligence (AI) and machine learning (ML) enabled healthcare is now feasible for many health systems, yet little is known about effective strategies of system architecture and governance mechanisms for implementation. Our objective was to identify the different computational and organizational setups that early-adopter health systems have utilized to integrate AI/ML clinical decision support (AI-CDS) and scrutinize their trade-offs.Materials and Methods: We conducted structured interviews with health systems with AI deployment experience about their organizational and computational setups for deploying AI-CDS at point of care.Results: We contacted 34 health systems and interviewed 20 healthcare sites (58% response rate). Twelve (60%) sites used the native electronic health record vendor configuration for model development and deployment, making it the most common shared infrastructure. Nine (45%) sites used alternative computational configurations which varied significantly. Organizational configurations for managing AI-CDS were distinguished by how they identified model needs, built and implemented models, and were separable into 3 major types: Decentralized translation (n = 10, 50%), IT Department led (n = 2, 10%), and Al in Healthcare (AIHC) Team (n =8, 40%).Discussion: No singular computational configuration enables all current use cases for AI-CDS. Health systems need to consider their desired applications for AI-CDS and whether investment in extending the off-the-shelf infrastructure is needed. Each organizational setup confers trade-offs for health systems planning strategies to implement AI-CDS.Conclusion: Health systems will be able to use this framework to understand strengths and weaknesses of alternative organizational and computational setups when designing their strategy for artificial intelligence.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000711702400015,34423364,
J,"Malec, Scott A.; Wei, Peng; Bernstam, Elmer, V; Boyce, Richard D.; Cohen, Trevor",,,,,"malec, scott/0000-0003-1696-1781",,,Using computable knowledge mined from the literature to elucidate confounders for EHR-based pharmacovigilance,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103719,10.1016/j.jbi.2021.103719,,MAR 2021,,MAY 2021,2021,"Introduction: Drug safety research asks causal questions but relies on observational data. Confounding bias threatens the reliability of studies using such data. The successful control of confounding requires knowledge of variables called confounders affecting both the exposure and outcome of interest. However, causal knowledge of dynamic biological systems is complex and challenging. Fortunately, computable knowledge mined from the literature may hold clues about confounders. In this paper, we tested the hypothesis that incorporating literaturederived confounders can improve causal inference from observational data.Methods: We introduce two methods (semantic vector-based and string-based confounder search) that query literature-derived information for confounder candidates to control, using SemMedDB, a database of computable knowledge mined from the biomedical literature. These methods search SemMedDB for confounders by applying semantic constraint search for indications treated by the drug (exposure) and that are also known to cause the adverse event (outcome). We then include the literature-derived confounder candidates in statistical and causal models derived from free-text clinical notes. For evaluation, we use a reference dataset widely used in drug safety containing labeled pairwise relationships between drugs and adverse events and attempt to rediscover these relationships from a corpus of 2.2 M NLP-processed free-text clinical notes. We employ standard adjustment and causal inference procedures to predict and estimate causal effects by informing the models with varying numbers of literature-derived confounders and instantiating the exposure, outcome, and confounder variables in the models with dichotomous EHR-derived data. Finally, we compare the results from applying these procedures with naive measures of association (chi 2 and reporting odds ratio) and with each other.Results and Conclusions: We found semantic vector-based search to be superior to string-based search at reducing confounding bias. However, the effect of including more rather than fewer literature-derived confounders was inconclusive. We recommend using targeted learning estimation methods that can address treatment-confounder feedback, where confounders also behave as intermediate variables, and engaging subject-matter experts to adjudicate the handling of problematic covariates.",,,,,,,,,0,0,0,0,0,0,0,,,1532-0464,1532-0480,,WOS:000663077000016,33716168,
J,"Lee, Jimin; Noh, Yoojin; Lee, Sukhyang",,,,,,,,Evaluation of preventable adverse drug reactions by implementation of the nationwide network of prospective drug utilization review program in Korea,,,,,,,,PLOS ONE,,,,13,4,,,,,e0195434,10.1371/journal.pone.0195434,,,,APR 11 2018,2018,"BackgroundA prospective Drug Utilization Review (DUR) program has been implemented in Korea to improve the quality and safety of medication use.ObjectiveTo evaluate the influence of the DUR program in reducing incidence of preventable adverse drug reactions (pADRs).MethodsThis study was performed using administrative data from the Health Insurance Review and Assessment Service (HIRA). The claims data for all adult patients with adverse drug events (ADE)-related diagnoses from 2009 to 2014 were obtained. Incidence rates of first-time and repeat pADRs prior to and after DUR program implementation were evaluated. Quarterly trends in incidence rates of overall ADE, allergic reactions, and ADRs were analyzed.ResultsData extraction covering the period from 2009 to 2014 led to the identification of 3,927,662 records. First-time pADR rates decreased gradually after implementation of the DUR program (change in slope: -0.016, p = 0.02). The program had a similar influence on repeat pADR rates (change in slope: -0.006, p <= 0.01). The program did not decrease rates of firsttime or repeat allergic reactions (change in slope: 0.018, p = 0.07 and 0.003, p = 0.04, respectively). In the cohort aged <= 65 years, first-time pADR rate reduction was significant (28.2% [27.1-29.3] in <= 18 years, and 19.8% [18.1-21.5] in 19-64 years). In contrast, firsttime pADR rate was increased by 0.6% [-0.7-1.9] in patients >= 65 years.ConclusionImplementation of the prospective DUR program effectively reduced the number of pADRs. In the future, to reduce non-preventable ADRs such as allergic reactions, provision of clinical information including allergy history should be added to the DUR program.",,,,,,,,,5,0,0,0,1,0,5,,,1932-6203,,,WOS:000429742900069,29641617,
J,"Foraker, Randi E.; Yu, Sean C.; Gupta, Aditi; Michelson, Andrew P.; Soto, Jose A. Pineda; Colvin, Ryan; Loh, Francis; Kollef, Marin H.; Maddox, Thomas; Evanoff, Bradley; Dror, Hovav; Zamstein, Noa; Lai, Albert M.; Payne, Philip R. O.",,,,,"Foraker, Randi/0000-0001-9255-9394",,,Spot the difference: comparing results of analyses from real patient data and synthetic derivatives,,,,,,,,JAMIA OPEN,,,,3,4,,,557,566,,10.1093/jamiaopen/ooaa060,,,,DEC 2020,2020,"Background: Synthetic data may provide a solution to researchers who wish to generate and share data in support of precision healthcare. Recent advances in data synthesis enable the creation and analysis of synthetic derivatives as if they were the original data; this process has significant advantages over data deidentification.Objectives: To assess a big-data platform with data-synthesizing capabilities (MDClone Ltd., Beer Sheva, Israel) for its ability to produce data that can be used for research purposes while obviating privacy and confidentiality concerns.Methods: We explored three use cases and tested the robustness of synthetic data by comparing the results of analyses using synthetic derivatives to analyses using the original data using traditional statistics, machine learning approaches, and spatial representations of the data. We designed these use cases with the purpose of conducting analyses at the observation level (Use Case 1), patient cohorts (Use Case 2), and population-level data (Use Case 3).Results: For each use case, the results of the analyses were sufficiently statistically similar (P> 0.05) between the synthetic derivative and the real data to draw the same conclusions.Discussion and conclusion: This article presents the results of each use case and outlines key considerations for the use of synthetic data, examining their role in clinical research for faster insights and improved data sharing in support of precision healthcare.",,,,,,,,,5,0,0,0,1,0,5,,,,2574-2531,,WOS:000645440800013,33623891,
J,"Brown, Andrew D.; Marotta, Thomas R.",,,,,"Brown, Andrew/0000-0002-5389-308X",,,Using machine learning for sequence-level automated MRI protocol selection in neuroradiology,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,5,,,568,571,,10.1093/jamia/ocx125,,,,MAY 2018,2018,"Incorrect imaging protocol selection can lead to important clinical findings being missed, contributing to both wasted health care resources and patient harm. We present a machine learning method for analyzing the unstructured text of clinical indications and patient demographics from magnetic resonance imaging (MRI) orders to automatically protocol MRI procedures at the sequence level. We compared 3 machine learning models - support vector machine, gradient boosting machine, and random forest - to a baseline model that predicted the most common protocol for all observations in our test set. The gradient boosting machine model significantly outperformed the baseline and demonstrated the best performance of the 3 models in terms of accuracy (95%), precision (86%), recall (80%), and Hamming loss (0.0487). This demonstrates the feasibility of automating sequence selection by applying machine learning to MRI orders. Automated sequence selection has important safety, quality, and financial implications and may facilitate improvements in the quality and safety of medical imaging service delivery.",,,,,,,,,26,0,0,0,3,0,26,,,1067-5027,1527-974X,,WOS:000434113200015,29092082,
J,"Na, Jie; Zong, Nansu; Wang, Chen; Midthun, David E.; Luo, Yuan; Yang, Ping; Jiang, Guoqian",,,,,,,,"Characterizing phenotypic abnormalities associated with high-risk individuals developing lung cancer using electronic health records from the All of Us researcher workbench (vol 28, pg 231, 2021)",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac032,,MAR 2022,,,2022,,,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000771145400001,35311903,
J,"Zhao, Juan; Grabowska, Monika E.; Kerchberger, Vern Eric; Smith, Joshua C.; Eken, H. Nur; Feng, QiPing; Peterson, Josh F.; Rosenbloom, S. Trent; Johnson, Kevin B.; Wei, Wei-Qi",,,,,"Peterson, Josh/0000-0002-7553-0749; Grabowska, Monika/0000-0003-0708-676X",,,ConceptWAS: A high-throughput method for early identification of COVID-19 presenting symptoms and characteristics from clinical notes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,117,,,,,,103748,10.1016/j.jbi.2021.103748,,APR 2021,,MAY 2021,2021,"Objective: Identifying symptoms and characteristics highly specific to coronavirus disease 2019 (COVID-19) would improve the clinical and public health response to this pandemic challenge. Here, we describe a high-throughput approach - Concept-Wide Association Study (ConceptWAS) - that systematically scans a disease's clinical manifestations from clinical notes. We used this method to identify symptoms specific to COVID-19 early in the course of the pandemic.Methods: We created a natural language processing pipeline to extract concepts from clinical notes in a local ER corresponding to the PCR testing date for patients who had a COVID-19 test and evaluated these concepts as predictors for developing COVID-19. We identified predictors from Firth's logistic regression adjusted by age, gender, and race. We also performed ConceptWAS using cumulative data every two weeks to identify the timeline for recognition of early COVID-19-specific symptoms.Results: We processed 87,753 notes from 19,692 patients subjected to COVID-19 PCR testing between March 8, 2020, and May 27, 2020 (1,483 COVID-19-positive). We found 68 concepts significantly associated with a positive COVID-19 test. We identified symptoms associated with increasing risk of COVID-19, including anosmia (odds ratio [OR] = 4.97, 95% confidence interval [CI] = 3.21-7.50), fever (OR = 1.43, 95% CI = 1.28-1.59), cough with fever (OR = 2.29, 95% CI = 1.75-2.96), and ageusia (OR = 5.18, 95% CI = 3.02-8.58). Using ConceptWAS, we were able to detect loss of smell and loss of taste three weeks prior to their inclusion as symptoms of the disease by the Centers for Disease Control and Prevention (CDC).Conclusion: ConceptWAS, a high-throughput approach for exploring specific symptoms and characteristics of a disease like COVID-19, offers a promise for enabling EHR-powered early disease manifestations identification.",,,,,,,,,1,0,0,0,1,0,1,,,1532-0464,1532-0480,,WOS:000663076900014,33774203,
J,"Campbell, Walter S.; Karlsson, Daniel; Vreeman, Daniel J.; Lazenby, Audrey J.; Talmon, Geoffrey A.; Campbell, James R.",,,,,"Vreeman, Daniel/0000-0001-5119-6531",,,A computable pathology report for precision medicine: extending an observables ontology unifying SNOMED CT and LOINC,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,3,,,259,266,,10.1093/jamia/ocx097,,,,MAR 2018,2018,"The College of American Pathologists (CAP) introduced the first cancer synoptic reporting protocols in 1998. However, the objective of a fully computable and machine-readable cancer synoptic report remains elusive due to insufficient definitional content in Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) and Logical Observation Identifiers Names and Codes (LOINC). To address this terminology gap, investigators at the University of Nebraska Medical Center (UNMC) are developing, authoring, and testing a SNOMED CT observable ontology to represent the data elements identified by the synoptic worksheets of CAP.Investigators along with collaborators from the US National Library of Medicine, CAP, the International Health Terminology Standards Development Organization, and the UK Health and Social Care Information Centre analyzed and assessed required data elements for colorectal cancer and invasive breast cancer synoptic reporting. SNOMED CT concept expressions were developed at UNMC in the Nebraska LexiconA (c) SNOMED CT namespace. LOINC codes for each SNOMED CT expression were issued by the Regenstrief Institute. SNOMED CT concepts represented observation answer value sets.UNMC investigators created a total of 194 SNOMED CT observable entity concept definitions to represent required data elements for CAP colorectal and breast cancer synoptic worksheets, including biomarkers. Concepts were bound to colorectal and invasive breast cancer reports in the UNMC pathology system and successfully used to populate a UNMC biobank.The absence of a robust observables ontology represents a barrier to data capture and reuse in clinical areas founded upon observational information. Terminology developed in this project establishes the model to characterize pathology data for information exchange, public health, and research analytics.",,,,,,,,,11,0,0,0,2,0,11,,,1067-5027,1527-974X,,WOS:000426850500006,29024958,
J,"Xie, Kevin; Gallagher, Ryan S.; Conrad, Erin C.; Garrick, Chadric O.; Baldassano, Steven N.; Bernabei, John M.; Galer, Peter D.; Ghosn, Nina J.; Greenblatt, Adam S.; Jennings, Tara; Kornspun, Alana; Kulick-Soper, Catherine, V; Panchal, Jal M.; Pattnaik, Akash R.; Scheid, Brittany H.; Wei, Danmeng; Weitzman, Micah; Muthukrishnan, Ramya; Kim, Joongwon; Litt, Brian; Ellis, Colin A.; Roth, Dan",,,,,"Xie, Kevin/0000-0003-1849-2085",,,Extracting seizure frequency from epilepsy clinic notes: a machine reading approach to natural language processing,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,,,,,,,,10.1093/jamia/ocac018,,FEB 2022,,,2022,"Objective Seizure frequency and seizure freedom are among the most important outcome measures for patients with epilepsy. In this study, we aimed to automatically extract this clinical information from unstructured text in clinical notes. If successful, this could improve clinical decision-making in epilepsy patients and allow for rapid, large-scale retrospective research. Materials and Methods We developed a finetuning pipeline for pretrained neural models to classify patients as being seizure-free and to extract text containing their seizure frequency and date of last seizure from clinical notes. We annotated 1000 notes for use as training and testing data and determined how well 3 pretrained neural models, BERT, RoBERTa, and Bio_ClinicalBERT, could identify and extract the desired information after finetuning. Results The finetuned models (BERTFT, Bio_ClinicalBERT(FT), and RoBERTa(FT)) achieved near-human performance when classifying patients as seizure free, with BERTFT and Bio_ClinicalBERT(FT) achieving accuracy scores over 80%. All 3 models also achieved human performance when extracting seizure frequency and date of last seizure, with overall F-1 scores over 0.80. The best combination of models was Bio_ClinicalBERT(FT) for classification, and RoBERTa(FT) for text extraction. Most of the gains in performance due to finetuning required roughly 70 annotated notes. Discussion and Conclusion Our novel machine reading approach to extracting important clinical outcomes performed at or near human performance on several tasks. This approach opens new possibilities to support clinical practice and conduct large-scale retrospective clinical research. Future studies can use our finetuning pipeline with minimal training annotations to answer new clinical questions.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000758836700001,35190834,
J,"Lavertu, Adam; Altman, Russ B.",,,,,"Altman, Russ/0000-0003-3859-2905",,,RedMed: Extending drug lexicons for social media applications,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103307,10.1016/j.jbi.2019.103307,,,,NOV 2019,2019,"Social media has been identified as a promising potential source of information for pharmacovigilance. The adoption of social media data has been hindered by the massive and noisy nature of the data. Initial attempts to use social media data have relied on exact text matches to drugs of interest, and therefore suffer from the gap between formal drug lexicons and the informal nature of social media. The Reddit comment archive represents an ideal corpus for bridging this gap. We trained a word embedding model, RedMed, to facilitate the identification and retrieval of health entities from Reddit data. We compare the performance of our model trained on a consumer-generated corpus against publicly available models trained on expert-generated corpora. Our automated classification pipeline achieves an accuracy of 0.88 and a specificity of > 0.9 across four different term classes. Of all drug mentions, an average of 79% (+/- 0.5%) were exact matches to a generic or trademark drug name, 14% (+/- 0.5%) were misspellings, 6.4% (+/- 0.3%) were synonyms, and 0.13% (+/- 0.05%) were pill marks. We find that our system captures an additional 20% of mentions; these would have been missed by approaches that rely solely on exact string matches. We provide a lexicon of misspellings and synonyms for 2978 drugs and a word embedding model trained on a health-oriented subset of Reddit.",,,,,,,,,4,0,0,0,2,0,4,,,1532-0464,1532-0480,,WOS:000525701400011,31627020,
J,"Tsiklidis, Evan J; Sinno, Talid; Diamond, Scott L",,,,,"Diamond, Scott/0000-0002-9791-2238",,,Predicting risk for trauma patients using static and dynamic information from the MIMIC III database.,,,,,,,,PloS one,,,,17,1,,,e0262523,e0262523,,10.1371/journal.pone.0262523,,,,2022,2022,"Risk quantification algorithms in the ICU can provide (1) an early alert to the clinician that a patient is at extreme risk and (2) help manage limited resources efficiently or remotely. With electronic health records, large data sets allow the training of predictive models to quantify patient risk. A gradient boosting classifier was trained to predict high-risk and low-risk trauma patients, where patients were labeled high-risk if they expired within the next 10 hours or within the last 10% of their ICU stay duration. The MIMIC-III database was filtered to extract 5,400 trauma patient records (526 non-survivors) each of which contained 5 static variables (age, gender, etc.) and 28 dynamic variables (e.g., vital signs and metabolic panel). Training data was also extracted from the dynamic variables using a 3-hour moving time window whereby each window was treated as a unique patient-time fragment. We extracted the mean, standard deviation, and skew from each of these 3-hour fragments and included them as inputs for training. Additionally, a survival metric upon admission was calculated for each patient using a previously developed National Trauma Data Bank (NTDB)-trained gradient booster model. The final model was able to distinguish between high-risk and low-risk patients to an AUROC of 92.9%, defined as the area under the receiver operator characteristic curve. Importantly, the dynamic survival probability plots for patients who die appear considerably different from those who survive, an example of reducing the high dimensionality of the patient record to a single trauma trajectory.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35045100,35045100,
J,"Sarker, Abeed; Gonzalez-Hernandez, Graciela",,,,"Sarker, Abeed/W-1044-2019","Sarker, Abeed/0000-0001-7358-544X; Gonzalez Hernandez, Graciela/0000-0002-6416-9556",,,An unsupervised and customizable misspelling generator for mining noisy health-related text sources,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,88,,,,98,107,,10.1016/j.jbi.2018.11.007,,,,DEC 2018,2018,"Background: Data collection and extraction from noisy text sources such as social media typically rely on keyword-based searching/listening. However, health-related terms are often misspelled in such noisy text sources due to their complex morphology, resulting in the exclusion of relevant data for studies. In this paper, we present a customizable data-centric system that automatically generates common misspellings for complex health-related terms, which can improve the data collection process from noisy text sources.Materials and methods: The spelling variant generator relies on a dense vector model learned from large, unlabeled text, which is used to find semantically close terms to the original/seed keyword, followed by the filtering of terms that are lexically dissimilar beyond a given threshold. The process is executed recursively, converging when no new terms similar (lexically and semantically) to the seed keyword are found. The weighting of intra-word character sequence similarities allows further problem-specific customization of the system.Results: On a dataset prepared for this study, our system outperforms the current state-of-the-art medication name variant generator with best F-1 score of 0.69 and F-1/4 - score of 0.78. Extrinsic evaluation of the system on a set of cancer-related terms demonstrated an increase of over 67% in retrieval rate from Twitter posts when the generated variants are included.Discussion. Our proposed spelling variant generator has several advantages over past spelling variant generators - (i) it is capable of filtering out lexically similar but semantically dissimilar terms, (ii) the number of variants generated is low, as many low-frequency and ambiguous misspellings are filtered out, and (iii) the system is fully automatic, customizable and easily executable. While the base system is fully unsupervised, we show how supervision may be employed to adjust weights for task-specific customizations.Conclusion: The performance and relative simplicity of our proposed approach make it a much-needed spelling variant generation resource for health-related text mining from noisy sources. The source code for the system has been made publicly available for research.",,,,,,,,,21,0,0,0,8,0,21,,,1532-0464,1532-0480,,WOS:000460600200010,30445220,
J,"Bai, Lawrence; Scott, Madeleine K. D.; Steinberg, Ethan; Kalesinskas, Laurynas; Habtezion, Aida; Shah, Nigam H.; Khatri, Purvesh",,,,,"Khatri, Purvesh/0000-0002-4143-4708",,,Computational drug repositioning of atorvastatin for ulcerative colitis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2325,2335,,10.1093/jamia/ocab165,,SEP 2021,,NOV 2021,2021,"Objective: Ulcerative colitis (UC) is a chronic inflammatory disorder with limited effective therapeutic options for long-term treatment and disease maintenance. We hypothesized that a multi-cohort analysis of independent cohorts representing real-world heterogeneity of UC would identify a robust transcriptomic signature to improve identification of FDA-approved drugs that can be repurposed to treat patients with UC.Materials and Methods: We performed a multi-cohort analysis of 272 colon biopsy transcriptome samples across 11 publicly available datasets to identify a robust UC disease gene signature. We compared the gene signature to in vitro transcriptomic profiles induced by 781 FDA-approved drugs to identify potential drug targets. We used a retrospective cohort study design modeled after a target trial to evaluate the protective effect of predicted drugs on colectomy risk in patients with UC from the Stanford Research Repository (STARR) database and Optum Clinformatics DataMart.Results: Atorvastatin treatment had the highest inverse-correlation with the UC gene signature among non-oncolytic FDA-approved therapies. In both STARR (n =827) and Optum (n=7821), atorvastatin intake was significantly associated with a decreased risk of colectomy, a marker of treatment-refractory disease, compared to patients prescribed a comparator drug (STARR: HR = 0.47, P= .03; Optum: HR = 0.66, P=.03), irrespective of age and length of atorvastatin treatment.Discussion & Conclusion: These findings suggest that atorvastatin may serve as a novel therapeutic option for ameliorating disease in patients with UC. Importantly, we provide a systematic framework for integrating publicly available heterogeneous molecular data with clinical data at a large scale to repurpose existing FDA-approved drugs for a wide range of human diseases.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000711702400003,34529084,
J,"Read, Robert W.; Schlauch, Karen A.; Elhanan, Gai; Metcalf, William J.; Slonim, Anthony D.; Aweti, Ramsey; Borkowski, Robert; Grzymski, Joseph J.",,,,,"Grzymski, Joseph/0000-0003-2646-8958; Read, Robert/0000-0002-6967-5634",,,GWAS and PheWAS of red blood cell components in a Northern Nevadan cohort,,,,,,,,PLOS ONE,,,,14,6,,,,,e0218078,10.1371/journal.pone.0218078,,,,JUN 13 2019,2019,"In this study, we perform a full genome-wide association study (GWAS) to identify statistically significantly associated single nucleotide polymorphisms (SNPs) with three red blood cell (RBC) components and follow it with two independent PheWASs to examine associations between phenotypic data (case-control status of diagnoses or disease), significant SNPs, and RBC component levels. We first identified associations between the three RBC components: mean platelet volume (MPV), mean corpuscular volume (MCV), and platelet counts (PC), and the genotypes of approximately 500,000 SNPs on the Illumina Infimum DNA Human OmniExpress-24 BeadChip using a single cohort of 4,673 Northern Nevadans. Twenty-one SNPs in five major genomic regions were found to be statistically significantly associated with MPV, two regions with MCV, and one region with PC, with p<5x10(-8). Twenty-nine SNPs and nine chromosomal regions were identified in 30 previous GWASs, with effect sizes of similar magnitude and direction as found in our cohort. The two strongest associations were SNP rs1354034 with MPV (p = 2.4x10(-13)) and rs855791 with MCV (p = 5.2x10(-12)). We then examined possible associations between these significant SNPs and incidence of 1,488 phenotype groups mapped from International Classification of Disease version 9 and 10 (ICD9 and ICD10) codes collected in the extensive electronic health record (EHR) database associated with Healthy Nevada Project consented participants. Further leveraging data collected in the EHR, we performed an additional PheWAS to identify associations between continuous red blood cell (RBC) component measures and incidence of specific diagnoses. The first PheWAS illuminated whether SNPs associated with RBC components in our cohort were linked with other hematologic phenotypic diagnoses or diagnoses of other nature. Although no SNPs from our GWAS were identified as strongly associated to other phenotypic components, a number of associations were identified with p-values ranging between 1x10(-3) and 1x10(-4) with traits such as respiratory failure, sleep disorders, hypoglycemia, hyperglyceridemia, GERD and IBS. The second PheWAS examined possible phenotypic predictors of abnormal RBC component measures: a number of hematologic phenotypes such as thrombocytopenia, anemias, hemoglobinopathies and pancytopenia were found to be strongly associated to RBC component measures; additional phenotypes such as (morbid) obesity, malaise and fatigue, alcoholism, and cirrhosis were also identified to be possible predictors of RBC component measures.",,,,,,,,,6,0,0,0,5,0,6,,,1932-6203,,,WOS:000471238300041,31194788,
J,"Jung, Kenneth; Kashyap, Sehj; Avati, Anand; Harman, Stephanie; Shaw, Heather; Li, Ron; Smith, Margaret; Shum, Kenny; Javitz, Jacob; Vetteth, Yohan; Seto, Tina; Bagley, Steven C.; Shah, Nigam H.",,,,,"Seto, Tina/0000-0002-7937-9564",,,A framework for making predictive models useful in practice,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1149,1158,,10.1093/jamia/ocaa318,,,,JUN 2021,2021,"Objective: To analyze the impact of factors in healthcare delivery on the net benefit of triggering an Advanced Care Planning (ACP) workflow based on predictions of 12-month mortality.Materials and Methods: We built a predictive model of 12-month mortality using electronic health record data and evaluated the impact of healthcare delivery factors on the net benefit of triggering an ACP workflow based on the models' predictions. Factors included nonclinical reasons that make ACP inappropriate: limited capacity for ACP, inability to follow up due to patient discharge, and availability of an outpatient workflow to follow up on missed cases. We also quantified the relative benefits of increasing capacity for inpatient ACP versus outpatient ACP.Results: Work capacity constraints and discharge timing can significantly reduce the net benefit of triggering the ACP workflow based on a model's predictions. However, the reduction can be mitigated by creating an outpatient ACP workflow. Given limited resources to either add capacity for inpatient ACP versus developing outpatient ACP capability, the latter is likely to provide more benefit to patient care.Discussion: The benefit of using a predictive model for identifying patients for interventions is highly dependent on the capacity to execute the workflow triggered by the model. We provide a framework for quantifying the impact of healthcare delivery factors and work capacity constraints on achieved benefit.Conclusion: An analysis of the sensitivity of the net benefit realized by a predictive model triggered clinical workflow to various healthcare delivery factors is necessary for making predictive models useful in practice.",,,,,,,,,6,0,0,0,2,0,6,,,1067-5027,1527-974X,,WOS:000671031900011,33355350,
J,"Rattsev, Ilia; Flaks-Manov, Natalie; Jelin, Angie C.; Bai, Jiawei; Taylor, Casey Overby",,,,,,,,Recurrent preterm birth risk assessment for two delivery subtypes: A multivariable analysis,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,29,2,,,306,320,,10.1093/jamia/ocab184,,SEP 2021,,FEB 2021,2021,"Objective: The study sought to develop and apply a framework that uses a clinical phenotyping tool to assess risk for recurrent preterm birth.Materials and Methods: We extended an existing clinical phenotyping tool and applied a 4-step framework for our retrospective cohort study. The study was based on data collected in the Genomic and Proteomic Network for Preterm Birth Research Longitudinal Cohort Study (GPN-PBR LS). A total of 52 sociodemographic, clinical and obstetric history-related risk factors were selected for the analysis. Spontaneous and indicated delivery subtypes were analyzed both individually and in combination. Chi-square analysis and Kaplan-Meier estimate were used for univariate analysis. A Cox proportional hazards model was used for multivariable analysis.Results: A total of 428 women with a history of spontaneous preterm birth qualified for our analysis. The predictors of preterm delivery used in multivariable model were maternal age, maternal race, household income, marital status, previous caesarean section, number of previous deliveries, number of previous abortions, previous birth weight, cervical insufficiency, decidual hemorrhage, and placental dysfunction. The models stratified by delivery subtype performed better than the naive model (concordance 0.76 for the spontaneous model, 0.87 for the indicated model, and 0.72 for the naive model).Discussion: The proposed 4-step framework is effective to analyze risk factors for recurrent preterm birth in a retrospective cohort and possesses practical features for future analyses with other data sources (eg, electronic health record data).Conclusions: We developed an analytical framework that utilizes a clinical phenotyping tool and performed a survival analysis to analyze risk for recurrent preterm birth.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000749569600009,34559221,
J,"Meyer, Melanie A.",,,,,,,,"Healthcare data scientist qualifications, skills, and job focus: a content analysis of job postings",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,5,,,383,391,,10.1093/jamia/ocy181,,,,MAY 2019,2019,"Objective: Growth in big data and its potential impact on the healthcare industry have driven the need for more data scientists. In health care, big data can be used to improve care quality, increase efficiency, lower costs, and drive innovation. Given the importance of data scientists to U.S. healthcare organizations, I examine the qualifications and skills these organizations require for data scientist positions and the specific focus of their work.Materials and Methods: A content analysis of U.S. healthcare data scientist job postings was conducted using an inductive approach to capture and categorize core information about each posting and a deductive approach to evaluate skills required. Profiles were generated for 4 job focus areas.Results: There is a spectrum of healthcare data scientist positions that varies based on hiring organization type, job level, and job focus area. The focus of these positions ranged from performance improvement to innovation and product development with some positions more broadly defined to address organizational-specific needs. Based on the job posting sample, the primary skills these organizations required were statistics, R, machine learning, storytelling, and Python.Conclusions: These results may be useful to organizations as they deepen our understanding of the qualifications and skills required for data scientist positions and may aid organizations in identifying skills and knowledge areas that have been overlooked in position postings.",,,,,,,,,17,0,0,0,4,0,17,,,1067-5027,1527-974X,,WOS:000465119800002,30830169,
J,"Dagliati, Arianna; Sacchi, Lucia; Tibollo, Valentina; Cogni, Giulia; Teliti, Marsida; Martinez-Millana, Antonio; Traver, Vicente; Segagni, Daniele; Posada, Jorge; Ottaviano, Manuel; Fico, Giuseppe; Teresa Arredondo, Maria; De Cata, Pasquale; Chiovato, Luca; Bellazzi, Riccardo",,,,"SACCHI, LUCIA/AAC-5074-2022; Cogni, Giulia/AAC-1747-2020; chiovato, luca/AAC-9003-2019; Tibollo, Valentina/AAC-1652-2020; Martinez-Millana, Antonio/O-8012-2015; Chiovato, Luca/K-6617-2016; De Cata, Pasquale/AAC-7854-2020; dagliati, arianna/I-7119-2019; Waldmeyer, María Teresa Arredondo/AAQ-1497-2021; Bellazzi, Riccardo/J-6432-2018; Fico, Giuseppe/K-3640-2017","SACCHI, LUCIA/0000-0002-1390-9825; Tibollo, Valentina/0000-0003-2687-3822; Martinez-Millana, Antonio/0000-0003-1056-5067; Chiovato, Luca/0000-0001-7457-7353; De Cata, Pasquale/0000-0002-6342-1203; dagliati, arianna/0000-0002-5041-0409; Waldmeyer, María Teresa Arredondo/0000-0003-3113-3976; Bellazzi, Riccardo/0000-0002-6974-9808; Fico, Giuseppe/0000-0003-1551-4613; Ottaviano, Manuel/0000-0003-0002-4988; cogni, giulia/0000-0003-2556-813X",,,A dashboard-based system for supporting diabetes care,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,5,,,538,547,,10.1093/jamia/ocx159,,,,MAY 2018,2018,"Objective: To describe the development, as part of the European Union MOSAIC (Models and Simulation Techniques for Discovering Diabetes Influence Factors) project, of a dashboard-based system for the management of type 2 diabetes and assess its impact on clinical practice.Methods: The MOSAIC dashboard system is based on predictive modeling, longitudinal data analytics, and the reuse and integration of data from hospitals and public health repositories. Data are merged into an i2b2 data warehouse, which feeds a set of advanced temporal analytic models, including temporal abstractions, care-flow mining, drug exposure pattern detection, and risk-prediction models for type 2 diabetes complications. The dashboard has 2 components, designed for (1) clinical decision support during follow-up consultations and (2) outcome assessment on populations of interest. To assess the impact of the clinical decision support component, a pre-post study was conducted considering visit duration, number of screening examinations, and lifestyle interventions. A pilot sample of 700 Italian patients was investigated. Judgments on the outcome assessment component were obtained via focus groups with clinicians and health care managers.Results: The use of the decision support component in clinical activities produced a reduction in visit duration (P << .01) and an increase in the number of screening exams for complications (P < .01). We also observed a relevant, although nonstatistically significant, increase in the proportion of patients receiving lifestyle interventions (from 69% to 77%). Regarding the outcome assessment component, focus groups highlighted the system's capability of identifying and understanding the characteristics of patient subgroups treated at the center.Conclusion: Our study demonstrates that decision support tools based on the integration of multiple-source data and visual and predictive analytics do improve the management of a chronic disease such as type 2 diabetes by enacting a successful implementation of the learning health care system cycle.",,,,,,,,,21,0,0,0,1,0,21,,,1067-5027,1527-974X,,WOS:000434113200011,29409033,
J,"Zhang, Hansi; Wheldon, Christopher; Dunn, Adam G.; Tao, Cui; Huo, Jinhai; Zhang, Rui; Prosperi, Mattia; Guo, Yi; Bian, Jiang",,,,"; Dunn, Adam/E-6828-2011","Tao, Cui/0000-0002-4267-1924; Dunn, Adam/0000-0002-1720-8209",,,Mining Twitter to assess the determinants of health behavior toward human papillomavirus vaccination in the United States,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,2,,,225,235,,10.1093/jamia/ocz191,,,,FEB 2020,2020,"Objectives: The study sought to test the feasibility of using Twitter data to assess determinants of consumers' health behavior toward human papillomavirus (HPV) vaccination informed by the Integrated Behavior Model (IBM).Materials and Methods: We used 3 Twitter datasets spanning from 2014 to 2018. We preprocessed and geocoded the tweets, and then built a rule-based model that classified each tweet into either promotional information or consumers' discussions. We applied topic modeling to discover major themes and subsequently explored the associations between the topics learned from consumers' discussions and the responses of HPV-related questions in the Health Information National Trends Survey (HINTS).Results: We collected 2 846 495 tweets and analyzed 335 681 geocoded tweets. Through topic modeling, we identified 122 high-quality topics. The most discussed consumer topic is cervical cancer screening; while in promotional tweets, the most popular topic is to increase awareness of HPV causes cancer. A total of 87 of the 122 topics are correlated between promotional information and consumers' discussions. Guided by IBM, we examined the alignment between our Twitter findings and the results obtained from HINTS. Thirty-five topics can be mapped to HINTS questions by keywords, 112 topics can be mapped to IBM constructs, and 45 topics have statistically significant correlations with HINTS responses in terms of geographic distributions.Conclusions: Mining Twitter to assess consumers' health behaviors can not only obtain results comparable to surveys, but also yield additional insights via a theory-driven approach. Limitations exist; nevertheless, these encouraging results impel us to develop innovative ways of leveraging social media in the changing health communication landscape.",,,,,,,,,15,0,0,0,2,0,15,,,1067-5027,1527-974X,,WOS:000515121300006,31711186,
J,"Barnett, Ian; Torous, John; Staples, Patrick; Keshavan, Matcheri; Onnela, Jukka-Pekka",,,,,,,,Beyond smartphones and sensors: choosing appropriate statistical methods for the analysis of longitudinal data,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,12,,,1669,1674,,10.1093/jamia/ocy121,,,,DEC 2018,2018,"Objectives: As smartphones and sensors become more prominently used in mobile health, the methods used to analyze the resulting data must also be carefully considered. The advantages of smartphone-based studies, including large quantities of temporally dense longitudinally captured data, must be matched with the appropriate statistical methods in order draw valid conclusions. In this paper, we review and provide recommendations in 3 critical domains of analysis for these types of temporally dense longitudinal data and highlight how misleading results can arise from improper use of these methods.Target Audience: Clinicians, biostatisticians, and data analysts who have digital phenotyping data or are interested in performing a digital phenotyping study or any other type of longitudinal study with frequent measurements taken over an extended period of time.Scope: We cover the following topics: 1) statistical models using longitudinal repeated measures, 2) multiple comparisons of correlated tests, and 3) dimension reduction for correlated behavioral covariates. While these 3 classes of methods are frequently used in digital phenotyping data analysis, we demonstrate via actual clinical studies data that they may sometimes not perform as expected when applied to novel digital data.",,,,,,,,,22,0,0,0,7,0,22,,,1067-5027,1527-974X,,WOS:000457590600013,30272176,
J,"Patel, Riyaz S; Denaxas, Spiros; Howe, Laurence J; Eggo, Rosalind M; Shah, Anoop D; Allen, Naomi E; Danesh, John; Hingorani, Aroon; Sudlow, Cathie; Hemingway, Harry",,,,"Hemingway, Harry/C-1219-2009","Hemingway, Harry/0000-0003-2279-0624",,,Reproducible disease phenotyping at scale: Example of coronary artery disease in UK Biobank.,,,,,,,,PloS one,,,,17,4,,,e0264828,e0264828,,10.1371/journal.pone.0264828,,,,2022,2022,"IMPORTANCE: A lack of internationally agreed standards for combining available data sources at scale risks inconsistent disease phenotyping limiting research reproducibility.OBJECTIVE: To develop and then evaluate if a rules-based algorithm can identify coronary artery disease (CAD) sub-phenotypes using electronic health records (EHR) and questionnaire data from UK Biobank (UKB).DESIGN: Case-control and cohort study.SETTING: Prospective cohort study of 502K individuals aged 40-69 years recruited between 2006-2010 into the UK Biobank with linked hospitalization and mortality data and genotyping.PARTICIPANTS: We included all individuals for phenotyping into 6 predefined CAD phenotypes using hospital admission and procedure codes, mortality records and baseline survey data. Of these, 408,470 unrelated individuals of European descent had a polygenic risk score (PRS) for CAD estimated.EXPOSURE: CAD Phenotypes.MAIN OUTCOMES AND MEASURES: Association with baseline risk factors, mortality (n = 14,419 over 7.8 years median f/u), and a PRS for CAD.RESULTS: The algorithm classified individuals with CAD into prevalent MI (n = 4,900); incident MI (n = 4,621), prevalent CAD without MI (n = 10,910), incident CAD without MI (n = 8,668), prevalent self-reported MI (n = 2,754); prevalent self-reported CAD without MI (n = 5,623), yielding 37,476 individuals with any type of CAD. Risk factors were similar across the six CAD phenotypes, except for fewer men in the self-reported CAD without MI group (46.7% v 70.1% for the overall group). In age- and sex- adjusted survival analyses, mortality was highest following incident MI (HR 6.66, 95% CI 6.07-7.31) and lowest for prevalent self-reported CAD without MI at baseline (HR 1.31, 95% CI 1.15-1.50) compared to disease-free controls. There were similar graded associations across the six phenotypes per SD increase in PRS, with the strongest association for prevalent MI (OR 1.50, 95% CI 1.46-1.55) and the weakest for prevalent self-reported CAD without MI (OR 1.08, 95% CI 1.05-1.12). The algorithm is available in the open phenotype HDR UK phenotype library (https://portal.caliberresearch.org/).CONCLUSIONS: An algorithmic, EHR-based approach distinguished six phenotypes of CAD with distinct survival and PRS associations, supporting adoption of open approaches to help standardize CAD phenotyping and its wider potential value for reproducible research in other conditions.",,,,,,,,,0,0,0,0,0,0,0,,,,1932-6203,,MEDLINE:35381005,35381005,
J,"Klann, Jeffrey G.; Phillips, Lori C.; Herrick, Christopher; Joss, Matthew A. H.; Wagholikar, Kavishwar B.; Murphy, Shawn N.",,,,"Wagholikar, Kavishwar/M-1249-2013","Wagholikar, Kavishwar/0000-0002-6219-861X",,,Web services for data warehouses: OMOP and PCORnet on i2b2,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,25,10,,,1331,1338,,10.1093/jamia/ocy093,,,,OCT 2018,2018,"Objective: Healthcare organizations use research data models supported by projects and tools that interest them, which often means organizations must support the same data in multiple models. The healthcare research ecosystem would benefit if tools and projects could be adopted independently from the underlying data model. Here, we introduce the concept of a reusable application programming interface (API) for healthcare and show that the i2b2 API can be adapted to support diverse patient-centric data models.Materials and Methods: We develop methodology for extending i2b2's pre-existing API to query additional data models, using i2b2's recent multi-fact-table querying feature. Our method involves developing data-model-specific i2b2 ontologies and mapping these to query non-standard table structure.Results: We implement this methodology to query OMOP and PCORnet models, which we validate with the i2b2 query tool. We implement the entire PCORnet data model and a five-domain subset of the OMOP model. We also demonstrate that additional, ancillary data model columns can be modeled and queried as i2b2 modifiers.Discussion: i2b2' s REST API can be used to query multiple healthcare data models, enabling shared tooling to have a choice of backend data stores. This enables separation between data model and software tooling for some of the more popular open analytic data models in healthcare.Conclusion: This methodology immediately allows querying OMOP and PCORnet using the i2b2 API. It is released as an open-source set of Docker images, and also on the i2b2 community wiki.",,,,,,,,,11,0,0,0,2,0,11,,,1067-5027,1527-974X,,WOS:000448166200008,30085008,
J,"Liu, Cong; Yuan, Chi; Butler, Alex M.; Carvajal, Richard D.; Li, Ziran Ryan; Ta, Casey N.; Weng, Chunhua",,,,"Carvajal, Richard/ABA-3285-2021",,,,DQueST: dynamic questionnaire for search of clinical trials,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,11,,,1333,1343,,10.1093/jamia/ocz121,,,,NOV 2019,2019,"Objective: Information overload remains a challenge for patients seeking clinical trials. We present a novel system (DQueST) that reduces information overload for trial seekers using dynamic questionnaires.Materials and Methods: DQueST first performs information extraction and criteria library curation. DQueST transforms criteria narratives in the ClinicalTrials.gov repository into a structured format, normalizes clinical entities using standard concepts, clusters related criteria, and stores the resulting curated library. DQueST then implements a real-time dynamic question generation algorithm. During user interaction, the initial search is similar to a standard search engine, and then DQueST performs real-time dynamic question generation to select criteria from the library 1 at a time by maximizing its relevance score that reflects its ability to rule out ineligible trials. DQueST dynamically updates the remaining trial set by removing ineligible trials based on user responses to corresponding questions. The process iterates until users decide to stop and begin manually reviewing the remaining trials.Results: In simulation experiments initiated by 10 diseases, DQueST reduced information overload by filtering out 60%-80% of initial trials after 50 questions. Reviewing the generated questions against previous answers, on average, 79.7% of the questions were relevant to the queried conditions. By examining the eligibility of random samples of trials ruled out by DQueST, we estimate the accuracy of the filtering procedure is 63.7%. In a study using 5 mock patient profiles, DQueST on average retrieved trials with a 1.465 times higher density of eligible trials than an existing search engine. In a patient-centered usability evaluation, patients found DQueST useful, easy to use, and returning relevant results.Conclusion: DQueST contributes a novel framework for transforming free-text eligibility criteria to questions and filtering out clinical trials based on user answers to questions dynamically. It promises to augment keyword-based methods to improve clinical trial search.",,,,,,,,,4,0,0,0,1,0,4,,,1067-5027,1527-974X,,WOS:000498169400022,31390010,
J,"Oberhardt, Matthew; Friedman, Alexander M; Perotte, Rimma; Sheen, Jean-Ju; Kessler, Alan; Vawdrey, David K; Green, Robert; D'Alton, Mary E; Goffman, Dena",,,,,"Perotte, Rimma/0000-0002-7686-189X",,,A principled framework for phenotyping postpartum hemorrhage across multiple levels of severity.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2019,,,,691,698,,,,,,2019,2019,"Maternal morbidity and mortality have gained major attention recently, spurred on by rising domestic rates even as maternal mortality decreases in Europe. A major driver of morbidity and mortality among delivering women is postpartum hemorrhage (PPH). PPH is currently phenotyped using the subjective measure of 'Estimated blood loss' (EBL), which has been shown to be unreliable for tracking quality. Here we present a framework for phenotyping PPH into multiple severity levels, using a combination of data-driven techniques and expert-derived clinical indicators. We validate the framework by predicting large drops in hematocrit and quantitative blood loss, finding that the framework performs better in predicting coded PPH than a hematocrit-based predictor or predictors based on other metrics such as blood transfusions, and does better in predicting quantitative blood loss, a gold standard metric for blood loss that we have for a subset of patients, than any predictor we could build using hematocrit drops alone. In all, we present a principled framework that can be used to phenotype PPH in hospitals using readily available EHR data, and that will perform with more granularity and accuracy than existing methods.",,,,,,,,,1,0,0,0,0,0,1,,,,1942-597X,,MEDLINE:32308864,32308864,
J,"Maguire, Frances B.; Morris, Cyllene R.; Parikh-Patel, Arti; Cress, Rosemary D.; Keegan, Theresa H. M.; Li, Chin-Shang; Lin, Patrick S.; Kizer, Kenneth W.",,,,,"Maguire, Frances/0000-0001-8490-6229",,,A text-mining approach to obtain detailed treatment information from free-text fields in population-based cancer registries: A study of non-small cell lung cancer in California,,,,,,,,PLOS ONE,,,,14,2,,,,,e0212454,10.1371/journal.pone.0212454,,,,FEB 22 2019,2019,"BackgroundPopulation-based cancer registries have treatment information for all patients making them an excellent resource for population-level monitoring. However, specific treatment details, such as drug names, are contained in a free-text format that is difficult to process and summarize. We assessed the accuracy and efficiency of a text-mining algorithm to identify systemic treatments for lung cancer from free-text fields in the California Cancer Registry.MethodsThe algorithm used Perl regular expressions in SAS 9.4 to search for treatments in 24,845 free-text records associated with 17,310 patients in California diagnosed with stage IV non-small cell lung cancer between 2012 and 2014. Our algorithm categorized treatments into six groups that align with National Comprehensive Cancer Network guidelines. We compared results to a manual review (gold standard) of the same records.ResultsPercent agreement ranged from 91.1% to 99.4%. Ranges for other measures were 0.71-0.92 (Kappa), 74.3%-97.3% (sensitivity), 92.4%-99.8% (specificity), 60.4%-96.4% (positive predictive value), and 92.9%-99.9% (negative predictive value). The text-mining algorithm used one-sixth of the time required for manual review.ConclusionSAS-based text mining of free-text data can accurately detect systemic treatments administered to patients and save considerable time compared to manual review, maximizing the utility of the extant information in population-based cancer registries for comparative effectiveness research.",,,,,,,,,5,0,0,0,0,0,5,,,1932-6203,,,WOS:000459709100069,30794610,
J,"Small, Aeron M.; Huffman, Jennifer E.; Klarin, Derek; Lynch, Julie A.; Assimes, Themistocles; DuVall, Scott; Sun, Yan, V; Shere, Labiba; Natarajan, Pradeep; Gaziano, Michael; Rader, Daniel J.; Wilson, Peter W. F.; Tsao, Philip S.; Chang, Kyong-Mi; Cho, Kelly; O'Donnell, Christopher J.; Casas, Juan P.; Damrauer, Scott M.",,VA Million Vet Program,,"Natarajan, Pradeep/H-9764-2019; Assimes, Themistocles/D-9696-2015","Natarajan, Pradeep/0000-0001-8402-7435; Assimes, Themistocles/0000-0003-2349-0009; Klarin, Derek/0000-0002-4636-5780",,,PCSK9 loss of function is protective against extra-coronary atherosclerotic cardiovascular disease in a large multi-ethnic cohort,,,,,,,,PLOS ONE,,,,15,11,,,,,e0239752,10.1371/journal.pone.0239752,,,,NOV 9 2020,2020,"BackgroundTherapeutic inhibition of PCSK9 protects against coronary artery disease (CAD) and ischemic stroke (IS). The impact on other diseases remains less well characterized.MethodsWe created a genetic risk score (GRS) for PCSK9 using four single nucleotide polymorphisms (SNPs) at or near the PCSK9 locus known to impact lower LDL-Cholesterol (LDL-C): rs11583680, rs11591147, rs2479409, and rs11206510. We then used our GRS to calculate weighted odds ratios reflecting the impact of a genetically determined 10 mg/dL decrease in LDL-C on several pre-specified phenotypes including CAD, IS, peripheral artery disease (PAD), abdominal aortic aneurysm (AAA), type 2 diabetes, dementia, chronic obstructive pulmonary disease, and cancer. Finally, we used our weighted GRS to perform a phenome-wide association study.ResultsGenetic and electronic health record data that passed quality control was available in 312,097 individuals, (227,490 White participants, 58,907 Black participants, and 25,700 Hispanic participants). PCSK9 mediated reduction in LDL-C was associated with a reduced risk of CAD and AAA in trans-ethnic meta-analysis (CAD OR 0.83 [95% CI 0.80-0.87], p = 6.0 x 10(-21); AAA OR 0.76 [95% CI 0.68-0.86], p = 2.9 x 10(-06)). Significant protective effects were noted for PAD in White individuals (OR 0.83 [95% CI 0.71-0.97], p = 2.3 x 10(-04)) but not in other genetic ancestries. Genetically reduced PCSK9 function associated with a reduced risk of dementia in trans-ethnic meta-analysis (OR 0.86 [95% CI 0.78-0.93], p = 5.0 x 10(-04)).ConclusionsGenetically reduced PCSK9 function results in a reduction in risk of several important extra-coronary atherosclerotic phenotypes in addition to known effects on CAD and IS, including PAD and AAA. We also highlight a novel reduction in risk of dementia, supporting a well-recognized vascular component to cognitive impairment and an opportunity for therapeutic repositioning.",,,,,,,,,2,0,0,0,1,0,2,,,1932-6203,,,WOS:000592382600088,33166319,
J,"Kaji, Deepak A.; Zech, John R.; Kim, Jun S.; Cho, Samuel K.; Dangayach, Neha S.; Costa, Anthony B.; Oermann, Eric K.",,,,"Oermann, Eric/AAD-9729-2020; Kim, Jun Sup/ABB-5046-2021; Costa, Anthony/C-5471-2009","Oermann, Eric/0000-0002-1876-5963; Kim, Jun Sup/0000-0002-6114-2673; Kaji, Deepak/0000-0002-0470-3219; Cho, Samuel/0000-0001-7511-2486; Costa, Anthony/0000-0002-2202-6450",,,An attention based deep learning model of clinical events in the intensive care unit,,,,,,,,PLOS ONE,,,,14,2,,,,,e0211057,10.1371/journal.pone.0211057,,,,FEB 13 2019,2019,"This study trained long short-term memory (LSTM) recurrent neural networks (RNNs) incorporating an attention mechanism to predict daily sepsis, myocardial infarction (MI), and vancomycin antibiotic administration over two week patient ICU courses in the MIMIC-III dataset. These models achieved next-day predictive AUC of 0.876 for sepsis, 0.823 for MI, and 0.833 for vancomycin administration. Attention maps built from these models highlighted those times when input variables most influenced predictions and could provide a degree of interpretability to clinicians. These models appeared to attend to variables that were proxies for clinician decision-making, demonstrating a challenge of using flexible deep learning approaches trained with EHR data to build clinical decision support. While continued development and refinement is needed, we believe that such models could one day prove useful in reducing information overload for ICU physicians by providing needed clinical decision support for a variety of clinically important tasks.",,,,,,,,,40,0,0,0,12,0,40,,,1932-6203,,,WOS:000458761300029,30759094,
J,"Martinez, Diego A.; Cai, Jiarui; Oke, Jimi B.; Jarrell, Andrew S.; Feijoo, Felipe; Appelbaum, Jeffrey; Klein, Eili; Barnes, Sean; Levin, Scott R.",,AHRQ Patient Safety Learning Lab; CDC Mind Healthcare Program,,"Feijoo, Felipe/ABB-8098-2021; Martinez, Diego A./ABF-4412-2021; Martinez, Diego/R-7804-2016","Martinez, Diego/0000-0003-3236-2471; Oke, Jimi/0000-0001-6610-445X",,,Where is my infusion pump? Harnessing network dynamics for improved hospital equipment fleet management,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,6,,,884,892,,10.1093/jamia/ocaa033,,,,JUN 2020,2020,"Objective: Timely availability of intravenous infusion pumps is critical for high-quality care delivery. Pumps are shared among hospital units, often without central management of their distribution. This study seeks to characterize unit-to-unit pump sharing and its impact on shortages, and to evaluate a system-control tool that balances inventory across all care areas, enabling increased availability of pumps.Materials and Methods: A retrospective study of 3832 pumps moving in a network of 5292 radiofrequency and infrared sensors from January to November 2017 at The Johns Hopkins Hospital in Baltimore, Maryland. We used network analysis to determine whether pump inventory in one unit was associated with inventory fluctuations in others. We used a quasi-experimental design and segmented regressions to evaluate the effect of the system-control tool on enabling safe inventory levels in all care areas.Results: We found 93 care areas connected through 67,111 pump transactions and 4 discernible clusters of pump sharing. Up to 17% (95% confidence interval, 7%-27%) of a unit's pump inventory was explained by the inventory of other units within its cluster. The network analysis supported design and deployment of a hospital-wide inventory balancing system, which resulted in a 44% (95% confidence interval, 36%-53%) increase in the number of care areas above safe inventory levels.Conclusions: Network phenomena are essential inputs to hospital equipment fleet management. Consequently, benefits of improved inventory management in strategic unit(s) are capable of spreading safer inventory levels throughout the hospital.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000542064800007,32337588,
J,"Mistry, Sejal; Gouripeddi, Ramkiran; Facelli, Julio C.",,,,"Mistry, Sejal/AAB-9033-2022","Mistry, Sejal/0000-0001-6847-7006",,,Data-driven identification of temporal glucose patterns in a large cohort of nondiabetic patients with COVID-19 using time-series clustering,,,,,,,,JAMIA OPEN,,,,4,3,,,,,ooab063,10.1093/jamiaopen/ooab063,,,,JUL 2021,2021,"Objective: Hyperglycemia has emerged as an important clinical manifestation of coronavirus disease 2019 (COVID-19) in diabetic and nondiabetic patients. Whether these glycemic changes are specific to a subgroup of patients and persist following COVID-19 resolution remains to be elucidated. This work aimed to characterize longitudinal random blood glucose in a large cohort of nondiabetic patients diagnosed with COVID-19.Materials and Methods: De-identified electronic medical records of 7502 patients diagnosed with COVID-19 without prior diagnosis of diabetes between January 1, 2020, and November 18, 2020, were accessed through the TriNetX Research Network. Glucose measurements, diagnostic codes, medication codes, laboratory values, vital signs, and demographics were extracted before, during, and after COVID-19 diagnosis. Unsupervised time-series clustering algorithms were trained to identify distinct clusters of glucose trajectories. Cluster associations were tested for demographic variables, COVID-19 severity, glucose-altering medications, glucose values, and new-onset diabetes diagnoses.Results: Time-series clustering identified a low-complexity model with 3 clusters and a high-complexity model with 19 clusters as the best-performing models. In both models, cluster membership differed significantly by death status, COVID-19 severity, and glucose levels. Clusters membership in the 19 cluster model also differed significantly by age, sex, and new-onset diabetes mellitus.Discussion and Conclusion: This work identified distinct longitudinal blood glucose changes associated with subclinical glucose dysfunction in the low-complexity model and increased new-onset diabetes incidence in the high-complexity model. Together, these findings highlight the utility of data-driven techniques to elucidate longitudinal glycemic dysfunction in patients with COVID-19 and provide clinical evidence for further evaluation of the role of COVID-19 in diabetes pathogenesis.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,WOS:000731864500032,34409266,
J,"Song, Rebecca J.; Ho, Yuk-Lam; Schubert, Petra; Park, Yojin; Posner, Daniel; Lord, Emily M.; Costa, Lauren; Gerlovin, Hanna; Kurgansky, Katherine E.; Anglin-Foote, Tori; DuVall, Scott; Huffman, Jennifer E.; Pyarajan, Saiju; Beckham, Jean C.; Chang, Kyong-Mi; Liao, Katherine P.; Djousse, Luc; Gagnon, David R.; Whitbourne, Stacey B.; Ramoni, Rachel; Muralidhar, Sumitra; Tsao, Philip S.; O'Donnell, Christopher J.; Gaziano, John Michael; Casas, Juan P.; Cho, Kelly",,VA Million Vet Program COVID-19,,,"Anglin-Foote, Tori/0000-0002-9084-7111; Gerlovin, Hanna/0000-0002-6700-2129; Posner, Daniel C/0000-0002-3056-6924; Schubert, Petra/0000-0002-6135-0173",,,Phenome-wide association of 1809 phenotypes and COVID-19 disease progression in the Veterans Health Administration Million Veteran Program,,,,,,,,PLOS ONE,,,,16,5,,,,,e0251651,10.1371/journal.pone.0251651,,,,MAY 13 2021,2021,"Background The risk factors associated with the stages of Coronavirus Disease-2019 (COVID-19) disease progression are not well known. We aim to identify risk factors specific to each state of COVID-19 progression from SARS-CoV-2 infection through death.Methods and results We included 648,202 participants from the Veteran Affairs Million Veteran Program (2011-). We identified characteristics and 1,809 ICD code-based phenotypes from the electronic health record. We used logistic regression to examine the association of age, sex, body mass index (BMI), race, and prevalent phenotypes to the stages of COVID-19 disease progression: infection, hospitalization, intensive care unit (ICU) admission, and 30-day mortality (separate models for each). Models were adjusted for age, sex, race, ethnicity, number of visit months and ICD codes, state infection rate and controlled for multiple testing using false discovery rate (<= 0.1). As of August 10, 2020, 5,929 individuals were SARS-CoV-2 positive and among those, 1,463 (25%) were hospitalized, 579 (10%) were in ICU, and 398 (7%) died. We observed a lower risk in women vs. men for ICU and mortality (Odds Ratio (95% CI): 0.48 (0.30-0.76) and 0.59 (0.31-1.15), respectively) and a higher risk in Black vs. Other race patients for hospitalization and ICU (OR (95%CI): 1.53 (1.32-1.77) and 1.63 (1.32-2.02), respectively). We observed an increased risk of all COVID-19 disease states with older age and BMI >= 35 vs. 20-24 kg/m(2). Renal failure, respiratory failure, morbid obesity, acid-base balance disorder, white blood cell diseases, hydronephrosis and bacterial infections were associated with an increased risk of ICU admissions; sepsis, chronic skin ulcers, acid-base balance disorder and acidosis were associated with mortality.Conclusions Older age, higher BMI, males and patients with a history of respiratory, kidney, bacterial or metabolic comorbidities experienced greater COVID-19 severity. Future studies to investigate the underlying mechanisms associated with these phenotype clusters and COVID-19 are warranted.",,,,,,,,,2,0,0,0,1,0,2,,,1932-6203,,,WOS:000664628200112,33984066,
J,"Finke, Michael T.; Filice, Ross W.; Kahn, Charles E., Jr.",,,,"Kahn, Charles/U-5055-2019","Kahn, Charles/0000-0002-6654-7434",,,"Integrating ontologies of human diseases, phenotypes, and radiological diagnosis",,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,2,,,149,154,,10.1093/jamia/ocy161,,,,FEB 2019,2019,"Mappings between ontologies enable reuse and interoperability of biomedical knowledge. The Radiology Gamuts Ontology (RGO)an ontology of 16 918 diseases, interventions, and imaging observationsprovides a resource for differential diagnosis and automated textual report understanding in radiology. An automated process with subsequent manual review was used to identify exact and partial matches of RGO entities to the Disease Ontology (DO) and the Human Phenotype Ontology (HPO). Exact mappings identified equivalent concepts; partial mappings identified subclass and superclass relationships. A total of 7913 distinct RGO entities (46.8%) were mapped to one or both of the two target ontologies. Integration of RGO's causal knowledge resulted in 9605 axioms that expressed direct causal relationships between DO diseases and HPO phenotypic abnormalities, and allowed one to formulate queries about causal relations using the abstraction properties in those two ontologies. The mappings can be used to support automated diagnostic reasoning, data mining, and knowledge discovery.",,,,,,,,,4,0,0,0,0,0,4,,,1067-5027,1527-974X,,WOS:000460629800008,30624645,
J,"Hong, Woo Suk; Haimovich, Adrian Daniel; Taylor, Richard Andrew",,,,,,,,Predicting 72-hour and 9-day return to the emergency department using machine learning,,,,,,,,JAMIA OPEN,,,,2,3,,,346,352,,10.1093/jamiaopen/ooz019,,,,OCT 2019,2019,"Objectives: To predict 72-h and 9-day emergency department (ED) return by using gradient boosting on an expansive set of clinical variables from the electronic health record.Methods: This retrospective study included all adult discharges from a level 1 trauma center ED and a community hospital ED covering the period of March 2013 to July 2017. A total of 1500 variables were extracted for each visit, and samples split randomly into training, validation, and test sets (80%, 10%, and 10%). Gradient boosting models were fit on 3 selections of the data: administrative data (demographics, prior hospital usage, and comorbidity categories), data available at triage, and the full set of data available at discharge. A logistic regression (LR) model built on administrative data was used for baseline comparison. Finally, the top 20 most informative variables identified from the full gradient boosting models were used to build a reduced model for each outcome.Results: A total of 330 631 discharges were available for analysis, with 29 058 discharges (8.8%) resulting in 72 h return and 52 748 discharges (16.0%) resulting in 9-day return to either ED. LR models using administrative data yielded test AUCs of 0.69 (95% confidence interval [CI] 0.68-0.70) and 0.71(95% CI 0.70-0.72), while gradient boosting models using administrative data yielded test AUCs of 0.73 (95% CI 0.72-0.74) and 0.74 (95% CI 0.73-0.74) for 72-h and 9-day return, respectively. Gradient boosting models using variables available at triage yielded test AUCs of 0.75 (95% CI 0.74-0.76) and 0.75 (95% CI 0.74-0.75), while those using the full set of variables yielded test AUCs of 0.76 (95% CI 0.75-0.77) and 0.75 (95% CI 0.75-0.76). Reduced models using the top 20 variables yielded test AUCs of 0.73 (95% CI 0.71-0.74) and 0.73 (95% CI 0.72-0.74).Discussion and Conclusion: Gradient boosting models leveraging clinical data are superior to LR models built on administrative data at predicting 72-h and 9-day returns.",,,,,,,,,9,0,0,0,2,0,9,,,,2574-2531,,WOS:000645417900012,31984367,
J,"Huser, Vojtech; Amos, Liz",,,,,,,,Analyzing Real-World Use of Research Common Data Elements.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2018,,,,602,608,,,,,,2018,2018,"Common Data Elements (CDEs) are defined as data elements that are common to multiple data sets across different studies and provide structured, standardized definitions so that data may be collected and used across different datasets. CDE collections are traditionally developed prospectively by subject-matter and domain experts. However, there has been little systematic research and evidence to demonstrate how CDEs are used in real-world datasets and the subsequent impact on data discoverability. Our study builds upon previous mapping work to investigate the number of CDEs that could be identified using a varying level of commonness threshold in a real-world data repository, the Database of Phenotypes and Genotypes (dbGaP). In an analyzed collection of mapped variables from 426 dbGaP studies, only 1,414 PhenX variables (PHENotypes and eXposures; a CDE initiative) are observed out of all 24,938 defined PhenX variables. Results include CDEs that are identified with varying levels of commonness thresholds. After the semantic grouping of 68 PhenX variables collected in at least 15 studies (n=15), we observed 32 truly common common data elements. We discuss benefits of post-hoc mapping of study data to a CDE framework for purposes of findability and reuse, as well as the informatics challenges of pre-populating clinical research case report forms with data from Electronic Health Record that are typically coded in terminologies aimed at routine healthcare needs.",,,,,,,,,4,0,0,0,1,0,4,,,,1942-597X,,MEDLINE:30815101,30815101,
J,"Fiorini, Samuele; Hajati, Farshid; Barla, Annalisa; Girosi, Federico",,,,"Barla, Annalisa/K-6417-2015","Barla, Annalisa/0000-0002-3436-035X; Girosi, Federico/0000-0003-3937-2285",,,Predicting diabetes second-line therapy initiation in the Australian population via time span-guided neural attention network,,,,,,,,PLOS ONE,,,,14,10,,,,,e0211844,10.1371/journal.pone.0211844,,,,OCT 18 2019,2019,"IntroductionThe first line of treatment for people with Diabetes mellitus is metformin. However, over the course of the disease metformin may fail to achieve appropriate glycemic control, and a second-line therapy may become necessary. In this paper we introduce Tangle, a time span-guided neural attention model that can accurately and timely predict the upcoming need for a second-line diabetes therapy from administrative data in the Australian adult population. The method is suitable for designing automatic therapy review recommendations for patients and their providers without the need to collect clinical measures.DataWe analyzed seven years of de-identified records (2008-2014) of the 10% publicly available linked sample of Medicare Benefits Schedule (MBS) and Pharmaceutical Benefits Scheme (PBS) electronic databases of Australia.MethodsBy design, Tangle inherits the representational power of pre-trained word embedding, such as GloVe, to encode sequences of claims with the related MBS codes. Moreover, the proposed attention mechanism natively exploits the information hidden in the time span between two successive claims (measured in number of days). We compared the proposed method against state-of-the-art sequence classification methods.ResultsTangle outperforms state-of-the-art recurrent neural networks, including attention-based models. In particular, when the proposed time span-guided attention strategy is coupled with pre-trained embedding methods, the model performance reaches an Area Under the ROC Curve of 90%, an improvement of almost 10 percentage points over an attentionless recurrent architecture.Implementation Tangle is implemented in Python using Keras and it is hosted on GitHub at https://github.com/samuelefiorini/tangle.",,,,,,,,,5,0,0,0,3,0,5,,,1932-6203,,,WOS:000532567700001,31626666,
J,"Wang, Qiong; Ji, Zongcheng; Wang, Jingqi; Wu, Stephen; Lin, Weiyan; Li, Wenzhen; Ke, Li; Xiao, Guohong; Jiang, Qing; Xu, Hua; Zhou, Yi",,,,,"Wang, Qiong/0000-0002-7225-5235",,,A study of entity-linking methods for normalizing Chinese diagnosis and procedure terms to ICD codes,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,105,,,,,,103418,10.1016/j.jbi.2020.103418,,,,MAY 2020,2020,"Objective: This study aims to develop and evaluate effective methods that can normalize diagnosis and procedure terms written by physicians to standard concepts in International Classification of Diseases (ICD) in Chinese, with the goal to facilitate automated medical coding in China.Methods: We applied the entity-linking framework to normalize Chinese diagnosis and procedure terms, which consists of two steps - candidate concept generation and candidate concept ranking. For candidate concept generation, we implemented both the traditional BM25 algorithm and an extended version that integrates a synonym knowledgebase. For candidate concept ranking, we investigated a number of different algorithms: (1) the BM25 algorithm, (2) ranking support vector machines (RankSVM), (3) a previously reported Convolutional Neural Network (CNN) approach, (4) 11 deep ranking-based methods from the MatchZoo toolkit, and (5) a new BERT (Bidirectional Encoder Representations from Transformers) based ranking method. Using two manually annotated datasets (8,547 diagnoses and 8,282 procedures) collected from a Tier 3A hospital in China, we evaluated above methods and reported their performance (i.e., accuracy) at different cutoffs.Results: The coverage of candidate concept generation was greatly improved after integrating the synonym knowledgebase, achieving 97.9% for diagnoses and 93.4% for procedures respectively. Overall the new BERT-based ranking method achieved the best performance on both diagnosis and procedure normalization, with the best accuracy of 92.1% for diagnosis and 80.1% for procedure, when the top one concept and exact match criteria were used.Conclusions: This study developed and compared diverse entity-linking methods to normalize clinical terms in Chinese and our evaluation shows good performance on mapping disease terms to ICD codes, demonstrating the feasibility of automated encoding of clinical terms in Chinese.",,,,,,,,,5,0,0,0,2,0,5,,,1532-0464,1532-0480,,WOS:000535653800001,32298846,
J,"Major, Vincent J; Jethani, Neil; Aphinyanaphongs, Yindalon",,,,,"Aphinyanaphongs, Yin/0000-0001-8605-5392",,,Estimating real-world performance of a predictive model: a case-study in predicting mortality.,,,,,,,,JAMIA open,,,,3,2,,,243,251,,10.1093/jamiaopen/ooaa008,,,,2020-Jul,2020,"Objective: One primary consideration when developing predictive models is downstream effects on future model performance. We conduct experiments to quantify the effects of experimental design choices, namely cohort selection and internal validation methods, on (estimated) real-world model performance.Materials and Methods: Four years of hospitalizations are used to develop a 1-year mortality prediction model (composite of death or initiation of hospice care). Two common methods to select appropriate patient visits from their encounter history (backwards-from-outcome and forwards-from-admission) are combined with 2 testing cohorts (random and temporal validation). Two models are trained under otherwise identical conditions, and their performances compared. Operating thresholds are selected in each test set and applied to a real-world cohort of labeled admissions from another, unused year.Results: Backwards-from-outcome cohort selection retains 25% of candidate admissions (n=23579), whereas forwards-from-admission selection includes many more (n=92148). Both selection methods produce similar performances when applied to a random test set. However, when applied to the temporally defined real-world set, forwards-from-admission yields higher areas under the ROC and precision recall curves (88.3% and 56.5% vs. 83.2% and 41.6%).Discussion: A backwards-from-outcome experiment manipulates raw training data, simplifying the experiment. This manipulated data no longer resembles real-world data, resulting in optimistic estimates of test set performance, especially at high precision. In contrast, a forwards-from-admission experiment with a temporally separated test set consistently and conservatively estimates real-world performance.Conclusion: Experimental design choices impose bias upon selected cohorts. A forwards-from-admission experiment, validated temporally, can conservatively estimate real-world performance.LAY SUMMARY: The routine care of patients stands to benefit greatly from assistive technologies, including data-driven risk assessment. Already, many different machine learning and artificial intelligence applications are being developed from complex electronic health record data. To overcome challenges that arise from such data, researchers often start with simple experimental approaches to test their work. One key component is how patients (and their healthcare visits) are selected for the study from the pool of all patients seen. Another is how the group of patients used to create the risk estimator differs from the group used to evaluate how well it works. These choices complicate how the experimental setting compares to the real-world application to patients. For example, different selection approaches that depend on each patient's future outcome can simplify the experiment but are impractical upon implementation as these data are unavailable. We show that this kind of backwards experiment optimistically estimates how well the model performs. Instead, our results advocate for experiments that select patients in a forwards manner and temporal validation that approximates training on past data and implementing on future data. More robust results help gauge the clinical utility of recent works and aid decision-making before implementation into practice.",,,,,,,,,0,0,0,0,0,0,0,,,,2574-2531,,MEDLINE:32734165,32734165,
J,"Ostropolets, Anna; Zachariah, Philip; Ryan, Patrick; Chen, Ruijun; Hripcsak, George",,,,,"Ostropolets, Anna/0000-0002-0847-6682; Chen, RuiJun/0000-0001-5281-4143",,,Data Consult Service: Can we use observational data to address immediate clinical needs?,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,10,,,2139,2146,,10.1093/jamia/ocab122,,AUG 2021,,OCT 2021,2021,"Objective: A number of clinical decision support tools aim to use observational data to address immediate clinical needs, but few of them address challenges and biases inherent in such data. The goal of this article is to describe the experience of running a data consult service that generates clinical evidence in real time and characterize the challenges related to its use of observational data.Materials and Methods: In 2019, we launched the Data Consult Service pilot with clinicians affiliated with Columbia University Irving Medical Center. We created and implemented a pipeline (question gathering, data exploration, iterative patient phenotyping, study execution, and assessing validity of results) for generating new evidence in real time. We collected user feedback and assessed issues related to producing reliable evidence.Results: We collected 29 questions from 22 clinicians through clinical rounds, emails, and in-person communication. We used validated practices to ensure reliability of evidence and answered 24 of them. Questions differed depending on the collection method, with clinical rounds supporting proactive team involvement and gathering more patient characterization questions and questions related to a current patient. The main challenges we encountered included missing and incomplete data, underreported conditions, and nonspecific coding and accurate identification of drug regimens.Conclusions: While the Data Consult Service has the potential to generate evidence and facilitate decision making, only a portion of questions can be answered in real time. Recognizing challenges in patient phenotyping and designing studies along with using validated practices for observational research are mandatory to produce reliable evidence.",,,,,,,,,2,0,0,0,0,0,2,,,1067-5027,1527-974X,,WOS:000745625700010,34333606,
J,"Saldanha, Valdjane; de Araujo, Ivonete Batista; Vieira Cunha Lima, Sara Iasmin; Martins, Rand Randall; Oliveira, Antonio Gouveia",,,,"Martins, Rand Randall/X-8188-2019","Martins, Rand Randall/0000-0001-9668-0482; Lima, Sara/0000-0002-4127-7909",,,Risk factors for drug-related problems in a general hospital: A large prospective cohort,,,,,,,,PLOS ONE,,,,15,5,,,,,e0230215,10.1371/journal.pone.0230215,,,,MAY 5 2020,2020,"ObjectiveTo identify risk factors for potential Drug-Related Problems (DRP) at admission in hospitalized patients.MethodologyProspective cohort study conducted in adults patients hospitalized (May 2016 to May 2018) in a general tertiary care hospital in Brazil. Potential DRP were detected by daily review of 100% of electronic medication orders by hospital pharmacists and classified by the Pharmaceutical Care Network Europe classification system (PCNE version 6.2). For the identification of risk factors of potential DRP, backward stepwise logistic regression was used to identify the set of independent predictors among over 120 variables collected in the initial 48 hours after admission in a training set consisting of 2/3 of the study population. The model was validated in the remaining sample.ResultsThe study population consisted of 1686 patients aged 52.0+/-18.3 years-old, 51.4% females, with a median length of stay of 3.24 days, and 4.5% in-hospital mortality. The cumulative incidence of potential DRP was 14.5%. Admission for elective surgery and main diagnosis of disease of the circulatory system were associated with reduced risk of DRP (OR 0.41 and 0.57, respectively, p< 0.05). The independent risk factors of DRP are heart rate. 80 bpm (OR 1.41, p = 0.05), prescription of more than seven drugs in day 2 (OR 1.63, p = 0.05), prescription in day 1 of drugs of the Anatomical Therapeutic Chemical Code (ATC) class A (alimentary tract and metabolism, OR 2.24, p = 0.003), prescription in day 2 of two or more ATC class A drugs (OR = 3.52, p < 0.001), and in day 1 of ATC class J drugs (antiinfectives for systemic use, OR 1.97, p = 0.001). In the validation set, the c-statistic of the predictive model was 0.65, the sensitivity was 56.1% and the specificity was 65.2%.ConclusionThis study identified seven independent risk factors of potential DRP in patients hospitalized in a general hospital that have fair predictive performance for utilization in clinical practice.",,,,,,,,,5,0,0,0,0,0,5,,,1932-6203,,,WOS:000537280000003,32369489,
J,"Armstrong, Brett; Habtemariam, Daniel; Husser, Erica; Leslie, Douglas L.; Boltz, Marie; Jung, Yoojin; Fick, Donna M.; Inouye, Sharon K.; Marcantonio, Edward R.; Ngo, Long H.",,,,,,,,A mobile app for delirium screening,,,,,,,,JAMIA OPEN,,,,4,2,,,,,ooab027,10.1093/jamiaopen/ooab027,,,,APR 2021,2021,"Objective: The objective of this study is to describe the algorithm and technical implementation of a mobile app that uses adaptive testing to assess an efficient mobile app for the diagnosis of delirium.Materials and Methods: The app was used as part of a NIH-funded project to assess the feasibility, effectiveness, administration time, and costs of the 2-step delirium identification protocol when performed by physicians and nurses, and certified nursing assistants (CNA). The cohort included 535 hospitalized patients aged 79.7 (SD = 6.6) years enrolled at 2 different sites. Each patient was assessed on 2 consecutive days by the research associate who performed the reference delirium assessment. Thereafter, physicians, nurses, and CNAs performed adaptive delirium assessments using the app. Qualitative data to assess the experience of administering the 2-step protocol, and the app usability were also collected and analyzed from 50 physicians, 189 nurses, and 83 CNAs. We used extensible hypertext markup language (XHTML) and JavaScript to develop the app for the iOS-based iPad. The App was linked to Research Electronic Data Capture (REDCap), a relational database system, via a REDCap application programming interface (API) that sent and received data from/to the app. The data from REDCap were sent to the Statistical Analysis System for statistical analysis.Results: The app graphical interface was successfully implemented by XHTML and JavaScript. The API facilitated the instant updating and retrieval of delirium status data between REDCap and the app. Clinicians performed 881 delirium assessments using the app for 535 patients. The transmission of data between the app and the REDCap system showed no errors. Qualitative data indicated that the users were enthusiastic about using the app with no negative comments, 82% positive comments, and 18% suggestions of improvement. Delirium administration time for the 2-step protocol showed similar total time between nurses and physicians (103.9 vs 106.5 seconds). Weekly enrollment reports of the app data were generated for study tracking purposes, and the data are being used for statistical analyses for publications.Discussion: The app developed using iOS could be easily converted to other operating systems such as Android and could be linked to other relational databases beside REDCap, such as electronic health records to facilitate better data retrieval and updating of patient's delirium status.Conclusion: Our app operationalizes an adaptive 2-step delirium screening protocol. Its algorithm and cross-plat formed code of XHTML and JavaScript can be easily exported to other operating systems and hardware platforms, thus enabling wider use of the efficient delirium screening protocol that we have developed. The app is currently implemented as a research tool, but with adaptation could be implemented in the clinical setting to facilitate widespread delirium screening in hospitalized older adults.",,,,,,,,,2,0,0,0,1,0,2,,,,2574-2531,,WOS:000731861400007,34549169,
J,"Fleisher, Ilan; Geboy, Alexander G.; Nichols, Whitney; Desale, Sameer; Fernandez, Stephen; Basch, Peter; Fishbein, Dawn A.",,,,,"Fleisher, Ilan/0000-0001-7418-9908",,,HIV testing in patients who are HCV positive: Compliance with CDC guidelines in a large healthcare system,,,,,,,,PLOS ONE,,,,16,6,,,,,e0252412,10.1371/journal.pone.0252412,,,,JUN 2 2021,2021,"Background There are approximately 300,000 people in the United States who are co-infected with HIV and HCV. Several organizations recommend that individuals who are HCV infected, as well as persons over the age of 13, should be HIV tested. Comorbidities associated with HCV can be reduced with early identification of HIV. Our objective was to determine whether providers routinely followed HIV testing guidelines for patients who tested HCV positive (HCV+).Methods A retrospective chart review was conducted of all patients in primary care at an academic health system from 7/2015-3/2017 who tested HCV+. As part of a primary database, HCV testing data was collected; HIV testing data was abstracted manually. We collected and described the intervals between HCV and HIV tests. To determine associations with HIV testing univariable and multivariable analyses were performed.Results We identified 445 patients who tested HCV+: 56.6% were tested for HIV, the mean age was 57 10.9 years, 77% were from the Birth Cohort born 1945-1965 (BC); 61% were male; and 51% were Black/AA. Patients in the BC were more likely to be HIV tested if they were: male (p = 0.019), Black/AA (p<0.001), and had Medicaid (p = 0.005). These differences were not found in the non-BC. Six patients who were tested for both HIV and HCV were found to be newly HIV positive at the time of testing.Conclusion As demonstrated, providers did not routinely follow CDC recommendations as almost half of the HCV+ patients were not correctly tested for HIV. It is important to emphasize that six persons were tested HIV positive simultaneously with their HCV+ diagnosis. If providers did not follow the CDC guidelines, then these patients may not have been identified. Improvements in EHR clinical decision support tools and provider education can help improve the HIV testing rate among individuals who are HCV+.",,,,,,,,,0,0,0,0,0,0,0,,,1932-6203,,,WOS:000664638500043,34077476,
J,"Jain, Neha; Mittendorf, Kathleen F.; Holt, Marilyn; Lenoue-Newton, Michele; Maurer, Ian; Miller, Clinton; Stachowiak, Matthew; Botyrius, Michelle; Cole, James; Micheel, Christine; Levy, Mia",,,,"Micheel, Christine/AAZ-1370-2021","Mittendorf, Kathleen/0000-0003-1097-9171; Jain, Neha/0000-0002-0168-7874; Micheel, Christine/0000-0002-7744-9039",,,The My Cancer Genome clinical trial data model and trial curation workflow,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,27,7,,,1057,1066,,10.1093/jamia/ocaa066,,,,JUL 2020,2020,"Objective: As clinical trials evolve in complexity, clinical trial data models that can capture relevant trial data in meaningful, structured annotations and computable forms are needed to support accrual.Material and Methods: We have developed a clinical trial information model, curation information system, and a standard operating procedure for consistent and accurate annotation of cancer clinical trials. Clinical trial documents are pulled into the curation system from publicly available sources. Using a web-based interface, a curator creates structured assertions related to disease-biomarker eligibility criteria, therapeutic context, and treatment cohorts by leveraging our data model features. These structured assertions are published on the My Cancer Genome (MCG) website.Results: To date, over 5000 oncology trials have been manually curated. All trial assertion data are available for public view on the MCG website. Querying our structured knowledge base, we performed a landscape analysis to assess the top diseases, biomarker alterations, and drugs featured across all cancer trials.Discussion: Beyond curating commonly captured elements, such as disease and biomarker eligibility criteria, we have expanded our model to support the curation of trial interventions and therapeutic context (ie, neoadjuvant, metastatic, etc.), and the respective biomarker-disease treatment cohorts. To the best of our knowledge, this is the first effort to capture these fields in a structured format.Conclusion: This paper makes a significant contribution to the field of biomedical informatics and knowledge dissemination for precision oncology via the MCG website.",,,,,,,,,5,0,0,0,1,0,5,,,1067-5027,1527-974X,,WOS:000612220200010,32483629,
J,"Yin, Tong; Jaeger, Maria; Scheper, Carsten; Grodkowski, Gregorz; Sakowski, Tomasz; Klopcic, Marija; Bapst, Beat; Koenig, Sven",,,,"Sakowski, Tomasz/I-3772-2019","Sakowski, Tomasz/0000-0002-2264-4638; Scheper, Carsten/0000-0003-1189-2297",,,Multi-breed genome-wide association studies across countries for electronically recorded behavior traits in local dual-purpose cows,,,,,,,,PLOS ONE,,,,14,10,,,,,e0221973,10.1371/journal.pone.0221973,,,,OCT 30 2019,2019,"Basic bovine behavior is a crucial parameter influencing cattle domestication. In addition, behavior has an impact on cattle productivity, welfare and adaptation. The aim of the present study was to infer quantitative genetic and genomic mechanisms contributing to natural dual-purpose cow behavior in grazing systems. In this regard, we genotyped five dual-purpose breeds for a dense SNP marker panel from four different European countries. All cows from the across-country study were equipped with the same electronic recording devices. In this regard, we analyzed 97,049 longitudinal sensor behavior observations from 319 local dual-purpose cows for rumination, feeding, basic activity, high active, not active and ear temperature. According to the specific sensor behaviors and following a welfare protocol, we computed two different welfare indices. For genomic breed characterizations and multi-breed genome-wide association studies, sensor traits and test-day production records were merged with 35,826 SNP markers per cow. For the estimation of variance components, we used the pedigree relationship matrix and a combined similarity matrix that simultaneously included both pedigree and genotypes. Heritabilities for feeding, high active and not active were in a moderate range from 0.16 to 0.20. Estimates were very similar from both relationship matrix-modeling approaches and had quite small standard errors. Heritabilities for the remaining sensor traits (feeding, basic activity, ear temperature) and welfare indices were lower than 0.09. Five significant SNPs on chromosomes 11, 17, 27 and 29 were associated with rumination, and two different SNPs significantly influenced the sensor traits not active (chromosome 13) and feeding (chromosome 23). Gene annotation analyses inferred 22 potential candidate genes with a false discovery rate lower than 20%, mostly associated with rumination (13 genes) and feeding (8 genes). Mendelian randomization based on genomic variants (i.e., the instrumental variables) was used to infer causal inference between an exposure and an outcome. Significant regression coefficients among behavior traits indicate that all specific behavioral mechanisms contribute to similar physiological processes. The regression coefficients of rumination and feeding on milk yield were 0.10 kg/% and 0.12 kg/%, respectively, indicating their positive influence on dual-purpose cow productivity. Genomically, an improved welfare behavior of grazing cattle, i.e., a higher score for welfare indices, was significantly associated with increased fat and protein percentages.",,,,,,,,,2,0,0,0,2,0,2,,,1932-6203,,,WOS:000521547700001,31665138,
J,"Ben Souissi, Souhir; Abed, Mourad; El Hiki, Lahcen; Fortemps, Philippe; Pirlot, Marc",,,,,"Fortemps, Philippe/0000-0002-2831-105X; Abed, Mourad/0000-0001-9723-7714; Pirlot, Marc/0000-0002-3689-0944",,,"PARS, a system combining semantic technologies with multiple criteria decision aiding for supporting antibiotic prescriptions",,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,99,,,,,,103304,10.1016/j.jbi.2019.103304,,,,NOV 2019,2019,"Objective: Motivated by the well documented worldwide spread of adverse drug events, as well as the increased danger of antibiotic resistance (caused mainly by inappropriate prescribing and overuse), we propose a novel recommendation system for antibiotic prescription (PARS).Method: Our approach is based on the combination of semantic technologies with MCDA (Multiple Criteria Decision Aiding) that allowed us to build a two level decision support model. Given a specific domain, the approach assesses the adequacy of an alternative/action (prescription of antibiotic) for a specific subject (patient) with an issue (bacterial infection) in a given context (medical). The goal of the first level of the decision support model is to select the set of alternatives which have the potential to be suitable. Then the second level sorts the alternatives into categories according to their adequacy using an MCDA sorting method (MR-Sort with Veto) and a structured set of description logic queries.Results: We applied this approach in the domain of antibiotic prescriptions, working closely with the EpiCura Hospital Center (BE). Its performance was compared to the EpiCura recommendation guidelines which are currently in use. The results showed that the proposed system is more consistent in its recommendations when compared with the static EpiCura guidelines. Moreover, with PARS the antibiotic prescribing workflow becomes more flexible. PARS allows the user (physician) to update incrementally and dynamically a patient's profile with more information, or to input knowledge modifications that accommodate the decision context (like the introduction of new side effects and antibiotics, the development of germs that are resistant, etc). At the end of our evaluation, we detail a number of limitations of the current version of PARS and discuss future perspectives.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000525701400009,31622799,
J,"Rossetti, Sarah Collins; Knaplund, Chris; Albers, Dave; Dykes, Patricia C.; Kang, Min Jeoung; Korach, Tom Z.; Zhou, Li; Schnock, Kumiko; Garcia, Jose; Schwartz, Jessica; Fu, Li-Heng; Klann, Jeffrey G.; Lowenthal, Graham; Cato, Kenrick",,,,,"Rossetti, Sarah/0000-0003-2632-8867; Schwartz, Jessica/0000-0002-1457-5724; Albers, David/0000-0002-5369-526X",,,Healthcare Process Modeling to Phenotype Clinician Behaviors for Exploiting the Signal Gain of Clinical Expertise (HPM-ExpertSignals): Development and evaluation of a conceptual framework,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,6,,,1242,1251,,10.1093/jamia/ocab006,,FEB 2021,,JUN 2021,2021,"Objective: There are signals of clinicians' expert and knowledge-driven behaviors within clinical information systems (CIS) that can be exploited to support clinical prediction. Describe development of the Healthcare Process Modeling Framework to Phenotype Clinician Behaviors for Exploiting the Signal Gain of Clinical Expertise (HPM-ExpertSignals).Materials and Methods: We employed an iterative framework development approach that combined data-driven modeling and simulation testing to define and refine a process for phenotyping clinician behaviors. Our framework was developed and evaluated based on the Communicating Narrative Concerns Entered by Registered Nurses (CONCERN) predictive model to detect and leverage signals of clinician expertise for prediction of patient trajectories.Results: Seven themes-identified during development and simulation testing of the CONCERN model-informed framework development. The HPM-ExpertSignals conceptual framework includes a 3-step modeling technique: (1) identify patterns of clinical behaviors from user interaction with CIS; (2) interpret patterns as proxies of an individual's decisions, knowledge, and expertise; and (3) use patterns in predictive models for associations with outcomes. The CONCERN model differentiated at risk patients earlier than other early warning scores, lending confidence to the HPM-ExpertSignals framework.Discussion: The HPM-ExpertSignals framework moves beyond transactional data analytics to model clinical knowledge, decision making, and CIS interactions, which can support predictive modeling with a focus on the rapid and frequent patient surveillance cycle.Conclusions: We propose this framework as an approach to embed clinicians' knowledge-driven behaviors in predictions and inferences to facilitate capture of healthcare processes that are activated independently, and sometimes well before, physiological changes are apparent.",,,,,,,,,5,0,0,0,1,0,5,,,1067-5027,1527-974X,,WOS:000671031900021,33624765,
J,"Zhang, Xinyuan; Li, Ruowang; Ritchie, Marylyn D",,,,,,,,Statistical Impact of Sample Size and Imbalance on Multivariate Analysis in silico and A Case Study in the UK Biobank.,,,,,,,,AMIA ... Annual Symposium proceedings. AMIA Symposium,,,,2020,,,,1383,1391,,,,,,2020,2020,"Large-scale biobank cohorts coupled with electronic health records offer unprecedented opportunities to study genotype-phenotype relationships. Genome-wide association studies uncovered disease-associated loci through univariate methods, with the focus on one trait at a time. With genetic variants being identifiedfor thousands of traits, researchers found that 90% of human genetic loci are associated with more than one trait, highlighting the ubiquity of pleiotropy. Recently, multivariate methods have been proposed to effectively identify pleiotropy. However, the statistical performance in natural biomedical data, which often have unbalanced case-control sample sizes, is largely known. In this work, we designed 21 scenarios of real-data informed simulations to thoroughly evaluate the statistical characteristics of univariate and multivariate methods. Our results can serve as a reference guide for the application of multivariate methods. We also investigated potential pleiotropy across type II diabetes, Alzheimer's disease, atherosclerosis of arteries, depression, and atherosclerotic heart disease in the UK Biobank.",,,,,,,,,0,0,0,0,0,0,0,,,,1942-597X,,MEDLINE:33936514,33936514,
J,"Taseen, Ryeyan; Ethier, Jean-Francois",,,,,,,,Expected clinical utility of automatable prediction models for improving palliative and end-of-life care outcomes: Toward routine decision analysis before implementation,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,28,11,,,2366,2378,,10.1093/jamia/ocab140,,SEP 2021,,NOV 2021,2021,"Objective: The study sought to evaluate the expected clinical utility of automatable prediction models for increasing goals-of-care discussions (GOCDs) among hospitalized patients at the end of life (EOL).Materials and Methods: We built a decision model from the perspective of clinicians who aim to increase GOCDs at the EOL using an automated alert system. The alternative strategies were 4 prediction models-3 random forest models and the Modified Hospital One-year Mortality Risk model-to generate alerts for patients at a high risk of 1-year mortality. They were trained on admissions from 2011 to 2016 (70 788 patients) and tested with admissions from 2017-2018 (16 490 patients). GOCDs occurring in usual care were measured with code status orders. We calculated the expected risk difference (beneficial outcomes with alerts minus beneficial outcomes without alerts among those at the EOL), the number needed to benefit (number of alerts needed to increase benefit over usual care by 1 outcome), and the net benefit (benefit minus cost) of each strategy.Results: Models had a C-statistic between 0.79 and 0.86. A code status order occurred during 2599 of 3773 (69%) hospitalizations at the EOL. At a risk threshold corresponding to an alert prevalence of 10%, the expected risk difference ranged from 5.4% to 10.7% and the number needed to benefit ranged from 5.4 to 10.9 alerts. Using revealed preferences, only 2 models improved net benefit over usual care. A random forest model with diagnostic predictors had the highest expected value, including in sensitivity analyses.Discussion: Prediction models with acceptable predictive validity differed meaningfully in their ability to improve over usual decision making.Conclusions: An evaluation of clinical utility, such as by using decision curve analysis, is recommended after validating a prediction model because metrics of model predictiveness, such as the C-statistic, are not informative of clinical value.",,,,,,,,,0,0,0,0,0,0,0,,,1067-5027,1527-974X,,WOS:000711702400007,34472611,
J,"Lee, Jessica J. Y.; van Karnebeek, Clara D. M.; Wasserman, Wyeth W.",,,,,"Wasserman, Wyeth/0000-0001-6098-6412",,,Development and user evaluation of a rare disease gene prioritization workflow based on cognitive ergonomics,,,,,,,,JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION,,,,26,2,,,124,133,,10.1093/jamia/ocy153,,,,FEB 2019,2019,"Objective The clinical diagnosis of genetic disorders is undergoing transformation, driven by whole exome sequencing and whole genome sequencing (WES/WGS). However, such nucleotide-level resolution technologies create an interpretive challenge. Prior literature suggests that clinicians may employ characteristic cognitive processes during WES/WGS investigations to identify disruptions in genes causal for the observed disease. Based on cognitive ergonomics, we designed and evaluated a gene prioritization workflow that supported these cognitive processes.Materials and Methods We designed a novel workflow in which clinicians recalled known genetic diseases with similarity to patient phenotypes to inform WES/WGS data interpretation. This prototype-based workflow was evaluated against the common computational approach based on physician-specified sets of individual patient phenotypes. The evaluation was conducted as a web-based user study, in which 18 clinicians analyzed 2 simulated patient scenarios using a randomly assigned workflow. Data analysis compared the 2 workflows with respect to accuracy and efficiency in diagnostic interpretation, efficacy in collecting detailed phenotypic information, and user satisfaction.Results Participants interpreted genetic diagnoses faster using prototype-based workflows. The 2 workflows did not differ in other evaluated aspects.Discussion The user study findings indicate that prototype-based approaches, which are designed to model experts' cognitive processes, can expedite gene prioritization and provide utility in synergy with common phenotype-driven variant/gene prioritization approaches. However, further research of the extent of this effect across diverse genetic diseases is required.Conclusion The findings demonstrate potential for prototype-based phenotype description to accelerate computer-assisted variant/gene prioritization through complementation of skills and knowledge of clinical experts via human-computer interaction.",,,,,,,,,1,0,0,0,0,0,1,,,1067-5027,1527-974X,,WOS:000460629800005,30535356,
J,"Rezoagli, Emanuele; Gatti, Stefano; Villa, Silvia; Villa, Giulia; Muttini, Stefano; Rossi, Fabio; Faraldi, Loredana; Fumagalli, Roberto; Grasselli, Giacomo; Foti, Giuseppe; Bellani, Giacomo",,,,"Fumagalli, Roberto/AAB-9746-2019","Fumagalli, Roberto/0000-0003-0398-1329; Rezoagli, Emanuele/0000-0002-4506-7212; Bellani, Giacomo/0000-0002-3089-205X",,,ABO blood types and major outcomes in patients with acute hypoxaemic respiratory failure: A multicenter retrospective cohort study,,,,,,,,PLOS ONE,,,,13,10,,,,,e0206403,10.1371/journal.pone.0206403,,,,OCT 25 2018,2018,"IntroductionABO blood type A was reported to correlate with an increased risk of acute respiratory distress syndrome (ARDS) in white patients with severe sepsis and major trauma compared with patients with other blood types. Information regarding ABO phenotypes and major outcomes in patients with ARDS is unavailable. The primary aim was to determine the relationship between ABO blood type A and intensive care unit (ICU) mortality in patients with acute hypoxemic respiratory failure (AHRF). The secondary aim was to describe the association between ABO blood type A and ICU length of stay (LOS) in this study population.MethodsIn a multicenter, retrospective cohort study, we collected the clinical records of patients admitted from January 2012 to December 2014 in five ICUs of Northern Italy. We included adult white patients admitted to the ICU who were diagnosed with AHRF requiring mechanical ventilation.ResultsThe electronic records of 1732 patients with AHRF were reviewed. The proportion of patients with ABO blood type A versus other blood types was 39.9% versus 60.1%. ICU mortality (25%) and ICU LOS (median [interquartile range], 5 [2-12] days) were not different when stratified by ABO blood type (ICU mortality, overall p value = 0.905; ICU LOS, overall p value = 0.609). SAPSII was a positive predictor of ICU mortality (odds ration [OR], 32.80; 95% confidence interval [CI], 18.80-57.24; p < 0.001) and ICU LOS (beta coefficient, 0.55; 95% CI, 0.35-0.75; p < 0.001) at multivariate analyses, whereas ABO blood type did not predict ICU outcome when forced into the model.ConclusionABO blood type did not correlate with ICU mortality and ICU LOS in adult patients with AHRF who were mechanically ventilated.",,,,,,,,,10,0,0,0,2,0,10,,,1932-6203,,,WOS:000448438400076,30359446,
J,"Zheng, Ling; Chen, Yan; Elhanan, Gai; Perl, Yehoshua; Geller, James; Ochs, Christopher",,,,"Zheng, Ling/AAX-6924-2020",,,,Complex overlapping concepts: An effective auditing methodology for families of similarly structured BioPortal ontologies,,,,,,,,JOURNAL OF BIOMEDICAL INFORMATICS,,,,83,,,,135,149,,10.1016/j.jbi.2018.05.015,,,,JUL 2018,2018,"In previous research, we have demonstrated for a number of ontologies that structurally complex concepts (for different definitions of complex) in an ontology are more likely to exhibit errors than other concepts. Thus, such complex concepts often become fertile ground for quality assurance (QA) in ontologies. They should be audited first. One example of complex concepts is given by overlapping concepts (to be defined below.) Historically, a different auditing methodology had to be developed for every single ontology. For better scalability and efficiency, it is desirable to identify family-wide QA methodologies. Each such methodology would be applicable to a whole family of similar ontologies. In past research, we had divided the 685 ontologies of BioPortal into families of structurally similar ontologies. We showed for four ontologies of the same large family in BioPortal that overlapping concepts are indeed statistically significantly more likely to exhibit errors. In order to make an authoritative statement concerning the success of overlapping concepts as a methodology for a whole family of similar ontologies (or of large subhierarchies of ontologies), it is necessary to show that overlapping concepts have a higher likelihood of errors for six out of six ontologies of the family. In this paper, we are demonstrating for two more ontologies that overlapping concepts can successfully predict groups of concepts with a higher error rate than concepts from a control group. The fifth ontology is the Neoplasm sub hierarchy of the National Cancer Institute thesaurus (NCIt). The sixth ontology is the Infectious Disease sub hierarchy of SNOMED CT. We demonstrate quality assurance results for both of them. Furthermore, in this paper we observe two novel, important, and useful phenomena during quality assurance of overlapping concepts. First, an erroneous overlapping concept can help with discovering other erroneous non-overlapping concepts in its vicinity. Secondly, correcting erroneous overlapping concepts may turn them into non-overlapping concepts. We demonstrate that this may reduce the complexity of parts of the ontology, which in turn makes the ontology more comprehensible, simplifying maintenance and use of the ontology.",,,,,,,,,3,0,0,0,1,0,3,,,1532-0464,1532-0480,,WOS:000445054700013,29852316,
J,"Suhr, Ole Bernt; Wixner, Jonas; Anan, Intissar; Lundgren, Hans-Erik; Wijayatunga, Priyantha; Westermark, Per; Ihse, Elisabet",,,,"Wijayatunga, Priyantha/P-8098-2017; Wixner, Jonas/AAN-5812-2021; Wijayatunga, Priyantha/AAG-5817-2019","Wijayatunga, Priyantha/0000-0003-1654-9148; Wixner, Jonas/0000-0002-1536-1277; Wijayatunga, Priyantha/0000-0003-1654-9148; Suhr, Ole/0000-0002-1175-2369",,,Amyloid fibril composition within hereditary Val30Met (p. Val50Met) transthyretin amyloidosis families,,,,,,,,PLOS ONE,,,,14,2,,,,,e0211983,10.1371/journal.pone.0211983,,,,FEB 27 2019,2019,"BackgroundThe amyloid fibril in hereditary transthyretin (TTR) Val30Met (pVal50Met) amyloid (ATTR Val30Met) amyloidosis is composed of either a mixture of full-length and TTR fragments (Type A) or of only full-length TTR (Type B). The type of amyloid fibril exerts an impact on the phenotype of the disease, and on the outcome of diagnostic procedures and therapy. The aim of the present study was to investigate if the type of amyloid fibril remains the same within ATTR Val30Met amyloidosis families.MethodsFifteen families were identified in whom at least two first-degree relatives had their amyloid fibril composition determined. The type of ATTR was determined by Western blot in all but two patients. For these two patients a positive 99mTc-3,3-diphosphono-1,2-propanodicarboxylic acid scintigraphy indicated ATTR Type A.ResultsIn 14 of the 15 families, the same amyloid fibril composition was noted irrespective of differences in age at onset. In the one family, different ATTR fibril types was found in two brothers with similar ages at onset.ConclusionsFamily predisposition appears to have an impact on amyloid fibril composition in members of the family irrespective of their age at onset of disease, but if genetically determined, the gene/genes are likely to be situated at another location than the TTR gene in the genome.",,,,,,,,,9,0,1,0,3,0,10,,,1932-6203,,,WOS:000459806400043,30811423,